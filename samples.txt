
✅ Cluster Health:
{
  "cluster_name": "478852001205:research-papers",
  "status": "yellow",
  "timed_out": false,
  "number_of_nodes": 1,
  "number_of_data_nodes": 1,
  "discovered_master": true,
  "discovered_cluster_manager": true,
  "active_primary_shards": 15,
  "active_shards": 15,
  "relocating_shards": 0,
  "initializing_shards": 0,
  "unassigned_shards": 2,
  "delayed_unassigned_shards": 0,
  "number_of_pending_tasks": 0,
  "number_of_in_flight_fetch": 0,
  "task_max_waiting_in_queue_millis": 0,
  "active_shards_percent_as_number": 88.23529411764706
}

Indices:
- .plugins-ml-config (1 docs, status=green)
- .opensearch-observability (0 docs, status=green)
- research-papers-v2 (373 docs, status=yellow)
- .kibana_1 (1 docs, status=green)
- .opendistro_security (10 docs, status=green)
- research-papers (2 docs, status=yellow)

Documents from 'research-papers-v2':

================================================================================
Document #1 (ID: c03b86be12ac30b75fbeeda5c74a2dec46e335af4ae2ce84a86566055338e122)
================================================================================
  abstract: In this paper, we investigate whether Large Language Models (LLMs) exhibit
conspiratorial tendencies, whether they display sociodemographic biases in this
domain, and how easily they can be conditioned into adopting conspiratorial
perspectives. Conspiracy beliefs play a central role in the spread of
misinformation and in shaping distrust toward institutions, making them a
critical testbed for evaluating the social fidelity of LLMs. LLMs are
increasingly used as proxies for studying human behavior, yet little is known
about whether they reproduce higher-order psychological constructs such as a
conspiratorial mindset. To bridge this research gap, we administer validated
psychometric surveys measuring conspiracy mindset to multiple models under
different prompting and conditioning strategies. Our findings reveal that LLMs
show partial agreement with elements of conspiracy belief, and conditioning
with socio-demographic attributes produces uneven effects, exposing latent
demographic biases. Moreover, targeted prompts can easily shift model responses
toward conspiratorial directions, underscoring both the susceptibility of LLMs
to manipulation and the potential risks of their deployment in sensitive
contexts. These results highlight the importance of critically evaluating the
psychological dimensions embedded in LLMs, both to advance computational social
science and to inform possible mitigation strategies against harmful uses.
  abstract_embedding: [0.3984375, 0.46484375, 0.08154296875]... (1536 items)
  authors: ['Francesco Corso', 'Francesco Pierri', 'Gianmarco De Francisci Morales']
  code_generated: True
  code_generated_at: 2025-11-06T09:00:43.314308
  code_metadata_s3_key: c03b86be12ac30b75fbeeda5c74a2dec46e335af4ae2ce84a86566055338e122/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: c03b86be12ac30b75fbeeda5c74a2dec46e335af4ae2ce84a86566055338e122/code.py
  date: 2025-11-05T18:28:28+00:00
  decision: accept
  ingested_at: 1762419620852
  novelty: yes
  reason: This paper is relevant to current LLM, AI, and ML research as it investigates the conspiratorial tendencies and sociodemographic biases exhibited by large language models, which is an important aspect...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Do_Androids_Dream_of_Unseen_Puppeteers__Probing_for_a_Conspiracy_Mindset_in_Large_Language_Models.pdf
  sha_abstract: 16b590b2fbddb03d58b96fb3cb881ecebf49a1cdfaefcb0c0afcef8c758c6c58
  title: Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in Large Language Models
  title_normalized: do_androids_dream_of_unseen_puppeteers_probing_for_a_conspiracy_mindset_in_large_language_models

================================================================================
Document #2 (ID: 26ceb7270ddde187be633046b734c86c3cfaf41b9dca90f716a62492cc03087b)
================================================================================
  abstract: Collaborative dialogue relies on participants incrementally establishing
common ground, yet in asymmetric settings they may believe they agree while
referring to different entities. We introduce a perspectivist annotation scheme
for the HCRC MapTask corpus (Anderson et al., 1991) that separately captures
speaker and addressee grounded interpretations for each reference expression,
enabling us to trace how understanding emerges, diverges, and repairs over
time. Using a scheme-constrained LLM annotation pipeline, we obtain 13k
annotated reference expressions with reliability estimates and analyze the
resulting understanding states. The results show that full misunderstandings
are rare once lexical variants are unified, but multiplicity discrepancies
systematically induce divergences, revealing how apparent grounding can mask
referential misalignment. Our framework provides both a resource and an
analytic lens for studying grounded misunderstanding and for evaluating
(V)LLMs' capacity to model perspective-dependent grounding in collaborative
dialogue.
  abstract_embedding: [0.70703125, 0.546875, 0.271484375]... (1536 items)
  authors: ['Nan Li', 'Albert Gatt', 'Massimo Poesio']
  code_generated: True
  code_generated_at: 2025-11-06T09:00:43.396790
  code_metadata_s3_key: 26ceb7270ddde187be633046b734c86c3cfaf41b9dca90f716a62492cc03087b/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 26ceb7270ddde187be633046b734c86c3cfaf41b9dca90f716a62492cc03087b/code.py
  date: 2025-11-05T18:52:28+00:00
  decision: accept
  ingested_at: 1762419618393
  novelty: yes
  reason: This paper is relevant to current LLM, AI, and ML research as it focuses on understanding grounded misunderstandings in asymmetric dialogue, which is an important aspect of language understanding and ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Grounded_Misunderstandings_in_Asymmetric_Dialogue__A_Perspectivist_Annotation_Scheme_for_MapTask.pdf
  sha_abstract: 6732b1a975491ddfb484849845e8485d620e7e9dcd91ce7901afc388f9cf97ed
  title: Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask
  title_normalized: grounded_misunderstandings_in_asymmetric_dialogue_a_perspectivist_annotation_scheme_for_maptask

================================================================================
Document #3 (ID: puhGW5oBclM7MZc3BJI6)
================================================================================
  abstract: Large output spaces, also referred to as Extreme multilabel classification (XMC), is a setting that arises, e.g., in large-scale tagging and product-to-product recommendation, and is characterized by the number of labels ranging from hundreds of thousands to millions. This means that the linear classification head, usually only a tiny fraction of the overall model, turns into the main driver for compute and memory demand. Current state-of-the-art XMC methods predominantly rely on FP16-FP32 mixed-precision training, which we show can be unstable, and inefficient in terms of memory usage and computational overhead. Meanwhile, existing low-precision methods typically retain higher precision for the classification layer. In this work, we propose ELMO, a pure low-precision training framework for XMC models using BFloat16 and Float8 data types. By leveraging Kahan summation and stochastic rounding, we demonstrate that XMC models can be effectively trained entirely in Float8, without relying on single-precision master weights or tensor scaling. Low-precision training, combined with our proposed memory optimizations---gradient fusion and chunking---enables significant reductions in GPU memory usage. For example, we train a 3-million-label XMC model with only 6.6 GiB of GPU memory, compared to the 39.7GiB required by the optimized SOTA method, Renee without compromising accuracy.
  abstract_embedding: [0.248046875, 0.546875, 0.494140625]... (1536 items)
  authors: ['Jinbin Zhang', 'Nasib Ullah', 'Erik Schultheis']... (4 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:26:13.228810
  code_metadata_s3_key: puhGW5oBclM7MZc3BJI6/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: puhGW5oBclM7MZc3BJI6/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762467906606
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ELMO___Efficiency_via_Low-precision_and_Peak_Memory_Optimization_in_Large_Output_Spaces.pdf
  sha_abstract: 80a54899594deb8e561c42e7bb7c9842df10137a68b6ff00d6d0f556c9861d43
  title: ELMO : Efficiency via Low-precision and Peak Memory Optimization in Large Output Spaces
  title_normalized: elmo__efficiency_via_lowprecision_and_peak_memory_optimization_in_large_output_spaces

================================================================================
Document #4 (ID: pehGW5oBclM7MZc3ApIn)
================================================================================
  abstract: While popular optimization methods such as SGD, AdamW, and Lion depend on steepest descent updates in either $\ell_2$ or $\ell_\infty$ norms, there remains a critical gap in handling the non-Euclidean structure observed in modern deep networks training. In this work, we address this need by introducing a new accelerated $\ell_p$ steepest descent algorithm, called Stacey, which uses interpolated primal-dual iterate sequences to effectively navigate non-Euclidean smooth optimization tasks. In addition to providing novel theoretical guarantees for the foundations of our algorithm, we empirically compare our approach against these popular methods on tasks including image classification and language model (LLM) pretraining, demonstrating both faster convergence and higher final accuracy. We further evaluate different values of $p$ across various models and datasets, underscoring the importance and efficiency of non-Euclidean approaches over standard Euclidean methods. Code can be found at https://github.com/xinyuluo8561/Stacey.
  abstract_embedding: [0.396484375, 0.333984375, 0.365234375]... (1536 items)
  authors: ['Xinyu Luo', 'Site Bai', 'Bolian Li']... (6 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:25:50.827463
  code_metadata_s3_key: pehGW5oBclM7MZc3ApIn/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: pehGW5oBclM7MZc3ApIn/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762467906043
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Stacey__Promoting_Stochastic_Steepest_Descent_via_Accelerated___ell_p_-Smooth_Nonconvex_Optimization.pdf
  sha_abstract: d3771355be674f4b04a6257b6d6c308513ff51855e457d469259f140e26a6408
  title: Stacey: Promoting Stochastic Steepest Descent via Accelerated $\ell_p$-Smooth Nonconvex Optimization
  title_normalized: stacey_promoting_stochastic_steepest_descent_via_accelerated_ellpsmooth_nonconvex_optimization

================================================================================
Document #5 (ID: pOhGW5oBclM7MZc3AZIA)
================================================================================
  abstract: Feature evolvable learning studies the scenario where old features will vanish and new features will emerge when learning with data streams, and various methods have been developed by utilizing some useful relationships from old features to new features, rather than re-training from scratch. In this work, we focus on two fundamental problems: How to characterize the relationships between two different feature spaces, and how to exploit those relationships for feature evolvable learning. We introduce the Kernel Ortho-Mapping (KOM) discrepancy to characterize relationships between two different feature spaces via kernel functions, and correlate with the optimal classifiers learned from different feature spaces. Based on this discrepancy, we develop the one-pass algorithm for feature evolvable learning, which requires going through all instances only once without storing the entire or partial training data. Our basic idea is to take online kernel learning with the random Fourier features and incorporate some feature and label relationships via the KOM discrepancy for feature evolvable learning.  We finally validate the effectiveness of our proposed method both theoretically and empirically.
  abstract_embedding: [0.083984375, 0.34375, 0.177734375]... (1536 items)
  authors: ['Cun-Yuan Xing', 'Meng-Zhang Qian', 'Wu-Yang Chen']... (5 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:25:32.382234
  code_metadata_s3_key: pOhGW5oBclM7MZc3AZIA/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: pOhGW5oBclM7MZc3AZIA/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762467905778
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: One-Pass_Feature_Evolvable_Learning_with_Theoretical_Guarantees.pdf
  sha_abstract: 6885b8574d5ecf7e1b4a0112011d6130cbf79ec489fce3e599d9468eeece4053
  title: One-Pass Feature Evolvable Learning with Theoretical Guarantees
  title_normalized: onepass_feature_evolvable_learning_with_theoretical_guarantees

================================================================================
Document #6 (ID: rOhIW5oBclM7MZc3C5JX)
================================================================================
  abstract: In this paper, we examine the manufacturability gap in state-of-the-art generative models for 3D object representations.  Many models for generating 3D assets focus on rendering virtual content and do not consider the constraints of real-world manufacturing, such as milling, casting, or injection molding. We demonstrate that existing generative models for computer-aided design representation do not generalize outside of their training datasets or to unmodified real, human-created objects. We identify limitations with the current approaches, including missing manufacturing-readable semantics, the inability to decompose complex shapes into parameterized segments appropriate for computer-aided manufacturing, and a lack of appropriate scoring metrics to assess the generated output versus the true reconstruction. The academic community could greatly impact real-world manufacturing by rallying around pathways to solve these challenges. We offer revised, more realistic datasets and baseline benchmarks as a step in targeting the challenge. In evaluating these datasets, we find that existing models are severely overfit to simpler data.
  abstract_embedding: [0.0869140625, 0.203125, -0.0654296875]... (1536 items)
  authors: ['MA Kimmel', 'Mueed Ur Rehman', 'Yonatan Bisk']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468039452
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Position__You_Can_t_Manufacture_a_NeRF.pdf
  sha_abstract: 5a29f4a4137094df8439bbe034419b3a38cc460e4a8dcccb6f32c09188e8d389
  title: Position: You Can't Manufacture a NeRF
  title_normalized: position_you_cant_manufacture_a_nerf

================================================================================
Document #7 (ID: qehHW5oBclM7MZc3-pI0)
================================================================================
  abstract: Spatio-temporal forecasting provides potential for discovering evolutionary patterns in geographical scientific data. However, geographical scientific datasets are often manually collected across studies, resulting in limited time spans and data scales. This hinders existing methods that rely on rich historical data for individual entities. In this paper, we argue that heterogeneous datasets from different studies can provide complementary insights into the same underlying system, helping improve predictions for geographical entities with limited historical data. To this end, we propose a Segment Quadtree Geographical Embedding Framework (SQGEF). SQGEF integrates knowledge from datasets with varied target entities, time spans, and observation variables to learn unified representations for multi-granularity entities—including those absent during training. Specifically, we propose a novel data structure, Segment Quadtree, that flexibly accommodates entities of varying granularities. SQGEF not only captures multi-level interactions from grid data but also extracts nested relationships and human-defined boundaries from diverse entities, enabling a comprehensive understanding of complex geographical structures. 
Experiments on real-world datasets demonstrate that SQGEF effectively represents unseen geographical entities and enhances performance for various models.
  abstract_embedding: [0.83984375, 0.33984375, 0.455078125]... (1536 items)
  authors: ['Zhigaoyuan Wang', 'Ying Sun', 'Hengshu Zhu']
  code_generated: True
  code_generated_at: 2025-11-06T22:27:36.422903
  code_metadata_s3_key: qehHW5oBclM7MZc3-pI0/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: qehHW5oBclM7MZc3-pI0/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468035083
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Unifying_Knowledge_from_Diverse_Datasets_to_Enhance_Spatial-Temporal_Modeling__A_Granularity-Adaptive_Geographical_Embedding_Approach.pdf
  sha_abstract: fe07d40b933998a7a5d61980147428725be374bd16fc5cd19c5ffb6001ec6a47
  title: Unifying Knowledge from Diverse Datasets to Enhance Spatial-Temporal Modeling: A Granularity-Adaptive Geographical Embedding Approach
  title_normalized: unifying_knowledge_from_diverse_datasets_to_enhance_spatialtemporal_modeling_a_granularityadaptive_geographical_embedding_approach

================================================================================
Document #8 (ID: qOhHW5oBclM7MZc39ZJh)
================================================================================
  abstract: World models aim to learn action-controlled future prediction and have proven essential for the development of intelligent agents. However, most existing world models rely heavily on substantial action-labeled data and costly training, making it challenging to adapt to novel environments with heterogeneous actions through limited interactions. This limitation can hinder their applicability across broader domains. To overcome this limitation, we propose AdaWorld, an innovative world model learning approach that enables efficient adaptation. The key idea is to incorporate action information during the pretraining of world models. This is achieved by extracting latent actions from videos in a self-supervised manner, capturing the most critical transitions between frames. We then develop an autoregressive world model that conditions on these latent actions. This learning paradigm enables highly adaptable world models, facilitating efficient transfer and learning of new actions even with limited interactions and finetuning. Our comprehensive experiments across multiple environments demonstrate that AdaWorld achieves superior performance in both simulation quality and visual planning.
  abstract_embedding: [0.6484375, 0.4296875, 0.404296875]... (1536 items)
  authors: ['Shenyuan Gao', 'Siyuan Zhou', 'Yilun Du']... (5 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:27:36.776496
  code_metadata_s3_key: qOhHW5oBclM7MZc39ZJh/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: qOhHW5oBclM7MZc39ZJh/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468033841
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: AdaWorld__Learning_Adaptable_World_Models_with_Latent_Actions.pdf
  sha_abstract: b857ebd375babfcfb96d7f9f3d45924aa755f62dce28327068898893e5e2a95c
  title: AdaWorld: Learning Adaptable World Models with Latent Actions
  title_normalized: adaworld_learning_adaptable_world_models_with_latent_actions

================================================================================
Document #9 (ID: uehIW5oBclM7MZc3T5Lu)
================================================================================
  abstract: Hierarchical reinforcement learning (HRL) improves the efficiency of long-horizon reinforcement-learning tasks with sparse rewards by decomposing the task into a hierarchy of subgoals. The main challenge of HRL is efficient discovery of the hierarchical structure among subgoals and utilizing this structure to achieve the final goal. We address this challenge by modeling the subgoal structure as a causal graph and propose a causal discovery algorithm to learn it. Additionally, rather than intervening on the subgoals at random during exploration, we harness the discovered causal model to prioritize subgoal interventions based on their importance in attaining the final goal. These targeted interventions result in a significantly more efficient policy in terms of the training cost. Unlike previous work on causal HRL, which lacked theoretical analysis, we provide a formal analysis of the problem. Specifically, for tree structures and, for a variant of Erdős-Rényi random graphs, our approach results in remarkable improvements. Our experimental results on HRL tasks also illustrate that our proposed framework outperforms existing work in terms of training cost.
  abstract_embedding: [1.0390625, 0.1328125, 0.251953125]... (1536 items)
  authors: ['Mohammadsadegh Khorasani', 'Saber Salehkaleybar', 'Negar Kiyavash']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468057032
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Hierarchical_Reinforcement_Learning_with_Targeted_Causal_Interventions.pdf
  sha_abstract: 9469d65831f7bfb8e27a723842a7e6b1bf68e380a26f2e42efcab19e3577910f
  title: Hierarchical Reinforcement Learning with Targeted Causal Interventions
  title_normalized: hierarchical_reinforcement_learning_with_targeted_causal_interventions

================================================================================
Document #10 (ID: p-hHW5oBclM7MZc375LC)
================================================================================
  abstract: We consider a setting in which the agent aims to maximize the expected cumulative reward, subject to a constraint that the entropic risk of the total utility exceeds a given threshold. Unlike the risk-neutral case, standard primal-dual approaches fail to directly yield regret and violation bounds, as value iteration with respect to a combined state-action value function is not applicable in the risk-sensitive setting. To address this, we adopt the Optimized Certainty Equivalent (OCE) representation of the entropic risk measure and reformulate the problem by augmenting the state space with a continuous budget variable. We then propose a primal-dual algorithm tailored to this augmented formulation. In contrast to the standard approach for risk-neutral CMDPs, our method incorporates a truncated dual update to account for the possible absence of strong duality. We show that the proposed algorithm achieves regret of $\tilde{\mathcal{O}}\big(V_{g,\max}K^{3/4} + \sqrt{H^4 S^2 A \log(1/\delta)}K^{3/4}\big)$ and constraint violation of $\tilde{\mathcal{O}}\big(V_{g,\max} \sqrt{ {H^3 S^2 A \log(1/\delta)}}K^{3/4} \big)$ with probability at least $1-\delta$, where $S$ and $A$ denote the cardinalities of the state and action spaces, respectively, $H$ is the episode length, $K$ is the number of episodes, $\alpha < 0$ is the risk-aversion parameter, and $V_{g,\max} = \frac{1}{|\alpha|}(\exp(|\alpha|H) - 1)$.  *To the best of our knowledge, this is the first result establishing sublinear regret and violation bounds for the risk-sensitive CMDP problem.*
  abstract_embedding: [0.53125, 0.34765625, 0.06884765625]... (1536 items)
  authors: ['Arnob Ghosh', 'Mehrdad Moharrami']
  code_generated: True
  code_generated_at: 2025-11-06T22:27:40.074319
  code_metadata_s3_key: p-hHW5oBclM7MZc375LC/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: p-hHW5oBclM7MZc375LC/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468032414
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Online_Learning_in_Risk_Sensitive_constrained_MDP.pdf
  sha_abstract: 7cbff688350b05ec272db7e57f437ad9d373931036e15d1a9e1ce0d3e165ee7f
  title: Online Learning in Risk Sensitive constrained MDP
  title_normalized: online_learning_in_risk_sensitive_constrained_mdp

================================================================================
Document #11 (ID: t-hIW5oBclM7MZc3QpKr)
================================================================================
  abstract: The in-context learning paradigm with LLMs has been instrumental in advancing a wide range of natural language processing tasks. The selection of few-shot examples (exemplars / demonstration samples) is essential for constructing effective prompts under context-length budget constraints. In this paper, we formulate the exemplar selection task as a top-m best arms identification problem. A key challenge in this setup is the exponentially large number of arms that need to be evaluated to identify the m-best arms. We propose CASE (Challenger Arm Sampling for Exemplar selection), a novel sample-efficient selective exploration strategy that maintains a shortlist of “challenger” arms, which are current candidates for the top-m arms. In each iteration, only one of the arms from this shortlist or the current top-m set is pulled, thereby reducing sample complexity and, consequently, the number of LLM evaluations. Furthermore, we model the scores of exemplar subsets (arms) using a parameterized linear scoring function, leading to stochastic linear bandits setting. CASE achieves remarkable efficiency gains of up to 7× speedup in runtime while requiring 7× fewer LLM calls (87% reduction) without sacrificing performance compared to state-of-the-art exemplar selection methods. We release our code and data (https://github.com/kiranpurohit/CASE).
  abstract_embedding: [0.10693359375, 0.2099609375, 0.396484375]... (1536 items)
  authors: ['Kiran Purohit', 'Venktesh V', 'Sourangshu Bhattacharya']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468053632
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Sample_Efficient_Demonstration_Selection_for_In-Context_Learning.pdf
  sha_abstract: ed10027ae3a8c9e29c98da1f5535cdba04b7353374695146f9695089d8f0259a
  title: Sample Efficient Demonstration Selection for In-Context Learning
  title_normalized: sample_efficient_demonstration_selection_for_incontext_learning

================================================================================
Document #12 (ID: vOhIW5oBclM7MZc3XpJG)
================================================================================
  abstract: Monte Carlo Tree Search (MCTS) has demonstrated success in online planning for deterministic environments, yet significant challenges remain in adapting it to stochastic Markov Decision Processes (MDPs), particularly in continuous state-action spaces. Existing methods, such as HOOT, which combines MCTS with the Hierarchical Optimistic Optimization (HOO) bandit strategy, address continuous spaces but rely on a logarithmic exploration bonus that lacks theoretical guarantees in non-stationary, stochastic settings. Recent advancements, such as POLY-HOOT, introduced a polynomial bonus term to achieve convergence in deterministic MDPs, though a similar theory for stochastic MDPs remains undeveloped.
In this paper, we propose a novel MCTS algorithm, Stochastic-Power-HOOT, designed for continuous, stochastic MDPs. Stochastic-Power-HOOT integrates a power mean as a value backup operator, alongside a polynomial exploration bonus to address the non-stationarity inherent in continuous action spaces. Our theoretical analysis establishes that Stochastic-Power-HOOT converges at a polynomial rate of $\mathcal{O}(n^{-\zeta})$, $\zeta \in (0,1/2)$, where \( n \) is the number of visited trajectories, thereby extending the non-asymptotic convergence guarantees of POLY-HOOT to stochastic environments. Experimental results on stochastic tasks validate our theoretical findings, demonstrating the effectiveness of Stochastic-Power-HOOT in continuous, stochastic domains.
  abstract_embedding: [0.87109375, 0.2138671875, 0.455078125]... (1536 items)
  authors: ['Tuan Quang Dam']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468060714
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Power_Mean_Estimation_in_Stochastic_Continuous_Monte-Carlo_Tree_Search.pdf
  sha_abstract: 0033bc67773248b8f9ff32a0ec7d013b1f3366ad2c772b0353ca918841600611
  title: Power Mean Estimation in Stochastic Continuous Monte-Carlo Tree Search
  title_normalized: power_mean_estimation_in_stochastic_continuous_montecarlo_tree_search

================================================================================
Document #13 (ID: uuhIW5oBclM7MZc3VJL5)
================================================================================
  abstract: Monte Carlo Tree Search (MCTS) is a powerful framework for solving complex decision-making problems, yet it often relies on the assumption that the simulator and the real-world dynamics are identical. Although this assumption helps achieve the success of MCTS in games like Chess, Go, and Shogi, the real-world scenarios incur ambiguity due to their modeling mismatches in low-fidelity simulators. In this work, we present a new robust variant of MCTS that mitigates dynamical model ambiguities. Our algorithm addresses transition dynamics and reward distribution ambiguities to bridge the gap between simulation-based planning and real-world deployment. We incorporate a robust power mean backup operator and carefully designed exploration bonuses to ensure finite-sample convergence at every node in the search tree. We show that our algorithm achieves a convergence rate of $\mathcal{O}(n^{-1/2})$ for the value estimation at the root node, comparable to that of standard MCTS. Finally, we provide empirical evidence that our method achieves robust performance in planning problems even under significant ambiguity in the underlying reward distribution and transition dynamics.
  abstract_embedding: [0.92578125, 0.39453125, 0.57421875]... (1536 items)
  authors: ['Tuan Quang Dam', 'Kishan Panaganti', 'Brahim Driss']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468058339
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Online_Robust_Reinforcement_Learning_Through_Monte-Carlo_Planning.pdf
  sha_abstract: 2332e3a1aafed4997e872575766fc19205bfc795dabb3e8a9b69a074f9e21957
  title: Online Robust Reinforcement Learning Through Monte-Carlo Planning
  title_normalized: online_robust_reinforcement_learning_through_montecarlo_planning

================================================================================
Document #14 (ID: vehIW5oBclM7MZc3Y5Il)
================================================================================
  abstract: Adversarial training (AT) enhances neural network robustness. Typically, AT updates all trainable parameters, but can lead to overfitting and increased errors on clean data. Research suggests that fine-tuning specific parameters may be more effective; however, methods for identifying these essential parameters and establishing effective optimization objectives remain inadequately addressed. We present CLAT, an innovative adversarial fine-tuning algorithm that mitigates adversarial overfitting by integrating "criticality" into the training process. Instead of tuning the entire model, CLAT identifies and fine-tunes fewer parameters in robustness-critical layers—those predominantly learning non-robust features—while keeping the rest of the model fixed. Additionally, CLAT employs a dynamic layer selection process that adapts to changes in layer criticality during training. Empirical results demonstrate that CLAT can be seamlessly integrated with existing adversarial training methods, enhancing clean accuracy and adversarial robustness by over 2% compared to baseline approaches.
  abstract_embedding: [0.60546875, 0.52734375, 0.0322265625]... (1536 items)
  authors: ['Bhavna Gopal', 'Huanrui Yang', 'Jingyang Zhang']... (5 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468061931
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Boosting_Adversarial_Robustness_with_CLAT__Criticality_Leveraged_Adversarial_Training.pdf
  sha_abstract: 0ced74d7c8ebe3ee710bafcace79882080275f86fc874273f18ab715edcb9f92
  title: Boosting Adversarial Robustness with CLAT: Criticality Leveraged Adversarial Training
  title_normalized: boosting_adversarial_robustness_with_clat_criticality_leveraged_adversarial_training

================================================================================
Document #15 (ID: u-hIW5oBclM7MZc3WZJi)
================================================================================
  abstract: This paper introduces a novel backup strategy for Monte-Carlo Tree Search (MCTS) tailored for highly stochastic and partially observable Markov decision processes. We adopt a probabilistic approach, modeling both value and action-value nodes as Gaussian distributions, to introduce a novel backup operator that computes value nodes as the Wasserstein barycenter of their action-value children nodes; thus, propagating the uncertainty of the estimate across the tree to the root node. We study our novel backup operator when using a novel combination of $L^1$-Wasserstein barycenter with $\alpha$-divergence, by drawing a crucial connection to the generalized mean backup operator. We complement our probabilistic backup operator with two sampling strategies, based on optimistic selection and Thompson sampling, obtaining our Wasserstein MCTS algorithm. We provide theoretical guarantees of asymptotic convergence of $\mathcal{O}(n^{-1/2})$, with $n$ as the number of visited trajectories, to the optimal policy and an empirical evaluation on several stochastic and partially observable environments, where our approach outperforms well-known related baselines.
  abstract_embedding: [0.9140625, 0.080078125, 0.29296875]... (1536 items)
  authors: ['Tuan Quang Dam', 'Pascal Stenger', 'Lukas Schneider']... (6 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468059457
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Monte-Carlo_Tree_Search_with_Uncertainty_Propagation_via_Optimal_Transport.pdf
  sha_abstract: 0a29bbc0e6a983a19954e67a1746de59e0de3e36ba6cffbcf84251114317b3e2
  title: Monte-Carlo Tree Search with Uncertainty Propagation via Optimal Transport
  title_normalized: montecarlo_tree_search_with_uncertainty_propagation_via_optimal_transport

================================================================================
Document #16 (ID: uOhIW5oBclM7MZc3SZK6)
================================================================================
  abstract: We propose a novel method for simulating conditioned diffusion processes (diffusion bridges) in Euclidean spaces. By training a neural network to approximate bridge dynamics, our approach eliminates the need for computationally intensive Markov Chain Monte Carlo (MCMC) methods or reverse-process modeling. Compared to existing methods, it offers greater robustness across various diffusion specifications and conditioning scenarios. This applies in particular to rare events and multimodal distributions, which pose challenges for score-learning- and MCMC-based approaches. We propose a flexible variational family for approximating the diffusion bridge path measure which is  partially specified by a neural network. Once trained, it enables efficient independent sampling at a cost comparable to sampling the unconditioned (forward) process.
  abstract_embedding: [0.3671875, 0.78125, 0.26953125]... (1536 items)
  authors: ['Gefan Yang', 'Frank van der Meulen', 'Stefan Sommer']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468055436
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Neural_Guided_Diffusion_Bridges.pdf
  sha_abstract: b98f20b3eebecda653193402a5c9f1feb458694eaede508d8bb2694a3ee005f8
  title: Neural Guided Diffusion Bridges
  title_normalized: neural_guided_diffusion_bridges

================================================================================
Document #17 (ID: tuhIW5oBclM7MZc3PZJk)
================================================================================
  abstract: Deep neural networks often develop spurious bias, reliance on correlations between non-essential features and classes for predictions. For example, a model may identify objects based on frequently co-occurring backgrounds rather than intrinsic features, resulting in degraded performance on data lacking these correlations. Existing mitigation approaches typically depend on external annotations of spurious correlations, which may be difficult to obtain and are not relevant to the spurious bias in a model. In this paper, we take a step towards self-guided mitigation of spurious bias by proposing NeuronTune, a post hoc method that directly intervenes in a model's internal decision process. Our method probes in a model's latent embedding space to identify and regulate neurons that lead to spurious prediction behaviors. We theoretically justify our approach and show that it brings the model closer to an unbiased one. Unlike previous methods, NeuronTune operates without requiring spurious correlation annotations, making it a practical and effective tool for improving model robustness. Experiments across different architectures and data modalities demonstrate that our method significantly mitigates spurious bias in a self-guided way.
  abstract_embedding: [-0.1298828125, 0.546875, 0.32421875]... (1536 items)
  authors: ['Guangtao Zheng', 'Wenqian Ye', 'Aidong Zhang']
  code_generated: True
  code_generated_at: 2025-11-06T22:28:00.815646
  code_metadata_s3_key: tuhIW5oBclM7MZc3PZJk/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: tuhIW5oBclM7MZc3PZJk/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468052310
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: NeuronTune__Towards_Self-Guided_Spurious_Bias_Mitigation.pdf
  sha_abstract: 135972ab5a11f1e0dbc767d6fc37a4e3c307f5eebd7b91f93237fe6778b1d263
  title: NeuronTune: Towards Self-Guided Spurious Bias Mitigation
  title_normalized: neurontune_towards_selfguided_spurious_bias_mitigation

================================================================================
Document #18 (ID: yuhIW5oBclM7MZc3q5J7)
================================================================================
  abstract: High-dimensional time-series datasets are common in domains such as healthcare and economics. Variational autoencoder (VAE) models, where latent variables are modeled with a Gaussian process (GP) prior, have become a prominent model class to analyze such correlated datasets. However, their applications are challenged by the inherent cubic time complexity that requires specific GP approximation techniques, as well as the general challenge of modeling both shared and individual-specific correlations across time. Though inducing points enhance GP prior VAE scalability, optimizing them remains challenging, especially since discrete covariates resist gradient‑based methods. In this work, we propose a scalable basis function approximation technique for GP prior VAEs that mitigates these challenges and results in linear time complexity, with a global parametrization that eliminates the need for amortized variational inference and the associated amortization gap, making it well-suited for conditional generation tasks where accuracy and efficiency are crucial. Empirical evaluations on synthetic and real-world benchmark datasets demonstrate that our approach not only improves scalability and interpretability but also drastically enhances predictive performance.
  abstract_embedding: [-0.038330078125, 0.2412109375, 0.185546875]... (1536 items)
  authors: ['Mehmet Yiğit Balık', 'Maksim Sinelnikov', 'Priscilla Ong']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468080494
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Bayesian_Basis_Function_Approximation_for_Scalable_Gaussian_Process_Priors_in_Deep_Generative_Models.pdf
  sha_abstract: ba97f729d0555c86184fc0bf382ff31c7b42c9e84979d4d156b5aba2b46469cd
  title: Bayesian Basis Function Approximation for Scalable Gaussian Process Priors in Deep Generative Models
  title_normalized: bayesian_basis_function_approximation_for_scalable_gaussian_process_priors_in_deep_generative_models

================================================================================
Document #19 (ID: yehIW5oBclM7MZc3qJId)
================================================================================
  abstract: Secure Aggregation (SA) is a cornerstone of Federated Learning (FL), ensuring that user updates remain hidden from servers. The advanced Flamingo (S\&P'23) has realized multi-round aggregation and improved efficiency. However, it still faces several key challenges: scalability issues with dynamic user participation, a lack of verifiability for server-side aggregation results, and vulnerability to Model Inconsistency Attacks (MIA) caused by a malicious server distributing inconsistent models. To address these issues, we propose $\textit{Janus}$, a generic SA scheme based on dual-server architecture. Janus ensures security against up to $n-2$ colluding clients (where $n$ is the total client count), which prevents privacy breaches for non-colluders. Additionally, Janus is model-independent, ensuring applicability across any FL model without specific adaptations. Furthermore, Janus introduces a new cryptographic primitive, Separable Homomorphic Commitment, which enables clients to efficiently verify the correctness of aggregation. Finally, extensive experiments show that Janus not only significantly enhances security but also reduces per-client communication and computation overhead from logarithmic to constant scale, with a tolerable impact on model performance.
  abstract_embedding: [0.578125, 0.2294921875, 0.072265625]... (1536 items)
  authors: ['Lang Pu', 'Jingjing Gu', 'Chao Lin']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468079621
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Janus__Dual-Server_Multi-Round_Secure_Aggregation_with_Verifiability_for_Federated_Learning.pdf
  sha_abstract: 34476b0a8e744bfa483d42e1fad7bed0e85427bece714ebde65af189d05de5d7
  title: Janus: Dual-Server Multi-Round Secure Aggregation with Verifiability for Federated Learning
  title_normalized: janus_dualserver_multiround_secure_aggregation_with_verifiability_for_federated_learning

================================================================================
Document #20 (ID: y-hIW5oBclM7MZc3sJL0)
================================================================================
  abstract: Large multimodal models (LMMs) often struggle to recognize novel concepts, as they rely on pre-trained knowledge and have limited ability to capture subtle visual details. Domain-specific knowledge gaps in training also make them prone to confusing visually similar, commonly misrepresented, or low-resource concepts. To help LMMs better align nuanced visual features with language, improving their ability to recognize and reason about novel or rare concepts, we propose a Contrastive visual Data Augmentation (CoDA) strategy. CoDA extracts key contrastive textual and visual features of target concepts against the known concepts they are misrecognized as, and then uses multimodal generative models to produce targeted synthetic data. Automatic filtering of extracted features and augmented images is implemented to guarantee their quality, as verified by human annotators. We show the effectiveness and efficiency of CoDA on low-resource concept and diverse scene recognition datasets including INaturalist and SUN. We additionally collect NovelSpecies, a benchmark dataset consisting of newly discovered animal species that are guaranteed to be unseen by LMMs. LLaVA-1.6 1-shot updating results on these three datasets show CoDA significantly improves SOTA visual data augmentation strategies by 12.3% (NovelSpecies), 5.1% (SUN), and 6.0% (iNat) absolute gains in accuracy.
  abstract_embedding: [0.06884765625, 0.32421875, 0.04931640625]... (1536 items)
  authors: ['Yu Zhou', 'Bingxuan Li', 'Tang Mohan']... (9 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468081874
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Contrastive_Visual_Data_Augmentation.pdf
  sha_abstract: e870639695665e315c039b2b1ad342390016a11c4a55a979aa623a33e2bbb6d0
  title: Contrastive Visual Data Augmentation
  title_normalized: contrastive_visual_data_augmentation

================================================================================
Document #21 (ID: zehIW5oBclM7MZc3upKN)
================================================================================
  abstract: Continual Federated Learning (CFL) allows distributed devices to collaboratively learn novel concepts from continuously shifting training data while avoiding \textit{knowledge forgetting} of previously seen tasks. To tackle this challenge, most current CFL approaches rely on extensive rehearsal of previous data. Despite effectiveness, rehearsal comes at a cost to memory, and it may also violate data privacy. Considering these, we seek to apply regularization techniques to CFL by considering their cost-efficient properties that do not require sample caching or rehearsal. Specifically, we first apply traditional regularization techniques to CFL and observe that existing regularization techniques, especially synaptic intelligence, can achieve promising results under homogeneous data distribution but fail when the data is heterogeneous. Based on this observation, we propose a simple yet effective regularization algorithm for CFL named \textbf{FedSSI}, which tailors the synaptic intelligence for the CFL with heterogeneous data settings. FedSSI can not only reduce computational overhead without rehearsal but also address the data heterogeneity issue. Extensive experiments show that FedSSI achieves superior performance compared to state-of-the-art methods.
  abstract_embedding: [0.494140625, 0.35546875, -0.310546875]... (1536 items)
  authors: ['Yichen Li', 'Yuying Wang', 'Haozhao Wang']... (6 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468084355
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: FedSSI__Rehearsal-Free_Continual_Federated_Learning_with_Synergistic__Synaptic_Intelligence.pdf
  sha_abstract: fc0f4fcfb712bc63850cfa4f860815847d9ed1571d1be60cbded006b56225e9f
  title: FedSSI: Rehearsal-Free Continual Federated Learning with Synergistic  Synaptic Intelligence
  title_normalized: fedssi_rehearsalfree_continual_federated_learning_with_synergistic__synaptic_intelligence

================================================================================
Document #22 (ID: xuhIW5oBclM7MZc3nZJE)
================================================================================
  abstract: Dynamic graph representation learning using Spiking Neural Networks (SNNs) exploits the temporal spiking behavior of neurons, offering advantages in capturing the temporal evolution and sparsity of dynamic graphs. However, existing SNN-based methods often fail to effectively capture the impact of latency in information propagation on node representations. To address this, we propose Delay-DSGN, a dynamic spiking graph neural network incorporating a learnable delay mechanism. By leveraging synaptic plasticity, the model dynamically adjusts connection weights and propagation speeds, enhancing temporal correlations and enabling historical data to influence future representations. Specifically, we introduce a Gaussian delay kernel into the neighborhood aggregation process at each time step, adaptively delaying historical information to future time steps and mitigating information forgetting. Experiments on three large-scale dynamic graph datasets demonstrate that Delay-DSGN outperforms eight state-of-the-art methods, achieving the best results in node classification tasks. We also theoretically derive the constraint conditions between the Gaussian kernel's standard deviation and size, ensuring stable training and preventing gradient explosion and vanishing issues.
  abstract_embedding: [0.061767578125, 0.490234375, -0.03466796875]... (1536 items)
  authors: ['Zhiqiang Wang', 'Jianghao Wen', 'Jianqing Liang']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468076836
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Delay-DSGN__A_Dynamic_Spiking_Graph_Neural_Network_with_Delay_Mechanisms_for_Evolving_Graph.pdf
  sha_abstract: eb14c87ca6235f6371fbe0f8db303c51f43cd79696146cebb61ba43f538b7783
  title: Delay-DSGN: A Dynamic Spiking Graph Neural Network with Delay Mechanisms for Evolving Graph
  title_normalized: delaydsgn_a_dynamic_spiking_graph_neural_network_with_delay_mechanisms_for_evolving_graph

================================================================================
Document #23 (ID: zOhIW5oBclM7MZc3tpIF)
================================================================================
  abstract: The hierarchical structure inherent in many real-world datasets makes the modeling of such hierarchies a crucial objective in both unsupervised and supervised machine learning. While recent advancements have introduced deep architectures specifically designed for hierarchical clustering, we adopt a critical perspective on this line of research. Our findings reveal that these methods face significant limitations in scalability and performance when applied to realistic datasets.~Given these findings, we present an alternative approach and introduce a lightweight method that builds on pre-trained non-hierarchical clustering models. Remarkably, our approach outperforms specialized deep models for hierarchical clustering, and it is broadly applicable to any pre-trained clustering model that outputs logits, without requiring any fine-tuning. To highlight the generality of our approach, we extend its application to a supervised setting, demonstrating its ability to recover meaningful hierarchies from a pre-trained ImageNet classifier. Our results establish a practical and effective alternative to existing deep hierarchical clustering methods, with significant advantages in efficiency, scalability and performance.
  abstract_embedding: [0.037353515625, 0.359375, 0.30859375]... (1536 items)
  authors: ['Emanuele Palumbo', 'Moritz Vandenhirtz', 'Alain Ryser']... (5 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468083194
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: From_Logits_to_Hierarchies__Hierarchical_Clustering_made_Simple.pdf
  sha_abstract: fc6f58ded3cefe44a18a024f8eefc5007b9207c6a6bfd8af6f95b78db761c73d
  title: From Logits to Hierarchies: Hierarchical Clustering made Simple
  title_normalized: from_logits_to_hierarchies_hierarchical_clustering_made_simple

================================================================================
Document #24 (ID: x-hIW5oBclM7MZc3npJ6)
================================================================================
  abstract: We introduce Spatial Reasoning Models (SRMs), a framework to perform  reasoning over sets of continuous variables via denoising generative models. SRMs infer continuous representations on a set of unobserved variables, given observations on observed variables. 
Current generative models on spatial domains, such as diffusion and flow matching models, often collapse to hallucination in case of complex distributions. To measure this, we introduce a set of benchmark tasks that test the quality of complex reasoning in generative models and can quantify hallucination. The SRM framework allows to report key findings about importance of sequentialization in generation, the associated order, as well as the sampling strategies during training. It demonstrates, for the first time, that order of generation can successfully be predicted by the denoising network itself. Using these findings, we can increase the accuracy of specific reasoning tasks from <1% to >50%. Our [project website](https://geometric-rl.mpi-inf.mpg.de/srm/) provides additional videos, code, and the benchmark datasets.
  abstract_embedding: [0.56640625, 0.21875, 0.35546875]... (1536 items)
  authors: ['Christopher Wewer', 'Bartlomiej Pogodzinski', 'Bernt Schiele']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468077157
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Spatial_Reasoning_with_Denoising_Models.pdf
  sha_abstract: 28dc1791fc02f5e3df1554841f19e52cbadb02d6d2363e1e9e044f42f8eb8c0d
  title: Spatial Reasoning with Denoising Models
  title_normalized: spatial_reasoning_with_denoising_models

================================================================================
Document #25 (ID: yOhIW5oBclM7MZc3oZIj)
================================================================================
  abstract: Traditional conformal prediction faces significant challenges with the rise of streaming data and increasing concerns over privacy. In this paper, we introduce a novel online differentially private conformal prediction framework, designed to construct dynamic, model-free private prediction sets. Unlike existing approaches that either disregard privacy or require full access to the entire dataset, our proposed method ensures individual privacy with a one-pass algorithm, ideal for real-time, privacy-preserving decision-making. Theoretically, we establish guarantees for long-run coverage at the nominal confidence level. Moreover, we extend our method to conformal quantile regression, which is fully adaptive to heteroscedasticity. We validate the effectiveness and applicability of the proposed method through comprehensive simulations and real-world studies on the ELEC2 and PAMAP2 datasets.
  abstract_embedding: [0.60546875, 0.31640625, 0.4453125]... (1536 items)
  authors: ['Qiangqiang Zhang', 'Ting Li', 'Xinwei Feng']... (5 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468077820
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Online_Differentially_Private_Conformal_Prediction_for_Uncertainty_Quantification.pdf
  sha_abstract: 1255ab01339615eaa2da04151c07c060035164df42e01adfb4882ea8dd6fa603
  title: Online Differentially Private Conformal Prediction for Uncertainty Quantification
  title_normalized: online_differentially_private_conformal_prediction_for_uncertainty_quantification

================================================================================
Document #26 (ID: c62d85dc13654285fa3c43d8264e09cb8498c5fcb0956a507f2337ff409a4347)
================================================================================
  abstract: Agents are now used widely in the process of software development, but
building production-ready software engineering agents is a complex task.
Deploying software agents effectively requires flexibility in implementation
and experimentation, reliable and secure execution, and interfaces for users to
interact with agents. In this paper, we present the OpenHands Software Agent
SDK, a toolkit for implementing software development agents that satisfy these
desiderata. This toolkit is a complete architectural redesign of the agent
components of the popular OpenHands framework for software development agents,
which has 64k+ GitHub stars. To achieve flexibility, we design a simple
interface for implementing agents that requires only a few lines of code in the
default case, but is easily extensible to more complex, full-featured agents
with features such as custom tools, memory management, and more. For security
and reliability, it delivers seamless local-to-remote execution portability,
integrated REST/WebSocket services. For interaction with human users, it can
connect directly to a variety of interfaces, such as visual workspaces (VS
Code, VNC, browser), command-line interfaces, and APIs. Compared with existing
SDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native
sandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and
built-in security analysis. Empirical results on SWE-Bench Verified and GAIA
benchmarks demonstrate strong performance. Put together, these elements allow
the OpenHands Software Agent SDK to provide a practical foundation for
prototyping, unlocking new classes of custom applications, and reliably
deploying agents at scale.
  abstract_embedding: [0.80078125, 0.1044921875, 0.53125]... (1536 items)
  authors: ['Xingyao Wang', 'Simon Rosenberg', 'Juan Michelini']... (11 items)
  code_generated: True
  code_generated_at: 2025-11-06T09:00:47.681793
  code_metadata_s3_key: c62d85dc13654285fa3c43d8264e09cb8498c5fcb0956a507f2337ff409a4347/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: c62d85dc13654285fa3c43d8264e09cb8498c5fcb0956a507f2337ff409a4347/code.py
  date: 2025-11-05T18:16:44+00:00
  decision: accept
  ingested_at: 1762419625220
  novelty: yes
  reason: The paper is relevant to current LLM, AI, and ML research as it presents a software agent SDK for building production-ready software engineering agents. The toolkit provides flexibility, security, and...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: The_OpenHands_Software_Agent_SDK__A_Composable_and_Extensible_Foundation_for_Production_Agents.pdf
  sha_abstract: 92086b22928b4531a647d52031eae3947c2d526b9d2d65d1ae03a9eb385263d4
  title: The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents
  title_normalized: the_openhands_software_agent_sdk_a_composable_and_extensible_foundation_for_production_agents

================================================================================
Document #27 (ID: 2ea799b44aa94eb0659df92bf75e0f713eb2cd7adb9a05dadc4cd208e4dfa702)
================================================================================
  abstract: Analog/mixed-signal circuits are key for interfacing electronics with the
physical world. Their design, however, remains a largely handcrafted process,
resulting in long and error-prone design cycles. While the recent rise of
AI-based reinforcement learning and generative AI has created new techniques to
automate this task, the need for many time-consuming simulations is a critical
bottleneck hindering the overall efficiency. Furthermore, the lack of
explainability of the resulting design solutions hampers widespread adoption of
the tools. To address these issues, a novel agentic AI framework for
sample-efficient and explainable analog circuit sizing is presented. It employs
a multi-agent workflow where specialized Large Language Model (LLM)-based
agents collaborate to interpret the circuit topology, to understand the design
goals, and to iteratively refine the circuit's design parameters towards the
target goals with human-interpretable reasoning. The adaptive simulation
strategy creates an intelligent control that yields a high sample efficiency.
The AnaFlow framework is demonstrated for two circuits of varying complexity
and is able to complete the sizing task fully automatically, differently from
pure Bayesian optimization and reinforcement learning approaches. The system
learns from its optimization history to avoid past mistakes and to accelerate
convergence. The inherent explainability makes this a powerful tool for analog
design space exploration and a new paradigm in analog EDA, where AI agents
serve as transparent design assistants.
  abstract_embedding: [0.435546875, -0.013916015625, -0.01019287109375]... (1536 items)
  authors: ['Mohsen Ahmadzadeh', 'Kaichang Chen', 'Georges Gielen']
  code_generated: True
  code_generated_at: 2025-11-06T09:01:07.580788
  code_metadata_s3_key: 2ea799b44aa94eb0659df92bf75e0f713eb2cd7adb9a05dadc4cd208e4dfa702/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 2ea799b44aa94eb0659df92bf75e0f713eb2cd7adb9a05dadc4cd208e4dfa702/code.py
  date: 2025-11-05T18:24:01+00:00
  decision: accept
  ingested_at: 1762419622924
  novelty: yes
  reason: The paper is relevant to current LLM, AI, and ML research as it presents a novel agentic AI framework for sample-efficient and explainable analog circuit sizing, which leverages large language models ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: AnaFlow__Agentic_LLM-based_Workflow_for_Reasoning-Driven_Explainable_and_Sample-Efficient_Analog_Circuit_Sizing.pdf
  sha_abstract: ef9671254e9484b678d237a27981c58e618860d53d210747779bd74d0b2faef9
  title: AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing
  title_normalized: anaflow_agentic_llmbased_workflow_for_reasoningdriven_explainable_and_sampleefficient_analog_circuit_sizing

================================================================================
Document #28 (ID: c82ec1259ded48dcd98428fe92bb2cc2eee155c3d4fe4525671b936629d5c1dc)
================================================================================
  abstract: AI researchers have long focused on poker-like games as a testbed for
environments characterized by multi-player dynamics, imperfect information, and
reasoning under uncertainty. While recent breakthroughs have matched elite
human play at no-limit Texas hold'em, the multi-player dynamics are subdued:
most hands converge quickly with only two players engaged through multiple
rounds of bidding. In this paper, we present Solly, the first AI agent to
achieve elite human play in reduced-format Liar's Poker, a game characterized
by extensive multi-player engagement. We trained Solly using self-play with a
model-free, actor-critic, deep reinforcement learning algorithm. Solly played
at an elite human level as measured by win rate (won over 50% of hands) and
equity (money won) in heads-up and multi-player Liar's Poker. Solly also
outperformed large language models (LLMs), including those with reasoning
abilities, on the same metrics. Solly developed novel bidding strategies,
randomized play effectively, and was not easily exploitable by world-class
human players.
  abstract_embedding: [0.70703125, 0.10546875, 0.24609375]... (1536 items)
  authors: ['Richard Dewey', 'Janos Botyanszki', 'Ciamac C. Moallemi']... (4 items)
  code_generated: True
  code_generated_at: 2025-11-06T09:00:38.744566
  code_metadata_s3_key: c82ec1259ded48dcd98428fe92bb2cc2eee155c3d4fe4525671b936629d5c1dc/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: c82ec1259ded48dcd98428fe92bb2cc2eee155c3d4fe4525671b936629d5c1dc/code.py
  date: 2025-11-05T18:58:18+00:00
  decision: accept
  ingested_at: 1762419614535
  novelty: yes
  reason: The paper is relevant to current LLM, AI, and ML research as it presents an AI agent, Solly, that achieves elite human-level performance in the multi-player game of Liar's Poker. This is novel as it d...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Outbidding_and_Outbluffing_Elite_Humans__Mastering_Liar_s_Poker_via_Self-Play_and_Reinforcement_Learning.pdf
  sha_abstract: d2ccb973b91d614a2ab8172d84fb0d5501c2fb69e485f3737dcb4e0e0e7e3b7b
  title: Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning
  title_normalized: outbidding_and_outbluffing_elite_humans_mastering_liars_poker_via_selfplay_and_reinforcement_learning

================================================================================
Document #29 (ID: ouhFW5oBclM7MZc3-ZJs)
================================================================================
  abstract: While numerous work has been proposed to address fairness in machine learning, existing methods do not guarantee fair predictions under imperceptible feature perturbation, and a seemingly fair model can suffer from large group-wise disparities under such perturbation. Moreover, while adversarial training has been shown to be reliable in improving a model's robustness to defend against adversarial feature perturbation that deteriorates accuracy, it has not been properly studied in the context of adversarial perturbation against fairness. To tackle these challenges, in this paper, we study the problem of adversarial attack and adversarial robustness w.r.t. two terms: fairness and accuracy. From the adversarial attack perspective, we propose a unified structure for adversarial attacks against fairness which brings together common notions in group fairness, and we theoretically prove the equivalence of adversarial attacks against different fairness notions. Further, we derive the connections between adversarial attacks against fairness and those against accuracy. From the adversarial robustness perspective, we theoretically align robustness to adversarial attacks against fairness and accuracy, where robustness w.r.t. one term enhances robustness w.r.t. the other term. Our study suggests a novel way to unify adversarial training w.r.t. fairness and accuracy, and experiments show our proposed method achieves better robustness w.r.t. both terms.
  abstract_embedding: [0.392578125, 0.71875, -0.21875]... (1536 items)
  authors: ['Junyi Chai', 'Taeuk Jang', 'Jing Gao']... (4 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:25:31.660295
  code_metadata_s3_key: ouhFW5oBclM7MZc3-ZJs/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: ouhFW5oBclM7MZc3-ZJs/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762467903716
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: On_the_Alignment_between_Fairness_and_Accuracy__from_the_Perspective_of_Adversarial_Robustness.pdf
  sha_abstract: 63df8bab43375ea026f481f906fd3e82c3f01862c1a091d851021a97e533d8f7
  title: On the Alignment between Fairness and Accuracy: from the Perspective of Adversarial Robustness
  title_normalized: on_the_alignment_between_fairness_and_accuracy_from_the_perspective_of_adversarial_robustness

================================================================================
Document #30 (ID: o-hGW5oBclM7MZc3AJII)
================================================================================
  abstract: Model immunization aims to pre-train models that are difficult to fine-tune on harmful tasks while retaining their utility on other non-harmful tasks. Though prior work has shown empirical evidence for immunizing text-to-image models, the key understanding of when immunization is possible and a precise definition of an immunized model remain unclear. In this work, we propose a framework, based on the condition number of a Hessian matrix, to analyze model immunization for linear models. Building on this framework, we design an algorithm with regularization terms to control the resulting condition numbers after pre-training. Empirical results on linear models and non-linear deep-nets demonstrate the effectiveness of the proposed algorithm on model immunization. The code is available at https://github.com/amberyzheng/model-immunization-cond-num.
  abstract_embedding: [0.306640625, 0.5859375, 0.3359375]... (1536 items)
  authors: ['Amber Yijia Zheng', 'Site Bai', 'Brian Bullins']... (4 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:25:26.070274
  code_metadata_s3_key: o-hGW5oBclM7MZc3AJII/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: o-hGW5oBclM7MZc3AJII/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762467905495
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Model_Immunization_from_a_Condition_Number_Perspective.pdf
  sha_abstract: c175d963828ca97d67f4c0e999bb68183d3cc859d1c33d3aaccdc64416fdc845
  title: Model Immunization from a Condition Number Perspective
  title_normalized: model_immunization_from_a_condition_number_perspective

================================================================================
Document #31 (ID: tOhIW5oBclM7MZc3MpLO)
================================================================================
  abstract: Regression is a fundamental task in machine learning that has garnered extensive attention over the past decades. The conventional approach for regression involves employing loss functions that primarily concentrate on aligning model prediction with the ground truth for each individual data sample. Recent research endeavors have introduced novel perspectives by incorporating label similarity into regression through the imposition of additional pairwise regularization or contrastive learning on the latent feature space, demonstrating their effectiveness. However, there are two drawbacks to these approaches: (i) their pairwise operations in the latent feature space are computationally more expensive than conventional regression losses; (ii) they lack theoretical insights behind these methods. In this work, we propose GAR (Gradient Aligned Regression) as a competitive alternative method in label space, which is constituted by a conventional regression loss and two pairwise label difference losses for gradient alignment including magnitude and direction. GAR enjoys: i) the same level efficiency as conventional regression loss because the quadratic complexity for the proposed pairwise losses can be reduced to linear complexity; ii) theoretical insights from learning the pairwise label difference to learning the gradient of the ground truth function. We limit our current scope as regression on the clean data setting without noises, outliers or distributional shifts, etc. We demonstrate the effectiveness of the proposed method practically on two synthetic datasets and on eight extensive real-world tasks from six benchmark datasets with other eight competitive baselines. Running time experiments demonstrate the superior efficiency of the proposed GAR compared to existing methods with pairwise regularization or contrastive learning in the latent feature space. Additionally, ablation studies confirm the effectiveness of each component of GAR. The code is open sourced at https://github.com/DixianZhu/GAR.
  abstract_embedding: [0.326171875, 0.328125, 0.0869140625]... (1536 items)
  authors: ['Dixian Zhu', 'Tianbao Yang', 'Livnat Jerby']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468049602
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Gradient_Aligned_Regression_via_Pairwise_Losses.pdf
  sha_abstract: 79dfe0aa8edad3e3b676748994408b442c5e3ac11cbb056ba0f3b2c93d56de1f
  title: Gradient Aligned Regression via Pairwise Losses
  title_normalized: gradient_aligned_regression_via_pairwise_losses

================================================================================
Document #32 (ID: ruhIW5oBclM7MZc3FJLi)
================================================================================
  abstract: A foundational principle of connectionism is that perception, action, and cognition emerge from parallel computations among simple, interconnected units that generate and rely on neural representations. Accordingly, researchers employ multivariate pattern analysis to decode and compare the neural codes of artificial and biological networks, aiming to uncover their functions. However, there is limited analytical understanding of how a network’s representation and function relate, despite this being essential to any quantitative notion of underlying function or functional similarity. We address this question using analysable two-layer linear networks and numerical simulations in nonlinear networks. We find that function and representation are dissociated, allowing representational similarity without functional similarity and vice versa. Further, we show that neither robustness to input noise nor the level of generalisation error constrain representations to the task. In contrast, networks robust to parameter noise have limited representational flexibility and must employ task-specific representations. Our findings suggest that representational alignment reflects computational advantages beyond functional alignment alone, with significant implications for interpreting and comparing the representations of connectionist systems
  abstract_embedding: [0.2001953125, 0.21875, 0.10009765625]... (1536 items)
  authors: ['Lukas Braun', 'Erin Grant', 'Andrew M Saxe']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468041926
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Not_all_solutions_are_created_equal__An_analytical_dissociation_of_functional_and_representational_similarity_in_deep_linear_neural_networks.pdf
  sha_abstract: 6ba76d0b29f6b59eb57c974e2a5223a24ef06f7e8be80bcff8fd311f79090c91
  title: Not all solutions are created equal: An analytical dissociation of functional and representational similarity in deep linear neural networks
  title_normalized: not_all_solutions_are_created_equal_an_analytical_dissociation_of_functional_and_representational_similarity_in_deep_linear_neural_networks

================================================================================
Document #33 (ID: tehIW5oBclM7MZc3OJJ5)
================================================================================
  abstract: Irregular multivariate time series (IMTS) are characterized by irregular time intervals within variables and unaligned observations across variables, posing challenges in learning temporal and variable dependencies. 
Many existing IMTS models either require padded samples to learn separately from temporal and variable dimensions, or represent original samples via bipartite graphs or sets.
However, the former approaches often need to handle extra padding values affecting efficiency and disrupting original sampling patterns, while the latter ones have limitations in capturing dependencies among unaligned observations.
To represent and learn both dependencies from original observations in a unified form, we propose HyperIMTS, a **Hyper**graph neural network for **I**rregular **M**ultivariate **T**ime **S**eries forecasting.
Observed values are converted as nodes in the hypergraph, interconnected by temporal and variable hyperedges to enable message passing among all observations.
Through irregularity-aware message passing, HyperIMTS captures variable dependencies in a time-adaptive way to achieve accurate forecasting. 
Experiments demonstrate HyperIMTS's competitive performance among state-of-the-art models in IMTS forecasting with low computational cost.
Our code is available at [https://github.com/qianlima-lab/PyOmniTS](https://github.com/qianlima-lab/PyOmniTS).
  abstract_embedding: [0.5546875, 0.11865234375, 0.44921875]... (1536 items)
  authors: ['Boyuan Li', 'Yicheng Luo', 'Zhen Liu']... (6 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468051054
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: HyperIMTS__Hypergraph_Neural_Network_for_Irregular_Multivariate_Time_Series_Forecasting.pdf
  sha_abstract: e051c5a59f3201e6575ac1df451b9c05232cbf7f5120abd578a5d664594df111
  title: HyperIMTS: Hypergraph Neural Network for Irregular Multivariate Time Series Forecasting
  title_normalized: hyperimts_hypergraph_neural_network_for_irregular_multivariate_time_series_forecasting

================================================================================
Document #34 (ID: s-hIW5oBclM7MZc3LZJ7)
================================================================================
  abstract: We consider the problem of asynchronous stochastic optimization, where an optimization algorithm makes updates based on stale stochastic gradients of the objective that are subject to an arbitrary (possibly adversarial) sequence of delays. We present a procedure which, for any given $q \in (0,1]$, transforms any standard stochastic first-order method to an asynchronous method with convergence guarantee depending on the $q$-quantile delay of the sequence. This approach leads to convergence rates of the form $O(\tau_q/qT+\sigma/\sqrt{qT})$ for non-convex and $O(\tau_q^2/(q T)^2+\sigma/\sqrt{qT})$ for convex smooth problems, where $\tau_q$ is the $q$-quantile delay, generalizing and improving on existing results that depend on the average delay. We further show a method that automatically adapts to all quantiles simultaneously, without any prior knowledge of the delays, achieving convergence rates of the form $O(\inf_{q} \tau_q/qT+\sigma/\sqrt{qT})$ for non-convex and $O(\inf_{q} \tau_q^2/(q T)^2+\sigma/\sqrt{qT})$ for convex smooth problems. Our technique is based on asynchronous mini-batching with a careful batch-size selection and filtering of stale gradients.
  abstract_embedding: [0.3828125, 0.46484375, 0.330078125]... (1536 items)
  authors: ['Amit Attia', 'Ofir Gaash', 'Tomer Koren']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468048238
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Faster_Stochastic_Optimization_with_Arbitrary_Delays_via_Adaptive_Asynchronous_Mini-Batching.pdf
  sha_abstract: 81f86c618c25f700172108df6cdf927e4b46f34c8af360fb139d0ea3beddc7ff
  title: Faster Stochastic Optimization with Arbitrary Delays via Adaptive Asynchronous Mini-Batching
  title_normalized: faster_stochastic_optimization_with_arbitrary_delays_via_adaptive_asynchronous_minibatching

================================================================================
Document #35 (ID: suhIW5oBclM7MZc3KJKe)
================================================================================
  abstract: Maximal Update Parameterization ($\mu$P) has shown significant promise in allowing zero-shot hyperparameter transfer across neural network scales, reducing the prohibitive cost of hyperparameter tuning for large models. However, the theoretical foundation behind the observed approximate transferability of hyperparameters remains underexplored. Relying on a width-dominance regime, which ensures that as width grows, certain terms of the learning dynamics dominate, we establish the first fundamental separation of scales in $\mu$P between macro-variables (e.g. loss landscapes) and micro-variables (e.g. individual weights). Our formulation explains why hyperparameter tuning can be effectively performed in early training stages, i.e., \textit{early statistics effectively approximate global hyperparameter optima}, implying the potential to further reduce the training costs required for searching optimal hyperparameters. We further apply our main theory to explain an empirical deep learning phenomenon discovered independently by prior work.
  abstract_embedding: [0.56640625, 0.185546875, 0.1357421875]... (1536 items)
  authors: ['Letong Hong', 'Zhangyang Wang']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468046980
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: On_the_Provable_Separation_of_Scales_in_Maximal_Update_Parameterization.pdf
  sha_abstract: 83c34eaa06b5e2321190105213c82dbaff7c6869142779530516e38e4967a286
  title: On the Provable Separation of Scales in Maximal Update Parameterization
  title_normalized: on_the_provable_separation_of_scales_in_maximal_update_parameterization

================================================================================
Document #36 (ID: r-hIW5oBclM7MZc3GpIj)
================================================================================
  abstract: While there has been plenty of work on generating tests from existing code, there has been limited work on generating tests from issues. A correct test must validate the code patch that resolves the issue. This paper focuses on the scenario where that code patch does not yet exist. Doing so supports two major use-cases. First, it supports TDD (test-driven development), the discipline of "test first, write code later" that has well-documented benefits for human software engineers. Second, it also validates SWE (software engineering) agents, which generate code patches for resolving issues. This paper introduces TDD-Bench-Verified, a benchmark for generating tests from issues, and Otter, an LLM-based solution for this task. Otter augments LLMs with rule-based analysis to check and repair their outputs, and introduces a novel self-reflective action planner. Experiments show Otter outperforming state-of-the-art systems for generating tests from issues, in addition to enhancing systems that generate patches from issues. We hope that Otter helps make developers more productive at resolving issues and leads to more robust, well-tested code.
  abstract_embedding: [0.78515625, 0.1162109375, 0.2001953125]... (1536 items)
  authors: ['Toufique Ahmed', 'Jatin Ganhotra', 'Rangeet Pan']... (6 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468043279
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Otter__Generating_Tests_from_Issues_to_Validate_SWE_Patches.pdf
  sha_abstract: 95308ef5b720930560945a3df52ba86f4db9dacf0391db07a737d874c27e1862
  title: Otter: Generating Tests from Issues to Validate SWE Patches
  title_normalized: otter_generating_tests_from_issues_to_validate_swe_patches

================================================================================
Document #37 (ID: sOhIW5oBclM7MZc3HpLf)
================================================================================
  abstract: Asynchronous Stochastic Gradient Descent (Asynchronous SGD) is a cornerstone method for parallelizing learning in distributed machine learning. However, its performance suffers under arbitrarily heterogeneous computation times across workers, leading to suboptimal time complexity and inefficiency as the number of workers scales. While several Asynchronous SGD variants have been proposed, recent findings by Tyurin & Richtárik (NeurIPS 2023) reveal that none achieve optimal time complexity, leaving a significant gap in the literature. In this paper, we propose Ringmaster ASGD, a novel Asynchronous SGD method designed to address these limitations and tame the inherent challenges of Asynchronous SGD. We establish, through rigorous theoretical analysis, that Ringmaster ASGD achieves optimal time complexity under arbitrarily heterogeneous and dynamically fluctuating worker computation times. This makes it the first Asynchronous SGD method to meet the theoretical lower bounds for time complexity in such scenarios.
  abstract_embedding: [0.40234375, 0.25390625, 0.455078125]... (1536 items)
  authors: ['Arto Maranjyan', 'Alexander Tyurin', 'Peter Richtárik']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468044494
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Ringmaster_ASGD__The_First_Asynchronous_SGD_with_Optimal_Time_Complexity.pdf
  sha_abstract: 5a9b3c04ef15e1b7d7196ab989bbef57ec091ae155f9aa134612add9cdfca66b
  title: Ringmaster ASGD: The First Asynchronous SGD with Optimal Time Complexity
  title_normalized: ringmaster_asgd_the_first_asynchronous_sgd_with_optimal_time_complexity

================================================================================
Document #38 (ID: sehIW5oBclM7MZc3JJIT)
================================================================================
  abstract: We extend the standard reinforcement learning framework to random time horizons. While the classical setting typically assumes finite and deterministic or infinite runtimes of trajectories, we argue that multiple real-world applications naturally exhibit random (potentially trajectory-dependent) stopping times. Since those stopping times typically depend on the policy, their randomness has an effect on policy gradient formulas, which we (mostly for the first time) derive rigorously in this work both for stochastic and deterministic policies. We present two complementary perspectives, trajectory or state-space based, and establish connections to optimal control theory. Our numerical experiments demonstrate that using the proposed formulas can significantly improve optimization convergence compared to traditional approaches.
  abstract_embedding: [0.75390625, 0.1533203125, 0.357421875]... (1536 items)
  authors: ['Enric Ribera Borrell', 'Lorenz Richter', 'Christof Schuette']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468045817
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Reinforcement_Learning_with_Random_Time_Horizons.pdf
  sha_abstract: 581cc4ac0001aa91d40aa913a7de2e2fe13f23cdfc35aa893a6cfc2ffa247661
  title: Reinforcement Learning with Random Time Horizons
  title_normalized: reinforcement_learning_with_random_time_horizons

================================================================================
Document #39 (ID: quhIW5oBclM7MZc3AJJr)
================================================================================
  abstract: Recent advances in vision-language models have led to impressive progress in caption generation for images and short video clips. However, these models remain constrained by their limited temporal receptive fields, making it difficult to produce
coherent and comprehensive captions for long videos. While several methods have been proposed to aggregate information across video segments, they often rely on supervised fine-tuning or incur significant computational overhead. To address these challenges, we introduce a novel framework for long video captioning based on graph consolidation. Our approach first generates segment-level captions, corresponding to individual frames or short video intervals, using off-the-shelf visual captioning models. These captions are then parsed into individual scene graphs, which are subsequently consolidated into a unified graph representation that preserves both holistic context and fine-grained details throughout the video. A lightweight graph-to-text decoder then produces the final video-level caption. This framework effectively extends the temporal understanding capabilities of existing models without requiring any additional fine-tuning on long video datasets. Experimental results show that our method significantly outperforms existing LLM-based consolidation approaches, achieving strong zero-shot performance while substantially reducing computational costs.
  abstract_embedding: [0.05029296875, 0.380859375, 0.54296875]... (1536 items)
  authors: ['Sanghyeok Chu', 'Seonguk Seo', 'Bohyung Han']
  code_generated: True
  code_generated_at: 2025-11-06T22:27:47.405225
  code_metadata_s3_key: quhIW5oBclM7MZc3AJJr/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: quhIW5oBclM7MZc3AJJr/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468036681
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Fine-Grained_Captioning_of_Long_Videos_through_Scene_Graph_Consolidation.pdf
  sha_abstract: 969be6f28020f33b7a327f2280db76e279ba4dcda9044597a26e2519dacb736f
  title: Fine-Grained Captioning of Long Videos through Scene Graph Consolidation
  title_normalized: finegrained_captioning_of_long_videos_through_scene_graph_consolidation

================================================================================
Document #40 (ID: wehIW5oBclM7MZc3eZJO)
================================================================================
  abstract: Deep neural networks are vulnerable to backdoor attacks, where malicious behaviors are implanted during training. While existing defenses can effectively purify compromised models, they typically require labeled data or specific training procedures, making them difficult to apply beyond supervised learning settings. Notably, recent studies have shown successful backdoor attacks across various learning paradigms, highlighting a critical security concern. To address this gap, we propose Two-stage Symmetry Connectivity (TSC), a novel backdoor purification defense that operates independently of data format and requires only a small fraction of clean samples. Through theoretical analysis, we prove that by leveraging permutation invariance in neural networks and quadratic mode connectivity, TSC amplifies the loss on poisoned samples while maintaining bounded clean accuracy. Experiments demonstrate that TSC achieves robust performance comparable to state-of-the-art methods in supervised learning scenarios. Furthermore, TSC generalizes to self-supervised learning frameworks, such as SimCLR and CLIP, maintaining its strong defense capabilities. Our code is available at https://github.com/JiePeng104/TSC.
  abstract_embedding: [0.478515625, 0.70703125, 0.162109375]... (1536 items)
  authors: ['Jie Peng', 'Hongwei Yang', 'Jing Zhao']... (7 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468067523
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Circumventing_Backdoor_Space_via_Weight_Symmetry.pdf
  sha_abstract: eaa8f77788823480499a9632447e0f8bc571f7443f91b3543960562715c816ad
  title: Circumventing Backdoor Space via Weight Symmetry
  title_normalized: circumventing_backdoor_space_via_weight_symmetry

================================================================================
Document #41 (ID: q-hIW5oBclM7MZc3BpI2)
================================================================================
  abstract: Mental disorders are among the most widespread diseases globally. Analyzing functional brain networks through functional magnetic resonance imaging (fMRI) is crucial for understanding mental disorder behaviors. Although existing fMRI-based graph neural networks (GNNs) have demonstrated significant potential in brain network feature extraction, they often fail to characterize complex relationships between brain regions and demographic information in mental disorders. To overcome these limitations, we propose a learnable NeuroTree framework that integrates a $k$-hop AGE-GCN with neural ordinary differential equations (ODEs) and contrastive masked functional connectivity (CMFC) to enhance similarities and dissimilarities of brain region distance. Furthermore, NeuroTree effectively decodes fMRI network features into tree structures, which improves the capture of high-order brain regional pathway features and enables the identification of hierarchical neural behavioral patterns essential for understanding disease-related brain subnetworks. Our empirical evaluations demonstrate that NeuroTree achieves state-of-the-art performance across two distinct mental disorder datasets. It provides valuable insights into age-related deterioration patterns, elucidating their underlying neural mechanisms.  The code and datasets are available at https://github.com/Ding1119/NeuroTree.
  abstract_embedding: [0.68359375, 0.484375, -0.337890625]... (1536 items)
  authors: ['Jun-En Ding', 'Dongsheng Luo', 'Chenwei Wu']... (4 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:27:42.137187
  code_metadata_s3_key: q-hIW5oBclM7MZc3BpI2/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: q-hIW5oBclM7MZc3BpI2/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468038163
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: NeuroTree__Hierarchical_Functional_Brain_Pathway_Decoding_for_Mental_Health_Disorders.pdf
  sha_abstract: 716605a0965d20a5508bf8376e8d3b1493fb81626a1ecd7be212daa9e116f52c
  title: NeuroTree: Hierarchical Functional Brain Pathway Decoding for Mental Health Disorders
  title_normalized: neurotree_hierarchical_functional_brain_pathway_decoding_for_mental_health_disorders

================================================================================
Document #42 (ID: vuhIW5oBclM7MZc3aJId)
================================================================================
  abstract: Transformers have emerged as the dominant architecture in the field of deep learning, with a broad range of applications and remarkable in-context learning (ICL) capabilities. While not yet fully understood, ICL has already proved to be an intriguing phenomenon, allowing transformers to learn in context—without requiring further training. In this paper, we further advance the understanding of ICL by demonstrating that transformers can perform full Bayesian inference for commonly used statistical models in context. More specifically, we introduce a general framework that builds on ideas from prior fitted networks and continuous normalizing flows and enables us to infer complex posterior distributions for models such as generalized linear models and latent factor models. Extensive experiments on real-world datasets demonstrate that our ICL approach yields posterior samples that are similar in quality to state-of-the-art MCMC or variational inference methods that do not operate in context. The source code for this paper is available at https://github.com/ArikReuter/ICL_for_Full_Bayesian_Inference
  abstract_embedding: [-0.380859375, 0.2470703125, 0.021728515625]... (1536 items)
  authors: ['Arik Reuter', 'Tim G. J. Rudner', 'Vincent Fortuin']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468063230
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Can_Transformers_Learn_Full_Bayesian_Inference_in_Context_.pdf
  sha_abstract: e6cb3baf99fb30def56c3f65a70f20abca0eac08c333b8d0c074918f92c364e8
  title: Can Transformers Learn Full Bayesian Inference in Context?
  title_normalized: can_transformers_learn_full_bayesian_inference_in_context

================================================================================
Document #43 (ID: rehIW5oBclM7MZc3D5LF)
================================================================================
  abstract: We study the classical optimization problem $\min_{x \in \mathbb{R}^d} f(x)$ and analyze the gradient descent (GD) method in both nonconvex and convex settings. It is well-known that, under the $L$–smoothness assumption ($\|\| \nabla^2 f(x) \|\| \leq L$), the optimal point minimizing the quadratic upper bound $f(x_k) + \langle \nabla f(x_k), x_{k+1} - x_k \rangle + \frac{L}{2} \|\| x_{k+1} - x_k \|\|^2$ is $x_{k+1} = x_k - \gamma_k \nabla f(x_k)$ with step size  $\gamma_k = \frac{1}{L}$. Surprisingly, a similar result can be derived under the $\ell$-generalized smoothness assumption ($\|\| \nabla^2 f(x) \|\| \leq \ell( \|\| \nabla f(x) \|\| )$). In this case, we derive the step size $$\gamma_k = \int_{0}^{1} \frac{d v}{\ell( \|\| \nabla f(x_k) \|\| + \|\| \nabla f(x_k) \|\| v)}.$$ Using this step size rule, we improve upon existing theoretical convergence rates and obtain new results in several previously unexplored setups.
  abstract_embedding: [0.38671875, 0.38671875, -0.1259765625]... (1536 items)
  authors: ['Alexander Tyurin']
  code_generated: True
  code_generated_at: 2025-11-06T22:27:44.806471
  code_metadata_s3_key: rehIW5oBclM7MZc3D5LF/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: rehIW5oBclM7MZc3D5LF/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468040599
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Toward_a_Unified_Theory_of_Gradient_Descent_under_Generalized_Smoothness.pdf
  sha_abstract: 239b0f686db73a637e2bd166e807cf388ac07c31becfadcaa0e4993b19654390
  title: Toward a Unified Theory of Gradient Descent under Generalized Smoothness
  title_normalized: toward_a_unified_theory_of_gradient_descent_under_generalized_smoothness

================================================================================
Document #44 (ID: xOhIW5oBclM7MZc3ipK4)
================================================================================
  abstract: Large-scale text encoders in text-to-image (T2I) diffusion models have demonstrated exceptional performance in generating high-quality images from textual prompts. Unlike denoising modules that rely on multiple iterative steps, text encoders require only a single forward pass to produce text embeddings. However, despite their minimal contribution to total inference time and floating-point operations (FLOPs), text encoders demand significantly higher memory usage, up to eight times more than denoising modules. To address this inefficiency, we propose Skip and Re-use layers (Skrr), a simple yet effective pruning strategy specifically designed for text encoders in T2I diffusion models. Skrr exploits the inherent redundancy in transformer blocks by selectively skipping or reusing certain layers in a manner tailored for T2I tasks, thereby reducing memory consumption without compromising performance. Extensive experiments demonstrate that Skrr maintains image quality comparable to the original model even under high sparsity levels, outperforming existing blockwise pruning methods. Furthermore, Skrr achieves state-of-the-art memory efficiency while preserving performance across multiple evaluation metrics, including the FID, CLIP, DreamSim, and GenEval scores.
  abstract_embedding: [0.3671875, -0.14453125, 0.44921875]... (1536 items)
  authors: ['Hoigi Seo', 'Wongi Jeong', 'Jae-sun Seo']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468072074
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Skrr__Skip_and_Re-use_Text_Encoder_Layers_for_Memory_Efficient_Text-to-Image_Generation.pdf
  sha_abstract: 36e1cfd2f41b966be5655082025797c7ce9b73290ef876f7f56853036131dfb6
  title: Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation
  title_normalized: skrr_skip_and_reuse_text_encoder_layers_for_memory_efficient_texttoimage_generation

================================================================================
Document #45 (ID: xehIW5oBclM7MZc3mZIp)
================================================================================
  abstract: Despite significant advances in quality and complexity of the generations in text-to-image models, *prompting* does not always lead to the desired outputs. Controlling model behaviour by directly *steering* intermediate model activations has emerged as a viable alternative allowing to *reach* concepts in latent space that may otherwise remain inaccessible by prompt. In this work, we introduce a set of experiments to deepen our understanding of concept reachability. We design a training data setup with three key obstacles: scarcity of concepts, underspecification of concepts in the captions, and data biases with tied concepts. Our results show: (i) concept reachability in latent space exhibits a distinct phase transition, with only a small number of samples being sufficient to enable reachability, (ii) *where* in the latent space the intervention is performed critically impacts reachability, showing that certain concepts are reachable only at certain stages of transformation, and (iii) while prompting ability rapidly diminishes with a decrease in quality of the dataset, concepts often remain reliably reachable through steering. Model providers can leverage this to bypass costly retraining and dataset curation and instead innovate with user-facing control mechanisms.
  abstract_embedding: [0.154296875, 0.296875, 0.16796875]... (1536 items)
  authors: ['Marta Aparicio Rodriguez', 'Xenia Miscouridou', 'Anastasia Borovykh']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468075774
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Concept_Reachability_in_Diffusion_Models__Beyond_Dataset_Constraints.pdf
  sha_abstract: eccc9232fd1c55525e4653a5f817830dc778251ab274d85505cbd0441d32407c
  title: Concept Reachability in Diffusion Models: Beyond Dataset Constraints
  title_normalized: concept_reachability_in_diffusion_models_beyond_dataset_constraints

================================================================================
Document #46 (ID: v-hIW5oBclM7MZc3bZK4)
================================================================================
  abstract: We consider molecule generation in 3D space using language models (LMs), which requires discrete tokenization of 3D molecular geometries. Although tokenization of molecular graphs exists, that for 3D geometries is largely unexplored. Here, we attempt to bridge this gap by proposing a novel method which converts molecular geometries into SE(3)-invariant 1D discrete sequences. Our method consists of canonical labeling and invariant spherical representation steps, which together maintain geometric and atomic fidelity in a format conducive to LMs. Our experiments show that, when coupled with our proposed method, various LMs excel in molecular geometry generation, especially in controlled generation tasks. Our code has been released as part of the AIRS library (https://github.com/divelab/AIRS/).
  abstract_embedding: [0.62109375, 0.482421875, 0.0986328125]... (1536 items)
  authors: ['Xiner Li', 'Limei Wang', 'Youzhi Luo']... (8 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468064658
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Geometry_Informed_Tokenization_of_Molecules_for_Language_Model_Generation.pdf
  sha_abstract: b87f2d96133094d1d206cb11c2201f1a50342b0cd6d0f4aa4e0bbf7c6d051559
  title: Geometry Informed Tokenization of Molecules for Language Model Generation
  title_normalized: geometry_informed_tokenization_of_molecules_for_language_model_generation

================================================================================
Document #47 (ID: wuhIW5oBclM7MZc3f5J2)
================================================================================
  abstract: Aggregating preferences under incomplete or constrained feedback is a fundamental problem in social choice and related domains. While prior work has established strong impossibility results for pairwise comparisons, this paper extends the inquiry to improvement feedback, where voters express incremental adjustments rather than complete preferences. We provide a complete characterization of the positional scoring rules that can be computed given improvement feedback. Interestingly, while plurality is learnable under improvement feedback—unlike with pairwise feedback—strong impossibility results persist for many other positional scoring rules. Furthermore, we show that improvement feedback, unlike pairwise feedback, does not suffice for the computation of any Condorcet-consistent rule. We complement our theoretical findings with experimental results, providing further insights into the practical implications of improvement feedback for preference aggregation.
  abstract_embedding: [0.6640625, 0.578125, -0.2197265625]... (1536 items)
  authors: ['Evi Micha', 'Vasilis Varsamis']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468069117
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Computing_Voting_Rules_with_Improvement_Feedback.pdf
  sha_abstract: d5df6b218282d66dc372ee7924a4c68a7dbc25a423343d151d9874112f4c7e49
  title: Computing Voting Rules with Improvement Feedback
  title_normalized: computing_voting_rules_with_improvement_feedback

================================================================================
Document #48 (ID: wOhIW5oBclM7MZc3c5Jj)
================================================================================
  abstract: Training neural networks on randomly generated artificial datasets yields Bayesian models that capture the prior defined by the dataset-generating distribution.
Prior-data Fitted Networks (PFNs) are a class of methods designed to leverage this insight.
In an era of rapidly increasing computational resources for pre-training and a near stagnation in the generation of new real-world data in many applications, PFNs are poised to play a more important role across a wide range of applications.
They enable the efficient allocation of pre-training compute to low-data scenarios.
Originally applied to small Bayesian modeling tasks, the field of PFNs has significantly expanded to address more complex domains and larger datasets. 
This position paper argues that PFNs and other amortized inference approaches represent the future of Bayesian inference, leveraging amortized learning to tackle data-scarce problems. 
We thus believe they are a fruitful area of research. In this position paper, we explore their potential and directions to address their current limitations.
  abstract_embedding: [0.1572265625, 0.34375, 0.109375]... (1536 items)
  authors: ['Samuel Müller', 'Arik Reuter', 'Noah Hollmann']... (5 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:28:10.890615
  code_metadata_s3_key: wOhIW5oBclM7MZc3c5Jj/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: wOhIW5oBclM7MZc3c5Jj/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468066096
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Position__The_Future_of_Bayesian_Prediction_Is_Prior-Fitted.pdf
  sha_abstract: 7c0367db09f948d0d3c42fa5a6466c93d5113cdf1412fde53efeaffa5d277257
  title: Position: The Future of Bayesian Prediction Is Prior-Fitted
  title_normalized: position_the_future_of_bayesian_prediction_is_priorfitted

================================================================================
Document #49 (ID: 0uhIW5oBclM7MZc31JKh)
================================================================================
  abstract: Tensor regression is a powerful tool for analyzing complex multi-dimensional data in fields such as neuroimaging and spatiotemporal analysis, but its effectiveness is often hindered by insufficient sample sizes. To overcome this limitation, we adopt a transfer learning strategy that leverages knowledge from related source tasks to improve performance in data-scarce target tasks. This approach, however, introduces additional challenges including model shifts, covariate shifts, and decentralized data management. We propose the Low-Rank Tensor Transitions (LoRT) framework, which incorporates a novel fusion regularizer and a two-step refinement to enable robust adaptation while preserving low-tubal-rank structure. To support decentralized scenarios, we extend LoRT to D-LoRT, a distributed variant that maintains statistical efficiency with minimal communication overhead. Theoretical analysis and experiments on tensor regression tasks, including compressed sensing and completion, validate the robustness and versatility of the proposed methods. These findings indicate the potential of LoRT as a robust method for tensor regression in settings with limited data and complex distributional structures.
  abstract_embedding: [0.1572265625, -0.51171875, 0.3828125]... (1536 items)
  authors: ['Andong Wang', 'Yuning Qiu', 'Zhong Jin']... (5 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468091025
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Low-Rank_Tensor_Transitions__LoRT__for_Transferable_Tensor_Regression.pdf
  sha_abstract: 70ef34b3b1288b30f015726c8f11fcc5aa1e1a1dafcf59112255c6b87008e5c6
  title: Low-Rank Tensor Transitions (LoRT) for Transferable Tensor Regression
  title_normalized: lowrank_tensor_transitions_lort_for_transferable_tensor_regression

================================================================================
Document #50 (ID: 1OhIW5oBclM7MZc335Jb)
================================================================================
  abstract: Fairness in human and algorithmic decision-making is crucial in areas such as criminal justice, education, and social welfare. Recently, counterfactual fairness has drawn increasing research interest, suggesting that decision-making for individuals should remain the same when intervening with different values on protected attributes. Nevertheless, the question of "which attributes and individuals should be protected" is rarely discussed in the existing counterfactual fairness literature. For example, when considering leg disability as a protected attribute, the algorithms should not treat individuals with leg disabilities differently in college admissions, but one may naturally consider this factor when selecting runner athletes. In other words, when and how to enforce fairness is expected to depend on the causal relation between the protected attribute and the outcome of interest. Formally, this paper proposes principal counterfactual fairness using the concept of principal stratification from the causal inference literature, focusing on whether an algorithm is counterfactually fair for individuals whose protected attribute has no individual causal effect on the outcome of interest. To examine whether an algorithm satisfies principal counterfactual fairness, we derive the statistical bounds and propose a post-processing approach to achieving principal counterfactual fairness with minimal individual decision changes. Experiments are conducted using synthetic and real-world datasets to verify the effectiveness of our methods.
  abstract_embedding: [0.388671875, 0.2470703125, -0.25390625]... (1536 items)
  authors: ['Haoxuan Li', 'Zeyu Tang', 'Zhichao Jiang']... (7 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468093740
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Fairness_on_Principal_Stratum__A_New_Perspective_on_Counterfactual_Fairness.pdf
  sha_abstract: 9b2da5729aa974c1faafde19c6d815ed80ba461c44b14717161701ec00abba7c
  title: Fairness on Principal Stratum: A New Perspective on Counterfactual Fairness
  title_normalized: fairness_on_principal_stratum_a_new_perspective_on_counterfactual_fairness

================================================================================
Document #51 (ID: 1ehIW5oBclM7MZc35pJc)
================================================================================
  abstract: Concept learning seeks to extract semantic and interpretable representations of atomic concepts from high-dimensional data such as images and text, which can be instrumental to a variety of downstream tasks (e.g., image generation/editing). Despite its importance, the theoretical foundations for learning atomic concepts and their interactions, especially from multimodal distributions, remain underexplored.
In this work, we establish fundamental conditions for learning atomic multimodal concepts and their underlying interactions With identfiability guarantees. We formulate concept learning as a latent variable identification problem, representing atomic concepts in each modality as latent variables, with a graphical model to specify their interactions across modalities. Our theoretical contribution is to provide component-wise identifiability of atomic concepts under flexible, nonparametric conditions that accommodate both continuous and discrete modalities.  Building on these theoretical insights, we demonstrate the practical utility of our theory in a downstream task text-to-image (T2I) generation. We develop a principled T2I model that explicitly learns atomic textual and visual concepts with sparse connections between them, allowing us to achieve image generation and editing at the atomic concept level. Empirical evaluations show that our model outperforms existing methods in T2I generation tasks, offering superior controllability and interpretability.
  abstract_embedding: [0.2275390625, 0.203125, -0.056640625]... (1536 items)
  authors: ['Shaoan Xie', 'Lingjing Kong', 'Yujia Zheng']... (7 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468095561
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Learning_Vision_and_Language_Concepts_for_Controllable_Image_Generation.pdf
  sha_abstract: 387e9c4e8779705ed9cb645fc39340eaf3ccb4c76c13ab447c29cef9d6186b33
  title: Learning Vision and Language Concepts for Controllable Image Generation
  title_normalized: learning_vision_and_language_concepts_for_controllable_image_generation

================================================================================
Document #52 (ID: 0-hIW5oBclM7MZc32pJL)
================================================================================
  abstract: The autoregressive decoding for text generation in large language models (LLMs), while widely used, is inherently suboptimal due to the lack of a built-in mechanism to perform refinement and/or correction of the generated content. In this paper, we consider optimality in terms of the joint probability over the generated response, when jointly considering all tokens at the same time. We theoretically characterize the potential deviation of the autoregressively generated response from its globally optimal counterpart that is of the same length. Our analysis suggests that we need to be cautious when noticeable uncertainty arises during text generation, which may signal the sub-optimality of the generation history. To address the pitfall of autoregressive decoding for text generation, we propose an approach that incorporates a sliding reflection window and a pausing criterion, such that refinement and generation can be carried out interchangeably as the decoding proceeds. Our selective refinement framework strikes a balance between efficiency and optimality, and our extensive experimental results demonstrate the effectiveness of our approach.
  abstract_embedding: [0.047607421875, 0.166015625, 0.060791015625]... (1536 items)
  authors: ['Zeyu Tang', 'Zhenhao Chen', 'Xiangchen Song']... (9 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468092482
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Reflection-Window_Decoding__Text_Generation_with_Selective_Refinement.pdf
  sha_abstract: 42ad25452fa141c294e0ba1b91bd74ac59ad5f627e195b60091202c6039a2009
  title: Reflection-Window Decoding: Text Generation with Selective Refinement
  title_normalized: reflectionwindow_decoding_text_generation_with_selective_refinement

================================================================================
Document #53 (ID: z-hIW5oBclM7MZc3w5Kb)
================================================================================
  abstract: Decomposing hard problems into subproblems often makes them easier and more efficient to solve. With the high cost of running LLMs at scale, there is an increasing effort to decompose systems into sets of LLM-based agents, each of whom can be delegated sub-tasks. However, this decomposition (even when automated) is often intuitive, e.g., based on how a human might assign roles to members of a human team. How close are these role decompositions to optimal? This position paper argues that asymptotic analysis with LLM primitives is needed to reason about the efficiency of such problem decompositions, and that insights from such analysis will unlock opportunities for scaling such systems. By treating the LLM forward pass as the atomic unit of computational cost, one can separate out the (often opaque) inner workings of a particular LLM from the inherent efficiency of how a set of LLMs are orchestrated to solve hard problems. In other words, if we want to scale the deployment of LLMs to the limit, instead of anthropomorphizing LLMs, asymptotic analysis with LLM primitives should be used to reason about and develop more powerful decompositions of large problems into LLM agents.
  abstract_embedding: [0.9140625, 0.01708984375, 0.32421875]... (1536 items)
  authors: ['Elliot Meyerson', 'Xin Qiu']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468086674
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Position__Scaling_LLM_Agents_Requires_Asymptotic_Analysis_with_LLM_Primitives.pdf
  sha_abstract: 2bf4adfaf51f9d040ff73b0bac87d5025375b9ff2d29fc60a85c90b23749bb07
  title: Position: Scaling LLM Agents Requires Asymptotic Analysis with LLM Primitives
  title_normalized: position_scaling_llm_agents_requires_asymptotic_analysis_with_llm_primitives

================================================================================
Document #54 (ID: 1uhIW5oBclM7MZc365LV)
================================================================================
  abstract: Graph Transformers (GTs) have demonstrated remarkable performance in graph representation learning over popular graph neural networks (GNNs). However, self-attention, the core module of GTs, preserves only low-frequency signals in graph features, leading to ineffectiveness in capturing other important signals like high-frequency ones. Some recent GT models help alleviate this issue, but their flexibility and expressiveness are still limited since the filters they learn are fixed on predefined graph spectrum or spectral order. To tackle this challenge, we propose a Graph Fourier Kolmogorov-Arnold Transformer (GrokFormer), a novel GT model that learns highly expressive spectral filters with adaptive graph spectrum and spectral order through a Fourier series modeling over learnable activation functions. We demonstrate theoretically and empirically that the proposed GrokFormer filter offers better expressiveness than other spectral methods. Comprehensive experiments on 10 real-world node classification datasets across various domains, scales, and graph properties, as well as 5 graph classification datasets, show that GrokFormer outperforms state-of-the-art GTs and GNNs. Our code is available at https://github.com/GGA23/GrokFormer.
  abstract_embedding: [-0.09130859375, 0.126953125, 0.0002574920654296875]... (1536 items)
  authors: ['GuoguoAi', 'Guansong Pang', 'Hezhe Qiao']... (5 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468096974
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: GrokFormer__Graph_Fourier_Kolmogorov-Arnold_Transformers.pdf
  sha_abstract: 417b78e911e850206fd979d5716d743ccc0398040f3531f4a3e36ff795de9cc5
  title: GrokFormer: Graph Fourier Kolmogorov-Arnold Transformers
  title_normalized: grokformer_graph_fourier_kolmogorovarnold_transformers

================================================================================
Document #55 (ID: 0OhIW5oBclM7MZc3yZIS)
================================================================================
  abstract: It is widely believed that noise conditioning is indispensable for denoising diffusion models to work successfully. This work challenges this belief. Motivated by research on blind image denoising, we investigate a variety of denoising-based generative models in the absence of noise conditioning. To our surprise, most models exhibit graceful degradation, and in some cases, they even perform better without noise conditioning. We provide a mathematical analysis of the error introduced by removing noise conditioning and demonstrate that our analysis aligns with empirical observations. We further introduce a noise-*unconditional* model that achieves a competitive FID of 2.23 on CIFAR-10, significantly narrowing the gap to leading noise-conditional models. We hope our findings will inspire the community to revisit the foundations and formulations of denoising generative models.
  abstract_embedding: [-0.041259765625, 0.51171875, 0.09130859375]... (1536 items)
  authors: ['Qiao Sun', 'Zhicheng Jiang', 'Hanhong Zhao']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468088067
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Is_Noise_Conditioning_Necessary_for_Denoising_Generative_Models_.pdf
  sha_abstract: 490d3d19dfcc686e7d41c4f6730eace6102eaa904797a33485deabbe5cc5f767
  title: Is Noise Conditioning Necessary for Denoising Generative Models?
  title_normalized: is_noise_conditioning_necessary_for_denoising_generative_models

================================================================================
Document #56 (ID: w-hIW5oBclM7MZc3hJLd)
================================================================================
  abstract: We consider the problem of predicting perturbation effects via causal models. In many applications, it is a priori unknown which mechanisms of a system are modified by an external perturbation, even though the features of the perturbation are available. For example, in genomics, some properties of a drug may be known, but not their causal effects on the regulatory pathways of cells. We propose a generative intervention model (GIM) that learns to map these perturbation features to distributions over atomic interventions in a jointly-estimated causal model. Contrary to prior approaches, this enables us to predict the distribution shifts of unseen perturbation features while gaining insights about their mechanistic effects in the underlying data-generating process. On synthetic data and scRNA-seq drug perturbation data, GIMs achieve robust out-of-distribution predictions on par with unstructured approaches, while effectively inferring the underlying perturbation mechanisms, often better than other causal inference methods.
  abstract_embedding: [-0.11572265625, 0.439453125, -0.291015625]... (1536 items)
  authors: ['Nora Schneider', 'Lars Lorch', 'Niki Kilbertus']... (5 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:28:21.300586
  code_metadata_s3_key: w-hIW5oBclM7MZc3hJLd/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: w-hIW5oBclM7MZc3hJLd/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468070473
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Generative_Intervention_Models_for_Causal_Perturbation_Modeling.pdf
  sha_abstract: 5b3133ca530660aaab42211fee9bee0052ee70b039ec001afff5eb9c80178cdd
  title: Generative Intervention Models for Causal Perturbation Modeling
  title_normalized: generative_intervention_models_for_causal_perturbation_modeling

================================================================================
Document #57 (ID: 2-hJW5oBclM7MZc3D5Jf)
================================================================================
  abstract: Recent text-to-image generative models, e.g., Stable Diffusion V3 and Flux, have achieved notable progress. However, these models are strongly restricted to their limited knowledge, a.k.a., their own fixed parameters, that are trained with closed datasets. This leads to significant hallucinations or distortions when facing fine-grained and unseen novel real-world objects, e.g., the appearance of the Tesla Cybertruck. To this end, we present **the first** real-object-based retrieval-augmented generation framework (**RealRAG**), which augments fine-grained and unseen novel object generation by learning and retrieving real-world images to overcome the knowledge gaps of generative models. Specifically, to integrate missing memory for unseen novel object generation, we train a reflective retriever by **self-reflective contrastive learning**, which injects the generator's knowledge into the sef-reflective negatives, ensuring that the retrieved augmented images compensate for the model's missing knowledge. Furthermore, the real-object-based framework integrates fine-grained visual knowledge for the generative models, tackling the distortion problem and improving the realism for fine-grained object generation. Our Real-RAG is superior in its modular application to **all types** of state-of-the-art text-to-image generative models and also delivers **remarkable** performance boosts with all of them, such as a **gain of *16.18\%* FID score** with the auto-regressive model on the Stanford Car benchmark.
  abstract_embedding: [0.00543212890625, 0.203125, -0.2451171875]... (1536 items)
  authors: ['Yuanhuiyi Lyu', 'Xu Zheng', 'Lutao Jiang']... (8 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468106036
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: RealRAG__Retrieval-augmented_Realistic_Image_Generation_via_Self-reflective_Contrastive_Learning.pdf
  sha_abstract: 717543cad1e6484cdf36aad1132e0f7cf32a8977c9b6ee0a50fb9624dcb27a93
  title: RealRAG: Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning
  title_normalized: realrag_retrievalaugmented_realistic_image_generation_via_selfreflective_contrastive_learning

================================================================================
Document #58 (ID: 3OhJW5oBclM7MZc3FJI6)
================================================================================
  abstract: Long-range interactions are essential for the correct description of complex systems in many scientific fields. The price to pay for including them in the calculations, however, is a dramatic increase in the overall computational costs. Recently, deep graph networks have been employed as efficient, data-driven models for predicting properties of complex systems represented as graphs. These models rely on a message passing strategy that should, in principle, capture long-range information without explicitly modeling the corresponding interactions. In practice, most deep graph networks cannot really model long-range dependencies due to the intrinsic limitations of (synchronous) message passing, namely oversmoothing, oversquashing, and underreaching. This work proposes a general framework that \textit{learns to mitigate} these limitations: within a variational inference framework, we endow message passing architectures with the ability to adapt their depth and filter messages along the way. With theoretical and empirical arguments, we show that this strategy better captures long-range interactions, by competing with the state of the art on five node and graph prediction datasets.
  abstract_embedding: [0.36328125, 0.439453125, 0.259765625]... (1536 items)
  authors: ['Federico Errica', 'Henrik Christiansen', 'Viktor Zaverkin']... (6 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468107316
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Adaptive_Message_Passing__A_General_Framework_to_Mitigate_Oversmoothing__Oversquashing__and_Underreaching.pdf
  sha_abstract: 9f50d08bdf40ead617e6c9f8e40de1e2e26f426ea3417d8bb49af0256f0b001a
  title: Adaptive Message Passing: A General Framework to Mitigate Oversmoothing, Oversquashing, and Underreaching
  title_normalized: adaptive_message_passing_a_general_framework_to_mitigate_oversmoothing_oversquashing_and_underreaching

================================================================================
Document #59 (ID: 3ehJW5oBclM7MZc3GZKw)
================================================================================
  abstract: Graph Edit Distance (GED) is a widely used metric for measuring similarity between two graphs. Computing the optimal GED is NP-hard, leading to the development of various neural and non-neural heuristics. While neural methods have achieved improved approximation quality compared to non-neural approaches, they face significant challenges: (1) They require large amounts of ground truth data, which is itself NP-hard to compute. (2) They operate as black boxes, offering limited interpretability. (3) They lack cross-domain generalization, necessitating expensive retraining for each new dataset. We address these limitations with GRAIL, introducing a paradigm shift in this domain. Instead of training a neural model to predict GED, GRAIL employs a novel combination of large language models (LLMs) and automated prompt tuning to generate a *program* that is used to compute GED. This shift from predicting GED to generating programs imparts various advantages, including end-to-end interpretability and an autonomous self-evolutionary learning mechanism without ground-truth supervision. Extensive experiments on seven datasets confirm that GRAIL not only surpasses state-of-the-art GED approximation methods in prediction quality but also achieves robust cross-domain generalization across diverse graph distributions.
  abstract_embedding: [-0.255859375, 0.546875, -0.07373046875]... (1536 items)
  authors: ['Samidha Verma', 'Arushi Goyal', 'Ananya Mathur']... (5 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468108677
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: GRAIL__Graph_Edit_Distance_and_Node_Alignment_using_LLM-Generated_Code.pdf
  sha_abstract: f453dbd0317f23ed76dc5ce0f3caf53465216fa3a34ac6d984e1c37780b90d44
  title: GRAIL: Graph Edit Distance and Node Alignment using LLM-Generated Code
  title_normalized: grail_graph_edit_distance_and_node_alignment_using_llmgenerated_code

================================================================================
Document #60 (ID: 3uhJW5oBclM7MZc3H5K6)
================================================================================
  abstract: Modeling the evolution of high-dimensional systems from limited snapshot observations at irregular time points poses a significant challenge in quantitative biology and related fields. Traditional approaches often rely on dimensionality reduction techniques, which can oversimplify the dynamics and fail to capture critical transient behaviors in non-equilibrium systems. We present Multi-Marginal Stochastic Flow Matching (MMSFM), a novel extension of simulation-free score and flow matching methods to the multi-marginal setting, enabling the alignment of high-dimensional data measured at non-equidistant time points without reducing dimensionality. The use of measure-valued splines enhances robustness to irregular snapshot timing, and score matching prevents overfitting in high-dimensional spaces. 
We validate our framework on several synthetic and benchmark datasets, including gene expression data collected at uneven time points and an image progression task, demonstrating the method's versatility.
  abstract_embedding: [0.359375, 0.23046875, 0.050048828125]... (1536 items)
  authors: ['Justin Lee', 'Behnaz Moradijamei', 'Heman Shakeri']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468110235
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Multi-Marginal_Stochastic_Flow_Matching_for_High-Dimensional_Snapshot_Data_at_Irregular_Time_Points.pdf
  sha_abstract: 9a7f13e632aa58f9efbc107e1e86534c2e4fa3d149b313c66272e8a69e20701e
  title: Multi-Marginal Stochastic Flow Matching for High-Dimensional Snapshot Data at Irregular Time Points
  title_normalized: multimarginal_stochastic_flow_matching_for_highdimensional_snapshot_data_at_irregular_time_points

================================================================================
Document #61 (ID: 1-hIW5oBclM7MZc38ZJh)
================================================================================
  abstract: Watermarking for large language models (LLMs) offers a promising approach to identifying AI-generated text. Existing approaches, however, either compromise the distribution of original generated text by LLMs or are limited to embedding zero-bit information that only allows for watermark detection but ignores identification. We present StealthInk, a stealthy multi-bit watermarking scheme that preserves the original text distribution while enabling the embedding of provenance data, such as userID, TimeStamp, and modelID, within LLM-generated text. This enhances fast traceability without requiring access to the language model's API or prompts.  We derive a lower bound on the number of tokens necessary for watermark detection at a fixed equal error rate, which provides insights on how to enhance the capacity. Comprehensive empirical evaluations across diverse tasks highlight the stealthiness, detectability, and resilience of StealthInk, establishing it as an effective solution for LLM watermarking applications.
  abstract_embedding: [0.2451171875, 0.0218505859375, 0.16796875]... (1536 items)
  authors: ['Ya Jiang', 'Chuxiong Wu', 'Massieh Kordi Boroujeny']... (5 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468098394
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: StealthInk__A_Multi-bit_and_Stealthy_Watermark_for_Large_Language_Models.pdf
  sha_abstract: a816d107887467a989427fe3c639e2966f89b511a41c8d1f0aba58fa58d7bfa9
  title: StealthInk: A Multi-bit and Stealthy Watermark for Large Language Models
  title_normalized: stealthink_a_multibit_and_stealthy_watermark_for_large_language_models

================================================================================
Document #62 (ID: 2OhIW5oBclM7MZc3-JJ9)
================================================================================
  abstract: We study the policy evaluation problem in an online multi-reward multi-policy discounted setting, where multiple reward functions  must be evaluated simultaneously for different policies. We adopt an $(\epsilon,\delta)$-PAC perspective to achieve $\epsilon$-accurate estimates with high confidence over finite or convex sets of rewards, a setting that has not been systematically studied in the literature. Building on prior work on Multi-Reward Best Policy Identification, we adapt the MR-NaS exploration scheme  to jointly minimize sample complexity for evaluating different policies across different reward sets. Our approach leverages an instance-specific lower bound revealing how the sample complexity scales with a measure of value deviation, guiding the design of an efficient exploration policy. Although computing this bound entails a hard non-convex optimization, we propose an efficient convex approximation that holds for both finite and convex reward sets. Experiments in tabular domains demonstrate the effectiveness of  this adaptive exploration scheme. Code repository: https://github.com/rssalessio/multi-reward-multi-policy-eval.
  abstract_embedding: [0.8046875, 0.205078125, 0.390625]... (1536 items)
  authors: ['Alessio Russo', 'Aldo Pacchiano']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468100214
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Adaptive_Exploration_for_Multi-Reward_Multi-Policy_Evaluation.pdf
  sha_abstract: f5bb1565696d9fd6ebbabd00ab738079108d20398d5401e638325f809cb90cb6
  title: Adaptive Exploration for Multi-Reward Multi-Policy Evaluation
  title_normalized: adaptive_exploration_for_multireward_multipolicy_evaluation

================================================================================
Document #63 (ID: 2uhJW5oBclM7MZc3CJJb)
================================================================================
  abstract: We study inverse optimization (IO), where the goal is to use a parametric optimization program as the hypothesis class to infer relationships between input-decision pairs. Most of the literature focuses on learning only the objective function, as learning the constraint function (i.e., feasible regions) leads to nonconvex training programs. Motivated by this, we focus on learning feasible regions for known linear objectives, and introduce two training losses along with a hypothesis class to parameterize the  constraint function. Our hypothesis class surpasses the previous objective-only method by naturally capturing discontinuous behaviors in input-decision pairs. We introduce a customized block coordinate descent algorithm with a smoothing technique to solve the training problems, while for further restricted hypothesis classes, we reformulate the training optimization as a tractable convex program or mixed integer linear program. Synthetic experiments and two power system applications including comparisons with state-of-the-art approaches showcase and validate the proposed approach.
  abstract_embedding: [0.49609375, 0.306640625, -0.51171875]... (1536 items)
  authors: ['Ke Ren', 'Peyman Mohajerin Esfahani', 'Angelos Georghiou']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468104258
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Inverse_Optimization_via_Learning_Feasible_Regions.pdf
  sha_abstract: f8dd03cf36f556005618813c0c0f094f3da36a49242b322cdbc96505edf9d284
  title: Inverse Optimization via Learning Feasible Regions
  title_normalized: inverse_optimization_via_learning_feasible_regions

================================================================================
Document #64 (ID: zuhIW5oBclM7MZc3v5JN)
================================================================================
  abstract: This paper proposes a family of permutation-invariant graph embeddings, generalizing the Skew Spectrum of graphs of Kondor & Borgwardt (2008). Grounded in group theory and harmonic analysis, our method introduces a new class of graph invariants that are isomorphism-invariant and capable of embedding richer graph structures - including attributed graphs, multilayer graphs, and hypergraphs - which the Skew Spectrum could not handle. Our generalization further defines a family of functions that enables a trade-off between computational complexity and expressivity. By applying generalization-preserving heuristics to this family, we improve the Skew Spectrum's expressivity at the same computational cost. We formally prove the invariance of our generalization, demonstrate its improved expressiveness through experiments, and discuss its efficient computation.
  abstract_embedding: [-0.2890625, 0.5703125, -0.1865234375]... (1536 items)
  authors: ['Armando Bellante', 'Martin Plávala', 'Alessandro Luongo']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468085557
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: The_Generalized_Skew_Spectrum_of_Graphs.pdf
  sha_abstract: 752cf2a7fe9b841c20a6ab2618e5ec5890ccf76322dfaa1fdd563905242168b3
  title: The Generalized Skew Spectrum of Graphs
  title_normalized: the_generalized_skew_spectrum_of_graphs

================================================================================
Document #65 (ID: 0ehIW5oBclM7MZc3zZKs)
================================================================================
  abstract: Fine-tuning a pre-trained model on a downstream task often degrades its original capabilities, a phenomenon known as "catastrophic forgetting". This is especially an issue when one does not have access to the data and recipe used to develop the pre-trained model. Under this constraint, most existing methods for mitigating forgetting are inapplicable. To address this challenge, we propose a *sample weighting scheme for the fine-tuning data* solely based on the pre-trained model's losses. Specifically, we upweight the easy samples on which the pre-trained model's loss is low and vice versa to limit the drift from the pre-trained model. Our approach is orthogonal and yet complementary to existing methods; while such methods mostly operate on parameter or gradient space, we concentrate on the sample space. We theoretically analyze the impact of fine-tuning with our method in a linear setting, showing that it stalls learning in a certain subspace, which inhibits overfitting to the target task. We empirically demonstrate the efficacy of our method on both language and vision tasks. As an example, when fine-tuning Gemma 2 2B on MetaMathQA, our method results in only a $0.8$% drop in accuracy on GSM8K (another math dataset) compared to standard fine-tuning, while preserving $5.4$% more accuracy on the pre-training datasets.
  abstract_embedding: [0.1787109375, 0.349609375, -0.060546875]... (1536 items)
  authors: ['Sunny Sanyal', 'Hayden Prairie', 'Rudrajit Das']... (5 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:28:36.230360
  code_metadata_s3_key: 0ehIW5oBclM7MZc3zZKs/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 0ehIW5oBclM7MZc3zZKs/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468089241
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Upweighting_Easy_Samples_in_Fine-Tuning_Mitigates_Forgetting.pdf
  sha_abstract: 69ccc31f2f102f3ea8c6eaaa74212dfd07d87a1838d73bbab51c7b8c66a8b70a
  title: Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting
  title_normalized: upweighting_easy_samples_in_finetuning_mitigates_forgetting

================================================================================
Document #66 (ID: 5uhJW5oBclM7MZc3SJIa)
================================================================================
  abstract: In this work, we propose a novel approach that combines the strengths of FEAT and TabNet through knowledge distillation (KD), which we term FEAT-KD. FEAT is an intrinsically interpretable machine learning (ML) algorithm that constructs a weighted linear combination of concisely-represented features discovered via genetic programming optimization, which can often be inefficient. FEAT-KD leverages TabNet's deep-learning-based optimization and feature selection mechanisms instead. FEAT-KD finds a weighted linear combination of concisely-represented, symbolic features that are derived from piece-wise distillation of a trained TabNet model. We analyze FEAT-KD on regression tasks from two perspectives: 
(i) compared to TabNet, FEAT-KD significantly reduces model complexity while retaining competitive predictive performance, effectively converting a black-box deep learning model into a more interpretable white-box representation, (ii) compared to FEAT, our method consistently outperforms in prediction accuracy, produces more compact models, and reduces the complexity of learned symbolic expressions. In addition, we demonstrate that FEAT-KD easily supports multi-target regression, in which the shared features contribute to the interpretability of the system. Our results suggest that FEAT-KD is a promising direction for interpretable ML, bridging the gap between deep learning's predictive power and the intrinsic transparency of symbolic models.
  abstract_embedding: [0.46875, 0.2412109375, 0.34765625]... (1536 items)
  authors: ['Kei Sen Fong', 'Mehul Motani']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468120594
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: FEAT-KD__Learning_Concise_Representations_for_Single_and_Multi-Target_Regression_via_TabNet_Knowledge_Distillation.pdf
  sha_abstract: 50256139412c58553165fdadc9c7a804aca7b1cfb489bc048dc7cf79fd3ea6d6
  title: FEAT-KD: Learning Concise Representations for Single and Multi-Target Regression via TabNet Knowledge Distillation
  title_normalized: featkd_learning_concise_representations_for_single_and_multitarget_regression_via_tabnet_knowledge_distillation

================================================================================
Document #67 (ID: 5OhJW5oBclM7MZc3PpJ9)
================================================================================
  abstract: The problem of learning to defer with multiple experts consists of optimally assigning input instances to experts, balancing the trade-off between their accuracy and computational cost. This is a critical challenge in natural language generation, but also in other fields such as image processing, and medical diagnostics. Recent studies have proposed surrogate loss functions to optimize deferral, but challenges remain in ensuring their consistency properties. This paper introduces novel surrogate loss functions and efficient algorithms with strong theoretical learning guarantees. We address open questions regarding realizable $H$-consistency, $H$-consistency bounds, and Bayes-consistency for both single-stage (jointly learning predictor and deferral function) and two-stage (learning only the deferral function with a fixed expert) learning scenarios. For single-stage deferral, we introduce a family of new realizable $H$-consistent surrogate losses and further prove $H$-consistency for a selected member. For two-stage deferral, we derive new surrogate losses that achieve realizable $H$-consistency, $H$-consistency bounds, and Bayes-consistency for the two-expert scenario and, under natural assumptions, multiple-expert
scenario. Additionally, we provide enhanced theoretical guarantees under low-noise assumptions for both scenarios. Finally, we report the results of experiments using our proposed surrogate losses, comparing their performance against existing baselines.
  abstract_embedding: [0.466796875, 0.5234375, 0.13671875]... (1536 items)
  authors: ['Anqi Mao', 'Mehryar Mohri', 'Yutao Zhong']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468118102
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Mastering_Multiple-Expert_Routing__Realizable__H_-Consistency_and_Strong_Guarantees_for_Learning_to_Defer.pdf
  sha_abstract: 9d40284e6f898519130619ba8af8f4d8fd3cb1a4cab577e2b9c2ed492064453a
  title: Mastering Multiple-Expert Routing: Realizable $H$-Consistency and Strong Guarantees for Learning to Defer
  title_normalized: mastering_multipleexpert_routing_realizable_hconsistency_and_strong_guarantees_for_learning_to_defer

================================================================================
Document #68 (ID: 4uhJW5oBclM7MZc3NJIs)
================================================================================
  abstract: In applications with significant class imbalance or asymmetric costs, metrics such as the $F_\beta$-measure, AM measure, Jaccard similarity coefficient, and weighted accuracy offer more suitable evaluation criteria than standard binary classification loss. However, optimizing these metrics present significant computational and statistical challenges. Existing approaches often rely on the characterization of the Bayes-optimal classifier, and use threshold-based methods that first estimate class probabilities and then seek an optimal threshold. This leads to algorithms that are not tailored to restricted hypothesis sets and lack finite-sample performance guarantees. In this work, we introduce principled algorithms for optimizing generalized metrics, supported by $H$-consistency and finite-sample generalization bounds. Our approach reformulates metric optimization as a generalized cost-sensitive learning problem, enabling the design of novel surrogate loss functions with provable $H$-consistency guarantees. Leveraging this framework, we develop new algorithms, METRO (*Metric Optimization*), with strong theoretical performance guarantees. We report the results of experiments demonstrating the effectiveness of our methods compared to prior baselines.
  abstract_embedding: [0.279296875, 0.5390625, 0.051025390625]... (1536 items)
  authors: ['Anqi Mao', 'Mehryar Mohri', 'Yutao Zhong']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468115481
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Principled_Algorithms_for_Optimizing_Generalized_Metrics_in_Binary_Classification.pdf
  sha_abstract: 0eb5dffb893626bea057b552def243a704ef82dfd8865d25c7adbb84e362478f
  title: Principled Algorithms for Optimizing Generalized Metrics in Binary Classification
  title_normalized: principled_algorithms_for_optimizing_generalized_metrics_in_binary_classification

================================================================================
Document #69 (ID: 5ehJW5oBclM7MZc3Q5KT)
================================================================================
  abstract: Class imbalance remains a major challenge in machine learning, especially in multi-class problems with long-tailed distributions. Existing methods, such as data resampling, cost-sensitive techniques, and logistic loss modifications, though popular and often effective, lack solid theoretical foundations. As an example, we demonstrate that cost-sensitive methods  are not Bayes-consistent. This paper introduces a novel theoretical framework for analyzing generalization in imbalanced classification. We propose a new class-imbalanced margin loss function for both binary and multi-class settings, prove its strong $H$-consistency, and derive corresponding learning guarantees based on empirical loss and a new notion of class-sensitive Rademacher complexity. Leveraging these theoretical results, we devise novel and general learning algorithms, IMMAX (*Imbalanced Margin Maximization*), which incorporate confidence margins and are applicable to various hypothesis sets. While our focus is theoretical, we also present extensive empirical results demonstrating the effectiveness of our algorithms compared to existing baselines.
  abstract_embedding: [0.050537109375, 0.71875, 0.0498046875]... (1536 items)
  authors: ['Corinna Cortes', 'Anqi Mao', 'Mehryar Mohri']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468119436
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Balancing_the_Scales__A_Theoretical_and_Algorithmic_Framework_for_Learning_from_Imbalanced_Data.pdf
  sha_abstract: 9fb1df1cc924b5604f45e84b623670ae87e61ba1211d7199650a87c198e4efa2
  title: Balancing the Scales: A Theoretical and Algorithmic Framework for Learning from Imbalanced Data
  title_normalized: balancing_the_scales_a_theoretical_and_algorithmic_framework_for_learning_from_imbalanced_data

================================================================================
Document #70 (ID: 3-hJW5oBclM7MZc3JpJ4)
================================================================================
  abstract: The goal of offline reinforcement learning (RL) is to extract the best possible policy from the previously collected dataset considering the *out-of-distribution* (OOD) sample issue. Offline model-based RL (MBRL) is a captivating solution capable of alleviating such issues through a \textit{state-action transition augmentation} with a learned dynamic model. Unfortunately, offline MBRL methods have been observed to fail in sparse rewarded and long-horizon environments for a long time. In this work, we propose a novel MBRL method, dubbed Temporal Distance-Aware Transition Augmentation (TempDATA), that generates additional transitions in a geometrically structured representation space, instead of state space. For comprehending long-horizon behaviors efficiently, our main idea is to learn state abstraction, which captures a *temporal distance* from both *trajectory and transition levels* of state space. Our experiments empirically confirm that TempDATA outperforms previous offline MBRL methods and achieves matching or surpassing the performance of diffusion-based trajectory augmentation and goal-conditioned RL on the D4RL AntMaze, FrankaKitchen, CALVIN, and pixel-based FrankaKitchen.
  abstract_embedding: [0.8359375, 0.451171875, 0.484375]... (1536 items)
  authors: ['Dongsu Lee', 'Minhae Kwon']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468111967
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Temporal_Distance-aware_Transition_Augmentation_for_Offline_Model-based_Reinforcement_Learning.pdf
  sha_abstract: aee72c00932712b491f8751005482654b454f402d631221ce7e8b73ed2e19602
  title: Temporal Distance-aware Transition Augmentation for Offline Model-based Reinforcement Learning
  title_normalized: temporal_distanceaware_transition_augmentation_for_offline_modelbased_reinforcement_learning

================================================================================
Document #71 (ID: 4ehJW5oBclM7MZc3L5JD)
================================================================================
  abstract: The Area Under the ROC Curve (AUC) is a key metric for classification, especially under class imbalance, with growing research focus on optimizing AUC over accuracy in applications like medical image analysis and deepfake detection. This leads to fairness in AUC optimization becoming crucial as biases can impact protected groups. While various fairness mitigation techniques exist, fairness considerations in AUC optimization remain in their early stages, with most research focusing on improving AUC fairness under the
assumption of clean protected groups. However, these studies often overlook the impact of noisy protected groups, leading to fairness violations in practice. To address this, we propose the first robust AUC fairness approach under noisy protected groups with fairness theoretical guarantees using distributionally robust optimization. Extensive experiments on tabular and image datasets show that our method outperforms state-of-the-art approaches in preserving AUC fairness. The code is in https://github.com/Purdue-M2/AUC_Fairness_with_Noisy_Groups.
  abstract_embedding: [0.1181640625, 0.70703125, 0.00885009765625]... (1536 items)
  authors: ['Mingyang Wu', 'Li Lin', 'Wenbin Zhang']... (6 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468114236
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Preserving_AUC_Fairness_in_Learning_with_Noisy_Protected_Groups.pdf
  sha_abstract: 8fa80d483bc5a36c704a28c1da72a2c5b14dac2eebb342a3502fc3332caaccf2
  title: Preserving AUC Fairness in Learning with Noisy Protected Groups
  title_normalized: preserving_auc_fairness_in_learning_with_noisy_protected_groups

================================================================================
Document #72 (ID: 4OhJW5oBclM7MZc3K5Iq)
================================================================================
  abstract: In this paper, we provide a novel algorithm for solving planning and learning problems of Markov decision processes. 
The proposed algorithm follows a policy iteration-type update by using a rank-one approximation of the transition probability matrix in the policy evaluation step. 
This rank-one approximation is closely related to the stationary distribution of the corresponding transition probability matrix, 
which is approximated using the power method. 
We provide theoretical guarantees for the convergence of the proposed algorithm to optimal (action-)value function with the same rate and computational complexity as the value iteration algorithm in the planning problem and as the Q-learning algorithm in the learning problem. 
Through our extensive numerical simulations, however, we show that the proposed algorithm consistently outperforms first-order algorithms and their accelerated versions for both planning and learning problems.
  abstract_embedding: [0.9765625, 0.00125885009765625, 0.455078125]... (1536 items)
  authors: ['Arman Sharifi Kolarijani', 'Tolga Ok', 'Peyman Mohajerin Esfahani']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468113154
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Rank-One_Modified_Value_Iteration.pdf
  sha_abstract: 47681825c55e1312f48959a6b79c34db59cf1e598fb30a9520341b126a5480a3
  title: Rank-One Modified Value Iteration
  title_normalized: rankone_modified_value_iteration

================================================================================
Document #73 (ID: 4-hJW5oBclM7MZc3OZL5)
================================================================================
  abstract: Large Language Models (LLMs) have demonstrated remarkable potential in scientific domains, yet a fundamental question remains unanswered: Can we simulate human research communities with LLMs? Addressing this question can deepen our understanding of the processes behind idea brainstorming and inspire the automatic discovery of novel scientific insights. In this work, we propose ResearchTown, a multi-agent framework for research community simulation. Within this framework, the human research community is simplified as an agent-data graph, where researchers and papers are represented as agent-type and data-type nodes, respectively, and connected based on their collaboration relationships. We also introduce TextGNN, a text-based inference framework that models various research activities (e.g., paper reading, paper writing, and review writing) as special forms of a unified message-passing process on the agent-data graph. To evaluate the quality of the research community simulation, we present ResearchBench, a benchmark that uses a node-masking prediction task for scalable and objective assessment based on similarity. Our experiments reveal three key findings: (1) ResearchTown can provide a realistic simulation of collaborative research activities, including paper writing and review writing; (2) ResearchTown can maintain robust simulation with multiple researchers and diverse papers; (3) ResearchTown can generate interdisciplinary research ideas that potentially inspire pioneering research directions.
  abstract_embedding: [0.404296875, 0.58203125, 0.0537109375]... (1536 items)
  authors: ['Haofei Yu', 'Zhaochen Hong', 'Zirui Cheng']... (8 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:29:04.484077
  code_metadata_s3_key: 4-hJW5oBclM7MZc3OZL5/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 4-hJW5oBclM7MZc3OZL5/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468116974
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ResearchTown__Simulator_of_Human_Research_Community.pdf
  sha_abstract: 44a2ab5bb16ffadd4fb2c8a3cc511a23e1f02ff88045b162aae31fd68bf0022a
  title: ResearchTown: Simulator of Human Research Community
  title_normalized: researchtown_simulator_of_human_research_community

================================================================================
Document #74 (ID: 2ehJW5oBclM7MZc3A5JZ)
================================================================================
  abstract: Deep tabular models have demonstrated remarkable success on i.i.d. data, excelling in a variety of structured data tasks. 
However, their performance often deteriorates under temporal distribution shifts, where trends and periodic patterns are present in the evolving data distribution over time.
In this paper, we explore the underlying reasons for this failure in capturing temporal dependencies. 
We begin by investigating the training protocol, revealing a key issue in how the data is split for model training and validation.
While existing approaches typically use temporal ordering for splitting, we show that even a random split significantly improves model performance. 
By accounting for reducing training lag and validation bias to achieve better generalization ability, our proposed splitting protocol offers substantial improvements across a variety of methods.
Furthermore, we analyses how temporal data affects deep tabular representations, uncovering that these models often fail to capture crucial periodic and trend information. 
To address this gap, we introduce a plug-and-play temporal embedding based on Fourier series expansion to learn and incorporate temporal patterns, offering an adaptive approach to handle temporal shifts.
Our experiments demonstrate that this temporal embedding, combined with the improved splitting strategy, provides a more effective and robust framework for learning from temporal tabular data.
  abstract_embedding: [0.671875, 0.259765625, 0.609375]... (1536 items)
  authors: ['Haorun Cai', 'Han-Jia Ye']
  code_generated: True
  code_generated_at: 2025-11-06T22:28:51.475027
  code_metadata_s3_key: 2ehJW5oBclM7MZc3A5JZ/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 2ehJW5oBclM7MZc3A5JZ/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468102974
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Understanding_the_Limits_of_Deep_Tabular_Methods_with_Temporal_Shift.pdf
  sha_abstract: 426a58ff4f0f41b007bb70a7102b0cbf733c3d471fa60b338b9f9adddae859ab
  title: Understanding the Limits of Deep Tabular Methods with Temporal Shift
  title_normalized: understanding_the_limits_of_deep_tabular_methods_with_temporal_shift

================================================================================
Document #75 (ID: 5-hJW5oBclM7MZc3TZI_)
================================================================================
  abstract: Machine unlearning addresses the problem of updating a machine learning model/system trained on a dataset $S$ so that the influence of a set of deletion requests $U \subseteq S$ on the unlearned model is minimized. The gold standard definition of unlearning demands that the updated model, after deletion, be nearly identical to the model obtained by retraining. This definition is designed for a worst-case attacker (one who can recover not only the unlearned model but also the remaining data samples, i.e., $S \setminus U$). Such a stringent definition has made developing efficient unlearning algorithms challenging. However, such strong attackers are also unrealistic. In this work, we propose a new definition, *system-aware unlearning*, which aims to provide unlearning guarantees against an attacker that can at best only gain access to the data stored in the system for learning/unlearning requests and not all of $S\setminus U$.  With this new definition, we use the simple intuition that if a system can store less to make its learning/unlearning updates, it can be more secure and update more efficiently against a system-aware attacker. Towards that end, we present an exact system-aware unlearning algorithm for linear classification using a selective sampling-based approach, and we generalize the method for classification with general function classes. We theoretically analyze the tradeoffs between deletion capacity, accuracy, memory, and computation time.
  abstract_embedding: [0.1083984375, 0.341796875, 0.357421875]... (1536 items)
  authors: ['Linda Lu', 'Ayush Sekhari', 'Karthik Sridharan']
  code_generated: True
  code_generated_at: 2025-11-06T22:29:05.534889
  code_metadata_s3_key: 5-hJW5oBclM7MZc3TZI_/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 5-hJW5oBclM7MZc3TZI_/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468121876
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: System-Aware_Unlearning_Algorithms__Use_Lesser__Forget_Faster.pdf
  sha_abstract: 3ce669a6c7c683df646839d7dad524b902a185d2096a92534f8b6bd5c7c3d869
  title: System-Aware Unlearning Algorithms: Use Lesser, Forget Faster
  title_normalized: systemaware_unlearning_algorithms_use_lesser_forget_faster

================================================================================
Document #76 (ID: 6OhJW5oBclM7MZc3VpJQ)
================================================================================
  abstract: Despite tremendous recent progress, generative video models still struggle to capture real-world motion, dynamics, and physics. We show that this limitation arises from the conventional pixel reconstruction objective, which biases models toward appearance fidelity at the expense of motion coherence.
To address this, we introduce **VideoJAM**, a novel framework that instills an effective motion prior to video generators, by encouraging the model to learn *a joint appearance-motion representation*. VideoJAM is composed of two complementary units. During training, we extend the objective to predict both the generated pixels and their corresponding motion from a single learned representation. 
During inference, we introduce **Inner-Guidance**, a mechanism that steers the generation toward coherent motion by leveraging the model's own evolving motion prediction as a dynamic guidance signal.
Notably, our framework can be applied to any video model with minimal adaptations, requiring no modifications to the training data or scaling of the model.
VideoJAM achieves state-of-the-art performance in motion coherence, surpassing highly competitive proprietary models while also enhancing the perceived visual quality of the generations.
These findings emphasize that appearance and motion can be complementary and, when effectively integrated, enhance both the visual quality and the coherence of video generation.
  abstract_embedding: [-0.11328125, 0.11083984375, 0.36328125]... (1536 items)
  authors: ['Hila Chefer', 'Uriel Singer', 'Amit Zohar']... (8 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468124201
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: VideoJAM__Joint_Appearance-Motion_Representations_for_Enhanced_Motion_Generation_in_Video_Models.pdf
  sha_abstract: b8e9e44c1eea6c7c158c711e3d2eddcc43b496c7f3045b8bd9aee3c584659a7e
  title: VideoJAM: Joint Appearance-Motion Representations for Enhanced Motion Generation in Video Models
  title_normalized: videojam_joint_appearancemotion_representations_for_enhanced_motion_generation_in_video_models

================================================================================
Document #77 (ID: 6ehJW5oBclM7MZc3W5JQ)
================================================================================
  abstract: Most successful applications of deep learning involve similar training and test conditions. However, tasks such as biological sequence design involve searching for sequences that improve desirable properties beyond previously known values, which requires novel hypotheses that \emph{extrapolate} beyond training data. In these settings, extrapolation may be achieved by using random search methods such as Markov chain Monte Carlo (MCMC), which, given an initial state, sample local transformations to approximate a target density that rewards states with the desired properties. However, even with a well-designed proposal, MCMC may struggle to explore large structured state spaces efficiently. Rather than relying on stochastic search, it would be desirable to have a model that greedily optimizes the properties of interest, successfully extrapolating in as few steps as possible. We propose to learn such a model from the Markov chains resulting from MCMC search. Specifically, our approach uses selected states from Markov chains as a source of training data for an autoregressive model, which is then able to efficiently generate novel sequences that extrapolate along the sequence-level properties of interest. The proposed approach is validated on three problems: protein sequence design, text sentiment control, and text anonymization. We find that the autoregressive model can extrapolate as well or better than MCMC, but with the additional benefits of scalability and significantly higher sample efficiency.
  abstract_embedding: [0.416015625, 0.63671875, 0.28125]... (1536 items)
  authors: ['Sophia Hager', 'Aleem Khan', 'Andrew Wang']... (4 items)
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468125501
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Learning_Extrapolative_Sequence_Transformations_from_Markov_Chains.pdf
  sha_abstract: e03d9542100d1564abbb3dd2ab75f06d39171c22381fdb81c10f2a699311aad7
  title: Learning Extrapolative Sequence Transformations from Markov Chains
  title_normalized: learning_extrapolative_sequence_transformations_from_markov_chains

================================================================================
Document #78 (ID: 7OhJW5oBclM7MZc3gZLW)
================================================================================
  abstract: We study how inherent randomness in the training process—where each sample (or client in federated learning) contributes only to a randomly selected portion of training—can be leveraged for privacy amplification. This includes (1) data partitioning, where a sample participates in only a subset of training iterations, and (2) model partitioning, where a sample updates only a subset of the model parameters. We apply our framework to model parallelism in federated learning, where each client updates a randomly selected subnetwork to reduce memory and computational overhead, and show that existing methods, e.g. model splitting or dropout, provide a significant privacy amplification gain not captured by previous privacy analysis techniques. Additionally, we introduce balanced iteration subsampling, a new data partitioning method where each sample (or client) participates in a fixed number of training iterations. We show that in certain regimes, this method yields stronger privacy amplification than Poisson (i.i.d.) sampling of data (or clients). Our results demonstrate that randomness in the training process, which is  structured rather than i.i.d. and interacts with data in complex ways, can be systematically leveraged for nontrivial privacy amplification.
  abstract_embedding: [0.16015625, 0.359375, 0.1044921875]... (1536 items)
  authors: ['Andy Dong', 'Wei-Ning Chen', 'Ayfer Ozgur']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468135359
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Leveraging_Randomness_in_Model_and_Data_Partitioning_for_Privacy_Amplification.pdf
  sha_abstract: d88a0ce33f55227fa912ae57b2b99322a72bf0890e66070229678e86c19dede3
  title: Leveraging Randomness in Model and Data Partitioning for Privacy Amplification
  title_normalized: leveraging_randomness_in_model_and_data_partitioning_for_privacy_amplification

================================================================================
Document #79 (ID: 6uhJW5oBclM7MZc3YJI-)
================================================================================
  abstract: We present SketchDNN, a generative model for synthesizing CAD sketches that jointly models both continuous parameters and discrete class labels through a unified continuous-discrete diffusion process. Our core innovation is Gaussian-Softmax diffusion, where logits perturbed with Gaussian noise are projected onto the probability simplex via a softmax transformation, facilitating blended class labels for discrete variables. This formulation addresses 2 key challenges, namely, the heterogeneity of primitive parameterizations and the permutation invariance of primitives in CAD sketches. Our approach significantly improves generation quality, reducing Fréchet Inception Distance (FID) from 16.04 to 7.80 and negative log-likelihood (NLL) from 84.8 to 81.33, establishing a new state-of-the-art in CAD sketch generation on the SketchGraphs dataset.
  abstract_embedding: [-0.138671875, 0.64453125, 0.00640869140625]... (1536 items)
  authors: ['Sathvik Reddy Chereddy', 'John Femiani']
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468126774
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SketchDNN__Joint_Continuous-Discrete_Diffusion_for_CAD_Sketch_Generation.pdf
  sha_abstract: ad8ab43488a52955eaa1f26af32a24cf7044050ae19ca8fc7fb2207649663597
  title: SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation
  title_normalized: sketchdnn_joint_continuousdiscrete_diffusion_for_cad_sketch_generation

================================================================================
Document #80 (ID: 6-hJW5oBclM7MZc3Z5IJ)
================================================================================
  abstract: Whole slide image (WSI) analysis presents significant computational challenges due to the massive number of patches in gigapixel images. While transformer architectures excel at modeling long-range correlations through self-attention, their quadratic computational complexity makes them impractical for computational pathology applications. Existing solutions like local-global or linear self-attention reduce computational costs but compromise the strong modeling capabilities of full self-attention. In this work, we propose **Querent**, *i.e.*, the **quer**y-awar**e** long co**nt**extual dynamic modeling framework, which achieves a theoretically bounded approximation of full self-attention while delivering practical efficiency. Our method adaptively predicts which surrounding regions are most relevant for each patch, enabling focused yet unrestricted attention computation only with potentially important contexts. By using efficient region-wise metadata computation and importance estimation, our approach dramatically reduces computational overhead while preserving global perception to model fine-grained patch correlations. Through comprehensive experiments on biomarker prediction, gene mutation prediction, cancer subtyping, and survival analysis across over 10 WSI datasets, our method demonstrates superior performance compared to the state-of-the-art approaches. Codes are available at https://github.com/dddavid4real/Querent.
  abstract_embedding: [0.3359375, 0.2080078125, 0.05419921875]... (1536 items)
  authors: ['Zhengrui Guo', 'Qichen Sun', 'Jiabo MA']... (6 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:29:30.425572
  code_metadata_s3_key: 6-hJW5oBclM7MZc3Z5IJ/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 6-hJW5oBclM7MZc3Z5IJ/code.py
  date: 2025-06-18
  decision: accept
  ingested_at: 1762468128514
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Context_Matters__Query-aware_Dynamic_Long_Sequence_Modeling_of_Gigapixel_Images.pdf
  sha_abstract: 4befa630463be704cbdb5213470b94a53a2a62effb843fe6945c4a1d7e1ca7f6
  title: Context Matters: Query-aware Dynamic Long Sequence Modeling of Gigapixel Images
  title_normalized: context_matters_queryaware_dynamic_long_sequence_modeling_of_gigapixel_images

================================================================================
Document #81 (ID: 8OhTW5oBclM7MZc3JpJd)
================================================================================
  abstract: Evaluating aligned large language models' (LLMs) ability to recognize and reject unsafe user requests is crucial for safe, policy-compliant deployments. Existing evaluation efforts, however, face three limitations that we address with **SORRY-Bench**, our proposed benchmark. **First**, existing methods often use coarse-grained taxonomies of unsafe topics, and are over-representing some fine-grained topics. For example, among the ten existing datasets that we evaluated, tests for refusals of self-harm instructions are over 3x less represented than tests for fraudulent activities. SORRY-Bench improves on this by using a fine-grained taxonomy of 44 potentially unsafe topics, and 440 class-balanced unsafe instructions, compiled through human-in-the-loop methods. **Second**, evaluations often overlook the linguistic formatting of prompts, like different languages, dialects, and more --- which are only implicitly considered in many evaluations. We supplement SORRY-bench with 20 diverse linguistic augmentations to systematically examine these effects. **Third**, existing evaluations rely on large LLMs (e.g., GPT-4) for evaluation, which can be computationally expensive. We investigate design choices for creating a fast, accurate automated safety evaluator. By collecting 7K+ human annotations and conducting a meta-evaluation of diverse LLM-as-a-judge designs, we show that fine-tuned 7B LLMs can achieve accuracy comparable to GPT-4 scale LLMs, with lower computational cost. Putting these together, we evaluate over 50 proprietary and open-weight LLMs on SORRY-Bench, analyzing their distinctive safety refusal behaviors. We hope our effort provides a building block for systematic evaluations of LLMs' safety refusal capabilities, in a balanced, granular, and efficient manner. Benchmark demo, data, code, and models are available through [https://sorry-bench.github.io](https://sorry-bench.github.io).
  abstract_embedding: [0.6171875, 0.388671875, -0.03564453125]... (1536 items)
  authors: ['Tinghao Xie', 'Xiangyu Qi', 'Yi Zeng']... (16 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468767298
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SORRY-Bench__Systematically_Evaluating_Large_Language_Model_Safety_Refusal.pdf
  sha_abstract: 1132bdc951c96fa4b830c6af27985f86b76112fa1a30d90fe1911cc4c157e5ad
  title: SORRY-Bench: Systematically Evaluating Large Language Model Safety Refusal
  title_normalized: sorrybench_systematically_evaluating_large_language_model_safety_refusal

================================================================================
Document #82 (ID: 8ehTW5oBclM7MZc3LJJi)
================================================================================
  abstract: We propose Framer for interactive frame interpolation, which targets producing smoothly transitioning frames between two images as per user creativity. Concretely, besides taking the start and end frames as inputs, our approach supports customizing the transition process by tailoring the trajectory of some selected keypoints. Such a design enjoys two clear benefits. First, incorporating human interaction mitigates the issue arising from numerous possibilities of transforming one image to another, and in turn enables finer control of local motions. Second, as the most basic form of interaction, keypoints help establish the correspondence across frames, enhancing the model to handle challenging cases (e.g., objects on the start and end frames are of different shapes and styles). It is noteworthy that our system also offers an "autopilot" mode, where we introduce a module to estimate the keypoints and refine the trajectory automatically, to simplify the usage in practice. Extensive experimental results demonstrate the appealing performance of Framer on various applications, such as image morphing, time-lapse video generation, cartoon interpolation, etc. The code, model, and interface are publicly accessible at https://github.com/aim-uofa/Framer.
  abstract_embedding: [0.31640625, 0.375, 0.130859375]... (1536 items)
  authors: ['Wen Wang', 'Qiuyu Wang', 'Kecheng Zheng']... (9 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468768829
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Framer__Interactive_Frame_Interpolation.pdf
  sha_abstract: 79f7cda9d3e369c5f40cc1f1859cffb263308a12d1f02167e673f07e665edb37
  title: Framer: Interactive Frame Interpolation
  title_normalized: framer_interactive_frame_interpolation

================================================================================
Document #83 (ID: 8-hTW5oBclM7MZc3NJL7)
================================================================================
  abstract: Generative Foundation Models (GFMs) have achieved remarkable success in producing high-quality synthetic data for images and text. However, their application to tabular data presents significant challenges due to the heterogeneous nature of table features. Current cross-table learning frameworks struggle because they lack a generative model backbone and an effective mechanism to decode heterogeneous feature values. To address these challenges, we propose the Cross-Table Synthesizer (CTSyn), a diffusion-based generative foundation model for tabular data generation. CTSyn comprises two key components. The first is an autoencoder network that consolidates diverse tables into a unified latent space. It dynamically reconstructs table values using a table schema embedding, allowing adaptation to heterogeneous datasets. The second is a conditional latent diffusion model that generates samples from the learned latent space, conditioned on the table schema. Through large-scale pre-training, CTSyn outperforms existing table synthesizers on standard benchmarks in both utility and diversity.  These results position CTSyn as a promising framework for synthetic table generation and lay the groundwork for developing large-scale tabular foundation models.
  abstract_embedding: [0.5078125, -0.0234375, 0.40625]... (1536 items)
  authors: ['Xiaofeng Lin', 'Chenheng Xu', 'Matthew Yang']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468771055
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CTSyn__A_Foundation_Model_for_Cross_Tabular_Data_Generation.pdf
  sha_abstract: 0e3f1b904ae346acd8fce51a3ae0d89546340f4927c6fa95bf92b06fe5b012d3
  title: CTSyn: A Foundation Model for Cross Tabular Data Generation
  title_normalized: ctsyn_a_foundation_model_for_cross_tabular_data_generation

================================================================================
Document #84 (ID: 8uhTW5oBclM7MZc3MJK_)
================================================================================
  abstract: The prohibitive training costs of Large Language Models (LLMs) have emerged as a significant bottleneck in the development of next-generation LLMs. In this paper, we show that it is possible to significantly reduce the training costs of LLMs without sacrificing their performance. Specifically, we introduce patch-level training for LLMs, in which multiple tokens are aggregated into a unit of higher information density, referred to as a `patch', to serve as the fundamental text unit for training LLMs. During patch-level training, we feed the language model shorter sequences of patches and train it to predict the next patch, thereby processing the majority of the training data at a significantly reduced cost. Following this, the model continues token-level training on the remaining training data to align with the inference mode. Experiments on a diverse range of models (370M-2.7B parameters) demonstrate that patch-level training can reduce the overall training costs to 0.5$\times$, without compromising the model performance compared to token-level training. Source code: \url{https://github.com/shaochenze/PatchTrain}.
  abstract_embedding: [0.291015625, 0.1767578125, 0.162109375]... (1536 items)
  authors: ['Chenze Shao', 'Fandong Meng', 'Jie Zhou']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468769936
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Beyond_Next_Token_Prediction__Patch-Level_Training_for_Large_Language_Models.pdf
  sha_abstract: 9708cfcf22e205df0997b86176d4e0ecbd09b2f0c1216a1a4d6e21eb6fdb2ced
  title: Beyond Next Token Prediction: Patch-Level Training for Large Language Models
  title_normalized: beyond_next_token_prediction_patchlevel_training_for_large_language_models

================================================================================
Document #85 (ID: -uhTW5oBclM7MZc3WpK1)
================================================================================
  abstract: Visual perspective taking (VPT) is the ability to perceive and reason about the perspectives of others. It is an essential feature of human intelligence, which develops over the first decade of life and requires an ability to process the 3D structure of visual scenes. A growing number of reports have indicated that deep neural networks (DNNs) become capable of analyzing 3D scenes after training on large image datasets. We investigated if this emergent ability for 3D analysis in DNNs is sufficient for VPT with the 3D perception challenge (3D-PC): a novel benchmark for 3D perception in humans and DNNs. The 3D-PC is comprised of three 3D-analysis tasks posed within natural scene images: (i.) a simple test of object depth order, (ii.) a basic VPT task (VPT-basic), and (iii.) a more challenging version of VPT (VPT-perturb) designed to limit the effectiveness of "shortcut" visual strategies. We tested human participants (N=33) and linearly probed or text-prompted over 300 DNNs on the challenge and found that nearly all of the DNNs approached or exceeded human accuracy in analyzing object depth order. Surprisingly, DNN accuracy on this task correlated with their object recognition performance. In contrast, there was an extraordinary gap between DNNs and humans on VPT-basic. Humans were nearly perfect, whereas most DNNs were near chance. Fine-tuning DNNs on VPT-basic brought them close to human performance, but they, unlike humans, dropped back to chance when tested on VPT-perturb. Our challenge demonstrates that the training routines and architectures of today's DNNs are well-suited for learning basic 3D properties of scenes and objects but are ill-suited for reasoning about these properties like humans do. We release our 3D-PC datasets and code to help bridge this gap in 3D perception between humans and machines.
  abstract_embedding: [0.65234375, 0.341796875, 0.259765625]... (1536 items)
  authors: ['Drew Linsley', 'Peisen Zhou', 'Alekh Karkada Ashok']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468780715
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: The_3D-PC__a_benchmark_for_visual_perspective_taking_in_humans_and_machines.pdf
  sha_abstract: 9585d404d528dfa529c1117d0589fd23f599b5c8abee4464b3f10bd7ef74450b
  title: The 3D-PC: a benchmark for visual perspective taking in humans and machines
  title_normalized: the_3dpc_a_benchmark_for_visual_perspective_taking_in_humans_and_machines

================================================================================
Document #86 (ID: -OhTW5oBclM7MZc3T5IM)
================================================================================
  abstract: Large language models (LLMs) have achieved reasonable quality improvements in machine translation (MT).
However, most current research on MT-LLMs still faces significant challenges in maintaining translation consistency and accuracy when processing entire documents.
In this paper, we introduce DelTA, a Document-levEL Translation Agent designed to overcome these limitations.
DelTA features a multi-level memory structure that stores information across various granularities and spans, including Proper Noun Records, Bilingual Summary, Long-Term Memory, and Short-Term Memory, which are continuously retrieved and updated by auxiliary LLM-based components.
Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets, achieving an increase in consistency scores by up to 4.58 percentage points and in COMET scores by up to 3.16 points on average.
DelTA employs a sentence-by-sentence translation strategy, ensuring no sentence omissions and offering a memory-efficient solution compared to the mainstream method.
Furthermore, DelTA improves pronoun and context-dependent translation accuracy, and the summary component of the agent also shows promise as a tool for query-based summarization tasks.
The code and data of our approach are released at https://github.com/YutongWang1216/DocMTAgent.
  abstract_embedding: [0.89453125, 0.0247802734375, -0.04833984375]... (1536 items)
  authors: ['Yutong Wang', 'Jiali Zeng', 'Xuebo Liu']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468777696
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: DelTA__An_Online_Document-Level_Translation_Agent_Based_on_Multi-Level_Memory.pdf
  sha_abstract: f5aee9f167eb47888090f3c8ed664c0fea08c93410f1296da9a2eaf3e0521126
  title: DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory
  title_normalized: delta_an_online_documentlevel_translation_agent_based_on_multilevel_memory

================================================================================
Document #87 (ID: --hTW5oBclM7MZc3YJJU)
================================================================================
  abstract: In this work, we focus on Weakly Supervised Spatio-Temporal Video Grounding (WSTVG). It is a multimodal task aimed at localizing specific subjects  spatio-temporally based on textual queries without bounding box supervision. Motivated by recent advancements in multi-modal foundation models for grounding tasks, we first explore the potential of state-of-the-art object detection models for WSTVG. Despite their robust zero-shot capabilities, our adaptation reveals significant limitations, including inconsistent temporal predictions, inadequate understanding of complex queries, and challenges in adapting to difficult scenarios. We propose CoSPaL (Contextual Self-Paced Learning), a novel approach which is designed to overcome these limitations. CoSPaL integrates three core components: (1) Tubelet Phrase Grounding (TPG), which introduces spatio-temporal prediction by linking textual queries to tubelets; (2) Contextual Referral Grounding (CRG), which improves comprehension of complex queries by extracting contextual information to refine object identification over time; and (3) Self-Paced Scene Understanding (SPS), a training paradigm that progressively increases task difficulty, enabling the model to adapt to complex scenarios by transitioning from coarse to fine-grained understanding.
  abstract_embedding: [-0.2080078125, 0.1220703125, 0.515625]... (1536 items)
  authors: ['Akash Kumar', 'Zsolt Kira', 'Yogesh S Rawat']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468782155
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Contextual_Self-paced_Learning_for_Weakly_Supervised_Spatio-Temporal_Video_Grounding.pdf
  sha_abstract: f0ef99df8e38574f2f50aa9ed6a0bb51cef9b41af8cda2245698d6a5d3c13bb8
  title: Contextual Self-paced Learning for Weakly Supervised Spatio-Temporal Video Grounding
  title_normalized: contextual_selfpaced_learning_for_weakly_supervised_spatiotemporal_video_grounding

================================================================================
Document #88 (ID: _ehTW5oBclM7MZc3apLy)
================================================================================
  abstract: Real-world formal theorem proving often depends on a wealth of context, including definitions, lemmas, comments, file structure, and other information. We introduce $\texttt{miniCTX}$, which tests a model's ability to prove formal mathematical theorems that depend on new context that is not seen during training. $\texttt{miniCTX}$ contains theorems sourced from real Lean projects and textbooks, each associated with a context that can span tens of thousands of tokens. Models are tasked with proving a theorem given access to code from the theorem's repository, which contains context that is needed for the proof. As a baseline for $\texttt{miniCTX}$, we tested fine-tuning and prompting methods that condition theorem proving on preceding context. Both approaches substantially outperform traditional methods that rely solely on state information. We found that this ability to use context is not captured by previous benchmarks such as $\texttt{miniF2F}$. Alongside $\texttt{miniCTX}$, we offer $\texttt{ntp-toolkit}$ for automatically extracting and annotating theorem proving data, making it easy to add new projects into $\texttt{miniCTX}$ to ensure that contexts are not seen during training. $\texttt{miniCTX}$ offers a challenging and realistic evaluation of neural theorem provers.
  abstract_embedding: [0.66796875, 0.5625, 0.1298828125]... (1536 items)
  authors: ['Jiewen Hu', 'Thomas Zhu', 'Sean Welleck']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468784875
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: miniCTX__Neural_Theorem_Proving_with__Long-_Contexts.pdf
  sha_abstract: 2ecffffc4e68527d96a2c53287f70d7f192e37ae36cefe300b2529ef89d3f3ca
  title: miniCTX: Neural Theorem Proving with (Long-)Contexts
  title_normalized: minictx_neural_theorem_proving_with_longcontexts

================================================================================
Document #89 (ID: 9-hTW5oBclM7MZc3SZKt)
================================================================================
  abstract: Memorization in language models is typically treated as a homogenous phenomenon, neglecting the specifics of the memorized data. We instead model memorization as the effect of a set of complex factors that describe each sample and relate it to the model and corpus. To build intuition around these factors, we break memorization down into a taxonomy: recitation of highly duplicated sequences, reconstruction of inherently predictable sequences, and recollection of sequences that are neither. We demonstrate the usefulness of our taxonomy by using it to construct a predictive model for memorization. By analyzing dependencies and inspecting the weights of the predictive model, we find that different factors have different influences on the likelihood of memorization depending on the taxonomic category.
  abstract_embedding: [0.30859375, 0.30859375, -0.263671875]... (1536 items)
  authors: ['USVSN Sai Prashanth', 'Alvin Deng', "Kyle O'Brien"]... (12 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468776355
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Recite__Reconstruct__Recollect__Memorization_in_LMs_as_a_Multifaceted_Phenomenon.pdf
  sha_abstract: f478eb2ea9eaebe040e47758bd9f448039cb741aa313358df9d9c28a00a004be
  title: Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon
  title_normalized: recite_reconstruct_recollect_memorization_in_lms_as_a_multifaceted_phenomenon

================================================================================
Document #90 (ID: _OhTW5oBclM7MZc3ZpIG)
================================================================================
  abstract: Cascades and speculative decoding are two common approaches to improving language models' inference efficiency.  Both approaches interleave two models, but via fundamentally distinct mechanisms: deferral rule that invokes the larger model only for “hard” inputs, while  speculative decoding uses speculative execution to primarily invoke the larger model in parallel scoring mode. These mechanisms offer different benefits: empirically, cascades offer compelling cost-quality trade-offs, often even outperforming the large model; speculative cascades offer impressive speed-ups, while guaranteeing quality-neutrality. In this paper, we leverage the best of both these approaches by designing new speculative cascading techniques that implement their deferral rule through speculative execution. We characterize the optimal deferral rule for our speculative cascades, and employ a plug-in approximation to the optimal rule.  Experiments with Gemma and T5 models on a range of language benchmarks show that our approach yields better cost quality trade-offs than cascading and speculative decoding baselines.
  abstract_embedding: [0.259765625, 0.275390625, 0.11962890625]... (1536 items)
  authors: ['Harikrishna Narasimhan', 'Wittawat Jitkrittum', 'Ankit Singh Rawat']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468783581
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Faster_Cascades_via_Speculative_Decoding.pdf
  sha_abstract: c1740e4314d3ff87a4c6b53014889f0eada36cfb0e6ecf2e8582608fb1d7f6db
  title: Faster Cascades via Speculative Decoding
  title_normalized: faster_cascades_via_speculative_decoding

================================================================================
Document #91 (ID: 7ehTW5oBclM7MZc3GpJb)
================================================================================
  abstract: This paper proposes the Degradation Classification Pre-Training (DCPT), which enables models to learn how to classify the degradation type of input images for universal image restoration pre-training. Unlike the existing self-supervised pre-training methods, DCPT utilizes the degradation type of the input image as an extremely weak supervision, which can be effortlessly obtained, even intrinsic in all image restoration datasets. DCPT comprises two primary stages. Initially, image features are extracted from the encoder. Subsequently, a lightweight decoder, such as ResNet18, is leveraged to classify the degradation type of the input image solely based on the features extracted in the first stage, without utilizing the input image. The encoder is pre-trained with a straightforward yet potent DCPT, which is used to address universal image restoration and achieve outstanding performance. Following DCPT, both convolutional neural networks (CNNs) and transformers demonstrate performance improvements, with gains of up to 2.55 dB in the 10D all-in-one restoration task and 6.53 dB in the mixed degradation scenarios. Moreover, previous self-supervised pretraining methods, such as masked image modeling, discard the decoder after pre-training, while our DCPT utilizes the pre-trained parameters more effectively. This superiority arises from the degradation classifier acquired during DCPT, which facilitates transfer learning between models of identical architecture trained on diverse degradation types. Source code and models are available at \url{https://github.com/MILab-PKU/dcpt}.
  abstract_embedding: [-0.07373046875, 0.0306396484375, -0.08349609375]... (1536 items)
  authors: ['JiaKui Hu', 'Lujia Jin', 'Zhengjian Yao']... (4 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:39:45.140457
  code_metadata_s3_key: 7ehTW5oBclM7MZc3GpJb/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 7ehTW5oBclM7MZc3GpJb/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468764158
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Universal_Image_Restoration_Pre-training_via_Degradation_Classification.pdf
  sha_abstract: 0ffa4f4e1c77c9dfa3cd11b517bf448061d610b00c411635b5103a0d6b234c86
  title: Universal Image Restoration Pre-training via Degradation Classification
  title_normalized: universal_image_restoration_pretraining_via_degradation_classification

================================================================================
Document #92 (ID: 7uhTW5oBclM7MZc3HZLb)
================================================================================
  abstract: Graph Domain Adaptation (GDA) addresses a pressing challenge in cross-network learning, particularly pertinent due to the absence of labeled data in real-world graph datasets. Recent studies attempted to learn domain invariant representations by eliminating structural shifts between graphs. In this work, we show that existing methodologies have overlooked the significance of the graph node attribute, a pivotal factor for graph domain alignment. 
Specifically, we first reveal the impact of node attributes for GDA by theoretically proving that in addition to the graph structural divergence between the domains, the node attribute discrepancy also plays a critical role in GDA. Moreover, we also empirically show that the attribute shift is more substantial than the topology shift, which further underscore the importance of node attribute alignment in GDA. Inspired by this finding, a novel cross-channel module is developed to fuse and align both views between the source and target graphs for GDA. Experimental results on a variety of benchmark verify the effectiveness of our method.
  abstract_embedding: [0.296875, 0.30078125, -0.0693359375]... (1536 items)
  authors: ['Ruiyi Fang', 'Bingheng Li', 'zhao kang']... (8 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:39:49.285181
  code_metadata_s3_key: 7uhTW5oBclM7MZc3HZLb/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 7uhTW5oBclM7MZc3HZLb/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468765135
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: On_the_Benefits_of_Attribute-Driven_Graph_Domain_Adaptation.pdf
  sha_abstract: 32639fb627fececb4968bd2121248d5f9edebfae77eceb9bca62788b1b5a51ef
  title: On the Benefits of Attribute-Driven Graph Domain Adaptation
  title_normalized: on_the_benefits_of_attributedriven_graph_domain_adaptation

================================================================================
Document #93 (ID: _uhTW5oBclM7MZc3cZLX)
================================================================================
  abstract: Robust fine-tuning aims to adapt large foundation models to downstream tasks while preserving their robustness to distribution shifts. Existing methods primarily focus on constraining and projecting current model towards the pre-trained initialization based on the magnitudes between fine-tuned and pre-trained weights, which often require extensive hyper-parameter tuning and can sometimes result in underfitting. In this work, we propose $\textbf{Di}$rectional $\textbf{Gra}$dient $\textbf{P}$rojection (DiGraP), a novel layer-wise trainable method that incorporates directional information from gradients to bridge regularization and multi-objective optimization. Besides demonstrating our method on image classification, as another contribution we generalize this area to the multi-modal evaluation settings for robust fine-tuning. Specifically, we first bridge the uni-modal and multi-modal gap by performing analysis on Image Classification reformulated Visual Question Answering (VQA) benchmarks and further categorize ten out-of-distribution (OOD) VQA datasets by distribution shift types and degree (i.e. near versus far OOD). Experimental results show that DiGraP consistently outperforms existing baselines across Image Classfication and VQA tasks with discriminative and generative backbones, improving both in-distribution (ID) generalization and OOD robustness.
  abstract_embedding: [0.34375, 0.5390625, 0.1337890625]... (1536 items)
  authors: ['Chengyue Huang', 'Junjiao Tian', 'Brisa Maneechotesuwan']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468786635
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Directional_Gradient_Projection_for_Robust_Fine-Tuning_of_Foundation_Models.pdf
  sha_abstract: ba5d0249766995fe9964cf3837984acec094b1a550edbb523f9d42f97e68d001
  title: Directional Gradient Projection for Robust Fine-Tuning of Foundation Models
  title_normalized: directional_gradient_projection_for_robust_finetuning_of_foundation_models

================================================================================
Document #94 (ID: A-hTW5oBclM7MZc3jZMt)
================================================================================
  abstract: An important prerequisite for safe control is aligning the policy with the underlying constraints in the environment. In many real-world applications, due to the difficulty of manually specifying these constraints, existing works have proposed recovering constraints from expert demonstrations by solving the Inverse Constraint Learning (ICL) problem. However, ICL is inherently ill-posed, as multiple constraints can equivalently explain the experts' preferences, making the optimal solutions not uniquely identifiable. In this work, instead of focusing solely on a single constraint, we propose the novel approach of Exploratory ICL (ExICL). The goal of ExICL is to recover a diverse set of feasible constraints, thereby providing practitioners the flexibility to select the most appropriate constraint based on the practical needs of deployment. To achieve this goal, we design a generative diffusion verifier that guides the trajectory generation process using the probabilistic representation of an optimal constrained policy. By comparing these decisions with those made by expert agents, we can efficiently verify a candidate constraint. Driven by the verification feedback, ExICL implements an exploratory constraint update mechanism that strategically facilitates diversity within the collection of feasible constraints. Our empirical results demonstrate that ExICL can seamlessly and reliably generalize across different tasks and environments. The code is available at https://github.com/ZhaoRunyi/ExICL.
  abstract_embedding: [0.57421875, 0.73046875, -0.039306640625]... (1536 items)
  authors: ['Runyi Zhao', 'Sheng Xu', 'Bo Yue']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468793635
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Toward_Exploratory_Inverse_Constraint_Inference_with_Generative_Diffusion_Verifiers.pdf
  sha_abstract: 4d18304d337bc38f84922e8603772c257d14737c3af47ca881dcc542344cdf01
  title: Toward Exploratory Inverse Constraint Inference with Generative Diffusion Verifiers
  title_normalized: toward_exploratory_inverse_constraint_inference_with_generative_diffusion_verifiers

================================================================================
Document #95 (ID: BOhTW5oBclM7MZc3k5PP)
================================================================================
  abstract: Domain Generalization (DG) aims to learn from multiple known source domains a model that can generalize well to unknown target domains. One of the key approaches in DG is training an encoder which generates domain-invariant representations. However, this approach is not applicable in Federated Domain Generalization (FDG), where data from various domains are distributed across different clients. In this paper, we introduce a novel approach, dubbed Federated Learning via On-server Matching Gradient (FedOMG), which can efficiently leverage domain information from distributed domains. Specifically, we utilize the local gradients as information about the distributed models to find an invariant gradient direction across all domains through gradient inner product maximization. The advantages are two-fold: 1) FedOMG can aggregate the characteristics of distributed models on the centralized server without incurring any additional communication cost, and 2) FedOMG is orthogonal to many existing FL/FDG methods, allowing for additional performance improvements by being seamlessly integrated with them. Extensive experimental evaluations on various settings demonstrate the robustness of FedOMG compared to other FL/FDG baselines. Our method outperforms recent SOTA baselines on four FL benchmark datasets (MNIST, EMNIST, CIFAR-10, and CIFAR-100), and three FDG benchmark datasets (PACS, VLCS, and OfficeHome). The reproducible code is publicly available~\footnote[1]{\url{https://github.com/skydvn/fedomg}}.
  abstract_embedding: [0.625, 0.4609375, -0.13671875]... (1536 items)
  authors: ['Trong Binh Nguyen', 'Duong Minh Nguyen', 'Jinsun Park']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468795297
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Federated_Domain_Generalization_with_Data-free_On-server_Matching_Gradient.pdf
  sha_abstract: e5451dd8105d59d1129baa649e484046b9abe7b66cec7d026cd08ddafc3bf941
  title: Federated Domain Generalization with Data-free On-server Matching Gradient
  title_normalized: federated_domain_generalization_with_datafree_onserver_matching_gradient

================================================================================
Document #96 (ID: AuhTW5oBclM7MZc3iJNl)
================================================================================
  abstract: We explore neuro-symbolic approaches to generalize actionable knowledge, enabling embodied agents to tackle complex tasks more effectively in open-domain environments. A key challenge for embodied agents is the generalization of knowledge across diverse environments and situations, as limited experiences often confine them to their prior knowledge. To address this issue, we introduce a novel framework, NeSyC, a neuro-symbolic continual learner that emulates the hypothetico-deductive model by continually formulating and validating knowledge from limited experiences through the combined use of Large Language Models (LLMs) and symbolic tools. Specifically, we devise a contrastive generality improvement scheme within NeSyC, which iteratively generates hypotheses using LLMs and conducts contrastive validation via symbolic tools. This scheme reinforces the justification for admissible actions while minimizing the inference of inadmissible ones. Additionally, we incorporate a memory-based monitoring scheme that efficiently detects action errors and triggers the knowledge refinement process across domains. Experiments conducted on diverse embodied task benchmarks—including ALFWorld, VirtualHome, Minecraft, RLBench, and a real-world robotic scenario—demonstrate that NeSyC is highly effective in solving complex embodied tasks across a range of open-domain environments.
  abstract_embedding: [0.6640625, 0.267578125, 0.2734375]... (1536 items)
  authors: ['Wonje Choi', 'Jinwoo Park', 'Sanghyun Ahn']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468792376
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: NeSyC__A_Neuro-symbolic_Continual_Learner_For_Complex_Embodied_Tasks_in_Open_Domains.pdf
  sha_abstract: 174ab84a6e13c0f94b91c0fc30c0c130aabe6c3bb1898c7e106dddef745edae2
  title: NeSyC: A Neuro-symbolic Continual Learner For Complex Embodied Tasks in Open Domains
  title_normalized: nesyc_a_neurosymbolic_continual_learner_for_complex_embodied_tasks_in_open_domains

================================================================================
Document #97 (ID: AOhTW5oBclM7MZc3e5Mz)
================================================================================
  abstract: Diffusion Language Models (DLMs) have emerged as a promising new paradigm for text generative modeling, potentially addressing limitations of autoregressive (AR) models. However, current DLMs have been studied at a smaller scale compared to their AR counterparts and lack fair comparison on language modeling benchmarks. Additionally, training diffusion models from scratch at scale remains challenging. Given the prevalence of open-source AR language models, we propose adapting these models to build text diffusion models. We demonstrate connections between AR and diffusion modeling objectives and introduce a simple continual pre-training approach for training diffusion models. Through systematic evaluation on language modeling, reasoning, and commonsense benchmarks, we show that we can convert AR models ranging from 127M to 7B parameters (GPT2 and LLaMA) into diffusion models DiffuGPT and DiffuLLaMA, using less than 200B tokens for training. Our experimental results reveal that these models outperform earlier DLMs and are competitive with their AR counterparts. We release a suite of DLMs (127M-355M-7B) capable of generating fluent text, performing in-context learning, filling in the middle without prompt re-ordering, and following instructions.
  abstract_embedding: [0.259765625, 0.380859375, 0.294921875]... (1536 items)
  authors: ['Shansan Gong', 'Shivam Agarwal', 'Yizhe Zhang']... (12 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468788997
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Scaling_Diffusion_Language_Models_via_Adaptation_from_Autoregressive_Models.pdf
  sha_abstract: 78f73b00d77f60394656599f83889b95403bbb4502ce0e3651797efb6939554d
  title: Scaling Diffusion Language Models via Adaptation from Autoregressive Models
  title_normalized: scaling_diffusion_language_models_via_adaptation_from_autoregressive_models

================================================================================
Document #98 (ID: _-hTW5oBclM7MZc3dpJy)
================================================================================
  abstract: A recent line of work in mechanistic interpretability has focused on reverse-engineering the computation performed by neural networks trained on the binary operation of finite groups. We investigate the internals of one-hidden-layer neural networks trained on this task, revealing previously unidentified structure and producing a more complete description of such models in a step towards unifying the explanations of previous works (Chughtai et al., 2023; Stander et al., 2024). Notably, these models approximate equivariance in each input argument. We verify that our explanation applies to a large fraction of networks trained on this task by translating it into a compact proof of model performance, a quantitative evaluation of the extent to which we faithfully and concisely explain model internals. In the main text, we focus on the symmetric group S5. For models trained on this group, our explanation yields a guarantee of model accuracy that runs 3x faster than brute force and gives a >=95% accuracy bound for 45% of the models we trained. We were unable to obtain nontrivial non-vacuous accuracy bounds using only explanations from previous works.
  abstract_embedding: [0.0166015625, 0.392578125, 0.056640625]... (1536 items)
  authors: ['Wilson Wu', 'Louis Jaburi', 'jacob drori']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468787777
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Towards_a_Unified_and_Verified_Understanding_of_Group-Operation_Networks.pdf
  sha_abstract: d475afb9f3dd8840f600b5793dbe4d0b8a4fcf5d77c57facc38018254f2708d0
  title: Towards a Unified and Verified Understanding of Group-Operation Networks
  title_normalized: towards_a_unified_and_verified_understanding_of_groupoperation_networks

================================================================================
Document #99 (ID: AehTW5oBclM7MZc3gpNP)
================================================================================
  abstract: We introduce DrugFlow, a generative model for structure-based drug design that integrates continuous flow matching with discrete Markov bridges, demonstrating state-of-the-art performance in learning chemical, geometric, and physical aspects of three-dimensional protein-ligand data. We endow DrugFlow with an uncertainty estimate that is able to detect out-of-distribution samples. To further enhance the sampling process towards distribution regions with desirable metric values, we propose a joint preference alignment scheme applicable to both flow matching and Markov bridge frameworks. Furthermore, we extend our model to also explore the conformational landscape of the protein by jointly sampling side chain angles and molecules.
  abstract_embedding: [0.3515625, 0.361328125, 0.3046875]... (1536 items)
  authors: ['Arne Schneuing', 'Ilia Igashov', 'Adrian W. Dobbelstein']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468790855
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Multi-domain_Distribution_Learning_for_De_Novo_Drug_Design.pdf
  sha_abstract: 7299172cd01a0123aae5f15f4fa31f56f0fe25422cdc70ad62a6b2f3687da9d2
  title: Multi-domain Distribution Learning for De Novo Drug Design
  title_normalized: multidomain_distribution_learning_for_de_novo_drug_design

================================================================================
Document #100 (ID: 9ehTW5oBclM7MZc3PpLl)
================================================================================
  abstract: Knowledge distillation (KD) is widely used to train small, high-performing student language models (LMs) using large teacher LMs. 
While effective in fine-tuning, KD during pre-training faces efficiency, flexibility, and effectiveness issues. 
Existing methods either incur high computational costs due to online teacher inference, require tokenization matching between teacher and student LMs, or risk losing the difficulty and diversity of the teacher-generated training data.
In this work, we propose **MiniPLM**, a KD framework for pre-training LMs by refining the training data distribution with the teacher LM's knowledge.
For efficiency, MiniPLM performs offline teacher inference, allowing KD for multiple student LMs without adding training costs.
For flexibility, MiniPLM operates solely on the training corpus, enabling KD across model families.
For effectiveness, MiniPLM leverages the differences between large and small LMs to enhance the training data difficulty and diversity, helping student LMs acquire versatile and sophisticated knowledge.
Extensive experiments demonstrate that MiniPLM boosts the student LMs' performance on 9 common downstream tasks, improves language modeling capabilities, and reduces pre-training computation. 
The benefit of MiniPLM extends to larger training scales, evidenced by the scaling curve extrapolation.
Further analysis reveals that MiniPLM supports KD across model families and enhances the pre-training data utilization. Our code, data, and models can be found at https://github.com/thu-coai/MiniPLM.
  abstract_embedding: [0.4296875, 0.44921875, 0.392578125]... (1536 items)
  authors: ['Yuxian Gu', 'Hao Zhou', 'Fandong Meng']... (5 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:40:04.202380
  code_metadata_s3_key: 9ehTW5oBclM7MZc3PpLl/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 9ehTW5oBclM7MZc3PpLl/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468773595
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MiniPLM__Knowledge_Distillation_for_Pre-training_Language_Models.pdf
  sha_abstract: 23c4a07f43020622c025e4aecec48dd5be474aeb05ee40c87ab7d2d8cc02dfee
  title: MiniPLM: Knowledge Distillation for Pre-training Language Models
  title_normalized: miniplm_knowledge_distillation_for_pretraining_language_models

================================================================================
Document #101 (ID: 7-hTW5oBclM7MZc3IZJs)
================================================================================
  abstract: The dynamics of information diffusion within graphs is a critical open issue that heavily influences graph representation learning, especially when considering long-range propagation. This calls for principled approaches that control and regulate the degree of propagation and dissipation of information throughout the neural flow. Motivated by this, we introduce port-Hamiltonian Deep Graph Networks, a novel framework that models neural information flow in graphs by building on the laws of conservation of Hamiltonian dynamical systems. We reconcile under a single theoretical and practical framework both non-dissipative long-range propagation and non-conservative behaviors, introducing tools from mechanical systems to gauge the equilibrium between the two components. Our approach can be applied to general message-passing architectures, and it provides theoretical guarantees on information conservation in time. Empirical results prove the effectiveness of our port-Hamiltonian scheme in pushing simple graph convolutional architectures to state-of-the-art performance in long-range benchmarks.
  abstract_embedding: [0.59765625, 0.318359375, -0.0189208984375]... (1536 items)
  authors: ['Simon Heilig', 'Alessio Gravina', 'Alessandro Trenta']... (5 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:40:05.119845
  code_metadata_s3_key: 7-hTW5oBclM7MZc3IZJs/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 7-hTW5oBclM7MZc3IZJs/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468766000
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Port-Hamiltonian_Architectural_Bias_for_Long-Range_Propagation_in_Deep_Graph_Networks.pdf
  sha_abstract: d9b47761e54c4140622ea15eb058b1db477fc309e9ef0d92b3597e3d7e1f5b0d
  title: Port-Hamiltonian Architectural Bias for Long-Range Propagation in Deep Graph Networks
  title_normalized: porthamiltonian_architectural_bias_for_longrange_propagation_in_deep_graph_networks

================================================================================
Document #102 (ID: 9uhTW5oBclM7MZc3RJLR)
================================================================================
  abstract: In response to the call for agent-based solutions that leverage the ever-increasing capabilities of the deep models' ecosystem, we introduce a comprehensive solution for selecting appropriate models and subsequently planning a set of atomic actions to satisfy the end-users' instructions.

Our system, Hive, operates over sets of models and, upon receiving natural language instructions, schedules and executes, explainable plans of atomic actions. These actions can involve one or more of the available models to achieve the overall task, while respecting end-users specific constraints. Hive is able to plan complex chains of actions while guaranteeing explainability, using an LLM-based formal logic backbone empowered by PDDL operations. We introduce the MuSE benchmark in order to offer a comprehensive evaluation of the multi-modal capabilities of agent systems. Our findings show that our framework redefines the state-of-the-art for task selection, outperforming other competing systems that plan operations across multiple models while offering transparency guarantees while fully adhering to user constraints.
  abstract_embedding: [0.8515625, 0.06103515625, 0.447265625]... (1536 items)
  authors: ['Kaustubh Vyas', 'Damien Graux', 'Yijun Yang']... (11 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:40:00.889383
  code_metadata_s3_key: 9uhTW5oBclM7MZc3RJLR/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 9uhTW5oBclM7MZc3RJLR/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468775076
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: From_an_LLM_Swarm_to_a_PDDL-empowered_Hive__Planning_Self-executed_Instructions_in_a_Multi-modal_Jungle.pdf
  sha_abstract: b4a622954b6e7560e33006a2eb89c6174322b980169809f88b9b2a00cd3663dd
  title: From an LLM Swarm to a PDDL-empowered Hive: Planning Self-executed Instructions in a Multi-modal Jungle
  title_normalized: from_an_llm_swarm_to_a_pddlempowered_hive_planning_selfexecuted_instructions_in_a_multimodal_jungle

================================================================================
Document #103 (ID: B-hTW5oBclM7MZc3ppPi)
================================================================================
  abstract: Vision Language Models (VLMs) have demonstrated strong capabilities across various visual understanding and reasoning tasks, driven by incorporating image representations into the token inputs of Large Language Models (LLMs). However, their real-world deployment is often constrained by high latency during inference due to the substantial compute required by the LLM to process the large number of input tokens, predominantly arising from the image. To reduce inference costs, one can either downsize the LLM or reduce the number of input tokens needed to represent the image, the latter of which has been the focus of many recent efforts around token compression. However, it is unclear what the optimal trade-off is given a fixed inference budget. 
We first characterize this optimal trade-off between the number of visual tokens and LLM parameters by establishing scaling laws that capture variations in performance with these two factors. Our results reveal a surprising trend: for visual reasoning tasks, the inference-optimal behavior in VLMs is achieved by using the largest LLM that fits within the inference budget while minimizing visual token count - often to a single token. While the token reduction literature has mainly focused on maintaining base model performance by modestly reducing the token count (e.g., $5-10\times$), our results indicate that the compute-optimal inference regime requires operating under even higher token compression ratios. Based on these insights, we take the first steps toward designing token compression algorithms tailored for high-compression settings, utilizing prompt-based compression of tokens. Our work underscores the performance and efficiency benefits of operating in low visual token regimes and the importance of developing tailored token reduction algorithms for such conditions.
  abstract_embedding: [0.061279296875, 0.263671875, 0.51171875]... (1536 items)
  authors: ['Kevin Li', 'Sachin Goyal', 'João D. Semedo']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468800215
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Inference_Optimal_VLMs_Need_Fewer_Visual_Tokens_and_More_Parameters.pdf
  sha_abstract: c88738c13ff825d5d3d77962d25af31795562c13e261e7c4c382f4650d5b6780
  title: Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters
  title_normalized: inference_optimal_vlms_need_fewer_visual_tokens_and_more_parameters

================================================================================
Document #104 (ID: BehTW5oBclM7MZc3mZPn)
================================================================================
  abstract: Large Language Model's are instruction-finetuned to enhance their ability to follow user instructions and better comprehend input context. Still, they often struggle to follow the input context, especially when it contradicts model's parametric knowledge. This manifests as various failures, such as hallucinations where a model inserts outdated or unwarranted facts into its response. In this work, we observe an intriguing phenomenon: the context reliance of the model decreases as instruction finetuning progresses, $\textit{despite an initial expected increase}$. We call this phenomenon as the $\textbf{context-parametric inversion}$. This is surprising, as one would expect instruction tuning to improve the model's ability to follow input instructions.  We observe this behavior on multiple general purpose instruction tuning datasets such as TULU, Alpaca and Ultrachat, across multiple model families like Llama, Mistral and Pythia.  We perform various controlled studies to eliminate some simple hypothesis for this observed behavior and isolate what datapoints cause this counter-intuitive behavior. We then analyze the phenomenon theoretically, to explain why context reliance varies across the trajectory of finetuning. 
We tie the observed context-parametric inversion to the properties of the finetuning data, which provides us with some potential mitigation strategies that provide limited but insightful gains.
  abstract_embedding: [0.443359375, 0.279296875, -0.041748046875]... (1536 items)
  authors: ['Sachin Goyal', 'Christina Baek', 'J Zico Kolter']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468796865
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Context-Parametric_Inversion__Why_Instruction_Finetuning_May_Not_Actually_Improve_Context_Reliance.pdf
  sha_abstract: ddb23dfb5f724a0aa2c4422256a6951b7cea7096a55b22eda400200b1b3bfe64
  title: Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance
  title_normalized: contextparametric_inversion_why_instruction_finetuning_may_not_actually_improve_context_reliance

================================================================================
Document #105 (ID: C-hTW5oBclM7MZc3wZPH)
================================================================================
  abstract: Building deep reinforcement learning (RL) agents that find a good policy with few samples has proven notoriously challenging. To achieve sample efficiency, recent work has explored updating neural networks with large numbers of gradient steps for every new sample. While such high update-to-data (UTD) ratios have shown strong empirical performance, they also introduce instability to the training process.  Previous approaches need to rely on periodic neural network parameter resets to address this instability, but restarting the training process is infeasible in many real-world applications and requires tuning the resetting interval. In this paper, we focus on one of the core difficulties of stable training with limited samples: the inability of learned value functions to generalize to unobserved on-policy actions. We mitigate this issue directly by augmenting the off-policy RL training process with a small amount of data generated from a learned world model. Our method, Model-Augmented Data for TD Learning (MAD-TD) uses small amounts of generated data to stabilize high UTD training and achieve competitive performance on the most challenging tasks in the DeepMind control suite. Our experiments further highlight the importance of employing a good model to generate data, MAD-TD's ability to combat value overestimation, and its practical stability gains for continued learning.
  abstract_embedding: [0.97265625, 0.146484375, 0.4140625]... (1536 items)
  authors: ['Claas A Voelcker', 'Marcel Hussing', 'Eric Eaton']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468807100
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MAD-TD__Model-Augmented_Data_stabilizes_High_Update_Ratio_RL.pdf
  sha_abstract: de33890c223c008f9657b46ae8a0f14091ca069c4b024347c2f3b8034ec28770
  title: MAD-TD: Model-Augmented Data stabilizes High Update Ratio RL
  title_normalized: madtd_modelaugmented_data_stabilizes_high_update_ratio_rl

================================================================================
Document #106 (ID: COhTW5oBclM7MZc3r5PO)
================================================================================
  abstract: We propose a zero-shot method for generating images in arbitrary spaces (e.g., a sphere for 360◦ panoramas and a mesh surface for texture) using a pretrained image diffusion model. The zero-shot generation of various visual content using a pretrained image diffusion model has been explored mainly in two directions. First, Diffusion Synchronization–performing reverse diffusion processes jointly across different projected spaces while synchronizing them in the target space–generates high-quality outputs when enough conditioning is provided, but it struggles in its absence. Second, Score Distillation Sampling–gradually updating the target space data through gradient descent–results in better coherence but often lacks detail. In this paper, we reveal for the first time the interconnection between these two methods while highlighting their differences. To this end, we propose StochSync, a novel approach that combines the strengths of both, enabling effective performance with weak conditioning. Our experiments demonstrate that StochSync provides the best performance in 360◦ panorama generation (where image conditioning is not given), outperforming previous finetuning-based methods, and also delivers comparable results in 3D mesh texturing (where depth conditioning is provided) with previous methods.
  abstract_embedding: [0.1611328125, 0.6171875, 0.33984375]... (1536 items)
  authors: ['Kyeongmin Yeo', 'Jaihoon Kim', 'Minhyuk Sung']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468802482
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: StochSync__Stochastic_Diffusion_Synchronization_for_Image_Generation_in_Arbitrary_Spaces.pdf
  sha_abstract: f7c538d27a0658b43507adc170d31e1f3acf1466e49103e6c84c570b4b9faf96
  title: StochSync: Stochastic Diffusion Synchronization for Image Generation in Arbitrary Spaces
  title_normalized: stochsync_stochastic_diffusion_synchronization_for_image_generation_in_arbitrary_spaces

================================================================================
Document #107 (ID: CuhTW5oBclM7MZc3vJPZ)
================================================================================
  abstract: Consistency models (CMs) offer faster sampling than traditional diffusion models, but their training is resource-intensive. For example, as of 2024, training a state-of-the-art CM on CIFAR-10 takes one week on 8 GPUs. In this work, we propose an effective scheme for training CMs that largely improves the efficiency of building such models. Specifically, by expressing CM trajectories via a particular differential equation, we argue that diffusion models can be viewed as a special case of CMs. We can thus fine-tune a consistency model starting from a pretrained diffusion model and progressively approximate the full consistency condition to stronger degrees over the training process. Our resulting method, which we term Easy Consistency Tuning (ECT), achieves vastly reduced training times while improving upon the quality of previous methods: for example, ECT achieves a 2-step FID of 2.73 on CIFAR10 within 1 hour on a single A100 GPU, matching Consistency Distillation trained for hundreds of GPU hours. Owing to this computational efficiency, we investigate the scaling laws of CMs under ECT, showing that they obey the classic power law scaling, hinting at their ability to improve efficiency and performance at larger scales. Our [code](https://github.com/locuslab/ect) is available.
  abstract_embedding: [0.466796875, 0.484375, 0.51171875]... (1536 items)
  authors: ['Zhengyang Geng', 'Ashwini Pokle', 'Weijian Luo']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468805835
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Consistency_Models_Made_Easy.pdf
  sha_abstract: b978c9f23f73106902eda090ff5d0c4fcbb5debeed4bbbaee7fb1f176ae5fdef
  title: Consistency Models Made Easy
  title_normalized: consistency_models_made_easy

================================================================================
Document #108 (ID: CehTW5oBclM7MZc3tJP0)
================================================================================
  abstract: Recent work has shown that diffusion models memorize and reproduce training data examples. At the same time, large copyright lawsuits and legislation such as GDPR have highlighted the need for erasing datapoints from diffusion models. However, retraining from scratch is often too expensive. This motivates the setting of data unlearning, i.e., the study of efficient techniques for unlearning specific datapoints from the training set. Existing concept unlearning techniques require an anchor prompt/class/distribution to guide unlearning, which is not available in the data unlearning setting. General-purpose machine unlearning techniques were found to be either unstable or failed to unlearn data. We therefore propose a family of new loss functions called Subtracted Importance Sampled Scores (SISS) that utilize importance sampling and are the first method to unlearn data with theoretical guarantees. SISS is constructed as a weighted combination between simpler objectives that are responsible for preserving model quality and unlearning the targeted datapoints. When evaluated on CelebA-HQ and MNIST, SISS achieved Pareto optimality along the quality and unlearning strength dimensions. On Stable Diffusion, SISS successfully mitigated memorization on nearly 90% of the prompts we tested. We release our code online.
  abstract_embedding: [0.5625, 0.451171875, 0.33984375]... (1536 items)
  authors: ['Silas Alberti', 'Kenan Hasanaliyev', 'Manav Shah']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468803796
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Data_Unlearning_in_Diffusion_Models.pdf
  sha_abstract: f9809c3aa8412392e95ce3b1d7f9c31a490e00be541cbe489bbfc9e7a0c44abe
  title: Data Unlearning in Diffusion Models
  title_normalized: data_unlearning_in_diffusion_models

================================================================================
Document #109 (ID: 9OhTW5oBclM7MZc3OZK_)
================================================================================
  abstract: Audio is essential for multimodal video understanding. On the one hand, video inherently contains audio, which supplies complementary information to vision. Besides, video large language models (Video-LLMs) can encounter many audio-centric settings. However, existing Video-LLMs and Audio-Visual Large Language Models (AV-LLMs) exhibit deficiencies in exploiting audio information, leading to weak understanding and hallucinations. To solve the issues, we delve into the model architecture and dataset. (1) From the architectural perspective, we propose a fine-grained AV-LLM, namely Dolphin. The concurrent alignment of audio and visual modalities in both temporal and spatial dimensions ensures a comprehensive and accurate understanding of videos. Specifically, we devise an audio-visual multi-scale adapter for multi-scale information aggregation, which achieves spatial alignment. For temporal alignment, we propose audio-visual interleaved merging. (2) From the dataset perspective, we curate an audio-visual caption \& instruction-tuning dataset, called AVU. It comprises 5.2 million diverse, open-ended data tuples (video, audio, question, answer) and introduces a novel data partitioning strategy. Extensive experiments show our model not only achieves remarkable performance in audio-visual understanding, but also mitigates potential hallucinations.
  abstract_embedding: [0.2314453125, -0.04052734375, 0.4375]... (1536 items)
  authors: ['Yuxin Guo', 'Shuailei Ma', 'Shijie Ma']... (10 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:40:09.321641
  code_metadata_s3_key: 9OhTW5oBclM7MZc3OZK_/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: 9OhTW5oBclM7MZc3OZK_/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468772275
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Aligned_Better__Listen_Better_for_Audio-Visual_Large_Language_Models.pdf
  sha_abstract: aea160d31c518a004e227ae3e8b13321f328b817bd3feeb19d57c6b24724e83c
  title: Aligned Better, Listen Better for Audio-Visual Large Language Models
  title_normalized: aligned_better_listen_better_for_audiovisual_large_language_models

================================================================================
Document #110 (ID: DehTW5oBclM7MZc3zJMk)
================================================================================
  abstract: The composition of pretraining data is a key determinant of foundation models' performance, but there is no standard guideline for allocating a limited computational budget across different data sources. Most current approaches either rely on extensive experiments with smaller models or dynamic data adjustments that also require proxy models, both of which significantly increase the workflow complexity and computational overhead. In this paper, we introduce Adaptive Data Optimization (ADO), an algorithm that optimizes data distributions in an online fashion, concurrent with model training. Unlike existing techniques, ADO does not require external knowledge, proxy models, or modifications to the model update. Instead, ADO uses per-domain scaling laws to estimate the learning potential of each domain during training and adjusts the data mixture accordingly, making it more scalable and easier to integrate. Experiments demonstrate that ADO can achieve comparable or better performance than prior methods while maintaining computational efficiency across different computation scales, offering a practical solution for dynamically adjusting data distribution without sacrificing flexibility or increasing costs. Beyond its practical benefits, ADO also provides a new perspective on data collection strategies via scaling laws.
  abstract_embedding: [0.40625, 0.2041015625, 0.474609375]... (1536 items)
  authors: ['Yiding Jiang', 'Allan Zhou', 'Zhili Feng']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468809722
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Adaptive_Data_Optimization__Dynamic_Sample_Selection_with_Scaling_Laws.pdf
  sha_abstract: c4902c4850a377de50bb4fd6ba922c5296f41298277455585e6aafe05e879c19
  title: Adaptive Data Optimization: Dynamic Sample Selection with Scaling Laws
  title_normalized: adaptive_data_optimization_dynamic_sample_selection_with_scaling_laws

================================================================================
Document #111 (ID: -ehTW5oBclM7MZc3U5K-)
================================================================================
  abstract: In reinforcement learning (RL), world models serve as internal simulators, enabling agents to predict environment dynamics and future outcomes in order to make informed decisions. While previous approaches leveraging discrete latent spaces, such as DreamerV3, have demonstrated strong performance in discrete action settings and visual control tasks, their comparative performance in state-based continuous control remains underexplored. In contrast, methods with continuous latent spaces, such as TD-MPC2, have shown notable success in state-based continuous control benchmarks. In this paper, we demonstrate that modeling discrete latent states has benefits over continuous latent states and that discrete codebook encodings are more effective representations for continuous control, compared to alternative encodings, such as one-hot and label-based encodings. Based on these insights, we introduce DCWM: Discrete Codebook World Model, a self-supervised world model with a discrete and stochastic latent space, where latent states are codes from a codebook. We combine DCWM with decision-time planning to get our model-based RL algorithm, named DC-MPC: Discrete Codebook Model Predictive Control, which performs competitively against recent state-of-the-art algorithms, including TD-MPC2 and DreamerV3, on continuous control benchmarks.
  abstract_embedding: [0.63671875, 0.341796875, 0.4453125]... (1536 items)
  authors: ['Aidan Scannell', 'Mohammadreza Nakhaeinezhadfard', 'Kalle Kujanpää']... (7 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:40:14.150859
  code_metadata_s3_key: -ehTW5oBclM7MZc3U5K-/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: -ehTW5oBclM7MZc3U5K-/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468778900
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Discrete_Codebook_World_Models_for_Continuous_Control.pdf
  sha_abstract: 4ecb5992b96ab009e0644e81a836cf294143da8a5d51aac50000e3381dd5587d
  title: Discrete Codebook World Models for Continuous Control
  title_normalized: discrete_codebook_world_models_for_continuous_control

================================================================================
Document #112 (ID: EOhTW5oBclM7MZc32ZPN)
================================================================================
  abstract: First-order logic (FOL) reasoning, which involves sequential deduction, is pivotal for intelligent systems and serves as a valuable task for evaluating reasoning capabilities, particularly in chain-of-thought (CoT) contexts. Existing benchmarks often rely on extensive human annotation or handcrafted templates, making it difficult to achieve the necessary complexity, scalability, and diversity for robust evaluation. To address these limitations, we propose a novel framework called ProverGen that synergizes the generative strengths of Large Language Models (LLMs) with the rigor and precision of symbolic provers, enabling the creation of a scalable, diverse, and high-quality FOL reasoning dataset, ProverQA. ProverQA is also distinguished by its inclusion of accessible and logically coherent intermediate reasoning steps for each problem. Our evaluation shows that state-of-the-art LLMs struggle to solve ProverQA problems, even with CoT prompting, highlighting the dataset's challenging nature. We also finetune Llama3.1-8B-Instruct on a separate training set generated by our framework.
The finetuned model demonstrates consistent improvements on both in-distribution and out-of-distribution test sets, suggesting the value of our proposed data generation framework. Code available at: \url{https://github.com/opendatalab/ProverGen}
  abstract_embedding: [0.23828125, 0.443359375, 0.07080078125]... (1536 items)
  authors: ['Chengwen Qi', 'Ren Ma', 'Bowen Li']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468813217
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Large_Language_Models_Meet_Symbolic_Provers_for_Logical_Reasoning_Evaluation.pdf
  sha_abstract: b644c34c9c0e4766fc8f7b20535638636e876085f3ad3e0f2db94e88c30a7b7e
  title: Large Language Models Meet Symbolic Provers for Logical Reasoning Evaluation
  title_normalized: large_language_models_meet_symbolic_provers_for_logical_reasoning_evaluation

================================================================================
Document #113 (ID: D-hTW5oBclM7MZc31ZMb)
================================================================================
  abstract: The robustness of LLMs to jailbreak attacks, where users design prompts to circumvent safety measures and misuse model capabilities, has been studied primarily for LLMs acting as simple chatbots. Meanwhile, LLM agents---which use external tools and can execute multi-stage tasks---may pose a greater risk if misused, but their robustness remains underexplored. To facilitate research on LLM agent misuse, we propose a new benchmark called AgentHarm. The benchmark includes a diverse set of 110 explicitly malicious agent tasks (440 with augmentations), covering 11 harm categories including fraud, cybercrime, and harassment. In addition to measuring whether models refuse harmful agentic requests, scoring well on AgentHarm requires jailbroken agents to maintain their capabilities following an attack to complete a multi-step task. We evaluate a range of leading LLMs, and find (1) leading LLMs are surprisingly complaint with malicious agent requests without jailbreaking, (2) simple universal jailbreak strings can be adapted to effectively jailbreak agents, and (3) these jailbreaks enable coherent and malicious multi-step agent behavior and retain model capabilities. To enable simple and reliable evaluation of attacks and defenses for LLM-based agents, we publicly release AgentHarm at https://huggingface.co/datasets/ai-safety-institute/AgentHarm.
  abstract_embedding: [1.203125, 0.357421875, 0.02392578125]... (1536 items)
  authors: ['Maksym Andriushchenko', 'Alexandra Souly', 'Mateusz Dziemian']... (12 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468812028
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: AgentHarm__A_Benchmark_for_Measuring_Harmfulness_of_LLM_Agents.pdf
  sha_abstract: 112e83a7b152a913153f288f3bee4ae334b3671856467caec6ca6ee3eaa1b397
  title: AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents
  title_normalized: agentharm_a_benchmark_for_measuring_harmfulness_of_llm_agents

================================================================================
Document #114 (ID: E-hTW5oBclM7MZc355NT)
================================================================================
  abstract: Recent advances in Code Large Language Models (CodeLLMs) have primarily focused on open-ended code generation, often overlooking the crucial aspect of code understanding & reasoning. To bridge this gap, we introduce CodeMMLU, a comprehensive multiple-choice benchmark designed to evaluate the depth of software and code comprehension in LLMs. CodeMMLU includes nearly 20,000 questions spanning diverse domains, including code analysis, defect detection, and software engineering principles across multiple programming languages. Unlike traditional benchmarks that emphasize code generation, CodeMMLU assesses a model’s ability to reason about programs across a wide-range of tasks such as code repair, execution reasoning, and fill-in-the-blank challenges. Our extensive evaluation reveals that even state-of-the-art models struggle with CodeMMLU, highlighting significant gaps in comprehension beyond generation. By emphasizing the essential connection between code understanding and effective AI-assisted development, CodeMMLU provides a critical resource for advancing more reliable and capable coding assistants.
  abstract_embedding: [0.4375, 0.0291748046875, 0.390625]... (1536 items)
  authors: ['Dung Manh Nguyen', 'Thang Chau Phan', 'Nam Le Hai']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468816715
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CodeMMLU__A_Multi-Task_Benchmark_for_Assessing_Code_Understanding___Reasoning_Capabilities_of_CodeLLMs.pdf
  sha_abstract: 7c84a259afc65efa679d9499ff6a900f1586d356dd47469613a886e159221043
  title: CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding & Reasoning Capabilities of CodeLLMs
  title_normalized: codemmlu_a_multitask_benchmark_for_assessing_code_understanding__reasoning_capabilities_of_codellms

================================================================================
Document #115 (ID: EuhTW5oBclM7MZc34pOP)
================================================================================
  abstract: Large-scale latent diffusion models (LDMs) excel in content generation across various modalities, but their reliance on phonemes and durations in text-to-speech (TTS) limits scalability and access from other fields. While recent studies show potential in removing these domain-specific factors, performance remains suboptimal. In this work, we introduce DiTTo-TTS, a Diffusion Transformer (DiT)-based TTS model, to investigate whether LDM-based TTS can achieve state-of-the-art performance without domain-specific factors. Through rigorous analysis and empirical exploration, we find that (1) DiT with minimal modifications outperforms U-Net, (2) variable-length modeling with a speech length predictor significantly improves results over fixed-length approaches, and (3) conditions like semantic alignment in speech latent representations are key to further enhancement. By scaling our training data to 82K hours and the model size to 790M parameters, we achieve superior or comparable zero-shot performance to state-of-the-art TTS models in naturalness, intelligibility, and speaker similarity, all without relying on domain-specific factors. Speech samples are available at https://ditto-tts.github.io.
  abstract_embedding: [0.3125, 0.392578125, 0.1328125]... (1536 items)
  authors: ['Keon Lee', 'Dong Won Kim', 'Jaehyeon Kim']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468815495
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: DiTTo-TTS__Diffusion_Transformers_for_Scalable_Text-to-Speech_without_Domain-Specific_Factors.pdf
  sha_abstract: 73fd9e3269f52eca5ac6eca6d24e70d4e8dec5781900c25a45bf24bc58a4a45d
  title: DiTTo-TTS: Diffusion Transformers for Scalable Text-to-Speech without Domain-Specific Factors
  title_normalized: dittotts_diffusion_transformers_for_scalable_texttospeech_without_domainspecific_factors

================================================================================
Document #116 (ID: EehTW5oBclM7MZc33pMJ)
================================================================================
  abstract: Policy Mirror Descent (PMD) is a popular framework in reinforcement learning, serving as a unifying perspective that encompasses numerous algorithms. These algorithms are derived through the selection of a mirror map and enjoy finite-time convergence guarantees. Despite its popularity, the exploration of PMD's full potential is limited, with the majority of research focusing on a particular mirror map---namely, the negative entropy---which gives rise to the renowned Natural Policy Gradient (NPG) method. It remains uncertain from existing theoretical studies whether the choice of mirror map significantly influences PMD's efficacy. In our work, we conduct empirical investigations to show that the conventional mirror map choice (NPG) often yields less-than-optimal outcomes across several standard benchmark environments. Using evolutionary strategies, we identify more efficient mirror maps that enhance the performance of PMD. We first focus on a tabular environment, i.e.\ Grid-World, where we relate existing theoretical bounds with the performance of PMD for a few standard mirror maps and the learned one. We then show that it is possible to learn a mirror map that outperforms the negative entropy in more complex environments, such as the MinAtar suite. Additionally, we demonstrate that the learned mirror maps generalize effectively to different tasks by testing each map across various other environments.
  abstract_embedding: [0.9375, 0.5625, 0.05908203125]... (1536 items)
  authors: ['Carlo Alfano', 'Sebastian Rene Towers', 'Silvia Sapora']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468814335
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Learning_mirror_maps_in_policy_mirror_descent.pdf
  sha_abstract: 46b3d71542c2cb31f9802e0047593be6abe7594059d25028a51bca0493ee2e29
  title: Learning mirror maps in policy mirror descent
  title_normalized: learning_mirror_maps_in_policy_mirror_descent

================================================================================
Document #117 (ID: DuhTW5oBclM7MZc30JOX)
================================================================================
  abstract: Why do larger language models generalize better? To explore this question, we develop generalization bounds on the pretraining objective of large language models (LLMs) in the compute-optimal regime, as described by the Chinchilla scaling laws. We introduce a novel, fully empirical Freedman-type martingale concentration inequality that tightens existing bounds by accounting for the variance of the loss function. The generalization bound can be broken into three contributions: the number of parameters per token, the loss variance, and the quantization error at a fixed bitrate. As language models are scaled up, the number of parameters per data point stays constant; however, both the loss variance and the quantization error decrease, implying that larger models should have \emph{smaller} generalization gaps. We examine why larger models tend to be more quantizable from an information theoretic perspective, showing that the rate at which they can integrate new information grows slower than their capacity on the compute optimal frontier. From these findings we produce a scaling law for the generalization gap, showing that our bounds decrease in a predictable way.
  abstract_embedding: [0.0849609375, 0.2490234375, 0.1728515625]... (1536 items)
  authors: ['Marc Anton Finzi', 'Sanyam Kapoor', 'Diego Granziol']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468810895
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Compute-Optimal_LLMs_Provably_Generalize_Better_with_Scale.pdf
  sha_abstract: b1f48346893cc97894134708442d6e2b754391da8abe3e023129a45c250fd82b
  title: Compute-Optimal LLMs Provably Generalize Better with Scale
  title_normalized: computeoptimal_llms_provably_generalize_better_with_scale

================================================================================
Document #118 (ID: BuhTW5oBclM7MZc3opMb)
================================================================================
  abstract: Optimization in deep learning remains poorly understood.  A key difficulty is that optimizers exhibit complex oscillatory dynamics, referred to as "edge of stability," which cannot be captured by traditional optimization theory.  In this paper, we show that the path taken by an oscillatory optimizer can often be captured by a  _central flow_: a differential equation which directly models the time-averaged (i.e. smoothed) optimization trajectory. We empirically show that these central flows can predict long-term optimization trajectories for generic neural networks with a high degree of numerical accuracy.  By interpreting these flows, we are able to understand  how gradient descent makes progress even as the loss sometimes goes up; how adaptive optimizers ``adapt'' to the local loss landscape; and how adaptive optimizers implicitly seek out regions of weight space where they can take larger steps.  These insights (and others) are not apparent from the optimizers' update rules, but are revealed by the central flows.  Therefore, we believe that central flows constitute a promising tool for reasoning about optimization in deep learning.
  abstract_embedding: [0.2734375, 0.19921875, -0.01153564453125]... (1536 items)
  authors: ['Jeremy Cohen', 'Alex Damian', 'Ameet Talwalkar']... (5 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:40:22.847278
  code_metadata_s3_key: BuhTW5oBclM7MZc3opMb/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: BuhTW5oBclM7MZc3opMb/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468798995
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Understanding_Optimization_in_Deep_Learning_with_Central_Flows.pdf
  sha_abstract: c5c0a3b3911f0355fdb3889f0811c9f9985f0b99054055705ac877dc709b5494
  title: Understanding Optimization in Deep Learning with Central Flows
  title_normalized: understanding_optimization_in_deep_learning_with_central_flows

================================================================================
Document #119 (ID: FOhTW5oBclM7MZc37JNV)
================================================================================
  abstract: Progress in AI is driven largely by the scale and quality of training data. Despite this, there is a deficit of empirical analysis examining the attributes of well-established datasets beyond text. In this work we conduct the largest and first-of-its-kind longitudinal audit across modalities --- popular text, speech, and video datasets --- from their detailed sourcing trends and use restrictions to their geographical and linguistic representation. Our manual analysis covers nearly 4000 public datasets between 1990-2024, spanning 608 languages, 798 sources, 659 organizations, and 67 countries. We find that multimodal machine learning applications have overwhelmingly turned to web-crawled, synthetic, and social media platforms, such as YouTube, for their training sets, eclipsing all other sources since 2019. Secondly, tracing the chain of dataset derivations we find that while less than 33% of datasets are restrictively licensed, over 80% of the source content in widely-used text, speech, and video datasets, carry non-commercial restrictions. Finally, counter to the rising number of languages and geographies represented in public AI training datasets, our audit demonstrates measures of relative geographical and multilingual representation have failed to significantly improve their coverage since 2013. We believe the breadth of our audit enables us to empirically examine trends in data sourcing, restrictions, and Western-centricity at an ecosystem-level, and that visibility into these questions are essential to progress in responsible AI. As a contribution to ongoing improvements in dataset transparency and responsible use, we release our entire multimodal audit, allowing practitioners to trace data provenance across text, speech, and video.
  abstract_embedding: [0.419921875, 0.318359375, 0.263671875]... (1536 items)
  authors: ['Shayne Longpre', 'Nikhil Singh', 'Manuel Cherep']... (43 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468817995
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Bridging_the_Data_Provenance_Gap_Across_Text__Speech__and_Video.pdf
  sha_abstract: 5b99f498a593207ff7578c6e1ca895af9d6fde5f1b679116650aa44c357d16f4
  title: Bridging the Data Provenance Gap Across Text, Speech, and Video
  title_normalized: bridging_the_data_provenance_gap_across_text_speech_and_video

================================================================================
Document #120 (ID: GehUW5oBclM7MZc3CJPr)
================================================================================
  abstract: As AI systems are increasingly deployed in high-stakes applications, ensuring their interpretability is essential. Mechanistic Interpretability (MI) aims to reverse-engineer neural networks by extracting human-understandable algorithms embedded within their structures to explain their behavior. This work systematically examines a fundamental question: for a fixed behavior to explain, and under the criteria that MI sets for itself, are we guaranteed a unique explanation? Drawing an analogy with the concept of identifiability in statistics, which ensures the uniqueness of parameters inferred from data under specific modeling assumptions, we speak about the identifiability of explanations produced by MI.

We identify two broad strategies to produce MI explanations: (i) "where-then-what", which first identifies a subset of the network (a circuit) that replicates the model's behavior before deriving its interpretation, and (ii) "what-then-where", which begins with candidate explanatory algorithms and searches in the activation subspaces of the neural model where the candidate algorithm may be implemented, relying on notions of causal alignment between the states of the candidate algorithm and the neural network. 

We systematically test the identifiability of both strategies using simple tasks (learning Boolean functions) and multi-layer perceptrons small enough to allow a complete enumeration of candidate explanations. Our experiments reveal overwhelming evidence of non-identifiability in all cases: multiple circuits can replicate model behavior, multiple interpretations can exist for a circuit, several algorithms can be causally aligned with the neural network, and a single algorithm can be causally aligned with different subspaces of the network.

We discuss whether the unicity intuition is necessary. One could adopt a pragmatic stance, requiring explanations only to meet predictive and/or manipulability standards. However, if unicity is considered essential, e.g., to provide a sense of understanding, we also discuss less permissive criteria. Finally, we also refer to the inner interpretability framework that demands explanations to be validated by multiple complementary criteria. This work aims to contribute constructively to the ongoing effort to formalize what we expect from explanations in AI.
  abstract_embedding: [0.2734375, 0.2236328125, -0.0400390625]... (1536 items)
  authors: ['Maxime Méloux', 'Silviu Maniu', 'François Portet']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468825315
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Everything__Everywhere__All_at_Once__Is_Mechanistic_Interpretability_Identifiable_.pdf
  sha_abstract: ed9823162141df36378ad1db13a29f50a5126df24f7e0c9a309d4d2787cb911c
  title: Everything, Everywhere, All at Once: Is Mechanistic Interpretability Identifiable?
  title_normalized: everything_everywhere_all_at_once_is_mechanistic_interpretability_identifiable

================================================================================
Document #121 (ID: GuhUW5oBclM7MZc3DZOs)
================================================================================
  abstract: Masked diffusion models (MDMs) have emerged as a popular research topic for generative modeling of discrete data, thanks to their superior performance over other discrete diffusion models, and are rivaling the auto-regressive models (ARMs) for language modeling tasks. The recent effort in simplifying the masked diffusion framework further leads to alignment with continuous-space diffusion models and more principled training and sampling recipes. 
In this paper, however, we reveal that both training and sampling of MDMs are theoretically free from the time variable, arguably the key signature of diffusion models, and are instead equivalent to masked models. The connection on the sampling aspect is drawn by our proposed first-hitting sampler (FHS). Specifically, we show that the FHS is theoretically equivalent to MDMs' original generation process while significantly alleviating the time-consuming categorical sampling and achieving a 20$\times$ speedup. In addition, our investigation raises doubts about whether MDMs can truly beat ARMs in text generation. We identify, for the first time, an underlying numerical issue, even with the commonly used 32-bit floating-point precision, which results in inaccurate categorical sampling. 
We show that it lowers the effective temperature both theoretically and empirically, and the resulting decrease in token diversity makes previous evaluations, which assess the generation quality solely through the incomplete generative perplexity metric, somewhat unfair.
  abstract_embedding: [0.154296875, 0.7109375, 0.46875]... (1536 items)
  authors: ['Kaiwen Zheng', 'Yongxin Chen', 'Hanzi Mao']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468826497
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Masked_Diffusion_Models_are_Secretly_Time-Agnostic_Masked_Models_and_Exploit_Inaccurate_Categorical_Sampling.pdf
  sha_abstract: 0c27bc80e84183a0ab222964b4054fbc1ab68222bb7a744b09729da3407a2bc5
  title: Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling
  title_normalized: masked_diffusion_models_are_secretly_timeagnostic_masked_models_and_exploit_inaccurate_categorical_sampling

================================================================================
Document #122 (ID: GOhUW5oBclM7MZc3BJMH)
================================================================================
  abstract: Graphical User Interface (GUI) agents hold great potential for automating complex tasks across diverse digital environments, from web applications to desktop software. However, the development of such agents is hindered by the lack of high-quality, multi-step trajectory data required for effective training. Existing approaches rely on expensive and labor-intensive human annotation, making them unsustainable at scale. To address this challenge, we propose AgentTrek, a scalable data synthesis pipeline that generates high-quality web agent trajectories by leveraging web tutorials. Our method automatically gathers tutorial-like texts from the internet, transforms them into task goals with step-by-step instructions, and employs a visual-language model (VLM) agent to simulate their execution in a real digital environment. A VLM-based evaluator ensures the correctness of the generated trajectories. We demonstrate that training GUI agents with these synthesized trajectories significantly improves their grounding and planning performance over the current models. Moreover, our approach is more cost-efficient compared to traditional human annotation methods. This work underscores the potential of guided replay with web tutorials as a viable strategy for large-scale GUI agent training, paving the way for more capable and autonomous digital agents.
  abstract_embedding: [0.69921875, -0.035400390625, 0.337890625]... (1536 items)
  authors: ['Yiheng Xu', 'Dunjie Lu', 'Zhennan Shen']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468824063
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: AgentTrek__Agent_Trajectory_Synthesis_via_Guiding_Replay_with_Web_Tutorials.pdf
  sha_abstract: 56be0f23c7ad987c4a2e633f8d54477e9ccb8f319e4c95ddbd6721f34c5ca9f3
  title: AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials
  title_normalized: agenttrek_agent_trajectory_synthesis_via_guiding_replay_with_web_tutorials

================================================================================
Document #123 (ID: G-hUW5oBclM7MZc3E5Ps)
================================================================================
  abstract: Denoising diffusion bridge models (DDBMs) are a powerful variant of diffusion models for interpolating between two arbitrary paired distributions given as endpoints. Despite their promising performance in tasks like image translation, DDBMs require a computationally intensive sampling process that involves the simulation of a (stochastic) differential equation through hundreds of network evaluations. In this work, we take the first step in fast sampling of DDBMs without extra training, motivated by the well-established recipes in diffusion models. We generalize DDBMs via a class of non-Markovian diffusion bridges defined on the discretized timesteps concerning sampling, which share the same marginal distributions and training objectives, give rise to generative processes ranging from stochastic to deterministic, and result in diffusion bridge implicit models (DBIMs). DBIMs are not only up to 25$\times$ faster than the vanilla sampler of DDBMs but also induce a novel, simple, and insightful form of ordinary differential equation (ODE) which inspires high-order numerical solvers. Moreover, DBIMs maintain the generation diversity in a distinguished way, by using a booting noise in the initial sampling step, which enables faithful encoding, reconstruction, and semantic interpolation in image translation tasks. Code is available at \url{https://github.com/thu-ml/DiffusionBridge}.
  abstract_embedding: [0.1435546875, 0.6328125, 0.38671875]... (1536 items)
  authors: ['Kaiwen Zheng', 'Guande He', 'Jianfei Chen']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468828114
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Diffusion_Bridge_Implicit_Models.pdf
  sha_abstract: 02ebb6c664597ebfb273f873b506b1c97b12ea6ef9940f138a945d4be57ee4ae
  title: Diffusion Bridge Implicit Models
  title_normalized: diffusion_bridge_implicit_models

================================================================================
Document #124 (ID: FuhTW5oBclM7MZc39pNn)
================================================================================
  abstract: Diffusion Probabilistic Models (DPMs) have achieved significant success in generative tasks. However, their training and sampling processes suffer from the issue of distribution mismatch. During the denoising process, the input data distributions differ between the training and inference stages, potentially leading to inaccurate data generation. To obviate this, we analyze the training objective of DPMs and theoretically demonstrate that this mismatch can be alleviated through Distributionally Robust Optimization (DRO), which is equivalent to performing robustness-driven Adversarial Training (AT) on DPMs. Furthermore, for the recently proposed Consistency Model (CM), which distills the inference process of the DPM, we prove that its training objective also encounters the mismatch issue. Fortunately, this issue can be mitigated by AT as well. Based on these insights, we propose to conduct efficient AT on both DPM and CM. Finally, extensive empirical studies validate the effectiveness of AT in diffusion-based models. The code is available at https://github.com/kugwzk/AT_Diff.
  abstract_embedding: [0.5390625, 0.51953125, 0.11865234375]... (1536 items)
  authors: ['Zekun Wang', 'Mingyang Yi', 'Shuchen Xue']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468820520
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Improved_Diffusion-based_Generative_Model_with_Better_Adversarial_Robustness.pdf
  sha_abstract: ea82003bd7cecc49176a65db9f5b12ca2995cbc9664ce440bf8c5aee0ea62660
  title: Improved Diffusion-based Generative Model with Better Adversarial Robustness
  title_normalized: improved_diffusionbased_generative_model_with_better_adversarial_robustness

================================================================================
Document #125 (ID: HehUW5oBclM7MZc3HJPQ)
================================================================================
  abstract: We study beyond worst-case dimensionality reduction for $s$-sparse vectors (vectors with at most $s$ non-zero coordinates). Our work is divided into two parts, each focusing on a different facet of beyond worst-case analysis:

\noindent (a)  We first consider average-case guarantees for embedding $s$-sparse vectors. Here, a well-known folklore upper bound based on the birthday-paradox states: For any collection $X$ of $s$-sparse vectors in $\mathbb{R}^d$, there exists a linear map $A: \mathbb{R}^d \rightarrow \mathbb{R}^{O(s^2)}$ which \emph{exactly} preserves the norm of $99\%$ of the vectors in $X$ in any $\ell_p$ norm (as opposed to the usual setting where guarantees hold for all vectors). We provide novel lower bounds showing that this is indeed optimal in many settings. Specifically, any oblivious linear map satisfying similar average-case guarantees must map to $\Omega(s^2)$ dimensions. The same lower bound also holds for a wider class of sufficiently smooth maps, including `encoder-decoder schemes', where we compare the norm of the original vector to that of a smooth function of the embedding. These lower bounds reveal a surprising separation result for smooth embeddings of sparse vectors, as an upper bound of $O(s \log(d))$ is possible if we instead use arbitrary functions, e.g., via compressed sensing algorithms.


 (b) Given these lower bounds, we specialize to sparse \emph{non-negative} vectors to hopes of improved upper bounds. For a dataset $X$ of non-negative $s$-sparse vectors and any $p \ge 1$, we can non-linearly embed $X$ to $O(s\log(|X|s)/\varepsilon^2)$ dimensions while preserving all pairwise distances in $\ell_p$ norm up to $1\pm \varepsilon$, with no dependence on $p$. Surprisingly, the non-negativity assumption enables much smaller embeddings than arbitrary sparse vectors, where the best known bound suffers an exponential $(\log |X|)^{O(p)}$ dependence. Our map also guarantees \emph{exact} dimensionality reduction for the $\ell_{\infty}$ norm by embedding $X$ into $O(s\log |X|)$ dimensions, which is tight. We further give separation results showing that both the non-linearity of $f$ and the non-negativity of $X$ are necessary, and provide downstream algorithmic improvements using our embedding.
  abstract_embedding: [0.17369219660758972, 0.17889337241649628, 0.41720280051231384]... (1536 items)
  authors: ['Sandeep Silwal', 'David Woodruff', 'Qiuyi Zhang']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468830371
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Beyond_Worst-Case_Dimensionality_Reduction_for_Sparse_Vectors.pdf
  sha_abstract: c617cdcdeff48204b886058fea7e8094a035f52e752bf42f1afbd9d0096f2cba
  title: Beyond Worst-Case Dimensionality Reduction for Sparse Vectors
  title_normalized: beyond_worstcase_dimensionality_reduction_for_sparse_vectors

================================================================================
Document #126 (ID: DOhTW5oBclM7MZc3x5Nz)
================================================================================
  abstract: We present InvMSAFold, an inverse folding method for generating protein sequences optimized for diversity and speed. For a given structure, InvMSAFold generates the parameters of a pairwise probability distribution over the space of sequences, capturing the amino acid covariances observed in Multiple Sequence Alignments (MSA) of homologous proteins. This allows for the efficient generation of highly diverse protein sequences while preserving structural and functional integrity.
We demonstrate that this increased diversity in sampled sequences translates into greater variability in biochemical properties, highlighting the exciting potential of our method for applications such as protein design. The orders of magnitude improvement in sampling speed compared to existing methods unlocks new possibilities for high-throughput in virtual screening.
  abstract_embedding: [0.0771484375, 0.8359375, 0.115234375]... (1536 items)
  authors: ['luca alessandro silva', 'Barthelemy Meynard-Piganeau', 'Carlo Lucibello']... (4 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:40:33.194936
  code_metadata_s3_key: DOhTW5oBclM7MZc3x5Nz/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: DOhTW5oBclM7MZc3x5Nz/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468808542
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Fast_Uncovering_of_Protein_Sequence_Diversity_from_Structure.pdf
  sha_abstract: 8eb22f03bc71b0f57c61fa23d160455d7c6749d88e318cd896a068819c33f4b2
  title: Fast Uncovering of Protein Sequence Diversity from Structure
  title_normalized: fast_uncovering_of_protein_sequence_diversity_from_structure

================================================================================
Document #127 (ID: I-hUW5oBclM7MZc3PJN6)
================================================================================
  abstract: Recently, the study of heavy-tailed noises in first-order nonconvex stochastic optimization has gotten a lot of attention since it was recognized as a more realistic condition as suggested by many empirical observations. Specifically, the stochastic noise (the difference between the stochastic and true gradient) is considered to have only a finite $\mathfrak{p}$-th moment where $\mathfrak{p}\in\left(1,2\right]$ instead of assuming it always satisfies the classical finite variance assumption. To deal with this more challenging setting, people have proposed different algorithms and proved them to converge at an optimal $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{3\mathfrak{p}-2}})$ rate for smooth objectives after $T$ iterations. Notably, all these new-designed algorithms are based on the same technique – gradient clipping. Naturally, one may want to know whether the clipping method is a necessary ingredient and the only way to guarantee convergence under heavy-tailed noises. In this work, by revisiting the existing Batched Normalized Stochastic Gradient Descent with Momentum (Batched NSGDM) algorithm, we provide the first convergence result under heavy-tailed noises but without gradient clipping. Concretely, we prove that Batched NSGDM can achieve the optimal $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{3\mathfrak{p}-2}})$ rate even under the relaxed smooth condition. More interestingly, we also establish the first $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{2\mathfrak{p}}})$ convergence rate in the case where the tail index $\mathfrak{p}$ is unknown in advance, which is arguably the common scenario in practice.
  abstract_embedding: [0.302734375, 0.26171875, 0.203125]... (1536 items)
  authors: ['Zijian Liu', 'Zhengyuan Zhou']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468838511
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Nonconvex_Stochastic_Optimization_under_Heavy-Tailed_Noises__Optimal_Convergence_without_Gradient_Clipping.pdf
  sha_abstract: ef8781698909539c5f457d98666ea16eaffd8d7ba8f0993016ee1423589ace66
  title: Nonconvex Stochastic Optimization under Heavy-Tailed Noises: Optimal Convergence without Gradient Clipping
  title_normalized: nonconvex_stochastic_optimization_under_heavytailed_noises_optimal_convergence_without_gradient_clipping

================================================================================
Document #128 (ID: HOhUW5oBclM7MZc3GJM4)
================================================================================
  abstract: We tackle the problem of parameter-efficient fine-tuning (PEFT) of a pre-trained large deep model on many different but related tasks. Instead of the simple but strong baseline strategy of task-wise independent fine-tuning, we aim to meta-learn the core shared information that can be used for unseen test tasks to improve the prediction performance further. That is, we propose a method for {\em learning-to-fine-tune} (LiFT). LiFT introduces a novel hierarchical Bayesian model that can be superior to both existing general meta learning algorithms like MAML and recent LoRA zoo mixing approaches such as LoRA-Retriever and model-based clustering. In our Bayesian model, the parameters of the task-specific LoRA modules are regarded as random variables where these task-wise LoRA modules are governed/regularized by higher-level latent random variables, which represents the prior of the LoRA modules that capture the shared information across all training tasks. To make the posterior inference feasible, we propose a novel SGLD-Gibbs sampling algorithm that is computationally efficient. To represent the posterior samples from the SGLD-Gibbs, we propose an online EM algorithm that maintains a Gaussian mixture representation for the posterior in an online manner in the course of iterative posterior sampling. We demonstrate the effectiveness of LiFT on NLP and vision multi-task meta learning benchmarks.
  abstract_embedding: [0.02734375, 0.349609375, 0.3828125]... (1536 items)
  authors: ['Minyoung Kim', 'Timothy Hospedales']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468829231
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: LiFT__Learning_to_Fine-Tune_via_Bayesian_Parameter_Efficient_Meta_Fine-Tuning.pdf
  sha_abstract: acb24036a419b330039e747be336d223aa500add9cd4638723a38c45b0f9229a
  title: LiFT: Learning to Fine-Tune via Bayesian Parameter Efficient Meta Fine-Tuning
  title_normalized: lift_learning_to_finetune_via_bayesian_parameter_efficient_meta_finetuning

================================================================================
Document #129 (ID: H-hUW5oBclM7MZc3KZMG)
================================================================================
  abstract: Instruction tuning is critical for adapting large language models (LLMs) to downstream tasks, and recent studies have demonstrated that small amounts of human-curated data can outperform larger datasets, challenging traditional data scaling laws. While LLM-based data quality rating systems offer a cost-effective alternative to human annotation, they often suffer from inaccuracies and biases, even in powerful models like GPT-4. In this work, we introduce $DS^2$, a **D**iversity-aware **S**core curation method for **D**ata **S**election. By systematically modeling error patterns through a score transition matrix, $DS^2$ corrects LLM-based scores and promotes diversity in the selected data samples. Our approach shows that a curated subset (just 3.3\% of the original dataset) outperforms full-scale datasets (300k samples) across various machine-alignment benchmarks, and matches or surpasses human-aligned datasets such as LIMA with the same sample size (1k samples). These findings challenge conventional data scaling assumptions, highlighting that redundant, low-quality samples can degrade performance and reaffirming that ``more can be less''.
  abstract_embedding: [0.388671875, 0.2041015625, 0.244140625]... (1536 items)
  authors: ['Jinlong Pang', 'Jiaheng Wei', 'Ankit Shah']... (9 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468833535
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Improving_Data_Efficiency_via_Curating_LLM-Driven_Rating_Systems.pdf
  sha_abstract: 3c5115fbf29eb8d1030f0c8b99d76fd2e7c686dced2331392748dac665fed628
  title: Improving Data Efficiency via Curating LLM-Driven Rating Systems
  title_normalized: improving_data_efficiency_via_curating_llmdriven_rating_systems

================================================================================
Document #130 (ID: HuhUW5oBclM7MZc3IpOe)
================================================================================
  abstract: Consistency distillation is a prevalent way for accelerating diffusion models adopted in consistency (trajectory) models, in which a student model is trained to traverse backward on the probability flow (PF) ordinary differential equation (ODE) trajectory determined by the teacher model. Preconditioning is a vital technique for stabilizing consistency distillation, by linear combining the input data and the network output with pre-defined coefficients as the consistency function. It imposes the boundary condition of consistency functions without restricting the form and expressiveness of the neural network. However, previous preconditionings are hand-crafted and may be suboptimal choices. In this work, we offer the first theoretical insights into the preconditioning in consistency distillation, by elucidating its design criteria and the connection to the teacher ODE trajectory. Based on these analyses, we further propose a principled way dubbed \textit{Analytic-Precond} to analytically optimize the preconditioning according to the consistency gap (defined as the gap between the teacher denoiser and the optimal student denoiser) on a generalized teacher ODE. We demonstrate that Analytic-Precond can facilitate the learning of trajectory jumpers, enhance the alignment of the student trajectory with the teacher's, and achieve $2\times$ to $3\times$ training acceleration of consistency trajectory models in multi-step generation across various datasets.
  abstract_embedding: [0.48828125, 0.40234375, 0.271484375]... (1536 items)
  authors: ['Kaiwen Zheng', 'Guande He', 'Jianfei Chen']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468831895
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Elucidating_the_Preconditioning_in_Consistency_Distillation.pdf
  sha_abstract: 92ac9a9c96c0178e57c8869d44e27ffa094e424fa40fffc5b6a8a5555482ea3c
  title: Elucidating the Preconditioning in Consistency Distillation
  title_normalized: elucidating_the_preconditioning_in_consistency_distillation

================================================================================
Document #131 (ID: IuhUW5oBclM7MZc3OJNB)
================================================================================
  abstract: Large language models (LLMs) could be valuable personal AI agents across various domains, provided they can precisely follow user instructions. However, recent studies have shown significant limitations in LLMs' instruction-following capabilities, raising concerns about their reliability in high-stakes applications. 
Accurately estimating LLMs' uncertainty in adhering to instructions is critical to mitigating deployment risks. We present, to our knowledge, the first systematic evaluation of the uncertainty estimation abilities of LLMs in the context of instruction-following. 
Our study identifies key challenges with existing instruction-following benchmarks, where multiple factors are entangled with uncertainty stems from instruction-following, complicating the isolation and comparison across methods and models.
To address these issues, we introduce a controlled evaluation setup with two benchmark versions of data, enabling a comprehensive comparison of uncertainty estimation methods under various conditions.
Our findings show that existing uncertainty methods struggle, particularly when models make subtle errors in instruction following. While internal model states provide some improvement, they remain inadequate in more complex scenarios. 
The insights from our controlled evaluation setups provide a crucial understanding of LLMs' limitations and potential for uncertainty estimation in instruction-following tasks, paving the way for more trustworthy AI agents.
  abstract_embedding: [0.28125, 0.05712890625, 0.1884765625]... (1536 items)
  authors: ['Juyeon Heo', 'Miao Xiong', 'Christina Heinze-Deml']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468837397
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Do_LLMs_estimate_uncertainty_well_in_instruction-following_.pdf
  sha_abstract: b76bd4af926c2820594d770badbcca82d202a958509c80a74e267c99e086fe7c
  title: Do LLMs estimate uncertainty well in instruction-following?
  title_normalized: do_llms_estimate_uncertainty_well_in_instructionfollowing

================================================================================
Document #132 (ID: IOhUW5oBclM7MZc3LpMt)
================================================================================
  abstract: Diffusion models have achieved great success in generating high-dimensional samples across various applications. While the theoretical guarantees for continuous-state diffusion models have been extensively studied, the convergence analysis of the discrete-state counterparts remains under-explored. In this paper, we study the theoretical aspects of score-based discrete diffusion models under the Continuous Time Markov Chain (CTMC) framework. We introduce a discrete-time sampling algorithm in the general state space $[S]^d$ that utilizes score estimators at predefined time points. We derive convergence bounds for the Kullback-Leibler (KL) divergence and total variation (TV) distance between the generated sample distribution and the data distribution, considering both scenarios with and without early stopping under reasonable assumptions. Notably, our KL divergence bounds are nearly linear in the dimension $d$, aligning with state-of-the-art results for diffusion models. Our convergence analysis employs a Girsanov-based method and establishes key properties of the discrete score function, which are essential for characterizing the discrete-time sampling process.
  abstract_embedding: [0.5, 0.53515625, 0.25390625]... (1536 items)
  authors: ['Zikun Zhang', 'Zixiang Chen', 'Quanquan Gu']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468834822
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Convergence_of_Score-Based_Discrete_Diffusion_Models__A_Discrete-Time_Analysis.pdf
  sha_abstract: f70ec12c35a76a20f14fc445be1ff5527602e424c01ef1a7db22730b99960cbe
  title: Convergence of Score-Based Discrete Diffusion Models: A Discrete-Time Analysis
  title_normalized: convergence_of_scorebased_discrete_diffusion_models_a_discretetime_analysis

================================================================================
Document #133 (ID: FehTW5oBclM7MZc38ZPe)
================================================================================
  abstract: We address the challenge of federated learning on graph-structured data distributed across multiple clients. Specifically, we focus on the prevalent scenario of interconnected subgraphs, where inter-connections between different clients play a critical role. We present a novel framework for this scenario, named FedStruct, that harnesses deep structural dependencies. To uphold privacy, unlike existing methods, FedStruct eliminates the necessity of sharing or generating sensitive node features or embeddings among clients. Instead, it leverages explicit global graph structure information to capture inter-node dependencies. We validate the effectiveness of FedStruct through experimental results conducted on six datasets for semi-supervised node classification, showcasing performance close to the centralized approach across various scenarios, including different data partitioning methods, varying levels of label availability, and number of clients.
  abstract_embedding: [0.0186767578125, 0.5078125, 0.17578125]... (1536 items)
  authors: ['Javad Aliakbari', 'Johan Östman', 'Alexandre Graell i Amat']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468819415
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Decoupled_Subgraph_Federated_Learning.pdf
  sha_abstract: e0204095f49e5e036d3c2ef9ffc0589a9eb5e57700f223442f462211d7494a0c
  title: Decoupled Subgraph Federated Learning
  title_normalized: decoupled_subgraph_federated_learning

================================================================================
Document #134 (ID: KehUW5oBclM7MZc3W5M_)
================================================================================
  abstract: Training language models currently requires pre-determining a fixed compute budget because the typical cosine learning rate schedule depends on the total number of steps. In contrast, the Warmup-Stable-Decay (WSD) schedule uses a constant learning rate to produce a main branch of iterates that can in principle continue indefinitely without a pre-specified compute budget. Then, given any compute budget, one can branch out from the main branch at a proper time with a rapidly decaying learning rate to produce a strong model. Empirically, WSD generates an intriguing, non-traditional loss curve: the loss remains elevated during the stable phase but sharply declines during the decay phase. Towards explaining this phenomenon, we conjecture that pretraining loss exhibits a river valley landscape, which resembles a deep valley with a river at its bottom. Under this assumption, we show that during the stable phase, the iterate undergoes large oscillations due to the high learning rate, yet it progresses swiftly along the river. During the decay phase, the rapidly dropping learning rate minimizes the iterate’s oscillations, moving it closer to the river and revealing true optimization progress. Therefore, the sustained high learning rate phase and fast decaying phase are responsible for progress in the river and the mountain directions, respectively, and are both critical. Our analysis predicts phenomenons consistent with empirical observations and shows that this landscape can naturally emerge from pretraining on a simple bi-gram dataset. Inspired by the theory, we introduce WSD-S, a variant of WSD that reuses previous checkpoints’ decay phases and keeps only one main branch, where we resume from a decayed checkpoint. WSD-S empirically outperforms WSD and Cyclic-Cosine in obtaining multiple pretrained language model checkpoints across various compute budgets in a single run for parameters scaling from 0.1B to 1.2B.
  abstract_embedding: [0.2236328125, 0.337890625, -0.09521484375]... (1536 items)
  authors: ['Kaiyue Wen', 'Zhiyuan Li', 'Jason S. Wang']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468846356
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Understanding_Warmup-Stable-Decay_Learning_Rates__A_River_Valley_Loss_Landscape_View.pdf
  sha_abstract: b2804e5eb0d77fef57d645fb89c3e16a56fa916cc6ca278d712859f3142691b3
  title: Understanding Warmup-Stable-Decay Learning Rates: A River Valley Loss Landscape View
  title_normalized: understanding_warmupstabledecay_learning_rates_a_river_valley_loss_landscape_view

================================================================================
Document #135 (ID: JuhUW5oBclM7MZc3S5OO)
================================================================================
  abstract: Federated Learning (FL) offers a promising framework for collaborative and privacy-preserving machine learning across distributed data sources. 
However, the substantial communication costs associated with FL significantly challenge its efficiency. 
Specifically, in each communication round, the communication costs scale linearly with the model's dimension, which presents a formidable obstacle, especially in large model scenarios. 
Despite various communication-efficient strategies, the intrinsic dimension-dependent communication cost remains a major bottleneck for current FL implementations.
This paper proposes a novel dimension-free communication algorithm - DeComFL, which leverages the zeroth-order optimization techniques and reduces the communication cost from $\mathcal{O}(d)$ to $\mathcal{O}(1)$ by transmitting only a constant number of scalar values between clients and the server in each round, regardless of the dimension $d$ of the model parameters.
Theoretically, in non-convex functions, we prove that our algorithm achieves state-of-the-art rates, which show a linear speedup of the number of clients and local steps under standard assumptions. With additional low effective rank assumption, we can further show that the convergence rate is independent of the model dimension $d$ as well.
Empirical evaluations, encompassing both classic deep learning training and large language model fine-tuning, demonstrate significant reductions in communication overhead. 
Notably, DeComFL achieves this by transmitting only around 1MB of data in total between the server and a client to fine-tune a model with billions of parameters. 
The code is available at https://github.com/ZidongLiu/DeComFL.
  abstract_embedding: [0.283203125, 0.43359375, 0.125]... (1536 items)
  authors: ['Zhe Li', 'Bicheng Ying', 'Zidong Liu']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468842375
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Achieving_Dimension-Free_Communication_in_Federated_Learning_via_Zeroth-Order_Optimization.pdf
  sha_abstract: 5ecd56638a7d57fc993d0d2bce6f664dd7917b67b630c7f120846ae99fcc9cd1
  title: Achieving Dimension-Free Communication in Federated Learning via Zeroth-Order Optimization
  title_normalized: achieving_dimensionfree_communication_in_federated_learning_via_zerothorder_optimization

================================================================================
Document #136 (ID: JOhUW5oBclM7MZc3QZMD)
================================================================================
  abstract: Recent advances in large language and vision-language models have enabled zero-shot inference, allowing models to solve new tasks without task-specific training. Various adaptation techniques such as prompt engineering, In-Context Learning (ICL), and supervised fine-tuning can further enhance the model’s performance on a downstream task, but they require substantial manual effort to construct effective prompts or labeled examples. In this work, we introduce a joint inference framework for fully unsupervised adaptation, eliminating the need for manual prompt engineering and labeled examples. Unlike zero-shot inference, which makes independent predictions, the joint inference makes predictions simultaneously for all inputs in a given task. Since direct joint inference involves computationally expensive optimization, we develop efficient approximation techniques, leading to two unsupervised adaptation methods: unsupervised fine-tuning and unsupervised ICL. We demonstrate the effectiveness of our methods across diverse tasks and models, including language-only Llama-3.1 on natural language processing tasks, reasoning-oriented Qwen2.5-Math on grade school math problems, vision-language OpenFlamingo on vision tasks, and the API-only access GPT-4o model on massive multi-discipline tasks. Our experiments demonstrate substantial improvements over the standard zero-shot approach, including 39% absolute improvement on the challenging GSM8K math reasoning dataset. Remarkably, despite being fully unsupervised, our framework often performs on par with supervised approaches that rely on ground truth labels.
  abstract_embedding: [-0.08935546875, 0.375, 0.197265625]... (1536 items)
  authors: ['Artyom Gadetsky', 'Andrei Atanov', 'Yulun Jiang']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468839658
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Large__Vision__Language_Models_are_Unsupervised_In-Context_Learners.pdf
  sha_abstract: 0f73661c7f6c590e011562660724046231dfa94d1e37e37cddc93dacf4b4526f
  title: Large (Vision) Language Models are Unsupervised In-Context Learners
  title_normalized: large_vision_language_models_are_unsupervised_incontext_learners

================================================================================
Document #137 (ID: JehUW5oBclM7MZc3R5ND)
================================================================================
  abstract: The challenge of mapping AI architectures to GPU hardware is creating a critical bottleneck in AI progress. Despite substantial efforts, hand-written custom kernels fail to meet their theoretical performance thresholds, even on well-established operations like linear attention. The diverse capabilities of GPUs suggests we might we need a wide variety of techniques to achieve high performance. However, our work explores if a small number of key abstractions can drastically simplify the process. We present ThunderKittens (TK), a framework for writing performant AI kernels while remaining easy to use. Our abstractions map to the three levels of the GPU hierarchy: (1) at the warp-level, we provide 16x16 matrix tiles as basic data structures and PyTorch-like operations, (2) at the thread-block level, we provide templates for asynchronously overlapping operations, and (3) at the grid-level, TK helps hide block launch, tear-down, and memory costs. We show the value of TK by providing simple & diverse kernels that match or outperform prior art. We match CuBLAS and FlashAttention-3 on GEMM and attention inference performance and outperform the strongest baselines by $10-40$\% on attention backwards, $8\times$ on state space models, and $14\times$ on linear attention.
  abstract_embedding: [0.1865234375, -0.059814453125, 0.38671875]... (1536 items)
  authors: ['Benjamin Frederick Spector', 'Simran Arora', 'Aaryan Singhal']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468841262
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ThunderKittens__Simple__Fast__and___textit_Adorable___Kernels.pdf
  sha_abstract: b51d3b3a548104606f5960672c19f35f3003ca696c500df8c77d196f1fed3abf
  title: ThunderKittens: Simple, Fast, and $\textit{Adorable}$ Kernels
  title_normalized: thunderkittens_simple_fast_and_textitadorable_kernels

================================================================================
Document #138 (ID: J-hUW5oBclM7MZc3T5Pv)
================================================================================
  abstract: Modern language models have demonstrated remarkable reasoning capabilities by using chain-of-thought (CoT). One hypothesis about the inner workings of CoT is that it breaks down originally complex tasks into smaller subtasks that are more amenable to learning. We formalize this notion by showing possibility and impossibility results of learning from in-context demonstrations with and without CoT. In particular, with CoT, we examine a family of learning algorithms that learn a task step-by-step, capable of composing simpler functions from individual reasoning steps to form an overall complex function. This process reduces the difficulty of learning a task to that of the hardest reasoning step in the chain. Moreover, we prove Transformers can express this algorithm and thus they can efficiently in-context learn arbitrary tasks as long as these tasks can be decomposed into a finite number of subtasks, each of which are efficiently learnable. In contrast, without CoT, we demonstrate that there exist tasks that are inherently unlearnable by the same algorithm. Overall, our results suggest several provably effective ways for decomposing target problems to instantiate CoT. Empirically, we demonstrate our proposed CoT construction significantly enhances the reasoning capabilities of real-world LLMs in solving challenging arithmetic reasoning tasks, including learning polynomials and Boolean formulas.
  abstract_embedding: [0.5703125, -0.150390625, 0.224609375]... (1536 items)
  authors: ['Chenxiao Yang', 'Zhiyuan Li', 'David Wipf']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468843495
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Chain-of-Thought_Provably_Enables_Learning_the__Otherwise__Unlearnable.pdf
  sha_abstract: bfd8f4faa8a534eac651d564ba4e8c06e23f674cc628d719487541d41f4e6e89
  title: Chain-of-Thought Provably Enables Learning the (Otherwise) Unlearnable
  title_normalized: chainofthought_provably_enables_learning_the_otherwise_unlearnable

================================================================================
Document #139 (ID: LOhUW5oBclM7MZc3aZMP)
================================================================================
  abstract: Graph Transformers are popular neural networks that extend the well-known Transformer architecture to the graph domain. These architectures operate by applying self-attention on graph nodes and incorporating graph structure through the use of positional encodings (e.g., Laplacian positional encoding) or structural encodings (e.g., random-walk structural encoding). The quality of such encodings is critical, since they provide the necessary \emph{graph inductive biases} to condition the model on graph structure. In this work, we propose \emph{motif structural encoding} (MoSE) as a flexible and powerful structural encoding framework based on counting graph homomorphisms. Theoretically, we compare the expressive power of MoSE to random-walk structural encoding and relate both encodings to the expressive power of standard message passing neural networks. Empirically, we observe that MoSE outperforms other well-known positional and structural encodings across a range of architectures, and it achieves state-of-the-art performance on a widely studied molecular property prediction dataset.
  abstract_embedding: [0.376953125, 0.451171875, 0.30078125]... (1536 items)
  authors: ['Linus Bao', 'Emily Jin', 'Michael M. Bronstein']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468849875
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Homomorphism_Counts_as_Structural_Encodings_for_Graph_Learning.pdf
  sha_abstract: aabb8fb183e66f16ec0357e532f2beb59779f15090a469d651cfcfca639d9150
  title: Homomorphism Counts as Structural Encodings for Graph Learning
  title_normalized: homomorphism_counts_as_structural_encodings_for_graph_learning

================================================================================
Document #140 (ID: K-hUW5oBclM7MZc3Y5N4)
================================================================================
  abstract: Stochastic Variance Reduced Gradient (SVRG), introduced by Johnson & Zhang (2013), is a theoretically compelling optimization method. However, as Defazio & Bottou (2019) highlight, its effectiveness in deep learning is yet to be proven. In this work, we demonstrate the potential of SVRG in optimizing real-world neural networks. Our empirical analysis finds that, for deeper neural networks, the strength of the variance reduction term in SVRG should be smaller and decrease as training progresses. Inspired by this, we introduce a multiplicative coefficient $\alpha$ to control the strength and adjust it through a linear decay schedule. We name our method $\alpha$-SVRG. Our results show $\alpha$-SVRG better optimizes models, consistently reducing training loss compared to the baseline and standard SVRG across various model architectures and multiple image classification datasets. We hope our findings encourage further exploration into variance reduction techniques in deep learning. Code is available at github.com/davidyyd/alpha-SVRG.
  abstract_embedding: [0.41015625, 0.197265625, -0.11083984375]... (1536 items)
  authors: ['Yida Yin', 'Zhiqiu Xu', 'Zhiyuan Li']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468848482
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: A_Coefficient_Makes_SVRG_Effective.pdf
  sha_abstract: 239e70df6a9d37c53d43744e790606c1a9a9cc55401e7c5e7658c9167d3edd5d
  title: A Coefficient Makes SVRG Effective
  title_normalized: a_coefficient_makes_svrg_effective

================================================================================
Document #141 (ID: KuhUW5oBclM7MZc3X5MB)
================================================================================
  abstract: We propose a novel neural network architecture, the normalized Transformer (nGPT) with representation learning on the hypersphere. In nGPT, all vectors forming the embeddings, MLP, attention matrices and hidden states are unit norm normalized. The input stream of tokens travels on the surface of a hypersphere, with each layer contributing a displacement towards the target output predictions. These displacements are defined by the MLP and attention blocks, whose vector components also reside on the same hypersphere. Experiments show that nGPT learns much faster, reducing the number of training steps required to achieve the same accuracy by a factor of 4 to 20, depending on the sequence length.
  abstract_embedding: [0.50390625, 0.016357421875, 0.515625]... (1536 items)
  authors: ['Ilya Loshchilov', 'Cheng-Ping Hsieh', 'Simeng Sun']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468847351
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: nGPT__Normalized_Transformer_with_Representation_Learning_on_the_Hypersphere.pdf
  sha_abstract: 9c456b374f8847aab6ebe1d4ef3e2027b4eee0cdf458dc29c93701a128c4c5d9
  title: nGPT: Normalized Transformer with Representation Learning on the Hypersphere
  title_normalized: ngpt_normalized_transformer_with_representation_learning_on_the_hypersphere

================================================================================
Document #142 (ID: IehUW5oBclM7MZc3M5O0)
================================================================================
  abstract: Despite the recent progress in long-context language models, it remains elusive how transformer-based models exhibit the capability to retrieve relevant information from arbitrary locations within the long context. This paper aims to address this question. Our systematic investigation across a wide spectrum of models reveals that a special type of attention heads are largely responsible for retrieving information, which we dub retrieval heads. We identify intriguing properties of retrieval heads:(1) universal: all the explored models with long-context capability have a set of retrieval heads; (2) sparse: only a small portion (less than 5\%) of the attention heads are retrieval. (3) intrinsic: retrieval heads already exist in models pretrained with short context. When extending the context length by continual pretraining, it is still the same set of heads that perform information retrieval. (4) dynamically activated: take Llama-2 7B for example, 12 retrieval heads always attend to the required information no matter how the context is changed. The rest of the retrieval heads are activated in different contexts. (5) causal: completely pruning retrieval heads leads to failure in retrieving relevant information and results in hallucination, while pruning random non-retrieval heads does not affect the model's retrieval ability. We further show that retrieval heads strongly influence chain-of-thought (CoT) reasoning, where the model needs to frequently refer back the question and previously-generated context. Conversely, tasks where the model directly generates the answer using its intrinsic knowledge are less impacted by masking out retrieval heads. These observations collectively explain which internal part of the model seeks information from the input tokens. We believe our insights will foster future research on reducing hallucination, improving reasoning, and compressing the KV cache.
  abstract_embedding: [0.2578125, -0.006805419921875, 0.322265625]... (1536 items)
  authors: ['Wenhao Wu', 'Yizhong Wang', 'Guangxuan Xiao']... (5 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:40:59.947397
  code_metadata_s3_key: IehUW5oBclM7MZc3M5O0/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: IehUW5oBclM7MZc3M5O0/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468836237
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Retrieval_Head_Mechanistically_Explains_Long-Context_Factuality.pdf
  sha_abstract: af70edec3b9426604b3c88ea7e943b7dc09f6c671ab0afd87f478a767fc26e26
  title: Retrieval Head Mechanistically Explains Long-Context Factuality
  title_normalized: retrieval_head_mechanistically_explains_longcontext_factuality

================================================================================
Document #143 (ID: NOhUW5oBclM7MZc3kZNq)
================================================================================
  abstract: Designing a safe policy for uncertain environments is crucial in real-world control systems. However, this challenge remains inadequately addressed within the Markov decision process (MDP) framework. This paper presents the first algorithm guaranteed to identify a near-optimal policy in a robust constrained MDP (RCMDP), where an optimal policy minimizes cumulative cost while satisfying constraints in the worst-case scenario across a set of environments. We first prove that the conventional policy gradient approach to the Lagrangian max-min formulation can become trapped in suboptimal solutions. This occurs when its inner minimization encounters a sum of conflicting gradients from the objective and constraint functions. To address this, we leverage the epigraph form of the RCMDP problem, which resolves the conflict by selecting a single gradient from either the objective or the constraints. Building on the epigraph form, we propose a bisection search algorithm with a policy gradient subroutine and prove that it identifies an $\varepsilon$-optimal policy in an RCMDP with $\widetilde{\mathcal{O}}(\varepsilon^{-4})$ robust policy evaluations.
  abstract_embedding: [0.9765625, 0.51953125, 0.1728515625]... (1536 items)
  authors: ['Toshinori Kitamura', 'Tadashi Kozuno', 'Wataru Kumagai']... (9 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468860255
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Near-Optimal_Policy_Identification_in_Robust_Constrained_Markov_Decision_Processes_via_Epigraph_Form.pdf
  sha_abstract: ab656bc49cbf15df676779a7d6e0fc62a27051b83a0676233c69972e7358057e
  title: Near-Optimal Policy Identification in Robust Constrained Markov Decision Processes via Epigraph Form
  title_normalized: nearoptimal_policy_identification_in_robust_constrained_markov_decision_processes_via_epigraph_form

================================================================================
Document #144 (ID: F-hTW5oBclM7MZc3_pM2)
================================================================================
  abstract: Discriminative approaches to classification often learn shortcuts that hold in-distribution but fail even under minor distribution shift. This failure mode stems from an overreliance on features that are spuriously correlated with the label. We show that generative classifiers, which use class-conditional generative models, can avoid this issue by modeling all features, both core and spurious, instead of mainly spurious ones. These generative classifiers are simple to train, avoiding the need for specialized augmentations, strong regularization, extra hyperparameters, or knowledge of the specific spurious correlations to avoid. We find that diffusion-based and autoregressive generative classifiers achieve state-of-the-art performance on five standard image and text distribution shift benchmarks and reduce the impact of spurious correlations in realistic applications, such as medical or satellite datasets. Finally, we carefully analyze a Gaussian toy setting to understand the inductive biases of generative classifiers, as well as the data properties that determine when generative classifiers outperform discriminative ones.
  abstract_embedding: [-0.232421875, 0.578125, 0.1318359375]... (1536 items)
  authors: ['Alexander Cong Li', 'Ananya Kumar', 'Deepak Pathak']
  code_generated: True
  code_generated_at: 2025-11-06T22:40:52.566251
  code_metadata_s3_key: F-hTW5oBclM7MZc3_pM2/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: F-hTW5oBclM7MZc3_pM2/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468822575
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Generative_Classifiers_Avoid_Shortcut_Solutions.pdf
  sha_abstract: 03648b7031675eca7d21544ee7e7ad61790aa0104fc114dda073cb5fb81638ad
  title: Generative Classifiers Avoid Shortcut Solutions
  title_normalized: generative_classifiers_avoid_shortcut_solutions

================================================================================
Document #145 (ID: LehUW5oBclM7MZc3bZOX)
================================================================================
  abstract: Large language models have shown remarkable reasoning abilities and scaling laws suggest that large parameter count, especially along the depth axis, is the primary driver. In this work, we make a stronger claim --- many reasoning problems require a large depth but not necessarily many parameters. This unlocks a novel application of looped models for reasoning. Firstly, we show that for many synthetic reasoning problems like addition, $p$-hop induction, and math problems, a $k$-layer transformer looped $L$ times nearly matches the performance of a $kL$-layer non-looped model, and is significantly better than a $k$-layer model. This is further corroborated by theoretical results showing that many such reasoning problems can be solved via iterative algorithms, and thus, can be solved effectively using looped models with nearly optimal depth. Perhaps surprisingly, these benefits also translate to practical settings of language modeling --- on many downstream reasoning tasks, a language model with $k$-layers looped $L$ times can be competitive to, if not better than, a $kL$-layer language model. In fact, our empirical analysis reveals an intriguing phenomenon: looped and non-looped models exhibit scaling behavior that depends on their effective depth, akin to the inference-time scaling of chain-of-thought (CoT) reasoning. We further elucidate the connection to CoT reasoning by proving that looped models implicitly generate latent thoughts and can simulate $T$ steps of CoT with $T$ loops. Inspired by these findings, we also present an interesting dichotomy between reasoning and memorization, and design a looping-based regularization that is effective on both fronts.
  abstract_embedding: [0.5546875, -0.09716796875, 0.3203125]... (1536 items)
  authors: ['Nikunj Saunshi', 'Nishanth Dikkala', 'Zhiyuan Li']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468851052
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Reasoning_with_Latent_Thoughts__On_the_Power_of_Looped_Transformers.pdf
  sha_abstract: 117b4a8d098d1d18e19701927e217ce52282f3b874faf73c968c79e3a9335147
  title: Reasoning with Latent Thoughts: On the Power of Looped Transformers
  title_normalized: reasoning_with_latent_thoughts_on_the_power_of_looped_transformers

================================================================================
Document #146 (ID: MuhUW5oBclM7MZc3h5Nn)
================================================================================
  abstract: Recent advancements in head avatar rendering using Gaussian primitives have achieved significantly high-fidelity results. Although precise head geometry is crucial for applications like mesh reconstruction and relighting, current methods struggle to capture intricate geometric details and render unseen poses due to their reliance on similarity transformations, which cannot handle stretch and shear transforms essential for detailed deformations of geometry. To address this, we propose SurFhead, a novel method that reconstructs riggable head geometry from RGB videos using 2D Gaussian surfels, which offer well-defined geometric properties, such as precise depth from fixed ray intersections and normals derived from their surface orientation, making them advantageous over 3D counterparts. SurFhead ensures high-fidelity rendering of both normals and images, even in extreme poses, by leveraging classical mesh-based deformation transfer and affine transformation interpolation. SurFhead introduces precise geometric deformation and blends surfels through polar decomposition of transformations, including those affecting normals. Our key contribution lies in bridging classical graphics techniques, such as mesh-based deformation, with modern Gaussian primitives, achieving state-of-the-art geometry reconstruction and rendering quality. Unlike previous avatar rendering approaches, SurFhead enables efficient reconstruction driven by Gaussian primitives while preserving high-fidelity geometry.
  abstract_embedding: [-0.166015625, 0.09228515625, 0.07421875]... (1536 items)
  authors: ['Jaeseong Lee', 'Taewoong Kang', 'Marcel Buehler']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468857695
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SurFhead__Affine_Rig_Blending_for_Geometrically_Accurate_2D_Gaussian_Surfel_Head_Avatars.pdf
  sha_abstract: 35510a1106bed9af79c5d43b4c845d70c609807d591f74717aa0757c90b1dc20
  title: SurFhead: Affine Rig Blending for Geometrically Accurate 2D Gaussian Surfel Head Avatars
  title_normalized: surfhead_affine_rig_blending_for_geometrically_accurate_2d_gaussian_surfel_head_avatars

================================================================================
Document #147 (ID: MehUW5oBclM7MZc3gZOf)
================================================================================
  abstract: Real-time instruction-based portrait image editing is crucial in various applications, including filters, augmented reality, and video communications, etc. However, real-time portrait editing presents three significant challenges: identity preservation, fidelity to editing instructions, and fast model inference. Given that these aspects often present a trade-off, concurrently addressing them poses an even greater challenge. While diffusion-based image editing methods have shown promising capabilities in personalized image editing in recent years, they lack a dedicated focus on portrait editing and thus suffer from the aforementioned problems as well. To address the gap, this paper introduces an Instant-Portrait Network (IPNet), the first one-step diffusion-based model for portrait editing. We train the network in two stages. We first employ an annealing identity loss to train an Identity Enhancement Network (IDE-Net), to ensure robust identity preservation. We then train the IPNet using a novel diffusion Multi-Objective Distillation approach that integrates adversarial loss, identity distillation loss, and a novel Facial-Style Enhancing loss. The Diffusion Multi-Objective Distillation approach efficiently reduces inference steps, ensures identity consistency, and enhances the precision of instruction-based editing. Extensive comparison with prior models demonstrates IPNet as a superior model in terms of identity preservation, text fidelity, and inference speed.
  abstract_embedding: [0.031494140625, 0.60546875, 0.039306640625]... (1536 items)
  authors: ['Zhixin Lai', 'Keqiang Sun', 'Fu-Yun Wang']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468856215
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: InstantPortrait__One-Step_Portrait_Editing_via_Diffusion_Multi-Objective_Distillation.pdf
  sha_abstract: a96a8d7ce5169f7c148e3963356c95e372419b327c7c667c395ace49f4ed295b
  title: InstantPortrait: One-Step Portrait Editing via Diffusion Multi-Objective Distillation
  title_normalized: instantportrait_onestep_portrait_editing_via_diffusion_multiobjective_distillation

================================================================================
Document #148 (ID: M-hUW5oBclM7MZc3jJPz)
================================================================================
  abstract: Ensuring that generative AI systems align with human values is essential but challenging, especially when considering multiple human values and their potential trade-offs. Since human values can be personalized and dynamically change over time, the desirable levels of value alignment vary across different ethnic groups, industry sectors, and user cohorts. Within existing frameworks, it is hard to define human values and align AI systems accordingly across different directions simultaneously, such as harmlessness, helpfulness, and positiveness. To address this, we develop a novel, first-principle approach called Multi-Human-Value Alignment Palette (MAP), which navigates the alignment across multiple human values in a structured and reliable way. MAP formulates the alignment problem as an optimization task with user-defined constraints, which define human value targets. It can be efficiently solved via a primal-dual approach, which determines whether a user-defined alignment target is achievable and how to achieve it. We conduct a detailed theoretical analysis of MAP by quantifying the trade-offs between values, the sensitivity to constraints, the fundamental connection between multi-value alignment and sequential alignment, and proving that linear weighted rewards are sufficient for multi-value alignment. Extensive experiments demonstrate MAP's ability to align multiple values in a principled manner while delivering strong empirical performance across various tasks.
  abstract_embedding: [1.2578125, 0.490234375, 0.259765625]... (1536 items)
  authors: ['Xinran Wang', 'Qi Le', 'Ammar Ahmed']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468859115
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MAP__Multi-Human-Value_Alignment_Palette.pdf
  sha_abstract: a65c1b15145123c0b86f1dbd80ffb6423b7733a839681a30f91c9c5deaebdce8
  title: MAP: Multi-Human-Value Alignment Palette
  title_normalized: map_multihumanvalue_alignment_palette

================================================================================
Document #149 (ID: LuhUW5oBclM7MZc3cpMn)
================================================================================
  abstract: Despite extensive research, recovering PDE expressions from experimental observations often involves symbolic regression. This method generally lacks the incorporation of meaningful physical insights, resulting in outcomes lacking clear physical interpretations. Recognizing that the primary interest of Machine Learning for Science (ML4Sci) often lies in understanding the underlying physical mechanisms or even discovering new physical laws rather than simply obtaining mathematical expressions, this paper introduces a novel ML4Sci task paradigm. This paradigm focuses on interpreting experimental data within the framework of prior physical hypotheses and theories, thereby guiding and constraining the discovery of PDE expressions. We have formulated this approach as a nonlinear mixed-integer programming (MIP) problem, addressed through an efficient search scheme developed for this purpose. Our experiments on newly designed Fluid Mechanics and Laser Fusion datasets demonstrate the interpretability and feasibility of this method.
  abstract_embedding: [0.337890625, 0.1181640625, -0.12060546875]... (1536 items)
  authors: ['Mingquan Feng', 'Yixin Huang', 'Yizhou Liu']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468852251
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: PhysPDE__Rethinking_PDE_Discovery_and_a_Physical_HYpothesis_Selection_Benchmark.pdf
  sha_abstract: 33c054c02e54d51c654da4c978d0c79c569da73345e9225f21cf57f089d47316
  title: PhysPDE: Rethinking PDE Discovery and a Physical HYpothesis Selection Benchmark
  title_normalized: physpde_rethinking_pde_discovery_and_a_physical_hypothesis_selection_benchmark

================================================================================
Document #150 (ID: L-hUW5oBclM7MZc3dpNb)
================================================================================
  abstract: Adam outperforms SGD when training language models. Yet this advantage is not well-understood theoretically --  previous convergence analysis for Adam and SGD mainly focuses on the number of steps $T$ and is already minimax-optimal in non-convex cases, which are both $\widetilde{O}(T^{-1/4})$. In this work, we argue that the exploitation of nice $\ell_\infty$-geometry is the key advantage of Adam over SGD. More specifically, we give a new convergence analysis for Adam under novel assumptions that loss is smooth under $\ell_\infty$-geometry rather than the more common $\ell_2$-geometry, which yields a much better empirical smoothness constant for GPT-2 and ResNet models. Our experiments confirm that Adam performs much worse when the favorable $\ell_\infty$-geometry is changed while SGD provably remains unaffected. We also extend the convergence analysis to blockwise Adam under novel blockwise smoothness assumptions.
  abstract_embedding: [0.91796875, 0.142578125, 0.3125]... (1536 items)
  authors: ['Shuo Xie', 'Mohamad Amin Mohamadi', 'Zhiyuan Li']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468853331
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Adam_Exploits___ell__infty_-geometry_of_Loss_Landscape_via_Coordinate-wise_Adaptivity.pdf
  sha_abstract: 2882a305d1a330b405e2214343e56b0bf3d6e093dcac7a434d7f79d153a7c913
  title: Adam Exploits $\ell_\infty$-geometry of Loss Landscape via Coordinate-wise Adaptivity
  title_normalized: adam_exploits_ellinftygeometry_of_loss_landscape_via_coordinatewise_adaptivity

================================================================================
Document #151 (ID: MOhUW5oBclM7MZc3epP7)
================================================================================
  abstract: We present a novel framework, StochastIc Network Graph Evolving operatoR (SINGER), for learning the evolution operator of high-dimensional partial differential equations (PDEs). The framework uses a sub-network to approximate the solution at the initial time step and stochastically evolves the sub-network parameters over time by a graph neural network to approximate the solution at later time steps. The framework is designed to inherit the desirable properties of the parametric solution operator, including graph topology, semigroup, and stability, with a theoretical guarantee. Numerical experiments on 8 evolution PDEs of 5,10,15,20-dimensions show that our method outperforms existing baselines in almost all cases (31 out of 32), and that our method generalizes well to unseen initial conditions, equation dimensions, sub-network width, and time steps.
  abstract_embedding: [0.291015625, 0.4453125, -0.212890625]... (1536 items)
  authors: ['Mingquan Feng', 'Yixin Huang', 'Weixin Liao']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468854516
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SINGER__Stochastic_Network_Graph_Evolving_Operator_for_High_Dimensional_PDEs.pdf
  sha_abstract: b04c6c4799ed42a5aae0b811473dfe01f0a9bac59403e97dd062a9b07ba0afa5
  title: SINGER: Stochastic Network Graph Evolving Operator for High Dimensional PDEs
  title_normalized: singer_stochastic_network_graph_evolving_operator_for_high_dimensional_pdes

================================================================================
Document #152 (ID: KOhUW5oBclM7MZc3VZPe)
================================================================================
  abstract: This paper investigates whether sequence models can learn to perform numerical algorithms, e.g. gradient descent, on the fundamental problem of least squares. Our goal is to inherit two properties of standard algorithms from numerical analysis: (1) machine precision, i.e. we want to obtain solutions that are accurate to near floating point error, and (2) numerical generality, i.e. we want them to apply broadly across problem instances. We find that prior approaches using Transformers fail to meet these criteria, and identify limitations present in existing architectures and training procedures. First, we show that softmax Transformers struggle to perform high-precision multiplications, which prevents them from precisely learning numerical algorithms. Second, we identify an alternate class of architectures, comprised entirely of polynomials, that can efficiently represent high-precision gradient descent iterates. Finally, we investigate precision bottlenecks during training and address them via a high-precision training recipe that reduces stochastic gradient noise. Our recipe enables us to train two polynomial architectures, gated convolutions and linear attention, to perform gradient descent iterates on least squares problems. For the first time, we demonstrate the ability to train to near machine precision. Applied iteratively, our models obtain $100,000\times$ lower MSE than standard Transformers trained end-to-end and they incur a $10,000\times$ smaller generalization gap on out-of-distribution problems. We make progress towards end-to-end learning of numerical algorithms for least squares.
  abstract_embedding: [0.2470703125, 0.1494140625, 0.27734375]... (1536 items)
  authors: ['Jerry Weihong Liu', 'Jessica Grogan', 'Owen M Dugan']... (7 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:41:12.501240
  code_metadata_s3_key: KOhUW5oBclM7MZc3VZPe/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: KOhUW5oBclM7MZc3VZPe/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468844998
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Towards_Learning_High-Precision_Least_Squares_Algorithms_with_Sequence_Models.pdf
  sha_abstract: a0aacaa6150ff4c3864629affca9d59c7d3fcd0f37d4a48bf46efd5ef51d0945
  title: Towards Learning High-Precision Least Squares Algorithms with Sequence Models
  title_normalized: towards_learning_highprecision_least_squares_algorithms_with_sequence_models

================================================================================
Document #153 (ID: Nug2ZpoBclM7MZc3wJOV)
================================================================================
  abstract: Policy gradient methods have become a staple of any single-agent reinforcement learning toolbox, due to their combination of desirable properties: iterate convergence, efficient use of stochastic trajectory feedback, and theoretically-sound avoidance of importance sampling corrections. In multi-agent imperfect-information settings (extensive-form games), however, it is still unknown whether the same desiderata can be guaranteed while retaining theoretical guarantees. Instead, sound methods for extensive-form games rely on approximating \emph{counterfactual} values (as opposed to Q values), which are incompatible with policy gradient methodologies. In this paper, we investigate whether policy gradient can be safely used in two-player zero-sum imperfect-information extensive-form games (EFGs). We establish positive results, showing for the first time that a policy gradient method leads to provable best-iterate convergence to a regularized Nash equilibrium in self-play.
  abstract_embedding: [0.82421875, 0.58203125, 0.04052734375]... (1536 items)
  authors: ['Mingyang Liu', 'Gabriele Farina', 'Asuman E. Ozdaglar']
  code_generated: True
  code_generated_at: 2025-11-09T01:25:55.576721
  code_metadata_s3_key: Nug2ZpoBclM7MZc3wJOV/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: Nug2ZpoBclM7MZc3wJOV/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762651455530
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: A_Policy-Gradient_Approach_to_Solving_Imperfect-Information_Games_with_Best-Iterate_Convergence.pdf
  sha_abstract: dd9845131d8bb2a36793379f26ab197675b30b0e5e8bd9ea51e564092fc8488e
  title: A Policy-Gradient Approach to Solving Imperfect-Information Games with Best-Iterate Convergence
  title_normalized: a_policygradient_approach_to_solving_imperfectinformation_games_with_bestiterate_convergence

================================================================================
Document #154 (ID: N-g2ZpoBclM7MZc3xpPD)
================================================================================
  abstract: Accurate prediction of thermodynamic properties is essential in drug discovery and materials science. Molecular dynamics (MD) simulations provide a principled approach to this task, yet they typically rely on prohibitively long sequential simulations. Implicit Transfer Operator (ITO) Learning offers a promising approach to address this limitation by enabling stable simulation with time steps orders of magnitude larger than MD. However, to train ITOs, we need extensive, unbiased MD data, limiting the scope of this framework. Here, we introduce Boltzmann Priors for ITO (BoPITO) to enhance ITO learning in two ways. First, BoPITO enables more efficient data generation, and second, it embeds inductive biases for long-term dynamical behavior, simultaneously improving sample efficiency by one order of magnitude and guaranteeing asymptotically unbiased equilibrium statistics. Furthermore, we showcase the use of BoPITO in a new tunable sampling protocol interpolating between ITOs trained on off-equilibrium simulations and an equilibrium model by incorporating unbiased correlation functions. Code is available at https://github.com/olsson-group/bopito.
  abstract_embedding: [-0.1337890625, 0.62109375, 0.29296875]... (1536 items)
  authors: ['Juan Viguera Diez', 'Mathias Jacob Schreiner', 'Ola Engkvist']... (4 items)
  code_generated: True
  code_generated_at: 2025-11-09T01:25:18.751188
  code_metadata_s3_key: N-g2ZpoBclM7MZc3xpPD/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: N-g2ZpoBclM7MZc3xpPD/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762651457188
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Boltzmann_priors_for_Implicit_Transfer_Operators.pdf
  sha_abstract: 90396f6e0f64a54399caf017a2ae9275b223e16c1741405a6b430255cad1f04f
  title: Boltzmann priors for Implicit Transfer Operators
  title_normalized: boltzmann_priors_for_implicit_transfer_operators

================================================================================
Document #155 (ID: NehUW5oBclM7MZc3lpNY)
================================================================================
  abstract: Tabular data generation has recently attracted a growing interest due to its different application scenarios. However, 
generating time series of tabular data, where each element of the series depends on the others,
remains a largely unexplored domain. 
This gap is probably due to the difficulty of jointly solving different problems, the main of which are the heterogeneity of tabular data (a problem common to non-time-dependent approaches) and the variable length of a time series.
In this paper, we propose a Diffusion Transformers (DiTs) based approach for tabular data series generation. Inspired by the recent success of DiTs in image and video generation, we extend this framework to deal with heterogeneous data and variable-length sequences. 
Using extensive experiments on six datasets, we show that the proposed approach  outperforms previous work by a large margin.
  abstract_embedding: [0.48046875, -0.037109375, 0.7421875]... (1536 items)
  authors: ['Fabrizio Garuti', 'Enver Sangineto', 'Simone Luetto']... (5 items)
  code_generated: True
  code_generated_at: 2025-11-06T22:41:22.305960
  code_metadata_s3_key: NehUW5oBclM7MZc3lpNY/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: NehUW5oBclM7MZc3lpNY/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762468861515
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Diffusion_Transformers_for_Tabular_Data_Time_Series_Generation.pdf
  sha_abstract: c31a6a36017ee539d9da44cb5efb4bdad2194eefe1b74aee98440ede84fb62d4
  title: Diffusion Transformers for Tabular Data Time Series Generation
  title_normalized: diffusion_transformers_for_tabular_data_time_series_generation

================================================================================
Document #156 (ID: Oeg2ZpoBclM7MZc3z5Pj)
================================================================================
  abstract: Vision-Language adaptation (VL adaptation) transforms Large Language Models (LLMs) into Large Vision-Language Models (LVLMs) for multimodal tasks, but this process often compromises the inherent safety capabilities embedded in the original LLMs. Despite potential harmfulness due to weakened safety measures, in-depth analysis on the effects of VL adaptation on safety remains under-explored. This study examines how VL adaptation influences safety and evaluates the impact of safety fine-tuning methods. Our analysis reveals that safety degradation occurs during VL adaptation, even when the training data is safe. While safety tuning techniques like supervised fine-tuning with safety datasets or reinforcement learning from human feedback mitigate some risks, they still lead to safety degradation and a reduction in helpfulness due to over-rejection issues. Further analysis of internal model weights suggests that VL adaptation may impact certain safety-related layers, potentially lowering overall safety levels. Additionally, our findings demonstrate that the objectives of VL adaptation and safety tuning are divergent, which often results in their simultaneous application being suboptimal. To address this, we suggest the weight merging approach as an optimal solution effectively reducing safety degradation while maintaining helpfulness. These insights help guide the development of more reliable and secure LVLMs for real-world applications.
  abstract_embedding: [0.703125, 0.1611328125, -0.0673828125]... (1536 items)
  authors: ['Seongyun Lee', 'Geewook Kim', 'Jiyeon Kim']... (7 items)
  code_generated: True
  code_generated_at: 2025-11-09T01:26:17.804011
  code_metadata_s3_key: Oeg2ZpoBclM7MZc3z5Pj/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: Oeg2ZpoBclM7MZc3z5Pj/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762651459500
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: How_Does_Vision-Language_Adaptation_Impact_the_Safety_of_Vision_Language_Models_.pdf
  sha_abstract: b38cf3e78d39c9ddbed4a9d7f0b96028f03f425c0cbd46165357b1f203366a9d
  title: How Does Vision-Language Adaptation Impact the Safety of Vision Language Models?
  title_normalized: how_does_visionlanguage_adaptation_impact_the_safety_of_vision_language_models

================================================================================
Document #157 (ID: Oug2ZpoBclM7MZc30pNS)
================================================================================
  abstract: In recent years, there has been increasing attention on the capabilities of large-scale models, particularly in handling complex tasks that small-scale models are unable to perform. Notably, large language models (LLMs) have demonstrated ``intelligent'' abilities such as complex reasoning and abstract language comprehension, reflecting cognitive-like behaviors. However, current research on emergent abilities in large models predominantly focuses on the relationship between model performance and size, leaving a significant gap in the systematic quantitative analysis of the internal structures and mechanisms driving these emergent abilities. Drawing inspiration from neuroscience research on brain network structure and self-organization, we propose (i) a general network representation of large models, (ii) a new analytical framework — *Neuron-based Multifractal Analysis (NeuroMFA)* - for structural analysis, and (iii) a novel structure-based metric as a proxy for emergent abilities of large models. By linking structural features to the capabilities of large models, *NeuroMFA* provides a quantitative framework for analyzing emergent phenomena in large models. Our experiments show that the proposed method yields a comprehensive measure of the network's evolving heterogeneity and organization, offering theoretical foundations and a new perspective for investigating emergence in large models.
  abstract_embedding: [-0.035400390625, 0.4140625, -0.006011962890625]... (1536 items)
  authors: ['Xiongye Xiao', 'Heng Ping', 'Chenyu Zhou']... (9 items)
  code_generated: True
  code_generated_at: 2025-11-09T01:26:38.165596
  code_metadata_s3_key: Oug2ZpoBclM7MZc30pNS/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: Oug2ZpoBclM7MZc30pNS/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762651460142
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Neuron-based_Multifractal_Analysis_of_Neuron_Interaction_Dynamics_in_Large_Models.pdf
  sha_abstract: 3310d0db7834f307efed29209e6dc91011177853ed6aae74d5dcdc03d4e001e5
  title: Neuron-based Multifractal Analysis of Neuron Interaction Dynamics in Large Models
  title_normalized: neuronbased_multifractal_analysis_of_neuron_interaction_dynamics_in_large_models

================================================================================
Document #158 (ID: OOg2ZpoBclM7MZc3yJN8)
================================================================================
  abstract: Generative models lack rigorous statistical guarantees with respect to their predictions. In this work, we propose Sequential Conformal Prediction for Generative Models (SCOPE-Gen), a sequential conformal prediction method producing prediction sets that satisfy a rigorous statistical guarantee called conformal admissibility control. This guarantee means that the prediction sets contain at least one admissible (or valid) example, with high probability. To this end, our method first samples an initial set of i.i.d. examples from a black box generative model. Then, this set is iteratively pruned via so-called greedy filters. As a consequence of the iterative generation procedure, admissibility of the final prediction set factorizes as a Markov chain, where each factor can be controlled separately, using conformal prediction. In comparison to prior work, our method demonstrates a large reduction in the number of admissibility evaluations during calibration. This is crucial e.g. in safety-critical applications, where these evaluations must be conducted manually by domain experts and are therefore costly and time consuming. We highlight the advantages of our method in terms of admissibility evaluations and cardinality of the prediction set through experiments in natural language generation and molecular graph extension tasks.
  abstract_embedding: [0.275390625, 0.416015625, 0.031005859375]... (1536 items)
  authors: ['Klaus-Rudolf Kladny', 'Bernhard Schölkopf', 'Michael Muehlebach']
  code_generated: True
  code_generated_at: 2025-11-09T01:25:59.339029
  code_metadata_s3_key: OOg2ZpoBclM7MZc3yJN8/metadata.json
  code_s3_bucket: papers-code-artifacts
  code_s3_key: OOg2ZpoBclM7MZc3yJN8/code.py
  date: 2024-10-04
  decision: accept
  ingested_at: 1762651457597
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Conformal_Generative_Modeling_with_Improved_Sample_Efficiency_through_Sequential_Greedy_Filtering.pdf
  sha_abstract: 84f6528c37fb81b3321f92c2bbe029ff9ec1497d1eadd737a7215a5b52b87662
  title: Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering
  title_normalized: conformal_generative_modeling_with_improved_sample_efficiency_through_sequential_greedy_filtering

================================================================================
Document #159 (ID: PehHZpoBclM7MZc3OpN7)
================================================================================
  abstract: Feedback data is widely used for fine-tuning and evaluating state-of-the-art AI models. Pairwise text preferences, where human or AI annotators select the “better” of two options, are particularly common. Such preferences are used to train (reward) models or to rank models with aggregate statistics. For many applications it is desirable to understand annotator preferences in addition to modelling them  – not least because extensive prior work has shown various unintended biases in preference datasets. Yet, preference datasets remain challenging to interpret. Neither black-box reward models nor statistics can answer why one text is preferred over another. Manual interpretation of the numerous (long) response pairs is usually equally infeasible. In this paper, we introduce the Inverse Constitutional AI (ICAI) problem, formulating the interpretation of pairwise text preference data as a compression task. In constitutional AI, a set of principles (a constitution) is used to provide feedback and fine-tune AI models. ICAI inverts this process: given a feedback dataset, we aim to extract a constitution that best enables a large language model (LLM) to reconstruct the original annotations. We propose a corresponding ICAI algorithm and validate its generated constitutions quantitatively based on annotation reconstruction accuracy on several datasets: (a) synthetic feedback data with known principles; (b) AlpacaEval cross-annotated human feedback data; (c) crowdsourced Chatbot Arena data; and (d) PRISM data from diverse demographic groups. As an example application, we further demonstrate the detection of biases in human feedback data. As a short and interpretable representation of the original dataset, generated constitutions have many potential use cases: they may help identify undesirable annotator biases, better understand model performance, scale feedback to unseen data, or assist with adapting AI models to individual user or group preferences. We release the source code for our algorithm and experiments at https://github.com/rdnfn/icai.
  abstract_embedding: [-0.01092529296875, 0.330078125, -0.11669921875]... (1536 items)
  authors: ['Arduin Findeis', 'Timo Kaufmann', 'Eyke Hüllermeier']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652535366
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Inverse_Constitutional_AI__Compressing_Preferences_into_Principles.pdf
  sha_abstract: 25a816fd95f6c5a39f7fabdbec1f2aa6234d2f164a4bb794c354c6baf254d857
  title: Inverse Constitutional AI: Compressing Preferences into Principles
  title_normalized: inverse_constitutional_ai_compressing_preferences_into_principles

================================================================================
Document #160 (ID: PuhHZpoBclM7MZc3PZPl)
================================================================================
  abstract: Text-conditioned human motion generation, which allows for user interaction through natural language, has become increasingly popular. Existing methods typically generate short, isolated motions based on a single input sentence. However, human motions are continuous and can extend over long periods, carrying rich semantics. Creating long, complex motions that precisely respond to streams of text descriptions, particularly in an online and real-time setting, remains a significant challenge. Furthermore, incorporating spatial constraints into text-conditioned motion generation presents additional challenges, as it requires aligning the motion semantics specified by text descriptions with geometric information, such as goal locations and 3D scene geometry. To address these limitations, we propose **DartC**ontrol, in short **DART**, a **D**iffusion-based **A**utoregressive motion primitive model for **R**eal-time **T**ext-driven motion **C**ontrol. Our model, DART, effectively learns a compact motion primitive space jointly conditioned on motion history and text inputs using latent diffusion models. By autoregressively generating motion primitives based on the preceding history and current text input, DART enables real-time, sequential motion generation driven by natural language descriptions. Additionally,  the learned motion primitive space allows for precise spatial motion control, which we formulate either as a latent noise optimization problem or as a Markov decision process addressed through reinforcement learning. We present effective algorithms for both approaches, demonstrating our model’s versatility and superior performance in various motion synthesis tasks. Experiments show our method outperforms existing baselines in motion realism, efficiency, and controllability. Video results and code are available at https://zkf1997.github.io/DART/.
  abstract_embedding: [0.3203125, 0.41015625, 0.279296875]... (1536 items)
  authors: ['Kaifeng Zhao', 'Gen Li', 'Siyu Tang']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652536269
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: DartControl__A_Diffusion-Based_Autoregressive_Motion_Model_for_Real-Time_Text-Driven_Motion_Control.pdf
  sha_abstract: c5cff511537f9ff25f26e8617c6df3710ba8fe868246632636d9a345b69d63be
  title: DartControl: A Diffusion-Based Autoregressive Motion Model for Real-Time Text-Driven Motion Control
  title_normalized: dartcontrol_a_diffusionbased_autoregressive_motion_model_for_realtime_textdriven_motion_control

================================================================================
Document #161 (ID: QOhHZpoBclM7MZc3Q5M8)
================================================================================
  abstract: The ability to construct transferable descriptors for molecular and biological systems has broad applications in drug discovery, molecular dynamics, and protein analysis. Geometric graph neural networks (Geom-GNNs) utilizing all-atom information have revolutionized atomistic simulations by enabling the prediction of interatomic potentials and molecular properties. Despite these advances, the application of all-atom Geom-GNNs in protein modeling remains limited due to computational constraints. In this work, we first demonstrate the potential of pre-trained Geom-GNNs as zero-shot transfer learners, effectively modeling protein systems with all-atom granularity. Through extensive experimentation to evaluate their expressive power, we characterize the scaling behaviors of Geom-GNNs across self-supervised, supervised, and unsupervised setups. Interestingly, we find that Geom-GNNs deviate from conventional power-law scaling observed in other domains, with no predictable scaling principles for molecular representation learning. Furthermore, we show how pre-trained graph embeddings can be directly used for analysis and synergize with other architectures to enhance expressive power for protein modeling.
  abstract_embedding: [-0.0260009765625, 0.486328125, 0.099609375]... (1536 items)
  authors: ['Zihan Pengmei', 'Zhengyuan Shen', 'Zichen Wang']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652537598
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Pushing_the_Limits_of_All-Atom_Geometric_Graph_Neural_Networks__Pre-Training__Scaling__and_Zero-Shot_Transfer.pdf
  sha_abstract: 6cd786019e8605c8e1c19a82037d407d4ea8b8da3b9aa694d44c3f7479c584c7
  title: Pushing the Limits of All-Atom Geometric Graph Neural Networks: Pre-Training, Scaling, and Zero-Shot Transfer
  title_normalized: pushing_the_limits_of_allatom_geometric_graph_neural_networks_pretraining_scaling_and_zeroshot_transfer

================================================================================
Document #162 (ID: POhHZpoBclM7MZc3OJPw)
================================================================================
  abstract: Momentum based optimizers are central to a wide range of machine learning applications. These typically rely on an Exponential Moving Average (EMA) of gradients, which decays exponentially the present contribution of older gradients. This accounts for gradients being local linear approximations which lose their relevance as the iterate moves along the loss landscape. This work questions the use of a single EMA to accumulate past gradients and empirically demonstrates how this choice can be sub-optimal: a single EMA cannot simultaneously give a high weight to the immediate past, and a non-negligible weight to older gradients. Building on this observation, we propose AdEMAMix, a simple modification of the Adam optimizer with a mixture of two EMAs to better take advantage of past gradients. Our experiments on language modeling and image classification show---quite surprisingly---that gradients can stay relevant for tens of thousands of steps. They help to converge faster, and often to lower minima: e.g., a $1.3$B parameter AdEMAMix LLM trained on $101$B tokens performs comparably to an AdamW model trained on $197$B tokens ($+95\%$). Moreover, our method significantly slows-down model forgetting during training. Our work motivates further exploration of different types of functions to leverage past gradients, beyond EMAs.
  abstract_embedding: [1.1015625, 0.16796875, 0.134765625]... (1536 items)
  authors: ['Matteo Pagliardini', 'Pierre Ablin', 'David Grangier']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652534992
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: The_AdEMAMix_Optimizer__Better__Faster__Older.pdf
  sha_abstract: 721eabf7ce68db7817d060b77be44e0509751c9f60cee971170ebcba5bcda532
  title: The AdEMAMix Optimizer: Better, Faster, Older
  title_normalized: the_ademamix_optimizer_better_faster_older

================================================================================
Document #163 (ID: P-hHZpoBclM7MZc3QZPZ)
================================================================================
  abstract: Many works have developed no-regret algorithms for contextual bandits with function approximation, where the mean rewards over context-action pairs belong to a function class $\mathcal{F}$. Although there are many approaches to this problem, algorithms based on the principle of optimism, such as optimistic least squares have gained in importance. It can be shown the regret of this algorithm scales as $\widetilde{\mathcal{O}}\left(\sqrt{d_{\mathrm{eluder}}(\mathcal{F}) \log(\mathcal{F}) T }\right)$ where $d_{\mathrm{eluder}}(\mathcal{F})$ is a statistical measure of the complexity of the function class $\mathcal{F}$ known as eluder dimension.  Unfortunately, even if the variance of the measurement noise of the rewards at time $t$ equals $\sigma_t^2$ and these are close to zero, the optimistic least squares algorithm’s regret scales with $\sqrt{T}$. In this work we are the first to develop algorithms that satisfy regret bounds for contextual bandits with function approximation of the form $\widetilde{\mathcal{O}}\left( \sigma \sqrt{\log(\mathcal{F})d_{\mathrm{eluder}}(\mathcal{F}) T } + d_{\mathrm{eluder}}(\mathcal{F}) \cdot \log(|\mathcal{F}|)\right) $ when the variances are unknown and satisfy $\sigma_t^2 = \sigma$ for all $t$ and $\widetilde{\mathcal{O}}\left( d_{\mathrm{eluder}}(\mathcal{F})\sqrt{\log(\mathcal{F})\sum_{t=1}^T \sigma_t^2  } + d_{\mathrm{eluder}}(\mathcal{F}) \cdot \log(|\mathcal{F}|)\right) $  when the variances change every time-step. These bounds generalize existing techniques for deriving second order bounds in contextual linear problems.
  abstract_embedding: [0.06689453125, 0.33203125, 0.349609375]... (1536 items)
  authors: ['Aldo Pacchiano']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652537262
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Second_Order_Bounds_for_Contextual_Bandits_with_Function_Approximation.pdf
  sha_abstract: c7c09ffa87238bf57b8f9d3eeb7283b305dcb7ea8abcf4172f93baf48ba83c41
  title: Second Order Bounds for Contextual Bandits with Function Approximation
  title_normalized: second_order_bounds_for_contextual_bandits_with_function_approximation

================================================================================
Document #164 (ID: O-hHZpoBclM7MZc3NZN7)
================================================================================
  abstract: Machine unlearning is a critical area of research aimed at safeguarding data privacy by enabling the removal of sensitive information from machine learning models. One unique challenge in this field is catastrophic unlearning, where erasing specific data from a well-trained model unintentionally removes essential knowledge, causing the model to deviate significantly from a retrained one. To address this, we introduce a novel approach that regularizes the unlearning process by utilizing synthesized mixup samples, which simulate the data susceptible to catastrophic effects. At the core of our approach is a generator-unlearner framework, MixUnlearn, where a generator adversarially produces challenging mixup examples, and the unlearner effectively forgets target information based on these synthesized data. Specifically, we first introduce a novel contrastive objective to train the generator in an adversarial direction: generating examples that prompt the unlearner to reveal information that should be forgotten, while losing essential knowledge. Then the unlearner, guided by two other contrastive loss terms, processes the synthesized and real data jointly to ensure accurate unlearning without losing critical knowledge, overcoming catastrophic effects. Extensive evaluations across benchmark datasets demonstrate that our method significantly outperforms state-of-the-art approaches, offering a robust solution to machine unlearning. This work not only deepens understanding of unlearning mechanisms but also lays the foundation for effective machine unlearning with mixup augmentation.
  abstract_embedding: [0.59375, 0.435546875, -0.00180816650390625]... (1536 items)
  authors: ['Zhuoyi PENG', 'Yixuan Tang', 'Yi Yang']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652534049
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Adversarial_Mixup_Unlearning.pdf
  sha_abstract: 1b3a949996b7e8156fd9fa98bf390418e538058900fa63c891cfafd66ce49ab7
  title: Adversarial Mixup Unlearning
  title_normalized: adversarial_mixup_unlearning

================================================================================
Document #165 (ID: RuhHZpoBclM7MZc3UJM6)
================================================================================
  abstract: Code has been shown to be effective in enhancing the mathematical reasoning abilities of large language models due to its precision and accuracy. Previous works involving continued mathematical pretraining  often include code that utilizes math-related packages, which are primarily designed for fields such as engineering, machine learning, signal processing, or module testing, rather than being directly focused on mathematical reasoning. In this paper, we introduce a novel method for generating mathematical code accompanied with corresponding reasoning steps for continued pretraining. Our approach begins with the construction of a high-quality mathematical continued pretraining dataset by incorporating math-related web data, code using mathematical packages, math textbooks, and synthetic data. Next, we construct reasoning steps by extracting LaTeX expressions, the conditions needed for the expressions, and the results of the expressions from the previously collected dataset. Based on this extracted information, we generate corresponding code to accurately capture the mathematical reasoning process. Appending the generated code to each reasoning step results in data consisting of paired natural language reasoning steps and their corresponding code. Combining this data with the original dataset results in a 19.2B-token high-performing mathematical pretraining corpus, which we name MathCode-Pile. Training several popular base models with this corpus significantly improves their mathematical abilities, leading to the creation of the MathCoder2 family of models. All of our data processing and training code is open-sourced, ensuring full transparency and easy reproducibility of the entire data collection and training pipeline.
  abstract_embedding: [0.296875, 0.3671875, 0.296875]... (1536 items)
  authors: ['Zimu Lu', 'Aojun Zhou', 'Ke Wang']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652540962
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MathCoder2__Better_Math_Reasoning_from_Continued_Pretraining_on_Model-translated_Mathematical_Code.pdf
  sha_abstract: eb66f3255069f9fa1718c1243249ec2d689860b9c41c9b74d04c1684f53b7d3e
  title: MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code
  title_normalized: mathcoder2_better_math_reasoning_from_continued_pretraining_on_modeltranslated_mathematical_code

================================================================================
Document #166 (ID: Q-hHZpoBclM7MZc3SJPm)
================================================================================
  abstract: Large Language Models (LLMs) applied to code-related applications have emerged as a prominent field, attracting significant interest from academia and industry. However, as new and improved LLMs are developed, existing evaluation benchmarks (e.g., HumanEvla, MBPP) are no longer sufficient for assessing their capabilities suffering from data contamination, overfitting, saturation, and focus on merely code generation. In this work, we propose LiveCodeBench, a comprehensive and contamination-free evaluation of LLMs for code, which collects new problems over time from contests across three competition platforms, Leetcode, Atcoder, and Codeforces. Notably, our benchmark also focuses on a broader range of code-related capabilities, such as self-repair, code execution, and test output prediction, beyond just code generation. Currently, LiveCodeBench hosts over six hundred coding problems that were published between May 2023 and Aug 2024. We evaluate over 50 LLMs on LiveCodeBench (LCB for brevity) presenting the largest evaluation study of code LLMs on competition problems. Based on the study, we present novel empirical findings on contamination, overfitting, and holistic evaluations. We demonstrate that time-segmented evaluations serve as a robust approach to evade contamination; they are successful at detecting contamination across a wide range of open and closed models including GPT-4O, Claude, Deepseek, and Codestral. Next, we highlight overfitting and saturation of traditional coding benchmarks like HumanEvla and demonstrate LCB allows more reliable evaluations. Finally, our holistic evaluation scenarios allow for measuring the different capabilities of programming agents in isolation.
  abstract_embedding: [0.423828125, 0.20703125, 0.29296875]... (1536 items)
  authors: ['Naman Jain', 'King Han', 'Alex Gu']... (10 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652539080
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: LiveCodeBench__Holistic_and_Contamination_Free_Evaluation_of_Large_Language_Models_for_Code.pdf
  sha_abstract: addae2285a052467c9db4a025661a67521342994cb4d6a4642502e74d7166074
  title: LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code
  title_normalized: livecodebench_holistic_and_contamination_free_evaluation_of_large_language_models_for_code

================================================================================
Document #167 (ID: RehHZpoBclM7MZc3TpMX)
================================================================================
  abstract: The deployment of Deep Neural Networks (DNNs) in energy-constrained environments, such as Energy Harvesting Wireless Sensor Networks (EH-WSNs), introduces significant challenges due to the intermittent nature of power availability. This study introduces NExUME, a novel training methodology designed specifically for DNNs operating under such constraints. We propose a dynamic adjustment of training parameters—dropout rates and quantization levels—that adapt in real-time to the available energy, which varies in energy harvesting scenarios.

This approach utilizes a model that integrates the characteristics of the network architecture and the specific energy harvesting profile. It dynamically adjusts training strategies, such as the intensity and timing of dropout and quantization, based on predictions of energy availability. This method not only conserves energy but also enhances the network’s adaptability, ensuring robust learning and inference capabilities even under stringent power constraints. Our results show a 6% to 22% improvement in accuracy over current methods, with an increase of less than 5% in computational overhead. This paper details the development of the adaptive training framework, describes the integration of energy profiles with dropout and quantization adjustments, and presents a comprehensive evaluation using real-world data. Additionally, we introduce a novel dataset aimed at furthering the application of energy harvesting in computational settings.
  abstract_embedding: [-0.0289306640625, 0.052490234375, 0.0654296875]... (1536 items)
  authors: ['Cyan Subhra Mishra', 'Deeksha Chaudhary', 'Jack Sampson']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652540378
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: NExUME__Adaptive_Training_and_Inference_for_DNNs_under_Intermittent_Power_Environments.pdf
  sha_abstract: c829ae22f4b4bba4e51d828c65fd0e1aafc4adb571661fd4f7db74a414f69cae
  title: NExUME: Adaptive Training and Inference for DNNs under Intermittent Power Environments
  title_normalized: nexume_adaptive_training_and_inference_for_dnns_under_intermittent_power_environments

================================================================================
Document #168 (ID: SOhHZpoBclM7MZc3UpM9)
================================================================================
  abstract: As large language models (LLMs) are rapidly advancing and achieving near-human capabilities on specific tasks, aligning them with human values is becoming more urgent. In scenarios where LLMs outperform humans, we face a weak-to-strong alignment problem where we need to effectively align strong student LLMs through weak supervision generated by weak teachers. Existing alignment methods mainly focus on strong-to-weak alignment and self-alignment settings, and it is impractical to adapt them to the much harder weak-to-strong alignment setting. To fill this gap, we propose a multi-agent contrastive preference optimization (MACPO) framework. MACPO facilitates weak teachers and strong students to learn from each other by iteratively reinforcing unfamiliar positive behaviors while penalizing familiar negative ones. To get this, we devise a mutual positive behavior augmentation strategy to encourage weak teachers and strong students to learn from each other's positive behavior and further provide higher quality positive behavior for the next iteration. Additionally, we propose a hard negative behavior construction strategy to induce weak teachers and strong students to generate familiar negative behavior by fine-tuning on negative behavioral data. Experimental results on the HH-RLHF and PKU-SafeRLHF datasets, evaluated using both automatic metrics and human judgments, demonstrate that MACPO simultaneously improves the alignment performance of strong students and weak teachers. Moreover, as the number of weak teachers increases, MACPO achieves better weak-to-strong alignment performance through more iteration optimization rounds.
  abstract_embedding: [0.546875, 0.60546875, 0.078125]... (1536 items)
  authors: ['Yougang Lyu', 'Lingyong Yan', 'Zihan Wang']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652541471
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MACPO__Weak-to-Strong_Alignment_via_Multi-Agent_Contrastive_Preference_Optimization.pdf
  sha_abstract: 0c932039fcf2bde530985aa566e92b411d4f5499445b7f35310a470443d7860e
  title: MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization
  title_normalized: macpo_weaktostrong_alignment_via_multiagent_contrastive_preference_optimization

================================================================================
Document #169 (ID: R-hHZpoBclM7MZc3UZNO)
================================================================================
  abstract: With the rise of medical foundation models and the growing availability of imaging data, scalable pretraining techniques offer a promising way to identify imaging biomarkers predictive of future disease risk. While current self-supervised methods for 3D medical imaging models capture local structural features like organ morphology, they fail to link pixel biomarkers with long-term health outcomes due to a missing context problem. Current approaches lack the temporal context necessary to identify biomarkers correlated with disease progression, as they rely on supervision derived only from images and concurrent text descriptions. To address this, we introduce time-to-event pretraining, a pretraining framework for 3D medical imaging models that leverages large-scale temporal supervision from paired, longitudinal electronic health records (EHRs). Using a dataset of 18,945 CT scans (4.2 million 2D images) and time-to-event distributions across thousands of EHR-derived tasks, our method improves outcome prediction, achieving an average AUROC increase of 23.7% and a 29.4% gain in Harrell’s C-index across 8 benchmark tasks. Importantly, these gains are achieved without sacrificing diagnostic classification performance. This study lays the foundation for integrating longitudinal EHR and 3D imaging data to advance clinical risk prediction.
  abstract_embedding: [0.35546875, 0.01171875, 0.0201416015625]... (1536 items)
  authors: ['Zepeng Frazier Huo', 'Jason Alan Fries', 'Alejandro Lozano']... (9 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652541219
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Time-to-Event_Pretraining_for_3D_Medical_Imaging.pdf
  sha_abstract: 37e1f31ea127119e2a47b580602aa5e79b237cbc8a0ab7b53216cdabc9187719
  title: Time-to-Event Pretraining for 3D Medical Imaging
  title_normalized: timetoevent_pretraining_for_3d_medical_imaging

================================================================================
Document #170 (ID: QehHZpoBclM7MZc3RpNS)
================================================================================
  abstract: The video-conditioned policy takes prompt videos of the desired tasks as a condition and is regarded for its prospective generalizability. Despite its promise, training a video-conditioned policy is non-trivial due to the need for abundant demonstrations. In some tasks, the expert rollouts are merely available as videos, and costly and time-consuming efforts are required to annotate action labels. To address this, we explore training video-conditioned policy on a mixture of demonstrations and unlabeled expert videos to reduce reliance on extensive manual annotation. We introduce the Joint Embedding Predictive Transformer (JEPT) to learn a video-conditioned policy through sequence modeling. JEPT is designed to jointly learn visual transition prediction and inverse dynamics. The visual transition is captured from both demonstrations and expert videos, on the basis of which the inverse dynamics learned from demonstrations is generalizable to the tasks without action labels. Experiments on a series of simulated visual control tasks evaluate that JEPT can effectively leverage the mixture dataset to learn a generalizable policy. JEPT outperforms baselines in the tasks without action-labeled data and unseen tasks. We also experimentally reveal the potential of JEPT as a simple visual priors injection approach to enhance the video-conditioned policy.
  abstract_embedding: [0.2392578125, 0.3515625, 0.4609375]... (1536 items)
  authors: ['Hao Luo', 'Zongqing Lu']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652538429
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Learning_Video-Conditioned_Policy_on_Unlabelled_Data_with_Joint_Embedding_Predictive_Transformer.pdf
  sha_abstract: f1b0ca9e6d8f866b78a820e5cc52d865bbd83b95adbb7e31604e28eed89ac8a3
  title: Learning Video-Conditioned Policy on Unlabelled Data with Joint Embedding Predictive Transformer
  title_normalized: learning_videoconditioned_policy_on_unlabelled_data_with_joint_embedding_predictive_transformer

================================================================================
Document #171 (ID: ROhHZpoBclM7MZc3SpM4)
================================================================================
  abstract: As function approximators, deep neural networks have served as an effective tool to represent various signal types. Recent approaches utilize multi-layer perceptrons (MLPs) to learn a nonlinear mapping from a coordinate to its corresponding signal, facilitating the learning of continuous neural representations from discrete data points. Despite notable successes in learning diverse signal types, coordinate-based MLPs often face issues of overfitting and limited generalizability beyond the training region, resulting in subpar extrapolation performance. This study addresses scenarios where the underlying true signals exhibit periodic properties, either spatially or temporally. We propose a novel network architecture, which extracts periodic patterns from measurements and leverages this information to represent the signal, thereby enhancing generalization and improving extrapolation performance. We demonstrate the efficacy of the proposed method through comprehensive experiments, including the learning of the periodic solutions for differential equations, and time series imputation (interpolation) and forecasting (extrapolation) on real-world datasets.
  abstract_embedding: [0.41796875, 0.470703125, 0.29296875]... (1536 items)
  authors: ['Woojin Cho', 'Minju Jo', 'Kookjin Lee']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652539407
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Neural_Functions_for_Learning_Periodic_Signal.pdf
  sha_abstract: 1ea927545c6ab2b1c639f82a80f82f96eb405b08df2f2ca24e49e93211d762ef
  title: Neural Functions for Learning Periodic Signal
  title_normalized: neural_functions_for_learning_periodic_signal

================================================================================
Document #172 (ID: QuhHZpoBclM7MZc3R5Ok)
================================================================================
  abstract: Measuring biodiversity is crucial for understanding ecosystem health. While prior works have developed machine learning models for taxonomic classification of photographic images and DNA separately, in this work, we introduce a multi-modal approach combining both, using CLIP-style contrastive learning to align images, barcode DNA, and text-based representations of taxonomic labels in a unified embedding space. This allows for accurate classification of both known and unknown insect species without task-specific fine-tuning, leveraging contrastive learning for the first time to fuse DNA and image data. Our method surpasses previous single-modality approaches in accuracy by over 8% on zero-shot learning tasks, showcasing its effectiveness in biodiversity studies.
  abstract_embedding: [0.34765625, 0.546875, 0.01068115234375]... (1536 items)
  authors: ['ZeMing Gong', 'Austin Wang', 'Xiaoliang Huo']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652538759
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CLIBD__Bridging_Vision_and_Genomics_for_Biodiversity_Monitoring_at_Scale.pdf
  sha_abstract: 827b9146e8be83e507ae171c4cd2e2da35db0e9c5385cb44164356e60965ea52
  title: CLIBD: Bridging Vision and Genomics for Biodiversity Monitoring at Scale
  title_normalized: clibd_bridging_vision_and_genomics_for_biodiversity_monitoring_at_scale

================================================================================
Document #173 (ID: UehHZpoBclM7MZc3ZpNn)
================================================================================
  abstract: Large Language Models (LLMs) are increasingly being used in workflows involving generating content to be consumed by humans (*e.g.,* marketing) and also in directly interacting with humans (*e.g.,* through chatbots). The development of such systems that are capable of generating verifiably persuasive messages presents both opportunities and challenges for society. On the one hand, such systems could positively impact domains like advertising and social good, such as addressing drug addiction, and on the other, they could be misused for spreading misinformation and shaping political opinions. To channel LLMs' impact on society, we need to develop systems to measure and benchmark their persuasiveness. With this motivation, we introduce **PersuasionBench** and **PersuasionArena**, the first large-scale benchmark and arena containing a battery of tasks to automatically measure the simulative and generative persuasion abilities of large language models. We introduce **transsuasion** (trans = carrying across, suasion = the act of persuading), a novel task of transforming non-persuasive language into persuasive content while preserving other factors determining persuasiveness (sender, receiver, time, and channel). Our findings indicate that the simulative persuasion capabilities of LLMs are barely above random; however, their generative persuasion capabilities are much better. For instance, GPT-4o loses only 36% of the time when playing against the best human persuader. Further, we find that LLMs' persuasiveness correlates positively with model size, but smaller models can also be made to have a higher persuasiveness than much larger models. Notably, targeted training using synthetic and natural datasets significantly enhances smaller models' persuasive capabilities, challenging scale-dependent assumptions. Our findings carry key implications for both model developers and policymakers. For instance, while the EU AI Act and California's SB-1047 aim to regulate AI models based on the number of floating point operations, we demonstrate that simple metrics like this alone fail to capture the full scope of AI's societal impact. We invite the community to explore and contribute to PersuasionArena and PersuasionBench, available at [behavior-in-the-wild.github.io/measure-persuasion](https://behavior-in-the-wild.github.io/measure-persuasion), to advance our understanding of AI-driven persuasion and its societal implications.
  abstract_embedding: [0.80078125, 0.255859375, 0.052490234375]... (1536 items)
  authors: ['Somesh Kumar Singh', 'Yaman Kumar Singla', 'Harini S I']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652546602
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Measuring_And_Improving_Persuasiveness_Of_Large_Language_Models.pdf
  sha_abstract: 18fc1889fe853dafa64efb3dbb118cab96b3b3436203e2e7e94b9fb4f2b06782
  title: Measuring And Improving Persuasiveness Of Large Language Models
  title_normalized: measuring_and_improving_persuasiveness_of_large_language_models

================================================================================
Document #174 (ID: T-hHZpoBclM7MZc3YZOD)
================================================================================
  abstract: Spatial intelligence is the ability of a machine to perceive, reason, and act in three dimensions within space and time.
Recent advancements in large-scale auto-regressive models have demonstrated remarkable capabilities across various reasoning tasks. However, these models often struggle with fundamental aspects of spatial reasoning, particularly in answering questions like "Where am I?" and "What will I see?". While some attempts have been done, existing approaches typically treat them as separate tasks, failing to capture their interconnected nature. In this paper, we present **G**enerative **S**patial **T**ransformer (GST), a novel auto-regressive framework that jointly addresses spatial localization and view prediction. Our model simultaneously estimates the camera pose from a single image and predicts the view from a new camera pose, effectively bridging the gap between spatial awareness and visual prediction. The proposed innovative camera tokenization method enables the model to learn the joint distribution of 2D projections and their corresponding spatial perspectives in an auto-regressive manner. This unified training paradigm demonstrates that joint optimization of pose estimation and novel view synthesis leads to improved performance in both tasks, for the first time, highlighting the inherent relationship between spatial awareness and visual prediction.
  abstract_embedding: [0.0830078125, -0.2431640625, 0.326171875]... (1536 items)
  authors: ['Junyi Chen', 'Di Huang', 'Weicai Ye']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652545403
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Where_Am_I_and_What_Will_I_See__An_Auto-Regressive_Model_for_Spatial_Localization_and_View_Prediction.pdf
  sha_abstract: 8561e15af7062e74b03c5d28f7c967863a993a8ffc9244c2ac5bf38a306890cf
  title: Where Am I and What Will I See: An Auto-Regressive Model for Spatial Localization and View Prediction
  title_normalized: where_am_i_and_what_will_i_see_an_autoregressive_model_for_spatial_localization_and_view_prediction

================================================================================
Document #175 (ID: S-hHZpoBclM7MZc3WpMk)
================================================================================
  abstract: This work tackles the information loss bottleneck of vector-quantization (VQ) autoregressive image generation by introducing a novel model architecture called the 2-Dimensional Autoregression (DnD) Transformer. The DnD-Transformer predicts more codes for an image by introducing a new direction, **model depth**, along with the sequence length. Compared to 1D autoregression and previous work using similar 2D image decomposition such as RQ-Transformer, the DnD-Transformer is an end-to-end model that can generate higher quality images with the same backbone model size and sequence length, opening a new optimization perspective for autoregressive image generation. Furthermore, our experiments reveal that the DnD-Transformer's potential extends beyond generating natural images. It can even generate images with rich text and graphical elements in a self-supervised manner, demonstrating an understanding of these combined modalities. This has not been previously demonstrated for popular vision generative models such as diffusion models, showing a spark of vision-language intelligence when trained solely on images. Code, datasets and models are open at https://github.com/chenllliang/DnD-Transformer.
  abstract_embedding: [0.154296875, -0.0830078125, 0.455078125]... (1536 items)
  authors: ['Liang Chen', 'Sinan Tan', 'Zefan Cai']... (10 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652543486
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: A_Spark_of_Vision-Language_Intelligence__2-Dimensional_Autoregressive_Transformer_for_Efficient_Finegrained_Image_Generation.pdf
  sha_abstract: 5b290a336ac314c12b8ac66e7a633742ef8a5eaf1a1c408d0919bc86b243e340
  title: A Spark of Vision-Language Intelligence: 2-Dimensional Autoregressive Transformer for Efficient Finegrained Image Generation
  title_normalized: a_spark_of_visionlanguage_intelligence_2dimensional_autoregressive_transformer_for_efficient_finegrained_image_generation

================================================================================
Document #176 (ID: TehHZpoBclM7MZc3XJPT)
================================================================================
  abstract: In pretraining data detection, the goal is to detect whether a given sentence is in the dataset used for training a Large Language Model LLM). Recent methods (such as Min-K % and Min-K%++) reveal that most training corpora are likely contaminated with both sensitive content and evaluation benchmarks, leading to inflated test set performance. These methods sometimes fail to detect samples from the pretraining data, primarily because they depend on statistics composed of causal token likelihoods. We introduce Infilling Score, a new test-statistic based on non-causal token likelihoods. Infilling Score can be computed for autoregressive models without re-training using Bayes rule. A naive application of Bayes rule scales linearly with the vocabulary size. However, we propose a ratio test-statistic whose computation is invariant to vocabulary size. Empirically, our method achieves a significant accuracy gain over state-of-the-art methods including Min-K%, and Min-K%++ on the WikiMIA benchmark across seven models with different parameter sizes. Further, we achieve higher AUC compared to reference-free methods on the challenging MIMIR benchmark. Finally, we create a benchmark dataset consisting of recent data sources published after the release of Llama-3; this benchmark provides a statistical baseline to indicate potential corpora used for Llama-3 training.
  abstract_embedding: [0.259765625, 0.50390625, 0.193359375]... (1536 items)
  authors: ['Negin Raoof', 'Litu Rout', 'Giannis Daras']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652544197
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Infilling_Score__A_Pretraining_Data_Detection_Algorithm_for_Large_Language_Models.pdf
  sha_abstract: 7338a791968bb05e419ab839e29a2be132c461602c466e2981cd69b04d8f54fe
  title: Infilling Score: A Pretraining Data Detection Algorithm for Large Language Models
  title_normalized: infilling_score_a_pretraining_data_detection_algorithm_for_large_language_models

================================================================================
Document #177 (ID: SuhHZpoBclM7MZc3VZNH)
================================================================================
  abstract: Video generation requires modeling a vast spatiotemporal space, which demands significant computational resources and data usage. To reduce the complexity, the prevailing approaches employ a cascaded architecture to avoid direct training with full resolution latent. Despite reducing computational demands, the separate optimization of each sub-stage hinders knowledge sharing and sacrifices flexibility. This work introduces a unified pyramidal flow matching algorithm. It reinterprets the original denoising trajectory as a series of pyramid stages, where only the final stage operates at the full resolution, thereby enabling more efficient video generative modeling. Through our sophisticated design, the flows of different pyramid stages can be interlinked to maintain continuity. Moreover, we craft autoregressive video generation with a temporal pyramid to compress the full-resolution history. The entire framework can be optimized in an end-to-end manner and with a single unified Diffusion Transformer (DiT). Extensive experiments demonstrate that our method supports generating high-quality 5-second (up to 10-second) videos at 768p resolution and 24 FPS within 20.7k A100 GPU training hours. All code and models are open-sourced at https://pyramid-flow.github.io.
  abstract_embedding: [0.01025390625, -0.052001953125, 0.44140625]... (1536 items)
  authors: ['Yang Jin', 'Zhicheng Sun', 'Ningyuan Li']... (11 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652542214
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Pyramidal_Flow_Matching_for_Efficient_Video_Generative_Modeling.pdf
  sha_abstract: fc51f69814967dd25ebdc0060f19aefd8f3b4b9b096d373d6e2a1357fe41869f
  title: Pyramidal Flow Matching for Efficient Video Generative Modeling
  title_normalized: pyramidal_flow_matching_for_efficient_video_generative_modeling

================================================================================
Document #178 (ID: TOhHZpoBclM7MZc3WpPu)
================================================================================
  abstract: Universal dexterous grasping across diverse objects presents a fundamental yet formidable challenge in robot learning. Existing approaches using reinforcement learning (RL) to develop policies on extensive object datasets face critical limitations, including complex curriculum design for multi-task learning and limited generalization to unseen objects. 
To overcome these challenges, we introduce ResDex, a novel approach that integrates residual policy learning with a mixture-of-experts (MoE) framework. ResDex is distinguished by its use of geometry-agnostic base policies that are efficiently acquired on individual objects and capable of generalizing across a wide range of unseen objects. Our MoE framework incorporates several base policies to facilitate diverse grasping styles suitable for various objects. By learning residual actions alongside weights that combine these base policies, ResDex enables efficient multi-task RL for universal dexterous grasping.
ResDex achieves state-of-the-art performance on the DexGraspNet dataset comprising 3,200 objects with an 88.8% success rate. It exhibits no generalization gap with unseen objects and demonstrates superior training efficiency, mastering all tasks within only 12 hours on a single GPU. For further details and videos, visit our project page.
  abstract_embedding: [1.28125, 0.1572265625, 0.36328125]... (1536 items)
  authors: ['Ziye Huang', 'Haoqi Yuan', 'Yuhui Fu']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652543716
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Efficient_Residual_Learning_with_Mixture-of-Experts_for_Universal_Dexterous_Grasping.pdf
  sha_abstract: 2f16f58a6f28a8679c786c64f6c41843321ff5bb0091e34714fe6b07b4dc07c7
  title: Efficient Residual Learning with Mixture-of-Experts for Universal Dexterous Grasping
  title_normalized: efficient_residual_learning_with_mixtureofexperts_for_universal_dexterous_grasping

================================================================================
Document #179 (ID: TuhHZpoBclM7MZc3XpOt)
================================================================================
  abstract: The potential of large language models (LLMs) as decision support tools is increasingly being explored in fields such as business, engineering, and medicine, which often face challenging tasks of *decision-making under uncertainty*. In this paper, we show that directly prompting LLMs on these types of decision-making problems can yield poor results, especially as the problem complexity increases. To aid in these tasks, we propose DeLLMa (Decision-making Large Language Model assistant), a framework designed to enhance decision-making accuracy in uncertain environments. DeLLMa involves a multi-step reasoning procedure that integrates recent best practices in scaling *inference-time reasoning*, drawing upon principles from decision theory and utility theory, to provide an accurate and human-auditable decision-making process. We validate our procedure on multiple realistic decision-making environments, demonstrating that DeLLMa can consistently enhance the decision-making performance of leading language models, and achieve up to a 40% increase in accuracy over competing methods. Additionally, we show how performance improves when scaling compute at test time, and carry out human evaluations to benchmark components of DeLLMa.
  abstract_embedding: [0.50390625, 0.0986328125, 0.287109375]... (1536 items)
  authors: ['Ollie Liu', 'Deqing Fu', 'Dani Yogatama']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652544659
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: DeLLMa__Decision_Making_Under_Uncertainty_with_Large_Language_Models.pdf
  sha_abstract: 5f60da8f5660a3f9ca08ee81a0d93c937ab3438df7d1b37302b35f8d5d95b937
  title: DeLLMa: Decision Making Under Uncertainty with Large Language Models
  title_normalized: dellma_decision_making_under_uncertainty_with_large_language_models

================================================================================
Document #180 (ID: SehHZpoBclM7MZc3U5Pt)
================================================================================
  abstract: Skill learning from language instructions is a critical challenge in developing intelligent agents that can generalize across diverse tasks and follow complex human instructions. Hierarchical methods address this by decomposing the learning problem into multiple levels, where the high-level and low-level policies are mediated through a latent plan space. Effective modeling and learning of this latent plan space are key to enabling robust and interpretable skill learning. In this paper, we introduce LADS, a hierarchical approach that learns language-conditioned discrete latent plans through semantic skill abstractions. Our method decouples the learning of the latent plan space from the language-conditioned high-level policy to improve training stability. First, we incorporate a trajectory encoder to learn a discrete latent space with the low-level policy, regularized by language instructions. Next, we model the high-level policy as a categorical distribution over these discrete latent plans to capture the multi-modality of the dataset. Through experiments in simulated control environments, we demonstrate that LADS outperforms state-of-the-art methods in both skill learning and compositional generalization.
  abstract_embedding: [0.84375, 0.357421875, 0.41015625]... (1536 items)
  authors: ['Haobin Jiang', 'Jiangxing Wang', 'Zongqing Lu']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652541905
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Discrete_Latent_Plans_via_Semantic_Skill_Abstractions.pdf
  sha_abstract: ba295660ae1e64bf5446e1727b0a9e1629dd6789101f2da29e30ddac5251bef6
  title: Discrete Latent Plans via Semantic Skill Abstractions
  title_normalized: discrete_latent_plans_via_semantic_skill_abstractions

================================================================================
Document #181 (ID: WuhHZpoBclM7MZc3cZNa)
================================================================================
  abstract: Communication is defined as "*Who* says *what* to *whom* with *what* effect." A message from a communicator generates downstream receiver effects, also known as behavior. Receiver behavior, being a downstream effect of the message, carries rich signals about it. Even after carrying signals about the message, the behavior signal is often ignored while training vision-language models. We show that training VLMs on receiver behavior can actually help improve their content-understanding abilities. We demonstrate that training VLMs to predict receiver behaviors, such as likes, comments, and replay graphs, which are available at scale, enhances the VLM's performance across a broad range of downstream content understanding tasks. We show this performance increase over 6 types of behavior, 46 different tasks covering image, video, text, and audio over 26 benchmark datasets across both zero-shot and fine-tuning settings, outperforming many supervised baselines on diverse tasks ranging from emotion recognition to captioning by up to 150%. We note that since receiver behavior, such as likes, comments, and replay graphs, is collected by default on the internet and does not need any human annotations to be useful, the performance improvement we get after training on this data is essentially free lunch.  We also release **BLIFT**, our **Behaviour-LLaVA IFT** dataset comprising 730k images and videos with their receiver behavior collected from multiple platforms on which we train our models to achieve this. The dataset and code are available at [behavior-in-the-wild.github.io/behavior-llava](https://behavior-in-the-wild.github.io/behavior-llava).
  abstract_embedding: [0.22265625, 0.014404296875, 0.14453125]... (1536 items)
  authors: ['Somesh Kumar Singh', 'Harini S I', 'Yaman Kumar Singla']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652549457
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Teaching_Human_Behavior_Improves_Content_Understanding_Abilities_Of_VLMs.pdf
  sha_abstract: 39b5d26014e353c3e8758016327ac89020679a60ee1b9d652e9d5b7ab2d82cee
  title: Teaching Human Behavior Improves Content Understanding Abilities Of VLMs
  title_normalized: teaching_human_behavior_improves_content_understanding_abilities_of_vlms

================================================================================
Document #182 (ID: WOhHZpoBclM7MZc3b5OX)
================================================================================
  abstract: Existing Video Scene Graph Generation (VidSGG) studies are trained in a fully supervised manner, which requires all frames in a video to be annotated, thereby incurring high annotation cost compared to Image Scene Graph Generation (ImgSGG). Although the annotation cost of VidSGG can be alleviated by adopting a weakly supervised approach commonly used for ImgSGG (WS-ImgSGG) that uses image captions, there are two key reasons that hinder such a naive adoption: 1) Temporality within video captions, i.e., unlike image captions, video captions include temporal markers (e.g., before, while, then, after) that indicate time-related details, and 2) Variability in action duration, i.e., unlike human actions in image captions, human actions in video captions unfold over varying duration. To address these issues, we propose a Natural Language-based Video Scene Graph Generation (NL-VSGG) framework that only utilizes the readily available video captions for training a VidSGG model. NL-VSGG consists of two key modules: Temporality-aware Caption Segmentation (TCS) module and Action Duration Variability-aware caption-frame alignment (ADV) module. Specifically, TCS segments the video captions into multiple sentences in a temporal order based on a Large Language Model (LLM), and ADV aligns each segmented sentence with appropriate frames considering the variability in action duration. Our approach leads to a significant enhancement in performance compared to simply applying the WS-ImgSGG pipeline to VidSGG on the Action Genome dataset. As a further benefit of utilizing the video captions as weak supervision, we show that the VidSGG model trained by NL-VSGG is able to predict a broader range of action classes that are not included in the training data, which makes our framework practical in reality.
  abstract_embedding: [-0.0069580078125, 0.51953125, 0.23046875]... (1536 items)
  authors: ['Kibum Kim', 'Kanghoon Yoon', 'Yeonjun In']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652548983
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Weakly_Supervised_Video_Scene_Graph_Generation_via_Natural_Language_Supervision.pdf
  sha_abstract: dccea06ed98bbecc61f47cd6aae9b5957f699408ce1e83374524ca397a818858
  title: Weakly Supervised Video Scene Graph Generation via Natural Language Supervision
  title_normalized: weakly_supervised_video_scene_graph_generation_via_natural_language_supervision

================================================================================
Document #183 (ID: VuhHZpoBclM7MZc3bZPq)
================================================================================
  abstract: In the realm of large-scale language models, a significant challenge arises when extrapolating sequences beyond the maximum allowable length. 
This is because the model's position embedding mechanisms are limited to positions encountered during training, thus preventing effective representation of positions in longer sequences.
We analyzed conventional position encoding methods for long contexts and found the following characteristics.
(1) When the representation dimension is regarded as the time axis, Rotary Position Embedding (RoPE) can be interpreted as a restricted wavelet transform using Haar-like wavelets. 
However, because it uses only a fixed scale parameter, it does not fully exploit the advantages of wavelet transforms, which capture the fine movements of non-stationary signals using multiple scales (window sizes). 
This limitation could explain why RoPE performs poorly in extrapolation.
(2)
Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention, using windows of varying sizes.
However, it has limitations in capturing deep dependencies because it restricts the receptive field of the model.
From these insights, we propose a new position representation method that captures multiple scales (i.e., window sizes) by leveraging wavelet transforms without limiting the model's attention field.
Experimental results show that this new method improves the performance of the model in both short and long contexts. 
In particular, our method allows extrapolation of position information without limiting the model's attention field.
  abstract_embedding: [0.25390625, 0.3984375, 0.43359375]... (1536 items)
  authors: ['Yui Oka', 'Taku Hasegawa', 'Kyosuke Nishida']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652548563
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Wavelet-based_Positional_Representation_for_Long_Context.pdf
  sha_abstract: b703606e85aa5bdb35db7ac23d9d6b5ee5836e6fd54072b3f5f4f199ddfdca1f
  title: Wavelet-based Positional Representation for Long Context
  title_normalized: waveletbased_positional_representation_for_long_context

================================================================================
Document #184 (ID: WehHZpoBclM7MZc3cJNv)
================================================================================
  abstract: Post-training quantization (PTQ) techniques applied to weights, activations, and the KV cache greatly reduce memory usage, latency, and power consumption of Large Language Models (LLMs), but may lead to large quantization errors when outliers are present. Rotating activation or weight matrices helps remove outliers and benefits quantization. In this work, we identify a collection of applicable rotation parameterizations that lead to identical outputs in full-precision Transformer architectures while enhancing quantization accuracy. In addition, we find that some random rotations lead to much better quantization than others, with an up to 13 points difference in downstream zero-shot reasoning performance. As a result, we propose SpinQuant, a novel approach that incorporates learned rotation matrices for optimal quantized network accuracy. With 4-bit quantization of weight, activation, and KV-cache, SpinQuant narrows the accuracy gap on zero-shot reasoning tasks with full precision to merely 2.9 points on the LLaMA-2 7B model, surpassing LLM-QAT by 19.1 points and SmoothQuant by 25.0 points. Furthermore, SpinQuant also outperforms concurrent work QuaRot, which applies random rotations to remove outliers. In particular, for LLaMA-3 8B models that are hard to quantize, SpinQuant reduces the gap to full precision by up to 45.1% relative to QuaRot. Code is available at https://github.com/facebookresearch/SpinQuant.
  abstract_embedding: [0.05224609375, 0.205078125, 0.39453125]... (1536 items)
  authors: ['Zechun Liu', 'Changsheng Zhao', 'Igor Fedorov']... (9 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652549213
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SpinQuant__LLM_Quantization_with_Learned_Rotations.pdf
  sha_abstract: 19a1e9b0210f36ee3a5ac1980fde673f6d4c0474e3b08532ec06c9cf1447cc1f
  title: SpinQuant: LLM Quantization with Learned Rotations
  title_normalized: spinquant_llm_quantization_with_learned_rotations

================================================================================
Document #185 (ID: U-hHZpoBclM7MZc3aJPE)
================================================================================
  abstract: Speculative decoding (SD), where an extra draft model is employed to provide multiple **draft** tokens first and then the original target model verifies these tokens in parallel, has shown great power for LLM inference acceleration.
However, existing SD methods suffer from the mutual waiting problem, i.e., the target model gets stuck when the draft model is *guessing* tokens, and vice versa. This problem is directly incurred by the asynchronous execution of the draft model and the target model, and is exacerbated due to the fixed draft length in speculative decoding.
To address these challenges, we propose a conceptually simple, flexible, and general framework to boost speculative decoding, namely 
**P**arallel sp**E**culative decoding with **A**daptive d**R**aft **L**ength (PEARL). 
Specifically, PEARL proposes *pre-verify* to verify the first draft token in advance during the drafting phase, and *post-verify* to generate more draft tokens during the verification phase.
PEARL parallels the drafting phase and the verification phase via applying the two strategies, and achieves adaptive draft length for different scenarios, which effectively alleviates the mutual waiting problem.
Experiments on various text generation benchmarks demonstrate the effectiveness of our PEARL, leading to a superior speedup performance up to **4.43$\times$** and **1.50$\times$**, compared to auto-regressive decoding and vanilla speculative decoding, respectively.
  abstract_embedding: [0.146484375, 0.2373046875, 0.3828125]... (1536 items)
  authors: ['Tianyu Liu', 'Yun Li', 'Qitan Lv']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652547257
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: PEARL__Parallel_Speculative_Decoding_with_Adaptive_Draft_Length.pdf
  sha_abstract: c4ea84ced88430de125af0f2501cec5b3e0a8ff5e44934a312b59cdfe6d97aa4
  title: PEARL: Parallel Speculative Decoding with Adaptive Draft Length
  title_normalized: pearl_parallel_speculative_decoding_with_adaptive_draft_length

================================================================================
Document #186 (ID: VOhHZpoBclM7MZc3apOS)
================================================================================
  abstract: In response to the increasing demand for tackling out-of-domain (OOD) scenarios, test-time adaptation (TTA) has garnered significant research attention in recent years. To adapt a source pre-trained model to target samples without getting access to their labels, existing approaches have typically employed entropy minimization (EM) loss as a primary objective function. In this paper, we propose an adaptive energy alignment (AEA) solution that achieves fast online TTA. We start from the re-interpretation of the EM loss by decomposing it into two energy-based terms with conflicting roles, showing that the EM loss can potentially hinder the assertive model adaptation. Our AEA addresses this challenge by strategically reducing the energy gap between the source and target domains during TTA, aiming to  effectively align the target domain with the source domains and thus to accelerate adaptation. We specifically propose two novel strategies, each contributing a necessary component for TTA: (i) aligning the energy level of each target sample with the energy zone of the source domain that the pre-trained model is already familiar with, and (ii) precisely guiding the direction of the energy alignment by matching the class-wise correlations between the source and target domains. Our approach demonstrates its effectiveness on various domain shift datasets including CIFAR10-C, CIFAR100-C, and TinyImageNet-C.
  abstract_embedding: [0.2333984375, 0.035888671875, 0.1328125]... (1536 items)
  authors: ['Wonjeong Choi', 'Do-Yeon Kim', 'Jungwuk Park']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652547688
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Adaptive_Energy_Alignment_for_Accelerating_Test-Time_Adaptation.pdf
  sha_abstract: a60a1c3d3a3eb153c7c9c6ffd13cf8c44ed17abf50ae7e7056f4d8072120ef5d
  title: Adaptive Energy Alignment for Accelerating Test-Time Adaptation
  title_normalized: adaptive_energy_alignment_for_accelerating_testtime_adaptation

================================================================================
Document #187 (ID: V-hHZpoBclM7MZc3bpPI)
================================================================================
  abstract: Inspired by the Kolmogorov-Arnold representation theorem, we propose Kolmogorov-Arnold Networks (KANs) as promising alternatives to Multi-Layer Perceptrons (MLPs). While MLPs have fixed activation functions on nodes ("neurons''), KANs have learnable activation functions on edges ("weights''). KANs have no linear weights at all -- every weight parameter is replaced by a univariate function parametrized as a spline. We show that this seemingly simple change makes KANs outperform MLPs in terms of accuracy and interpretability, on small-scale AI + Science tasks. For accuracy, smaller KANs can achieve comparable or better accuracy than larger MLPs in function fitting tasks. Theoretically and empirically, KANs possess faster neural scaling laws than MLPs. For interpretability, KANs can be intuitively visualized and can easily interact with human users. Through two examples in mathematics and physics, KANs are shown to be useful ``collaborators'' helping scientists (re)discover mathematical and physical laws. In summary, KANs are promising alternatives for MLPs. Despite the slow training of KANs, their improved accuracy and interpretability show the potential to improve today's deep learning models which rely heavily on MLPs. More research is necessary to make KANs' training more efficient.
  abstract_embedding: [0.4296875, 0.267578125, -0.125]... (1536 items)
  authors: ['Ziming Liu', 'Yixuan Wang', 'Sachin Vaidya']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652548772
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: KAN__Kolmogorov_Arnold_Networks.pdf
  sha_abstract: be0400dff60b35692e8f9c57f03bbd5d57d1bd57ad47a8ac05107de9dd8fd958
  title: KAN: Kolmogorov–Arnold Networks
  title_normalized: kan_kolmogorovarnold_networks

================================================================================
Document #188 (ID: UOhHZpoBclM7MZc3ZZNE)
================================================================================
  abstract: We introduce TetSphere Splatting, a Lagrangian geometry representation designed for high-quality 3D shape modeling. TetSphere splatting leverages an underused yet powerful geometric primitive -- volumetric tetrahedral meshes. It represents 3D shapes by deforming a collection of tetrahedral spheres, with geometric regularizations and constraints that effectively resolve common mesh issues such as irregular triangles, non-manifoldness, and floating artifacts. Experimental results on multi-view and single-view reconstruction highlight TetSphere splatting's superior mesh quality while maintaining competitive reconstruction accuracy compared to state-of-the-art methods. Additionally, TetSphere splatting demonstrates versatility by seamlessly integrating into generative modeling tasks, such as image-to-3D and text-to-3D generation.
  abstract_embedding: [0.30078125, 0.11181640625, -0.134765625]... (1536 items)
  authors: ['Minghao Guo', 'Bohan Wang', 'Kaiming He']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652546362
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: TetSphere_Splatting__Representing_High-Quality_Geometry_with_Lagrangian_Volumetric_Meshes.pdf
  sha_abstract: 6c80e780b9c58afbc8f316ebec78e35bd82732edb6170bd09a684eb43369c276
  title: TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes
  title_normalized: tetsphere_splatting_representing_highquality_geometry_with_lagrangian_volumetric_meshes

================================================================================
Document #189 (ID: VehHZpoBclM7MZc3a5NX)
================================================================================
  abstract: We present Pyramid Attention Broadcast (PAB), a real-time, high quality and training-free approach for DiT-based video generation. Our method is founded on the observation that attention difference in the diffusion process exhibits a U-shaped pattern, indicating significant redundancy. We mitigate this by broadcasting attention outputs to subsequent steps in a pyramid style. It applies different broadcast strategies to each attention based on their variance for best efficiency. We further introduce broadcast sequence parallel for more efficient distributed inference. PAB demonstrates up to 10.5x speedup across three models compared to baselines, achieving real-time generation for up to 720p videos. We anticipate that our simple yet effective method will serve as a robust baseline and facilitate future research and application for video generation.
  abstract_embedding: [0.005218505859375, 0.279296875, 0.275390625]... (1536 items)
  authors: ['Xuanlei Zhao', 'Xiaolong Jin', 'Kai Wang']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652547917
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Real-Time_Video_Generation_with_Pyramid_Attention_Broadcast.pdf
  sha_abstract: 9bf817c5065ea20b9acdf562a1ccb1c720730fb3642b059bb0145e21ec968c7d
  title: Real-Time Video Generation with Pyramid Attention Broadcast
  title_normalized: realtime_video_generation_with_pyramid_attention_broadcast

================================================================================
Document #190 (ID: UuhHZpoBclM7MZc3Z5Mo)
================================================================================
  abstract: Although it is traditionally believed that lossy image compression, such as JPEG compression, has a negative impact on the performance of deep neural networks (DNNs), it is shown by recent works that well-crafted JPEG compression can actually improve the performance of deep learning (DL). Inspired by this, we propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer. To make the quantization operation in JPEG compression trainable, a new differentiable soft quantizer is employed at the JPEG layer, and then the quantization operation and underlying DNN are jointly trained. Extensive experiments show that in comparison with the standard DL,  JPEG-DL delivers significant accuracy improvements across various datasets and model architectures while enhancing robustness against adversarial attacks. Particularly, on some fine-grained image classification datasets, JPEG-DL can increase prediction accuracy by as much as 20.9%. Our code is available on https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL.git.
  abstract_embedding: [0.0634765625, 0.55078125, 0.447265625]... (1536 items)
  authors: ['Ahmed H. Salamah', 'Kaixiang Zheng', 'Yiwen Liu']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652546846
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: JPEG_Inspired_Deep_Learning.pdf
  sha_abstract: 15e3779394814e5f249cf98e8a04665437e795ff9a6da8eeb1c6577509aa4092
  title: JPEG Inspired Deep Learning
  title_normalized: jpeg_inspired_deep_learning

================================================================================
Document #191 (ID: X-hHZpoBclM7MZc3eJN6)
================================================================================
  abstract: In this work, we introduce ChatQA 2, an Llama 3.0-based model with a 128K
context window, designed to bridge the gap between open-source LLMs and
leading proprietary models (e.g., GPT-4-Turbo-2024-04-09) in long context un-
derstanding and retrieval-augmented generation (RAG) capabilities. These two
capabilities are complementary to each other and essential for LLMs to process
large volumes of information that cannot fit into a single prompt. We present
a detailed continued training recipe to extend the context window of Llama3-
70B-base from 8K to 128K tokens, along with a three-stage instruction tun-
ing process to enhance the model’s instruction-following, RAG performance,
and long-context understanding capabilities. Our results demonstrate that the
Llama3-ChatQA-2-70B model outperforms most existing state-of-the-art models,
including GPT-4-Turbo-2024-04-09, Qwen2-72B-Instruct, and Llama3.1-70B-
Instruct, on ultra-long tasks beyond 100K tokens, as well as on the RAG benchmark
using only a 4K context window, showing the strong long context capability across
varying sequence lengths. We further provide extensive comparisons between
direct long-context and RAG solutions using the same state-of-the-art long-context
LLMs. Interestingly, we find that the performance of strong long-context LLMs
using RAG improves when retrieving a larger number of chunks. With a large set
of top-k chunks, RAG consistently outperforms direct long-context solution using
the same state-of-the-art long-context models (e.g., Llama3-ChatQA-2-70B and
Qwen2-72B-Instruct) on both 32K and 128K benchmarks. We open-source the
model weights, training data, and the evaluation setup for the for the community:
https://chatqa2-project.github.io/
  abstract_embedding: [0.12158203125, 0.017333984375, 0.1826171875]... (1536 items)
  authors: ['Peng Xu', 'Wei Ping', 'Xianchao Wu']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652551283
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ChatQA_2__Bridging_the_Gap_to_Proprietary_LLMs_in_Long_Context_and_RAG_Capabilities.pdf
  sha_abstract: 7cb6dbfa45647dad72507a06bb7d8fcbe07816050d3642130487159f647e3f7c
  title: ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG Capabilities
  title_normalized: chatqa_2_bridging_the_gap_to_proprietary_llms_in_long_context_and_rag_capabilities

================================================================================
Document #192 (ID: YOhHZpoBclM7MZc3eZNk)
================================================================================
  abstract: Prompt learning has demonstrated promising results in fine-tuning pre-trained multimodal models. However, the performance improvement is limited when applied to more complex and fine-grained tasks. The reason is that most existing methods directly optimize the parameters involved in the prompt generation process through loss backpropagation, which constrains the richness and specificity of the prompt representations. In this paper, we propose Diffusion-Driven Prompt Generator (Diff-Prompt), aiming to use the diffusion model to generate rich and fine-grained prompt information for complex downstream tasks. Specifically, our approach consists of three stages. In the first stage, we train a Mask-VAE to compress the masks into latent space. In the second stage, we leverage an improved Diffusion Transformer (DiT) to train a prompt generator in the latent space, using the masks for supervision. In the third stage, we align the denoising process of the prompt generator with the pre-trained model in the semantic space, and use the generated prompts to fine-tune the model. We conduct experiments on a complex pixel-level downstream task, referring expression comprehension, and compare our method with various parameter-efficient fine-tuning approaches. Diff-Prompt achieves a maximum improvement of 8.87 in R@1 and 14.05 in R@5 compared to the foundation model and also outperforms other state-of-the-art methods across multiple metrics. The experimental results validate the effectiveness of our approach and highlight the potential of using generative models for prompt generation. Code is available at https://github.com/Kelvin-ywc/diff-prompt.
  abstract_embedding: [0.1044921875, 0.55859375, 0.1416015625]... (1536 items)
  authors: ['Weicai Yan', 'Wang Lin', 'Zirun Guo']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652551517
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Diff-Prompt__Diffusion-driven_Prompt_Generator_with_Mask_Supervision.pdf
  sha_abstract: 423cfd7270b26afaa72c85438c671342647d87da7e46c9bf9c8ad15ec55e69c4
  title: Diff-Prompt: Diffusion-driven Prompt Generator with Mask Supervision
  title_normalized: diffprompt_diffusiondriven_prompt_generator_with_mask_supervision

================================================================================
Document #193 (ID: XuhHZpoBclM7MZc3d5Ou)
================================================================================
  abstract: Kolmogorov-Arnold Networks (KAN) \cite{liu2024kan} were very recently proposed as a potential alternative to the prevalent architectural backbone of many deep learning models, the multi-layer perceptron (MLP). KANs have seen success in various tasks of AI for science, with their empirical efficiency and accuracy demonstrated in function regression, PDE solving, and many more scientific problems.
 
In this article, we revisit the comparison of KANs and MLPs, with emphasis on a theoretical perspective. On the one hand, we compare the representation and approximation capabilities of KANs and MLPs. We establish that MLPs can be represented using KANs of a comparable size. This shows that the approximation and representation capabilities of KANs are at least as good as MLPs. Conversely, we show that KANs can be represented using MLPs, but that in this representation the number of parameters increases by a factor of the KAN grid size. This suggests that KANs with a large grid size may be more efficient than MLPs at approximating certain functions. On the other hand, from the perspective of learning and optimization, we study the spectral bias of KANs compared with MLPs. We demonstrate that KANs are less biased toward low frequencies than MLPs. We highlight that the multi-level learning feature specific to KANs, i.e. grid extension of splines, improves the learning process for high-frequency components.  Detailed comparisons with different choices of depth, width, and grid sizes of KANs are made, shedding some light on how to choose the hyperparameters in practice.
  abstract_embedding: [0.48828125, 0.296875, -0.11962890625]... (1536 items)
  authors: ['Yixuan Wang', 'Jonathan W. Siegel', 'Ziming Liu']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652551067
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: On_the_expressiveness_and_spectral_bias_of_KANs.pdf
  sha_abstract: 1e9d7472d3271a447dbe2f858777cc2584213363686c73b799f4c4ac07ac308f
  title: On the expressiveness and spectral bias of KANs
  title_normalized: on_the_expressiveness_and_spectral_bias_of_kans

================================================================================
Document #194 (ID: XehHZpoBclM7MZc3dpPG)
================================================================================
  abstract: The growth in the number of parameters of Large Language Models (LLMs) has led to a significant surge in computational requirements, making them challenging and costly to deploy.
Speculative decoding (SD) leverages smaller models to efficiently propose future tokens, which are then verified by the LLM in parallel.
Small models that utilise activations from the LLM currently achieve the fastest decoding speeds.
However, we identify several limitations of SD models including the lack of on-policyness during training and partial observability. 
To address these shortcomings, we propose a more grounded architecture for small models by introducing a Mixture of Attentions for SD.
Our novel architecture can be applied in two scenarios: a conventional single device deployment and a novel client-server deployment where the small model is hosted on a consumer device and the LLM on a server.
In a single-device scenario, we demonstrate state-of-the-art speedups improving EAGLE-2 by 9.5% and its acceptance length by 25%.
In a client-server setting, our experiments demonstrate: 1) state-of-the-art latencies with minimal calls to the server for different network conditions, and 2) in the event of a complete disconnection, our approach can maintain higher accuracy compared to other SD methods and demonstrates advantages over API calls to LLMs, which would otherwise be unable to continue the generation process.
  abstract_embedding: [0.23046875, 0.33984375, 0.392578125]... (1536 items)
  authors: ['Matthieu Zimmer', 'Milan Gritta', 'Gerasimos Lampouras']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652550847
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Mixture_of_Attentions_For_Speculative_Decoding.pdf
  sha_abstract: ca663163724fcd4eeb6907e8073974adfbc0e88de24f12a6dedab29ce699fe69
  title: Mixture of Attentions For Speculative Decoding
  title_normalized: mixture_of_attentions_for_speculative_decoding

================================================================================
Document #195 (ID: YehHZpoBclM7MZc3epNA)
================================================================================
  abstract: Designing synthetically accessible molecules and recommending analogs to unsynthesizable molecules are important problems for accelerating molecular discovery. We reconceptualize both problems using ideas from program synthesis. Drawing inspiration from syntax-guided synthesis approaches, we decouple the syntactic skeleton from the semantics of a synthetic tree to create a bilevel framework for reasoning about the combinatorial space of synthesis pathways. Given a molecule we aim to generate analogs for, we iteratively refine its skeletal characteristics via Markov Chain Monte Carlo simulations over the space of syntactic skeletons. Given a black-box oracle to optimize, we formulate a joint design space over syntactic templates and molecular descriptors and introduce evolutionary algorithms that optimize both syntactic and semantic dimensions synergistically. Our key insight is that once the syntactic skeleton is set, we can amortize over the search complexity of deriving the program's semantics by training policies to fully utilize the fixed horizon Markov Decision Process imposed by the syntactic template. We demonstrate performance advantages of our bilevel framework for synthesizable analog generation and synthesizable molecule design. Notably, our approach offers the user explicit control over the resources required to perform synthesis and biases the design space towards simpler solutions, making it particularly promising for autonomous synthesis platforms. Supporting code is at https://github.com/shiningsunnyday/SynthesisNet.
  abstract_embedding: [0.90625, 0.2099609375, 0.125]... (1536 items)
  authors: ['Michael Sun', 'Alston Lo', 'Minghao Guo']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652551737
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Procedural_Synthesis_of_Synthesizable_Molecules.pdf
  sha_abstract: e043c423ee94a8ba743e74879ed46fb2df4b596e20f1b89b2f730b07e8a78d8b
  title: Procedural Synthesis of Synthesizable Molecules
  title_normalized: procedural_synthesis_of_synthesizable_molecules

================================================================================
Document #196 (ID: XOhHZpoBclM7MZc3dZMP)
================================================================================
  abstract: MLLM agents demonstrate potential for complex embodied tasks by retrieving multimodal task-relevant trajectory data. However, current retrieval methods primarily focus on surface-level similarities of textual or visual cues in trajectories, neglecting their effectiveness for the specific task at hand. To address this issue, we propose a novel method, MART, which enhances the performance of embodied agents by utilizing interaction data to fine-tune an MLLM retriever based on preference learning, such that the retriever fully considers the effectiveness of trajectories and prioritize them for unseen tasks. We also introduce Trajectory Abstraction, a mechanism that leverages MLLMs' summarization capabilities to represent trajectories with fewer tokens while preserving key information, enabling agents to better comprehend milestones in the trajectory. Experimental results across various environments demonstrate our method significantly improves task success rates in unseen scenes compared to baseline methods. This work presents a new paradigm for multimodal retrieval in embodied agents, by fine-tuning a general-purpose MLLM as the retriever to assess trajectory effectiveness. All the code for benchmark tasks, simulator modifications and the MLLM retriever is available at https://github.com/PKU-RL/MART.
  abstract_embedding: [0.87890625, 0.41015625, 0.5234375]... (1536 items)
  authors: ['Junpeng Yue', 'Xinrun Xu', 'Börje F. Karlsson']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652550405
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MLLM_as_Retriever__Interactively_Learning_Multimodal_Retrieval_for_Embodied_Agents.pdf
  sha_abstract: 558d1922093521ab1cd4a80009828852d0e75204515578663805e8895beeec44
  title: MLLM as Retriever: Interactively Learning Multimodal Retrieval for Embodied Agents
  title_normalized: mllm_as_retriever_interactively_learning_multimodal_retrieval_for_embodied_agents

================================================================================
Document #197 (ID: W-hHZpoBclM7MZc3c5MY)
================================================================================
  abstract: We propose Step-by-Step Coding (SBSC): a multi-turn math reasoning framework that enables Large Language Models (LLMs) to generate sequence of programs for solving Olympiad level math problems. After each turn/step, by leveraging the code execution outputs and programs of previous steps, the model generates the next sub-task and the corresponding program to complete it. This way, SBSC, sequentially navigates to reach the final answer. SBSC allows more granular, flexible and precise approach to problem-solving compared to existing methods. Extensive experiments highlight the effectiveness of SBSC in tackling competition and Olympiad-level math problems. For Claude-3.5-Sonnet, we observe SBSC (greedy decoding) surpasses existing state-of-the-art (SOTA) program generation based reasoning strategies by absolute 10.7% on AMC12, 8% on AIME and 12.6% on MathOdyssey. Given SBSC is multi-turn in nature, we also benchmark SBSC’s greedy decoding against self- consistency decoding results of existing SOTA math reasoning strategies and observe performance gain by absolute 6.2% on AMC, 6.7% on AIME and 7.4% on MathOdyssey.
  abstract_embedding: [0.1376953125, 0.0201416015625, 0.400390625]... (1536 items)
  authors: ['Kunal Singh', 'Ankan Biswas', 'Sayandeep Bhowmick']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652549893
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SBSC__Step-by-Step_Coding_for_Improving_Mathematical_Olympiad_Performance.pdf
  sha_abstract: 998b33220e1b381deabb692ceb7d82425192b1246c910507f29b2b8c25ffa436
  title: SBSC: Step-by-Step Coding for Improving Mathematical Olympiad Performance
  title_normalized: sbsc_stepbystep_coding_for_improving_mathematical_olympiad_performance

================================================================================
Document #198 (ID: Y-hHZpoBclM7MZc3fpMS)
================================================================================
  abstract: Diffusion models have become the dominant approach for visual generation. They are trained by denoising a Markovian process which gradually adds noise to the input. We argue that the Markovian property limits the model’s ability to fully utilize the generation trajectory, leading to inefficiencies during training and inference. In this paper, we propose DART, a transformer-based model that unifies autoregressive (AR) and diffusion within a non-Markovian framework.  DART iteratively denoises image patches spatially and spectrally using an AR model that has the same architecture as standard language models. DART does not rely on image quantization, which enables more effective image modeling while maintaining flexibility. Furthermore, DART seamlessly trains with both text and image data in a unified model. Our approach demonstrates competitive performance on class-conditioned and text-to-image generation tasks, offering a scalable, efficient alternative to traditional diffusion models. Through this unified framework, DART sets a new benchmark for scalable, high-quality image synthesis.
  abstract_embedding: [0.1337890625, 0.1708984375, 0.408203125]... (1536 items)
  authors: ['Jiatao Gu', 'Yuyang Wang', 'Yizhe Zhang']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652552683
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Denoising_Autoregressive_Transformers_for_Scalable_Text-to-Image_Generation.pdf
  sha_abstract: 5b7c5b7433d94f34a10098f6d6ad399d34ac264e15c2a1f3b0379b5b2487693e
  title: Denoising Autoregressive Transformers for Scalable Text-to-Image Generation
  title_normalized: denoising_autoregressive_transformers_for_scalable_texttoimage_generation

================================================================================
Document #199 (ID: YuhHZpoBclM7MZc3fZM5)
================================================================================
  abstract: Dexterous hands exhibit significant potential for complex real-world grasping tasks. While recent studies have primarily focused on learning policies for specific robotic hands, the development of a universal policy that controls diverse dexterous hands remains largely unexplored.
In this work, we study the learning of cross-embodiment dexterous grasping policies using reinforcement learning (RL). Inspired by the capability of human hands to control various dexterous hands through teleoperation, we propose a universal action space based on the human hand's eigengrasps. The policy outputs eigengrasp actions that are then converted into specific joint actions for each robot hand through a retargeting mapping. We simplify the robot hand's proprioception to include only the positions of fingertips and the palm, offering a unified observation space across different robot hands. Our approach demonstrates an 80\% success rate in grasping objects from the YCB dataset across four distinct embodiments using a single vision-based policy. Additionally, our policy exhibits zero-shot generalization to two previously unseen embodiments and significant improvement in efficient finetuning. For further details and videos, visit our project page (https://sites.google.com/view/crossdex).
  abstract_embedding: [0.8828125, -0.1337890625, 0.115234375]... (1536 items)
  authors: ['Haoqi Yuan', 'Bohan Zhou', 'Yuhui Fu']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652552458
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Cross-Embodiment_Dexterous_Grasping_with_Reinforcement_Learning.pdf
  sha_abstract: aeb09c61758897cda7ad1f6d8e56d25507a17eb1c8d04f2a06540dcce03525e7
  title: Cross-Embodiment Dexterous Grasping with Reinforcement Learning
  title_normalized: crossembodiment_dexterous_grasping_with_reinforcement_learning

================================================================================
Document #200 (ID: Z-hHZpoBclM7MZc3hJMy)
================================================================================
  abstract: Multimodal foundation models, such as Gemini and ChatGPT, have revolutionized human-machine interactions by seamlessly integrating various forms of data. Developing a universal spoken language model that comprehends a wide range of natural language instructions is critical for bridging communication gaps and facilitating more intuitive interactions. However, the absence of a comprehensive evaluation benchmark poses a significant challenge. We present Dynamic-SUPERB Phase-2, an open and evolving benchmark for the comprehensive evaluation of instruction-based universal speech models. Building upon the first generation, this second version incorporates 125 new tasks contributed collaboratively by the global research community, expanding the benchmark to a total of 180 tasks, making it the largest benchmark for speech and audio evaluation. While the first generation of Dynamic-SUPERB was limited to classification tasks, Dynamic-SUPERB Phase-2 broadens its evaluation capabilities by introducing a wide array of novel and diverse tasks, including regression and sequence generation, across speech, music, and environmental audio. Evaluation results show that no model performed well universally. SALMONN-13B excelled in English ASR and Qwen2-Audio-7B-Instruct showed high accuracy in emotion recognition, but current models still require further innovations to handle a broader range of tasks. We open-source all task data and the evaluation pipeline at https://github.com/dynamic-superb/dynamic-superb.
  abstract_embedding: [0.322265625, 0.2099609375, 0.1748046875]... (1536 items)
  authors: ['Chien-yu Huang', 'Wei-Chih Chen', 'Shu-wen Yang']... (76 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652554280
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Dynamic-SUPERB_Phase-2__A_Collaboratively_Expanding_Benchmark_for_Measuring_the_Capabilities_of_Spoken_Language_Models_with_180_Tasks.pdf
  sha_abstract: 576677b90014246ea56e6377405276e6d0b969d3466acfde2b03b5d416b88677
  title: Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks
  title_normalized: dynamicsuperb_phase2_a_collaboratively_expanding_benchmark_for_measuring_the_capabilities_of_spoken_language_models_with_180_tasks

================================================================================
Document #201 (ID: bOhHZpoBclM7MZc3iZOk)
================================================================================
  abstract: Deploying large language models (LLMs) locally on mobile devices is advantageous in scenarios where transmitting data to remote cloud servers is either undesirable due to privacy concerns or impractical due to network connection. Recent advancements have facilitated the local deployment of LLMs. However, local deployment also presents challenges, particularly in balancing quality (generative performance), latency, and throughput within the hardware constraints of mobile devices. In this paper, we introduce our lightweight, all-in-one automated benchmarking framework that allows users to evaluate LLMs on mobile devices. We provide a comprehensive benchmark of various popular LLMs with different quantization configurations (both weights and activations) across multiple mobile platforms with varying hardware capabilities. Unlike traditional benchmarks that assess full-scale models on high-end GPU clusters, we focus on evaluating resource efficiency (memory and power consumption) and harmful output for compressed models on mobile devices. Our key observations include: i) differences in energy efficiency and throughput across mobile platforms; ii) the impact of quantization on memory usage, GPU execution time, and power consumption; and iii) accuracy and performance degradation of quantized models compared to their non-quantized counterparts; and iv) the frequency of hallucinations and toxic content generated by compressed LLMs on
mobile devices.
  abstract_embedding: [0.064453125, 0.2490234375, 0.25]... (1536 items)
  authors: ['Yilong Li', 'Jingyu Liu', 'Hao Zhang']... (9 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652555677
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: PALMBENCH__A_COMPREHENSIVE_BENCHMARK_OF_COMPRESSED_LARGE_LANGUAGE_MODELS_ON_MOBILE_PLATFORMS.pdf
  sha_abstract: 83be3bdcecd3676cd06f30ae8e8fb37c3c85803c7044403d69c437605977c7c9
  title: PALMBENCH: A COMPREHENSIVE BENCHMARK OF COMPRESSED LARGE LANGUAGE MODELS ON MOBILE PLATFORMS
  title_normalized: palmbench_a_comprehensive_benchmark_of_compressed_large_language_models_on_mobile_platforms

================================================================================
Document #202 (ID: aehHZpoBclM7MZc3hpMU)
================================================================================
  abstract: We propose Few-Class Arena (FCA), as a unified benchmark with focus on testing efficient image classification models for few classes. A wide variety of benchmark datasets with many classes (80-1000) have been created to assist Computer Vision architectural evolution. An increasing number of vision models are evaluated with these many-class datasets. However, real-world applications often involve substantially fewer classes of interest (2-10). This gap between many and few classes makes it difficult to predict performance of the few-class applications using models trained on the available many-class datasets. To date, little has been offered to evaluate models in this Few-Class Regime. We conduct a systematic evaluation of the ResNet family trained on ImageNet subsets from 2 to 1000 classes, and test a wide spectrum of Convolutional Neural Networks and Transformer architectures over ten datasets by using our newly proposed FCA tool. Furthermore, to aid an up-front assessment of dataset difficulty and a more efficient selection of models, we incorporate a difficulty measure as a function of class similarity. FCA offers a new tool for efficient machine learning in the Few-Class Regime, with goals ranging from a new efficient class similarity proposal, to lightweight model architecture design, to a new scaling law. FCA is user-friendly and can be easily extended to new models and datasets, facilitating future research work. Our benchmark is available at https://github.com/bryanbocao/fca.
  abstract_embedding: [-0.2890625, 0.46875, 0.5703125]... (1536 items)
  authors: ['Bryan Bo Cao', "Lawrence O'Gorman", 'Michael Coss']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652554763
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Few-Class_Arena__A_Benchmark_for_Efficient_Selection_of_Vision_Models_and_Dataset_Difficulty_Measurement.pdf
  sha_abstract: 7350e14f29d9a72c379b927144abb25d0cc8fbcfafd17cf62b0bc6ac2f70e570
  title: Few-Class Arena: A Benchmark for Efficient Selection of Vision Models and Dataset Difficulty Measurement
  title_normalized: fewclass_arena_a_benchmark_for_efficient_selection_of_vision_models_and_dataset_difficulty_measurement

================================================================================
Document #203 (ID: auhHZpoBclM7MZc3hpPp)
================================================================================
  abstract: Recent studies have discovered that widely used text-to-image diffusion models can replicate training samples during image generation, a phenomenon known as memorization. Existing detection methods primarily focus on identifying memorized prompts. However, in real-world scenarios, image owners may need to verify whether their proprietary or personal images have been memorized by the model, even in the absence of paired prompts or related metadata. We refer to this challenge as image-level memorization detection, where current methods relying on original prompts fall short. In this work, we uncover two characteristics of memorized images after perturbing the inference procedure: lower similarity of the original images and larger magnitudes of TCNP.
Building on these insights, we propose Inversion-based Inference Perturbation (IIP), a new framework for image-level memorization detection. Our approach uses unconditional DDIM inversion to derive latent codes that contain core semantic information of original images and optimizes random prompt embeddings to introduce effective perturbation. Memorized images exhibit distinct characteristics within the proposed pipeline, providing a robust basis for detection. To support this task, we construct a comprehensive setup for the image-level memorization detection, carefully curating datasets to simulate realistic memorization scenarios. Using this setup, we evaluate our IIP framework across three different memorization settings, demonstrating its state-of-the-art performance in identifying memorized images in various settings, even in the presence of data augmentation attacks.
  abstract_embedding: [0.5078125, 0.435546875, -0.13671875]... (1536 items)
  authors: ['Yue Jiang', 'Haokun Lin', 'Yang Bai']... (9 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652554977
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Image-level_Memorization_Detection_via_Inversion-based_Inference_Perturbation.pdf
  sha_abstract: 64b0fcaedb9f52a834e8c867294bc80a9fcd3896a15024117c22691f983bcef8
  title: Image-level Memorization Detection via Inversion-based Inference Perturbation
  title_normalized: imagelevel_memorization_detection_via_inversionbased_inference_perturbation

================================================================================
Document #204 (ID: ZOhHZpoBclM7MZc3f5Pu)
================================================================================
  abstract: Decision-making is a complex process requiring diverse abilities, making it an excellent framework for evaluating Large Language Models (LLMs). Researchers have examined LLMs' decision-making through the lens of Game Theory. However, existing evaluation mainly focus on two-player scenarios where an LLM competes against another. Additionally, previous benchmarks suffer from test set leakage due to their static design. We introduce GAMA($\gamma$)-Bench, a new framework for evaluating LLMs' Gaming Ability in Multi-Agent environments. It includes eight classical game theory scenarios and a dynamic scoring scheme specially designed to quantitatively assess LLMs' performance. $\gamma$-Bench allows flexible game settings and adapts the scoring system to different game parameters, enabling comprehensive evaluation of robustness, generalizability, and strategies for improvement. Our results indicate that GPT-3.5 demonstrates strong robustness but limited generalizability, which can be enhanced using methods like Chain-of-Thought. We also evaluate 13 LLMs from 6 model families, including GPT-3.5, GPT-4, Gemini, LLaMA-3.1, Mixtral, and Qwen-2. Gemini-1.5-Pro outperforms others, scoring of $69.8$ out of $100$, followed by LLaMA-3.1-70B ($65.9$) and Mixtral-8x22B ($62.4$). Our code and experimental results are publicly available at https://github.com/CUHK-ARISE/GAMABench.
  abstract_embedding: [0.734375, 0.1123046875, -0.034423828125]... (1536 items)
  authors: ['Jen-tse Huang', 'Eric John Li', 'Man Ho LAM']... (10 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652553170
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Competing_Large_Language_Models_in_Multi-Agent_Gaming_Environments.pdf
  sha_abstract: e2498d3e816d03ad0af889a929b551279d1569c8ac501814fe4ca75937c0e35a
  title: Competing Large Language Models in Multi-Agent Gaming Environments
  title_normalized: competing_large_language_models_in_multiagent_gaming_environments

================================================================================
Document #205 (ID: aOhHZpoBclM7MZc3hZNH)
================================================================================
  abstract: Multimodal Large Language Models have made significant strides in integrating visual and textual information, yet they often struggle with effectively aligning these modalities. We introduce a novel image tokenizer that bridges this gap by applying the principle of Byte-Pair Encoding (BPE) to visual data. Unlike conventional approaches that rely on separate visual encoders, our method directly incorporates structural prior information into image tokens, mirroring the successful tokenization strategies used in text-only Large Language Models. This innovative approach enables Transformer models to more effectively learn and reason across modalities. Through theoretical analysis and extensive experiments, we demonstrate that our BPE Image Tokenizer significantly enhances MLLMs' multimodal understanding capabilities, even with limited training data. Leveraging this method, we develop Being-VL-0, a model that demonstrates superior performance across various benchmarks and shows promising scalability, potentially paving the way for more efficient and capable multimodal foundation models. For further details, visit our website https://github.com/BeingBeyond/Being-VL-0.
  abstract_embedding: [0.19921875, 0.158203125, 0.34375]... (1536 items)
  authors: ['Wanpeng Zhang', 'Zilong Xie', 'Yicheng Feng']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652554561
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: From_Pixels_to_Tokens__Byte-Pair_Encoding_on_Quantized_Visual_Modalities.pdf
  sha_abstract: 177834435c5de790d44e011c3a698e6c129ff5113f609732a1c604b0cb9d8f6a
  title: From Pixels to Tokens: Byte-Pair Encoding on Quantized Visual Modalities
  title_normalized: from_pixels_to_tokens_bytepair_encoding_on_quantized_visual_modalities

================================================================================
Document #206 (ID: ZuhHZpoBclM7MZc3gZOF)
================================================================================
  abstract: Data Shapley offers a principled framework for attributing the contribution of data within machine learning contexts. However, the traditional notion of Data Shapley requires re-training models on various data subsets, which becomes computationally infeasible for large-scale models. Additionally, this retraining-based definition cannot evaluate the contribution of data for a specific model training run, which may often be of interest in practice. This paper introduces a novel concept, In-Run Data Shapley, which eliminates the need for model retraining and is specifically designed for assessing data contribution for a particular model of interest. In-Run Data Shapley calculates the Shapley value for each gradient update iteration and accumulates these values throughout the training process. We present several techniques that allow the efficient scaling of In-Run Data Shapley to the size of foundation models. In its most optimized implementation, our method adds negligible runtime overhead compared to standard model training. This dramatic efficiency improvement makes it possible to perform data attribution for the foundation model pretraining stage. We present several case studies that offer fresh insights into pretraining data's contribution and discuss their implications for copyright in generative AI and pretraining data curation.
  abstract_embedding: [0.40625, 0.17578125, 0.345703125]... (1536 items)
  authors: ['Jiachen T. Wang', 'Prateek Mittal', 'Dawn Song']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652553597
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Data_Shapley_in_One_Training_Run.pdf
  sha_abstract: a5a382072c0323edc4b255b358ddfd0a372fce780d8f06753b5cbf88ac3b7cb1
  title: Data Shapley in One Training Run
  title_normalized: data_shapley_in_one_training_run

================================================================================
Document #207 (ID: a-hHZpoBclM7MZc3iJPb)
================================================================================
  abstract: Zeroth-order optimization (ZO) is a memory-efficient strategy for fine-tuning Large Language Models using only forward passes. However, applying ZO fine-tuning in memory-constrained settings such as mobile phones and laptops remains challenging since these settings often involve weight quantization, while ZO requires full-precision perturbation and update. In this study, we address this limitation by combining static sparse ZO fine-tuning with quantization. Our approach transfers a small, static subset (0.1%) of "sensitive" parameters from pre-training to downstream tasks, focusing fine-tuning on this sparse set of parameters. The remaining untuned parameters are quantized, reducing memory demands. Our proposed workflow enables efficient ZO fine-tuning of an Llama2-7B model on a GPU device with less than 8GB of memory while outperforming full model ZO fine-tuning performance and in-context learning.
  abstract_embedding: [-0.0986328125, 0.455078125, 0.1396484375]... (1536 items)
  authors: ['Wentao Guo', 'Jikai Long', 'Yimeng Zeng']... (12 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652555477
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Zeroth-Order_Fine-Tuning_of_LLMs_with_Transferable_Static_Sparsity.pdf
  sha_abstract: a6392519eb03ce215fde58a1551ae2550ea10e787ae6603748e1d5f1485fcf52
  title: Zeroth-Order Fine-Tuning of LLMs with Transferable Static Sparsity
  title_normalized: zerothorder_finetuning_of_llms_with_transferable_static_sparsity

================================================================================
Document #208 (ID: ZehHZpoBclM7MZc3gJOy)
================================================================================
  abstract: We give online algorithms for $k$-Means(more generally, $(k, z)$-Clustering) with nearly optimal consistency (a notion suggested by Lattanzi & Vassilvitskii (2017)). 
Our result turns any $\alpha$-approximate offline algorithm for clustering into an $(1+\epsilon)\alpha^2$-competitive online algorithm for clustering with $O(k \text{poly} \log n)$ consistency. 
This consistency bound is optimal up to $\text{poly} \log(n)$ factors. 
Plugging in the offline algorithm that returns the exact optimal solution, 
we obtain the first
$(1 + \epsilon)$-competitive online algorithm for clustering that achieves a linear in $k$ consistency.
This simultaneously improves several previous results (Lattanzi & Vassilvitskii, 2017; Fichtenberger et al., 2021). 
We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm. 
Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.
  abstract_embedding: [0.123046875, 0.51953125, 0.232421875]... (1536 items)
  authors: ['T-H. Hubert Chan', 'Shaofeng H.-C. Jiang', 'Tianyi Wu']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652553385
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Online_Clustering_with_Nearly_Optimal_Consistency.pdf
  sha_abstract: f7d0fbad591092b695a6d038cecea62bc20ed3b8cd3de4db0effa07fe72f4ab8
  title: Online Clustering with Nearly Optimal Consistency
  title_normalized: online_clustering_with_nearly_optimal_consistency

================================================================================
Document #209 (ID: buhHZpoBclM7MZc3jZO4)
================================================================================
  abstract: Transformer has attracted increasing interest in spatio-temporal video grounding, or STVG, owing to its end-to-end pipeline and promising result. Existing Transformer-based STVG approaches often leverage a set of object queries, which are initialized simply using zeros and then gradually learn target position information via iterative interactions with multimodal features, for spatial and temporal localization. Despite simplicity, these zero object queries, due to lacking target-specific cues, are hard to learn discriminative target information from interactions with multimodal features in complicated scenarios (e.g., with distractors or occlusion), resulting in degradation. Addressing this, we introduce a novel $\textbf{T}$arget-$\textbf{A}$ware Transformer for $\textbf{STVG}$ ($\textbf{TA-STVG}$), which seeks to adaptively generate object queries via exploring target-specific cues from the given video-text pair, for improving STVG. The key lies in two simple yet effective modules, comprising text-guided temporal sampling (TTS) and attribute-aware spatial activation (ASA), working in a cascade. The former focuses on selecting target-relevant temporal cues from a video utilizing holistic text information, while the latter aims at further exploiting the fine-grained visual attribute information of the object from previous target-aware temporal cues, which is applied for object query initialization. Compared to existing methods leveraging zero-initialized queries, object queries in our TA-STVG, directly generated from a given video-text pair, naturally carry target-specific cues, making them adaptive and better interact with multimodal features for learning more discriminative information to improve STVG. In our experiments on three benchmarks, including HCSTVG-v1/-v2 and VidSTG, TA-STVG achieves state-of-the-art performance and significantly outperforms the baseline, validating its efficacy. Moreover, TTS and ASA are designed for general purpose. When applied to existing methods such as TubeDETR and STCAT, we show substantial performance gains, verifying its generality. Code is released at https://github.com/HengLan/TA-STVG.
  abstract_embedding: [-0.03857421875, -0.2392578125, 0.6640625]... (1536 items)
  authors: ['Xin Gu', 'Yaojie Shen', 'Chenxi Luo']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652556695
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Knowing_Your_Target__Target-Aware_Transformer_Makes_Better_Spatio-Temporal_Video_Grounding.pdf
  sha_abstract: 9079f20379fbd9e16626c72c29cce90ea1733efc0a4cd05222f2ee39c93512a3
  title: Knowing Your Target: Target-Aware Transformer Makes Better Spatio-Temporal Video Grounding
  title_normalized: knowing_your_target_targetaware_transformer_makes_better_spatiotemporal_video_grounding

================================================================================
Document #210 (ID: cehHZpoBclM7MZc3kZNR)
================================================================================
  abstract: Large language models (LLMs) have demonstrated significant potential in the development of intelligent LLM-based agents. However, when users use these agent applications to perform file operations, their interaction with the file system still remains the traditional paradigm: reliant on manual navigation through precise commands. This paradigm poses a bottleneck to the usability of these systems as users are required to navigate complex folder hierarchies and remember cryptic file names. To address this limitation, we propose an LLM-based Semantic File System (LSFS) for prompt-driven file management in LLM Agent Operating System (AIOS). Unlike conventional approaches, LSFS incorporates LLMs to enable users or agents to interact with files through natural language prompts, facilitating
semantic file management. At the macro-level, we develop a comprehensive API set to achieve semantic file management functionalities, such as semantic file retrieval, file update summarization, and semantic file rollback). At the micro-level, we store files by constructing semantic indexes for them, design and implement syscalls of different semantic operations, e.g., CRUD (create, read, update, delete),
group by, join. Our experiments show that LSFS can achieve at least 15% retrieval accuracy improvement with 2.1× higher retrieval speed in the semantic file retrieval task compared with the traditional file system. In the traditional keyword-based file retrieval task (i.e., retrieving by string-matching), LSFS also performs stably well, i.e., over 89% F1-score with improved usability, especially when the keyword conditions become more complex. Additionally, LSFS supports more advanced file management operations, i.e., semantic file rollback and file sharing and achieves 100% success rates in these tasks, further suggesting the capability of LSFS . The code is available at https://github.com/agiresearch/AIOS-LSFS.
  abstract_embedding: [0.361328125, 0.031982421875, 0.17578125]... (1536 items)
  authors: ['Zeru Shi', 'Kai Mei', 'Mingyu Jin']... (12 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652557625
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: From_Commands_to_Prompts__LLM-based_Semantic_File_System_for_AIOS.pdf
  sha_abstract: 33decfc66b06a1f60bbce9ae35a23360fdfc10f2a8c6aafc10dfc499c13376a7
  title: From Commands to Prompts: LLM-based Semantic File System for AIOS
  title_normalized: from_commands_to_prompts_llmbased_semantic_file_system_for_aios

================================================================================
Document #211 (ID: behHZpoBclM7MZc3jJOz)
================================================================================
  abstract: Large-scale pre-trained language models (PLMs) require significant computational resources to train from scratch on large volumes of data. But in the real world, emerging data from diverse sources may not be initially available for pre-training. Recent studies on lifelong learning have tried to solve this problem by exploring the use of model growth techniques to effectively incorporate new knowledge without the need for complete re-training. However, model growth approaches utilized have issues with growth operators that do not ensure strict function preservation or growth schedules that only include a few growth dimensions, reducing lifelong learning's effect. Furthermore, existing approaches often assume that emerging data has the same distribution as pre-training data, causing catastrophic forgetting of previously acquired knowledge. To address the aforementioned issues, we introduce LOIRE, a framework for lifelong learning that enables PLMs to effectively grow their capacity using incremental data. LOIRE employs growth operators for all feasible dimensions and a growth schedule to generate the optimal expansion sequence in the field of lifelong learning. Specifically, we present a novel plug-in layer growth operator with residual connections that skip the newly added layer during initial training while ensuring function preservation. We additionally propose an iterative distillation strategy for LOIRE that allows an intermediate model in the growth stages to switch between being a student and a teacher, reducing catastrophic forgetting during growth. Experiments show that LOIRE can reduce computational expenses by an average of 29.22\% while retaining equivalent or better downstream performance.
  abstract_embedding: [0.302734375, -0.091796875, 0.1240234375]... (1536 items)
  authors: ['Xue Han', 'Yitong Wang', 'Junlan Feng']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652556444
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: LOIRE__LifelOng_learning_on_Incremental_data_via_pre-trained_language_model_gRowth_Efficiently.pdf
  sha_abstract: f852b41e8ca41c243a60b369edceeec52f3c5291e32b0ce076ddf3b1aff8605d
  title: LOIRE: LifelOng learning on Incremental data via pre-trained language model gRowth Efficiently
  title_normalized: loire_lifelong_learning_on_incremental_data_via_pretrained_language_model_growth_efficiently

================================================================================
Document #212 (ID: dehHZpoBclM7MZc3l5Mu)
================================================================================
  abstract: We explore cross-domain offline reinforcement learning (RL) where offline datasets from another domain can be accessed to facilitate policy learning. However, the underlying environments of the two datasets may have dynamics mismatches, incurring inferior performance when simply merging the data of two domains. Existing methods mitigate this issue by training domain classifiers, using contrastive learning methods, etc. Nevertheless, they still rely on a large amount of target domain data to function well. Instead, we address this problem by establishing a concrete performance bound of a policy given datasets from two domains. Motivated by the theoretical insights, we propose to align transitions in the two datasets using optimal transport and selectively share source domain samples, without training any neural networks. This enables reliable data filtering even given a few target domain data. Additionally, we introduce a dataset regularization term that ensures the learned policy remains within the scope of the target domain dataset, preventing it from being biased towards the source domain data. Consequently, we propose the Optimal Transport Data Filtering (dubbed OTDF) method and examine its effectiveness by conducting extensive experiments across various dynamics shift conditions (e.g., gravity shift), given limited target domain data. It turns out that OTDF exhibits superior performance on many tasks and dataset qualities, often surpassing prior strong baselines by a large margin.
  abstract_embedding: [0.66015625, 0.2216796875, 0.345703125]... (1536 items)
  authors: ['Jiafei Lyu', 'Mengbei Yan', 'Zhongjian Qiao']... (9 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652559142
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Cross-Domain_Offline_Policy_Adaptation_with_Optimal_Transport_and_Dataset_Constraint.pdf
  sha_abstract: fdbc443a76c2a7bb3cdfffd21d51bd106ed782589934adc16feceaf5d740c0d2
  title: Cross-Domain Offline Policy Adaptation with Optimal Transport and Dataset Constraint
  title_normalized: crossdomain_offline_policy_adaptation_with_optimal_transport_and_dataset_constraint

================================================================================
Document #213 (ID: b-hHZpoBclM7MZc3jpNx)
================================================================================
  abstract: Computational RNA design tasks are often posed as inverse problems, where sequences are designed based on adopting a single desired secondary structure without considering 3D conformational diversity. We introduce gRNAde, a geometric RNA design pipeline operating on 3D RNA backbones to design sequences that explicitly account for structure and dynamics. gRNAde uses a multi-state Graph Neural Network and autoregressive decoding to generates candidate RNA sequences conditioned on one or more 3D backbone structures where the identities of the bases are unknown. On a single-state fixed backbone re-design benchmark of 14 RNA structures from the PDB identified by Das et al. (2010), gRNAde obtains higher native sequence recovery rates (56% on average) compared to Rosetta (45% on average), taking under a second to produce designs compared to the reported hours for Rosetta. We further demonstrate the utility of gRNAde on a new benchmark of multi-state design for structurally flexible RNAs, as well as zero-shot ranking of mutational fitness landscapes in a retrospective analysis of a recent ribozyme. Experimental wet lab validation on 10 different structured RNA backbones finds that gRNAde has a success rate of 50% at designing pseudoknotted RNA structures, a significant advance over 35% for Rosetta. Open source code and tutorials are available at: github.com/chaitjo/geometric-rna-design
  abstract_embedding: [0.421875, 0.61328125, 0.01116943359375]... (1536 items)
  authors: ['Chaitanya K. Joshi', 'Arian Rokkum Jamasb', 'Ramon Viñas Torné']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652556905
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: gRNAde__Geometric_Deep_Learning_for_3D_RNA_inverse_design.pdf
  sha_abstract: 0c31c653ef5c9e6068f4776a9542c5baef22f8e0ba7a7402670054fb8c72d432
  title: gRNAde: Geometric Deep Learning for 3D RNA inverse design
  title_normalized: grnade_geometric_deep_learning_for_3d_rna_inverse_design

================================================================================
Document #214 (ID: cuhHZpoBclM7MZc3k5Me)
================================================================================
  abstract: Explaining Graph Neural Network (XGNN) has gained growing attention to facilitate the trust of using GNNs, which is the mainstream method to learn graph data. Despite their growing attention, Existing XGNNs focus on improving the explanation performance, and its robustness under attacks is largely unexplored. We noticed that an adversary can slightly perturb the graph structure such that the explanation result of XGNNs is largely changed. Such vulnerability of XGNNs could cause serious issues particularly in safety/security-critical applications. In this paper, we take the first step to study the robustness of XGNN against graph perturbation attacks, and propose XGNNCert, the first provably robust XGNN. Particularly, our XGNNCert can provably ensure the explanation result for a graph under the worst-case graph perturbation attack is close to that without the attack, while not affecting the GNN prediction, when the number of perturbed edges is bounded. Evaluation results on multiple graph datasets and GNN explainers show the effectiveness of XGNNCert.
  abstract_embedding: [0.384765625, 0.671875, -0.5]... (1536 items)
  authors: ['Jiate Li', 'Meng Pang', 'Yun Dong']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652558051
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Provably_Robust_Explainable_Graph_Neural_Networks_against_Graph_Perturbation_Attacks.pdf
  sha_abstract: 8d33b7506b01ba61f098b7d0510ea638fb8fa051fb0ff8bd1dd4195e4d436957
  title: Provably Robust Explainable Graph Neural Networks against Graph Perturbation Attacks
  title_normalized: provably_robust_explainable_graph_neural_networks_against_graph_perturbation_attacks

================================================================================
Document #215 (ID: cOhHZpoBclM7MZc3kJNi)
================================================================================
  abstract: Consistency models (CMs) are a powerful class of diffusion-based generative models optimized for fast sampling. Most existing CMs are trained using discretized timesteps, which introduce additional hyperparameters and are prone to discretization errors. While continuous-time formulations can mitigate these issues, their success has been limited by training instability. To address this, we propose a simplified theoretical framework that unifies previous parameterizations of diffusion models and CMs, identifying the root causes of instability. Based on this analysis, we introduce key improvements in diffusion process parameterization, network architecture, and training objectives. These changes enable us to train continuous-time CMs at an unprecedented scale, reaching 1.5B parameters on ImageNet 512×512. Our proposed training algorithm, using only two sampling steps, achieves FID scores of 2.06 on CIFAR-10, 1.48 on ImageNet 64×64, and 1.88 on ImageNet 512×512, narrowing the gap in FID scores with the best existing diffusion models to within 10\%.
  abstract_embedding: [0.51171875, 0.578125, 0.41796875]... (1536 items)
  authors: ['Cheng Lu', 'Yang Song']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652557402
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Simplifying__Stabilizing_and_Scaling_Continuous-time_Consistency_Models.pdf
  sha_abstract: 25a29c7849c1e35f7eeb620d0cfbdefcd7946935053f7c36a08a14079e598a2c
  title: Simplifying, Stabilizing and Scaling Continuous-time Consistency Models
  title_normalized: simplifying_stabilizing_and_scaling_continuoustime_consistency_models

================================================================================
Document #216 (ID: c-hHZpoBclM7MZc3k5Pm)
================================================================================
  abstract: Existing score-based adversarial attacks mainly focus on crafting $top$-1 adversarial examples against classifiers with single-label classification. Their attack success rate and query efficiency are often less than satisfactory, particularly under small perturbation requirements; moreover, the vulnerability of classifiers with multi-label learning is yet to be studied. In this paper, we propose a comprehensive surrogate free score-based attack, named \b geometric \b score-based \b black-box \b attack (GSBA$^K$), to craft adversarial examples in an aggressive $top$-$K$ setting for both untargeted and targeted attacks, where the goal is to change the $top$-$K$ predictions of the target classifier. We introduce novel gradient-based methods to find a good initial boundary point to attack. Our iterative method employs novel gradient estimation techniques, particularly effective in $top$-$K$ setting, on the decision boundary to effectively exploit the geometry of the decision boundary. Additionally, GSBA$^K$ can be used to attack against classifiers with $top$-$K$ multi-label learning. Extensive experiential results on ImageNet and PASCAL VOC datasets validate the effectiveness of GSBA$^K$ in crafting $top$-$K$ adversarial examples.
  abstract_embedding: [0.765625, 0.67578125, -0.051025390625]... (1536 items)
  authors: ['Md Farhamdur Reza', 'Richeng Jin', 'Tianfu Wu']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652558297
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: GSBA__K____top_-_K__Geometric_Score-based_Black-box_Attack.pdf
  sha_abstract: f09b3395f84981e9b7b337ab65749e2dd3b2c124f2d47ce7bed7f13f80b627e0
  title: GSBA$^K$: $top$-$K$ Geometric Score-based Black-box Attack
  title_normalized: gsbak_topk_geometric_scorebased_blackbox_attack

================================================================================
Document #217 (ID: dOhHZpoBclM7MZc3lJOx)
================================================================================
  abstract: In this paper, we address conditional testing problems through the conformal inference framework. We define the localized conformal $p$-values by inverting prediction intervals and prove their theoretical properties. These defined $p$-values are then applied to several conditional testing problems to illustrate their practicality. Firstly, we propose a conditional outlier detection procedure to test for outliers in the conditional distribution with finite-sample false discovery rate (FDR) control. We also introduce a novel conditional label screening problem with the goal of screening multivariate response variables and propose a screening procedure to control the family-wise error rate (FWER). Finally, we consider the two-sample conditional distribution test and define a weighted U-statistic through the aggregation of localized $p$-values. Numerical simulations and real-data examples validate the superior performance of our proposed strategies.
  abstract_embedding: [0.53125, 0.26953125, -0.19140625]... (1536 items)
  authors: ['Xiaoyang Wu', 'Lin Lu', 'Zhaojun Wang']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652558505
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Conditional_Testing_based_on_Localized_Conformal__p_-values.pdf
  sha_abstract: 9dee60b5b00dec45da76a4d2852ed3ba128eb6e0b54798e86db62336e30627ea
  title: Conditional Testing based on Localized Conformal $p$-values
  title_normalized: conditional_testing_based_on_localized_conformal_pvalues

================================================================================
Document #218 (ID: fOhHZpoBclM7MZc3opMu)
================================================================================
  abstract: While large models trained with self-supervised learning on offline datasets have shown remarkable capabilities in text and image domains, achieving the same generalisation for agents that act in sequential decision problems remains an open challenge.
In this work, we take a step towards this goal by procedurally generating tens of millions of 2D physics-based tasks and using these to train a general reinforcement learning (RL) agent for physical control.
To this end, we introduce Kinetix: an open-ended space of physics-based RL environments that can represent tasks ranging from robotic locomotion and grasping to video games and classic RL environments, all within a unified framework.
Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.
Our trained agent exhibits strong physical reasoning capabilities in 2D space, being able to zero-shot solve unseen human-designed environments.  Furthermore, fine-tuning this general agent on tasks of interest shows significantly stronger performance than training an RL agent *tabula rasa*.  This includes solving some environments that standard RL training completely fails at.
We believe this demonstrates the feasibility of large scale, mixed-quality pre-training for online RL and we hope that Kinetix will serve as a useful framework to investigate this further.
  abstract_embedding: [0.8203125, 0.0703125, 0.2216796875]... (1536 items)
  authors: ['Michael Matthews', 'Michael Beukman', 'Chris Lu']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652561903
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Kinetix__Investigating_the_Training_of_General_Agents_through_Open-Ended_Physics-Based_Control_Tasks.pdf
  sha_abstract: f9d2afdf2f1cea0add90a53b65ba25d7fde924656920b7edd8562aadb7f0567a
  title: Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks
  title_normalized: kinetix_investigating_the_training_of_general_agents_through_openended_physicsbased_control_tasks

================================================================================
Document #219 (ID: duhHZpoBclM7MZc3mJPn)
================================================================================
  abstract: The Transformer architecture has inarguably revolutionized deep learning, overtaking classical architectures like multi-layer perceptions (MLPs) and convolutional neural networks (CNNs). At its core, the attention block differs in form and functionality from most other architectural components in deep learning—to the extent that, in comparison to MLPs/CNNs, Transformers are more often accompanied by adaptive optimizers, layer normalization, learning rate warmup, etc. The root causes behind these outward manifestations and the precise mechanisms that govern them remain poorly understood. In this work, we bridge this gap by providing a fundamental understanding of what distinguishes the Transformer from the other architectures—grounded in a theoretical comparison of the (loss) Hessian. Concretely, for a single self-attention layer, (a) we first entirely derive the Transformer’s Hessian and express it in matrix derivatives; (b) we then characterize it in terms of data, weight, and attention moment dependencies; and (c) while doing so further highlight the important structural differences to the Hessian of classical networks. Our results suggest that various common architectural and optimization choices in Transformers can be traced back to their highly non-linear dependencies on the data and weight matrices, which vary heterogeneously across parameters. Ultimately, our findings provide a deeper understanding of the Transformer’s unique optimization landscape and the challenges it poses.
  abstract_embedding: [0.41015625, -0.30859375, 0.3671875]... (1536 items)
  authors: ['Weronika Ormaniec', 'Felix Dangel', 'Sidak Pal Singh']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652559582
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: What_Does_It_Mean_to_Be_a_Transformer__Insights_from_a_Theoretical_Hessian_Analysis.pdf
  sha_abstract: e7b5d3b2b814ae4e4b5a47eacf57a503395369c396f604e397655bc73153d602
  title: What Does It Mean to Be a Transformer? Insights from a Theoretical Hessian Analysis
  title_normalized: what_does_it_mean_to_be_a_transformer_insights_from_a_theoretical_hessian_analysis

================================================================================
Document #220 (ID: e-hHZpoBclM7MZc3oZMf)
================================================================================
  abstract: There have been extensive studies on learning in zero-sum games, focusing on the analysis of the existence and algorithmic convergence of Nash equilibrium (NE). Existing studies mainly focus on symmetric games where the strategy spaces of the players are of the same type and size. For the few studies that do consider asymmetric games, they are mostly restricted to matrix games. In this paper, we define and study a new practical class of asymmetric games called two-player Asymmetric Combinatorial-Continuous zEro-Sum (ACCES) games, featuring a combinatorial action space for one player and an infinite compact space for the other. Such ACCES games have broad implications in the real world, particularly in combinatorial optimization problems (COPs) where one player optimizes a solution in a combinatorial space, and the opponent plays against it in an infinite (continuous) compact space (e.g., a nature player deciding epistemic parameters of the environmental model). Our first key contribution is to prove the existence of NE for two-player ACCES games, using the idea of essentially finite game approximation. Building on the theoretical insights and double oracle (DO)-based solutions to complex zero-sum games, our second contribution is to design the novel algorithm, Combinatorial Continuous DO (CCDO), to solve ACCES games, and prove the convergence of the proposed algorithm. Considering the NP-hardness of most COPs and recent advancements in reinforcement learning (RL)-based solutions to COPs, our third contribution is to propose a practical algorithm to solve NE in the real world, CCDORL (based on CCDO) and provide the novel convergence analysis in the ACCES game. Experimental results across diverse instances of COPs demonstrate the empirical effectiveness of our algorithms.
  abstract_embedding: [0.66015625, 0.6015625, 0.041015625]... (1536 items)
  authors: ['Yuheng Li', 'Wang Panpan', 'Haipeng Chen']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652561682
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Can_Reinforcement_Learning_Solve_Asymmetric_Combinatorial-Continuous_Zero-Sum_Games_.pdf
  sha_abstract: 54382e7b22f4f15396731719718759210758e9f412e53e0fdf923bbe5e93ea1a
  title: Can Reinforcement Learning Solve Asymmetric Combinatorial-Continuous Zero-Sum Games?
  title_normalized: can_reinforcement_learning_solve_asymmetric_combinatorialcontinuous_zerosum_games

================================================================================
Document #221 (ID: eOhHZpoBclM7MZc3mpO0)
================================================================================
  abstract: Source-Free Domain Adaptation (SFDA) seeks to adapt a pre-trained source model to the target domain using only unlabeled target data, without access to the original source data. While current state-of-the-art (SOTA) methods rely on leveraging weak supervision from the source model to extract reliable information for self-supervised adaptation, they often overlook the uncertainty that arises during the transfer process.  In this paper, we conduct a systematic and theoretical analysis of the uncertainty inherent in existing SFDA methods and demonstrate its impact on transfer performance through the lens of Distributionally Robust Optimization (DRO). Building upon the theoretical results, we propose a novel instance-dependent uncertainty control algorithm for SFDA.  Our method is designed to quantify and exploit the uncertainty during the adaptation process, significantly improving the model performance.  Extensive experiments on benchmark datasets and empirical analyses confirm the validity of our theoretical findings and the effectiveness of the proposed method. 
This work offers new insights into understanding and advancing SFDA performance.
  abstract_embedding: [0.059326171875, 0.1708984375, 0.2421875]... (1536 items)
  authors: ['Gezheng Xu', 'Hui Guo', 'Li Yi']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652560045
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Revisiting_Source-Free_Domain_Adaptation__a_New_Perspective_via_Uncertainty_Control.pdf
  sha_abstract: 9edd2cbee5eee62d631d4d75352e59f0afa372e1f47aa713247598b6116d5eeb
  title: Revisiting Source-Free Domain Adaptation: a New Perspective via Uncertainty Control
  title_normalized: revisiting_sourcefree_domain_adaptation_a_new_perspective_via_uncertainty_control

================================================================================
Document #222 (ID: d-hHZpoBclM7MZc3mZPR)
================================================================================
  abstract: The linear representation hypothesis is the informal idea that semantic concepts are encoded as linear directions in the representation spaces of large language models (LLMs). Previous work has shown how to make this notion precise for representing binary concepts that have natural contrasts (e.g., {male, female}) as _directions_ in representation space. However, many natural concepts do not have natural contrasts (e.g., whether the output is about an animal). In this work, we show how to extend the formalization of the linear representation hypothesis to represent features (e.g., is_animal) as _vectors_. This allows us to immediately formalize the representation of categorical concepts as polytopes in the representation space. Further, we use the formalization to prove a relationship between the hierarchical structure of concepts and the geometry of their representations. We validate these theoretical results on the Gemma and LLaMA-3 large language models, estimating representations for 900+ hierarchically related concepts using data from WordNet.
  abstract_embedding: [0.375, 0.310546875, 0.162109375]... (1536 items)
  authors: ['Kiho Park', 'Yo Joong Choe', 'Yibo Jiang']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652559803
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: The_Geometry_of_Categorical_and_Hierarchical_Concepts_in_Large_Language_Models.pdf
  sha_abstract: ff9619a534f988084b6fe5f74f7ab4d483ce2bee2270b198b94dc11b65fb3240
  title: The Geometry of Categorical and Hierarchical Concepts in Large Language Models
  title_normalized: the_geometry_of_categorical_and_hierarchical_concepts_in_large_language_models

================================================================================
Document #223 (ID: eehHZpoBclM7MZc3m5N6)
================================================================================
  abstract: We study how to subvert large language models (LLMs) from following prompt-specified rules.
We first formalize rule-following as inference in propositional Horn logic, a mathematical system in which rules have the form "if $P$ and $Q$, then $R$" for some propositions $P$, $Q$, and $R$.
Next, we prove that although small transformers can faithfully follow such rules, maliciously crafted prompts can still mislead both theoretical constructions and models learned from data.
Furthermore, we demonstrate that popular attack algorithms on LLMs find adversarial prompts and induce attention patterns that align with our theory.
Our novel logic-based framework provides a foundation for studying LLMs in rule-based settings, enabling a formal analysis of tasks like logical reasoning and jailbreak attacks.
  abstract_embedding: [0.451171875, 0.484375, 0.123046875]... (1536 items)
  authors: ['Anton Xue', 'Avishree Khare', 'Rajeev Alur']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652560242
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Logicbreaks__A_Framework_for_Understanding_Subversion_of_Rule-based_Inference.pdf
  sha_abstract: c982b81ee78494ed44f81e4941d28b05bdcbd6f99ab84bc6cf2ce91582dae93c
  title: Logicbreaks: A Framework for Understanding Subversion of Rule-based Inference
  title_normalized: logicbreaks_a_framework_for_understanding_subversion_of_rulebased_inference

================================================================================
Document #224 (ID: euhHZpoBclM7MZc3nJNQ)
================================================================================
  abstract: Uncertainty quantification in time series prediction is challenging due to the temporal dependence and distribution shift on sequential data. Conformal prediction provides a pivotal and flexible instrument for assessing the uncertainty of machine learning models through prediction sets. Recently, a series of online conformal inference methods updated thresholds of prediction sets by performing online gradient descent on a sequence of quantile loss functions. A drawback of such methods is that they only use the information of revealed non-conformity scores via miscoverage indicators but ignore error quantification, namely the distance between the non-conformity score and the current threshold. To accurately leverage the dynamic of miscoverage error, we propose Error-quantified Conformal Inference (ECI) by smoothing the quantile loss function. ECI introduces a continuous and adaptive feedback scale with the miscoverage error, rather than simple binary feedback in existing methods. We establish a long-term coverage guarantee for ECI under arbitrary dependence and distribution shift. The extensive experimental results show that ECI can achieve valid miscoverage control and output tighter prediction sets than other baselines.
  abstract_embedding: [0.54296875, 0.439453125, 0.62109375]... (1536 items)
  authors: ['Junxi Wu', 'Dongjian Hu', 'Yajie Bao']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652560457
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Error-quantified_Conformal_Inference_for_Time_Series.pdf
  sha_abstract: be0cd2ad4210cab9a8aa0cab80ba26703c58ab0ad93709d52258aea4d0a3522e
  title: Error-quantified Conformal Inference for Time Series
  title_normalized: errorquantified_conformal_inference_for_time_series

================================================================================
Document #225 (ID: fehHZpoBclM7MZc3opPm)
================================================================================
  abstract: High-quality sentence embeddings are fundamental in many natural language processing (NLP) tasks, such as semantic textual similarity (STS) and retrieval-augmented generation (RAG). However, most existing methods leverage fixed-length sentence embeddings from full-layer language models, which lack the scalability to accommodate the diverse available resources across various applications. Viewing this gap, we propose a novel sentence embedding model Espresso Sentence Embeddings (ESE) with two learning processes. First, the learn-to-express process encodes more salient representations to shallow layers. Second, the learn-to-compress process compacts essential features into the initial dimensions using Principal Component Analysis (PCA). This way, ESE can scale model depth via the former process and embedding size via the latter. Extensive experiments on STS and RAG suggest that ESE can effectively produce high-quality sentence embeddings with less model depth and embedding size, enhancing inference efficiency. The code is available at https://github.com/SeanLee97/AnglE/blob/main/README_ESE.md.
  abstract_embedding: [-0.000263214111328125, 0.17578125, 0.181640625]... (1536 items)
  authors: ['Xianming LI', 'Zongxi Li', 'Jing Li']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652562143
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ESE__Espresso_Sentence_Embeddings.pdf
  sha_abstract: 92e9e57e8e4c12d3c026452753744eb6b2fee5606dbe57c9d2738d5d4e9edd26
  title: ESE: Espresso Sentence Embeddings
  title_normalized: ese_espresso_sentence_embeddings

================================================================================
Document #226 (ID: gOhHZpoBclM7MZc3qZMh)
================================================================================
  abstract: Non-rigid alignment of point clouds is crucial for scene understanding, reconstruction, and various computer vision and robotics tasks. Recent advancements in implicit deformation networks for non-rigid registration have significantly reduced the reliance on large amounts of annotated training data. However, existing state-of-the-art methods still face challenges in handling occlusion scenarios. To address this issue, this paper introduces an innovative unsupervised method called Occlusion-Aware Registration (OAR) for non-rigidly aligning point clouds. The key innovation of our method lies in the utilization of the adaptive correntropy function as a localized similarity measure, enabling us to treat individual points distinctly. In contrast to previous approaches that solely minimize overall deviations between two shapes, we combine unsupervised implicit neural representations with the maximum correntropy criterion to optimize the deformation of unoccluded regions. This effectively avoids collapsed, tearing, and other physically implausible results. Moreover, we present a theoretical analysis and establish the relationship between the maximum correntropy criterion and the commonly used Chamfer distance, highlighting that the correntropy-induced metric can be served as a more universal measure for point cloud analysis. Additionally, we introduce
locally linear reconstruction to ensure that regions lacking correspondences between shapes still undergo physically natural deformations. Our method achieves superior or competitive performance compared to existing approaches, particularly when dealing with occluded geometries. We also demonstrate the versatility of our method in challenging tasks such as large deformations, shape interpolation, and shape completion under occlusion disturbances.
  abstract_embedding: [-0.416015625, 0.26953125, -0.04052734375]... (1536 items)
  authors: ['Mingyang Zhao', 'Gaofeng Meng', 'Dong-ming Yan']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652563737
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Occlusion-aware_Non-Rigid_Point_Cloud_Registration_via_Unsupervised_Neural_Deformation_Correntropy.pdf
  sha_abstract: 3ae1a6d69b7984c0f9f9c0dcf691ff316c086aa249f8992a356dcd7c41173883
  title: Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised Neural Deformation Correntropy
  title_normalized: occlusionaware_nonrigid_point_cloud_registration_via_unsupervised_neural_deformation_correntropy

================================================================================
Document #227 (ID: g-hHZpoBclM7MZc3q5Pz)
================================================================================
  abstract: Large Language Models (LLMs) demonstrate strong reasoning abilities but face limitations such as hallucinations and outdated knowledge. Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by grounding LLM outputs in structured external knowledge from KGs. However, current KG-based RAG frameworks still struggle to optimize the trade-off between retrieval effectiveness and efficiency in identifying a suitable amount of relevant graph information for the LLM to digest. We introduce SubgraphRAG, extending the KG-based RAG framework that retrieves subgraphs and leverages LLMs for reasoning and answer prediction. Our approach innovatively integrates a lightweight multilayer perceptron (MLP) with a parallel triple-scoring mechanism for efficient and flexible subgraph retrieval while encoding directional structural distances to enhance retrieval effectiveness. The size of retrieved subgraphs can be flexibly adjusted to match the query's needs and the downstream LLM's capabilities. This design strikes a balance between model complexity and reasoning power, enabling scalable and generalizable retrieval processes. Notably, based on our retrieved subgraphs, smaller LLMs like Llama3.1-8B-Instruct deliver competitive results with explainable reasoning, while larger models like GPT-4o achieve state-of-the-art accuracy compared with previous baselines—all without fine-tuning. Extensive evaluations on the WebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency, accuracy, and reliability by reducing hallucinations and improving response grounding.
  abstract_embedding: [0.291015625, 0.5390625, 0.1103515625]... (1536 items)
  authors: ['Mufei Li', 'Siqi Miao', 'Pan Li']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652564424
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Simple_is_Effective__The_Roles_of_Graphs_and_Large_Language_Models_in_Knowledge-Graph-Based_Retrieval-Augmented_Generation.pdf
  sha_abstract: 769e9d84cbba59762d0169d2ab6a7c2054036dee91322204bc5ba0606ad0194c
  title: Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation
  title_normalized: simple_is_effective_the_roles_of_graphs_and_large_language_models_in_knowledgegraphbased_retrievalaugmented_generation

================================================================================
Document #228 (ID: guhHZpoBclM7MZc3q5MD)
================================================================================
  abstract: The goal of the AlgoPerf: Training Algorithms competition is to evaluate practical speed-ups in neural network training achieved solely by improving the underlying training algorithms. In the external tuning ruleset, submissions must provide workload-agnostic hyperparameter search spaces, while in the self-tuning ruleset they must be completely hyperparameter-free. In both rulesets, submissions are compared on time-to-result across multiple deep learning workloads, training on fixed hardware. This paper presents the inaugural AlgoPerf competition's results, which drew 18 diverse submissions from 10 teams. Our investigation reveals several key findings: (1) The winning submission in the external tuning ruleset, using Distributed Shampoo, demonstrates the effectiveness of non-diagonal preconditioning over popular methods like Adam, even when compared on wall-clock runtime. (2) The winning submission in the self-tuning ruleset, based on the Schedule Free AdamW algorithm, demonstrates a new level of effectiveness for completely hyperparameter-free training algorithms. (3) The top-scoring submissions were surprisingly robust to workload changes. We also discuss the engineering challenges encountered in ensuring a fair comparison between different training algorithms. These results highlight both the significant progress so far, and the considerable room for further improvements.
  abstract_embedding: [0.25390625, 0.423828125, 0.2265625]... (1536 items)
  authors: ['Priya Kasimbeg', 'Frank Schneider', 'Runa Eschenhagen']... (14 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652564188
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Accelerating_neural_network_training__An_analysis_of_the_AlgoPerf_competition.pdf
  sha_abstract: 9fb05590bc9e1220bd9a98d70ee6831abce0b997134773d382eac86d490524ac
  title: Accelerating neural network training: An analysis of the AlgoPerf competition
  title_normalized: accelerating_neural_network_training_an_analysis_of_the_algoperf_competition

================================================================================
Document #229 (ID: fuhHZpoBclM7MZc3pZPX)
================================================================================
  abstract: Training embodied agents to perform complex robotic tasks presents significant challenges due to the entangled factors of task compositionality, environmental diversity, and dynamic changes. In this work, we introduce a novel imitation learning framework to train closed-loop concept-guided policies that enhance long-horizon task performance by leveraging discovered manipulation concepts. Unlike methods that rely on predefined skills and human-annotated labels, our approach allows agents to autonomously abstract manipulation concepts from their proprioceptive states, thereby alleviating misalignment due to ambiguities in human semantics and environmental complexity. Our framework comprises two primary components: an *Automatic Concept Discovery* module that identifies meaningful and consistent manipulation concepts, and a *Concept-Guided Policy Learning* module that effectively utilizes these manipulation concepts for adaptive task execution, including a *Concept Selection Transformer* for concept-based guidance and a *Concept-Guided Policy* for action prediction with the selected concepts. Experiments demonstrate that our approach significantly outperforms baseline methods across a range of tasks and environments, while showcasing emergent consistency in motion patterns associated with the discovered manipulation concepts. Codes are available at: https://github.com/PeiZhou26/AutoCGP.
  abstract_embedding: [0.4375, 0.376953125, 0.2333984375]... (1536 items)
  authors: ['Pei Zhou', 'Ruizhe Liu', 'Qian Luo']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652562858
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: AutoCGP__Closed-Loop_Concept-Guided_Policies_from_Unlabeled_Demonstrations.pdf
  sha_abstract: 88a818225ea6bda945e161cfb54a707d3c32ec00f13727f7d73891e879df7965
  title: AutoCGP: Closed-Loop Concept-Guided Policies from Unlabeled Demonstrations
  title_normalized: autocgp_closedloop_conceptguided_policies_from_unlabeled_demonstrations

================================================================================
Document #230 (ID: gehHZpoBclM7MZc3qpMS)
================================================================================
  abstract: Large Language Models (LLMs) have shown immense potential in enhancing various aspects of our daily lives, from conversational AI to search and AI assistants. However, their growing capabilities come at the cost of extremely large model sizes, making deployment on edge devices challenging due to memory and computational constraints. This paper introduces a novel approach to LLM weight pruning that directly optimizes for approximating the attention matrix, a core component of transformer architectures. Unlike existing methods that focus on linear approximations, our approach accounts for the non-linear nature of the Softmax attention mechanism. We provide theoretical guarantees for the convergence of our Gradient Descent-based optimization method to a near-optimal pruning mask solution. Our empirical results demonstrate the effectiveness of our non-linear pruning approach in maintaining model performance while significantly reducing computational costs, which is beyond the current state-of-the-art methods, i.e., SparseGPT and Wanda, by a large margin. This work establishes a new theoretical foundation for pruning algorithm design in LLMs, potentially paving the way for more efficient LLM inference on resource-constrained devices.
  abstract_embedding: [0.2431640625, 0.23828125, 0.392578125]... (1536 items)
  authors: ['Yingyu Liang', 'Jiangxuan Long', 'Zhenmei Shi']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652563963
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Beyond_Linear_Approximations__A_Novel_Pruning_Approach_for_Attention_Matrix.pdf
  sha_abstract: 6a9a8ed2e9bfa9e25e246563df607cdf67c0323666f2a7ffb8ff49f6443bd36a
  title: Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix
  title_normalized: beyond_linear_approximations_a_novel_pruning_approach_for_attention_matrix

================================================================================
Document #231 (ID: f-hHZpoBclM7MZc3p5Nv)
================================================================================
  abstract: Data heterogeneity and backdoor attacks rank among the most significant challenges facing federated learning (FL). For data heterogeneity, personalized federated learning (PFL) enables each client to maintain a private personalized model to cater to client-specific knowledge. Meanwhile, vanilla FL has proven vulnerable to backdoor attacks. However, recent advancements in PFL community have demonstrated a potential immunity against such attacks. This paper explores this intersection further, revealing that existing federated backdoor attacks fail in PFL because backdoors about manually designed triggers struggle to survive in personalized models. To tackle this, we degisn Bad-PFL, which employs features from natural data as our trigger. As long as the model is trained on natural data, it inevitably embeds the backdoor associated with our trigger, ensuring its longevity in personalized models. Moreover, our trigger undergoes mutual reinforcement training with the model, further solidifying the backdoor's durability and enhancing attack effectiveness. The large-scale experiments across three benchmark datasets demonstrate the superior performance of Bad-PFL against various PFL methods, even when equipped with state-of-the-art defense mechanisms.
  abstract_embedding: [0.36328125, 1.09375, -0.045654296875]... (1536 items)
  authors: ['Mingyuan Fan', 'Zhanyi Hu', 'Fuyi Wang']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652563302
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Bad-PFL__Exploiting_Backdoor_Attacks_against_Personalized_Federated_Learning.pdf
  sha_abstract: a8f5ec28d25113135fac317e7d8093af5019b552e899e1d3ce3cf46b3d98c4e8
  title: Bad-PFL: Exploiting Backdoor Attacks against Personalized Federated Learning
  title_normalized: badpfl_exploiting_backdoor_attacks_against_personalized_federated_learning

================================================================================
Document #232 (ID: hehHZpoBclM7MZc3sJM_)
================================================================================
  abstract: Synthetic datasets generated by structural causal models (SCMs) are commonly used for benchmarking causal structure learning algorithms. However, the variances and pairwise correlations in SCM data tend to increase along the causal ordering. Several popular algorithms exploit these artifacts, possibly leading to conclusions that do not generalize to real-world settings. Existing metrics like $\operatorname{Var}$-sortability and $\operatorname{R^2}$-sortability quantify these patterns, but they do not provide tools to remedy them. To address this, we propose internally-standardized structural causal models (iSCMs), a modification of SCMs that introduces a standardization operation at each variable during the generative process. By construction, iSCMs are not $\operatorname{Var}$-sortable. We also find empirical evidence that they are mostly not $\operatorname{R^2}$-sortable for commonly-used graph families. Moreover, contrary to the post-hoc standardization of data generated by standard SCMs, we prove that linear iSCMs are less identifiable from prior knowledge on the weights and do not collapse to deterministic relationships in large systems, which may make iSCMs a useful model in causal inference beyond the benchmarking problem studied here. Our code is publicly available at: https://github.com/werkaaa/iscm.
  abstract_embedding: [0.400390625, 0.03515625, -0.2421875]... (1536 items)
  authors: ['Weronika Ormaniec', 'Scott Sussex', 'Lars Lorch']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652565524
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Standardizing_Structural_Causal_Models.pdf
  sha_abstract: b35e0450f80c6bc7fa1047cd88c62104ca9e8721e52bea5982fa8c732a4f5ba2
  title: Standardizing Structural Causal Models
  title_normalized: standardizing_structural_causal_models

================================================================================
Document #233 (ID: huhHZpoBclM7MZc3sJP1)
================================================================================
  abstract: Weight space learning aims to extract information about a neural network, such as its training dataset or generalization error. Recent approaches learn directly from model weights, but this presents many challenges as weights are high-dimensional and include permutation symmetries between neurons. An alternative approach, Probing, represents a model by passing a set of learned inputs (probes) through the model, and training a predictor on top of the corresponding outputs. Although probing is typically not used as a stand alone approach, our preliminary experiment found that a vanilla probing baseline worked surprisingly well. However, we discover that current probe learning strategies are ineffective. We therefore propose Deep Linear Probe Generators (ProbeGen), a simple and effective modification to probing approaches. ProbeGen adds a shared generator module with a deep linear architecture, providing an inductive bias towards structured probes thus reducing overfitting. While simple, ProbeGen performs significantly better than the state-of-the-art and is very efficient, requiring between 30 to 1000 times fewer FLOPs than other top approaches.
  abstract_embedding: [-0.2373046875, 0.021240234375, 0.1962890625]... (1536 items)
  authors: ['Jonathan Kahana', 'Eliahu Horwitz', 'Imri Shuval']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652565741
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Deep_Linear_Probe_Generators_for_Weight_Space_Learning.pdf
  sha_abstract: bd02319374fafa9302b10516478a4a477f8b850abc09a201211eb1a1e5dbc1c3
  title: Deep Linear Probe Generators for Weight Space Learning
  title_normalized: deep_linear_probe_generators_for_weight_space_learning

================================================================================
Document #234 (ID: hOhHZpoBclM7MZc3rJOk)
================================================================================
  abstract: We consider the problem of learning nonlinear dynamical systems from a single sample trajectory. While the least squares estimate (LSE) is commonly used for this task, it suffers from poor identification errors when the sample size is small or the model fails to capture the system's true dynamics. To overcome these limitations, we propose a robust LSE framework, which incorporates robust optimization techniques, and prove that it is equivalent to regularizing LSE using general Schatten $p$-norms. We provide non-asymptotic performance guarantees for linear systems, achieving an error rate of $\widetilde{\mathcal{O}}(1/\sqrt{T})$, and show that it avoids the curse of dimensionality, unlike state-of-the-art Wasserstein robust optimization models. Empirical results demonstrate substantial improvements in real-world system identification and online control tasks, outperforming existing methods.
  abstract_embedding: [0.248046875, 0.337890625, 0.1298828125]... (1536 items)
  authors: ['Hyuk Park', 'Grani A. Hanasusanto', 'Yingying Li']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652564637
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Robust_System_Identification__Finite-sample_Guarantees_and_Connection_to_Regularization.pdf
  sha_abstract: ebedb2e6f85913119937e5fcd8ef0c2e23af81963f7fbae52689f84f5fa82fef
  title: Robust System Identification: Finite-sample Guarantees and Connection to Regularization
  title_normalized: robust_system_identification_finitesample_guarantees_and_connection_to_regularization

================================================================================
Document #235 (ID: i-hHZpoBclM7MZc3uJNJ)
================================================================================
  abstract: Traditional data influence estimation methods, like influence function, assume that learning algorithms are permutation-invariant with respect to training data. However, modern training paradigms—especially for foundation models using stochastic algorithms and non-convergent, multi-stage curricula—are sensitive to data ordering, thus violating this assumption. This mismatch renders influence functions inadequate for answering some critical questions in current machine learning: How can we differentiate the influence of the same data contributing at different stages of training? More generally, how can we capture the dependence of data influence on the optimization trajectory during training? To address this gap, we formalize the concept of \emph{trajectory-specific leave-one-out (LOO) influence}, which quantifies the impact of removing a data point from a specific iteration during training, accounting for the exact sequence of data encountered and the model's optimization trajectory. However, exactly evaluating the trajectory-specific LOO presents a significant computational challenge. To address this, we propose \emph{data value embedding}, a novel technique enabling efficient approximation of trajectory-specific LOO. Specifically, we compute a training data embedding that encapsulates the cumulative interactions between data and the evolving model parameters. The LOO can then be efficiently approximated through a simple dot-product between the data value embedding and the gradient of the given test data. As data value embedding captures training data ordering, it offers valuable insights into model training dynamics. In particular, we uncover distinct phases of data influence, revealing that data points in the early and late stages of training exert a greater impact on the final model. These insights translate into actionable strategies for managing the computational overhead of data selection by strategically timing the selection process, potentially opening new avenues in data curation research.
  abstract_embedding: [0.5390625, 0.0927734375, 0.43359375]... (1536 items)
  authors: ['Jiachen T. Wang', 'Dawn Song', 'James Zou']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652567600
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Capturing_the_Temporal_Dependence_of_Training_Data_Influence.pdf
  sha_abstract: a97bd3886592075551e69e8a953bac9f31a6b35d19eec5762c0a5d31704149e2
  title: Capturing the Temporal Dependence of Training Data Influence
  title_normalized: capturing_the_temporal_dependence_of_training_data_influence

================================================================================
Document #236 (ID: jehHZpoBclM7MZc3u5P4)
================================================================================
  abstract: Adversarial training is a widely-applied approach to training deep neural networks to be robust against adversarial perturbation. However, although adversarial training has achieved empirical success in practice, it still remains unclear why adversarial examples exist and how adversarial training methods improve model robustness. In this paper, we provide a theoretical understanding of adversarial examples and adversarial training algorithms from the perspective of feature learning theory. Specifically, we focus on a multiple classification setting, where the structured data can be composed of two types of features: the robust features, which are resistant to perturbation but sparse, and the non-robust features, which are susceptible to perturbation but dense. We train a two-layer smoothed ReLU convolutional neural network to learn our structured data. First, we prove that by using standard training (gradient descent over the empirical risk), the network learner primarily learns the non-robust feature rather than the robust feature, which thereby leads to the adversarial examples that are generated by perturbations aligned with negative non-robust feature directions. Then, we consider the gradient-based adversarial training algorithm, which runs gradient ascent to find adversarial examples and runs gradient descent over the empirical risk at adversarial examples to update models. We show that the adversarial training method can provably strengthen the robust feature learning and suppress the non-robust feature learning to improve the network robustness. Finally, we also empirically validate our theoretical findings with experiments on real-image datasets, including MNIST, CIFAR10 and SVHN.
  abstract_embedding: [0.5234375, 0.310546875, -0.045654296875]... (1536 items)
  authors: ['Binghui Li', 'Yuanzhi Li']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652568561
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Adversarial_Training_Can_Provably_Improve_Robustness__Theoretical_Analysis_of_Feature_Learning_Process_Under_Structured_Data.pdf
  sha_abstract: 44e72c15e1c5750dd15ce04f9d106c101295e0ab0590f3da57fe56faf48b6546
  title: Adversarial Training Can Provably Improve Robustness: Theoretical Analysis of Feature Learning Process Under Structured Data
  title_normalized: adversarial_training_can_provably_improve_robustness_theoretical_analysis_of_feature_learning_process_under_structured_data

================================================================================
Document #237 (ID: iOhHZpoBclM7MZc3s5Od)
================================================================================
  abstract: This paper proposes a new 3D molecule generation framework, called GOAT, for fast and effective 3D molecule generation based on the flow-matching optimal transport objective. Specifically, we formulate a geometric transport formula for measuring the cost of mapping multi-modal features (e.g., continuous atom coordinates and categorical atom types) between a base distribution and a target data distribution. Our formula is solved within a joint, equivariant, and smooth representation space. This is achieved by transforming the multi-modal features into a continuous latent space with equivariant networks. In addition, we find that identifying optimal distributional coupling is necessary for fast and effective transport between any two distributions. We further propose a mechanism for estimating and purifying optimal coupling to train the flow model with optimal transport. By doing so, GOAT can turn arbitrary distribution couplings into new deterministic couplings, leading to an estimated optimal transport plan for fast 3D molecule generation. The purification filters out the subpar molecules to ensure the ultimate generation quality. We theoretically and empirically prove that the proposed optimal coupling estimation and purification yield transport plan with non-increasing cost. Finally, extensive experiments show that GOAT enjoys the efficiency of solving geometric optimal transport, leading to a double speedup compared to the sub-optimal method while achieving the best generation quality regarding validity, uniqueness, and novelty.
  abstract_embedding: [0.390625, 0.1064453125, 0.1103515625]... (1536 items)
  authors: ['Haokai Hong', 'Wanyu Lin', 'KC Tan']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652566409
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Accelerating_3D_Molecule_Generation_via_Jointly_Geometric_Optimal_Transport.pdf
  sha_abstract: 38b437dcccd7c6564dccae64adb39c5207629bcd96ffc6fa5d426b0fffa03b38
  title: Accelerating 3D Molecule Generation via Jointly Geometric Optimal Transport
  title_normalized: accelerating_3d_molecule_generation_via_jointly_geometric_optimal_transport

================================================================================
Document #238 (ID: h-hHZpoBclM7MZc3spOd)
================================================================================
  abstract: Autoregressive (AR) Large Language Models (LLMs) have demonstrated significant success across numerous tasks. However, the AR modeling paradigm presents certain limitations; for instance, contemporary autoregressive LLMs are trained to generate one token at a time, which can result in noticeable latency. Recent advances have indicated that search and repeated sampling can enhance performance in various applications, such as theorem proving, code generation, and alignment, by utilizing greater computational resources during inference. In this study, we demonstrate that diffusion language models are capable of generating at least 32 tokens simultaneously, while exceeding the performance of AR models in text quality and on the LAMBADA natural language understanding benchmark. This outcome is achieved through a novel distillation method for discrete diffusion models, which reduces the number of inference steps by a factor of 32-64. Practically, at the 1.3B parameters scale, diffusion models, even without caching, can generate tokens at a rate that is up to 8 times faster than AR models employing KV-caching, and we anticipate further improvements with the inclusion of caching. Moreover, we demonstrate the efficacy of our approach for diffusion language models with up to 860M parameters.
  abstract_embedding: [0.33203125, 0.4140625, 0.388671875]... (1536 items)
  authors: ['Justin Deschenaux', 'Caglar Gulcehre']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652566167
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Beyond_Autoregression__Fast_LLMs_via_Self-Distillation_Through_Time.pdf
  sha_abstract: 6b0f0cb1f749c4c6c02f0505c93b074859e385a2286ec43f87add1f4451d7d21
  title: Beyond Autoregression: Fast LLMs via Self-Distillation Through Time
  title_normalized: beyond_autoregression_fast_llms_via_selfdistillation_through_time

================================================================================
Document #239 (ID: iehHZpoBclM7MZc3tJNz)
================================================================================
  abstract: As language models (LMs) approach human-level performance, a comprehensive understanding of their behavior becomes crucial. 
This includes evaluating capabilities, biases, task performance, and alignment with societal values. Extensive initial evaluations, including red teaming and diverse benchmarking, can establish a model’s behavioral profile. However, subsequent fine-tuning or deployment modifications may alter these behaviors in unintended ways. We present an efficient statistical test to tackle Behavioral Shift Auditing (BSA) in LMs, which we define as detecting distribution shifts in qualitative properties of the output distributions of LMs. Our test compares model generations from a baseline model to those of the model under scrutiny and provides theoretical guarantees for change detection while controlling false positives. The test features a configurable tolerance parameter that adjusts sensitivity to behavioral changes for different use cases. We evaluate our approach using two case studies: monitoring changes in (a) toxicity and (b) translation performance. We find that the test is able to detect meaningful changes in behavior distributions using just hundreds of examples.
  abstract_embedding: [0.65234375, 0.2138671875, 0.1953125]... (1536 items)
  authors: ['Leo Richter', 'Xuanli He', 'Pasquale Minervini']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652566623
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: An_Auditing_Test_to_Detect_Behavioral_Shift_in_Language_Models.pdf
  sha_abstract: ef85147ce8f1a88c04e272d3a7db87431f5f4acd43e0e59f2d0f5fad7e574a35
  title: An Auditing Test to Detect Behavioral Shift in Language Models
  title_normalized: an_auditing_test_to_detect_behavioral_shift_in_language_models

================================================================================
Document #240 (ID: jOhHZpoBclM7MZc3upMV)
================================================================================
  abstract: Recently, many self-supervised learning methods for image reconstruction have been proposed that can learn from noisy data alone, bypassing the need for ground-truth references.  Most existing methods cluster around two classes: i) Stein's Unbiased Risk Estimate (SURE) and similar approaches that assume full knowledge of the noise distribution, and ii) Noise2Self and similar cross-validation methods that require very mild knowledge about the noise distribution. The first class of methods tends to be impractical, as the noise level is often unknown in real-world applications, and the second class is often suboptimal compared to supervised learning.
In this paper, we provide a theoretical framework that characterizes this expressivity-robustness trade-off and propose a new approach based on SURE, but unlike the standard SURE, does not require knowledge about the noise level. Throughout a series of experiments, we show that the proposed estimator outperforms other existing self-supervised methods on various imaging inverse problems.
  abstract_embedding: [-0.072265625, 0.158203125, -0.12890625]... (1536 items)
  authors: ['Julián Tachella', 'Mike Davies', 'Laurent Jacques']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652568064
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: UNSURE__self-supervised_learning_with_Unknown_Noise_level__and_Stein_s_Unbiased_Risk_Estimate.pdf
  sha_abstract: 52681b75046c4b2f5856923756543c84229a74f201a9ab82dc654a3db8904d2a
  title: UNSURE: self-supervised learning with Unknown Noise level  and Stein's Unbiased Risk Estimate
  title_normalized: unsure_selfsupervised_learning_with_unknown_noise_level__and_steins_unbiased_risk_estimate

================================================================================
Document #241 (ID: juhHZpoBclM7MZc3vZPG)
================================================================================
  abstract: Recent advancements in large language models (LLMs) reveal a perplexing phenomenon in continual learning: despite extensive training, models experience significant performance declines, raising questions about task alignment and underlying knowledge retention. This study first explores the concept of "spurious forgetting", proposing that such performance drops often reflect a decline in task alignment rather than true knowledge loss. Through controlled experiments with a synthesized dataset, we investigate the dynamics of model performance during the initial training phases of new tasks, discovering that early optimization steps can disrupt previously established task alignments. Our theoretical analysis connects these shifts to orthogonal updates in model weights, providing a robust framework for understanding this behavior. Ultimately, we introduce a Freezing strategy that fix the bottom layers of the model, leading to substantial improvements in four continual learning scenarios. Our findings underscore the critical distinction between task alignment and knowledge retention, paving the way for more effective strategies in continual learning.
  abstract_embedding: [0.58984375, -0.003082275390625, -0.04052734375]... (1536 items)
  authors: ['Junhao Zheng', 'Xidi Cai', 'Shengjie Qiu']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652569023
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Spurious_Forgetting_in_Continual_Learning_of_Language_Models.pdf
  sha_abstract: e92db004b1d3967782a9027fc5c8f5a9f6e1e2f599ac4169bd65b50a39720b20
  title: Spurious Forgetting in Continual Learning of Language Models
  title_normalized: spurious_forgetting_in_continual_learning_of_language_models

================================================================================
Document #242 (ID: iuhHZpoBclM7MZc3tpNs)
================================================================================
  abstract: Procedural materials, represented as functional node graphs, are ubiquitous in computer graphics for photorealistic material appearance design. They allow users to perform intuitive and precise editing to achieve desired visual appearances. However, creating a procedural material given an input image requires professional knowledge and significant effort. In this work, we leverage the ability to convert procedural materials into standard Python programs and fine-tune a large pre-trained vision-language model (VLM) to generate such programs from input images. To enable effective fine-tuning, we also contribute an open-source procedural material dataset and propose to perform program-level augmentation by prompting another pre-trained large language model (LLM). Through extensive evaluation, we show that our method outperforms previous methods on both synthetic and real-world examples.
  abstract_embedding: [0.2373046875, 0.1455078125, -0.1728515625]... (1536 items)
  authors: ['Beichen Li', 'Rundi Wu', 'Armando Solar-Lezama']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652567105
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: VLMaterial__Procedural_Material_Generation_with_Large_Vision-Language_Models.pdf
  sha_abstract: 484d1034786a3e40f8834d6aac1c8cc21c65f7558d82278c78d80192bb78e78a
  title: VLMaterial: Procedural Material Generation with Large Vision-Language Models
  title_normalized: vlmaterial_procedural_material_generation_with_large_visionlanguage_models

================================================================================
Document #243 (ID: luhHZpoBclM7MZc3xZOR)
================================================================================
  abstract: Spatiotemporal dynamics pervade the natural sciences, from the morphogen dynamics underlying patterning in animal pigmentation to the protein waves controlling cell division. A central challenge lies in understanding how controllable parameters induce qualitative changes in system behavior called bifurcations. This endeavor is particularly difficult in realistic settings where governing partial differential equations (PDEs) are unknown and data is limited and noisy. To address this challenge, we propose TRENDy (Temporal Regression of Effective Nonlinear Dynamics), an equation-free approach to learning low-dimensional, predictive models of spatiotemporal dynamics. TRENDy first maps input data to a low-dimensional space of effective dynamics through a cascade of multiscale filtering operations. Our key insight is the recognition that these effective dynamics can be fit by a neural ordinary differential equation (NODE) having the same parameter space as the input PDE. The preceding filtering operations strongly regularize the phase space of the NODE, making TRENDy significantly more robust to noise compared to existing methods. We train TRENDy to predict the effective dynamics of synthetic and real data representing dynamics from across the physical and life sciences. We then demonstrate how we can automatically locate both Turing and Hopf bifurcations in unseen regions of parameter space. We finally apply our method to the analysis of spatial patterning of the ocellated lizard through development. We found that TRENDy's predicted effective state not only accurately predicts spatial changes over time but also identifies distinct pattern features unique to different anatomical regions, such as the tail, neck, and body--an insight that highlights the potential influence of surface geometry on reaction-diffusion mechanisms and their role in driving spatially varying pattern dynamics.
  abstract_embedding: [0.23828125, 0.4375, 0.0284423828125]... (1536 items)
  authors: ['Matt Ricci', 'Guy Pelc', 'Zoe Piran']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652571017
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: TRENDy__Temporal_Regression_of_Effective_Nonlinear_Dynamics.pdf
  sha_abstract: b473c4e85b4b4ead90188b00776675dbc233514ea00add44178ca0c84caf812a
  title: TRENDy: Temporal Regression of Effective Nonlinear Dynamics
  title_normalized: trendy_temporal_regression_of_effective_nonlinear_dynamics

================================================================================
Document #244 (ID: kuhHZpoBclM7MZc3wpNc)
================================================================================
  abstract: In the open world, detecting out-of-distribution (OOD) data, whose labels are disjoint with those of in-distribution (ID) samples, is important for reliable deep neural networks (DNNs). To achieve better detection performance, one type of approach proposes to fine-tune the model with auxiliary OOD datasets to amplify the difference between ID and OOD data through a separation loss defined on model outputs. However, none of these studies consider enlarging the feature disparity, which should be more effective compared to outputs. The main difficulty lies in the diversity of OOD samples, which makes it hard to describe their feature distribution, let alone design losses to separate them from ID features. In this paper, we neatly fence off the problem based on an aggregation property of ID features named Neural Collapse (NC). NC means that the penultimate features of ID samples within a class are nearly identical to the last layer weight of the corresponding class. Based on this property, we propose a simple but effective loss called Separation Loss, which binds the features of OOD data in a subspace orthogonal to the principal subspace of ID features formed by NC. In this way, the features of ID and OOD samples are separated by different dimensions. By optimizing the feature separation loss rather than purely enlarging output differences, our detection achieves SOTA performance on CIFAR10, CIFAR100 and ImageNet benchmarks without any additional data augmentation or sampling, demonstrating the importance of feature separation in OOD detection. Code is available
at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.
  abstract_embedding: [0.046875, 0.384765625, 0.384765625]... (1536 items)
  authors: ['Yingwen Wu', 'Ruiji Yu', 'Xinwen Cheng']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652570197
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Pursuing_Feature_Separation_based_on_Neural_Collapse_for_Out-of-Distribution_Detection.pdf
  sha_abstract: 9fb664e55c7fa39b06cf4eba29d45fc7617153a60dc06ea803e361e3bafa8856
  title: Pursuing Feature Separation based on Neural Collapse for Out-of-Distribution Detection
  title_normalized: pursuing_feature_separation_based_on_neural_collapse_for_outofdistribution_detection

================================================================================
Document #245 (ID: lehHZpoBclM7MZc3xJPf)
================================================================================
  abstract: Despite recent progress in Retrieval-Augmented Generation (RAG) achieved by large language models (LLMs), retrievers often recall uncorrelated documents, regarded as "noise" during subsequent text generation. To address this, some methods train LLMs to distinguish between relevant and irrelevant documents using labeled data, enabling them to select the most likely relevant ones as context. However, they remain sensitive to noise, as LLMs can easily make mistakes when the selected document is noisy. Some approaches increase the number of referenced documents and train LLMs to perform stepwise reasoning when presented with multiple documents. Unfortunately, these methods rely on extensive and diverse annotations to ensure generalization, which is both challenging and costly. In this paper, we propose **Backtracking Correction** to address these limitations. Specifically, we reformulate stepwise RAG into a multi-step decision-making process. Starting from the final step, we optimize the model through error sampling and self-correction, and then backtrack to the previous state iteratively. In this way, the model's learning scheme follows an easy-to-hard progression: as the target state moves forward, the context space decreases while the decision space increases. Experimental results demonstrate that **Backtracking Correction** enhances LLMs' ability to make complex multi-step assessments, improving the robustness of RAG in dealing with noisy documents.
  abstract_embedding: [0.3828125, 0.2734375, -0.05517578125]... (1536 items)
  authors: ['Huawen Feng', 'ZekunYao', 'Junhao Zheng']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652570804
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Training_Large_Language_Models_for_Retrieval-Augmented_Question_Answering_through_Backtracking_Correction.pdf
  sha_abstract: 3197838829c0199e7f4d6fe2312946a65d5ba0c5238298089ff69e03ed345633
  title: Training Large Language Models for Retrieval-Augmented Question Answering through Backtracking Correction
  title_normalized: training_large_language_models_for_retrievalaugmented_question_answering_through_backtracking_correction

================================================================================
Document #246 (ID: kehHZpoBclM7MZc3wZOa)
================================================================================
  abstract: We present SNOWS, a one-shot post-training pruning framework aimed at reducing the cost of vision network inference without retraining. Current leading one-shot pruning methods minimize layer-wise least squares reconstruction error which does not take into account deeper network representations. We propose to optimize a more global reconstruction objective. This objective accounts for nonlinear activations deep in the network to obtain a better proxy for the network loss. This nonlinear objective leads to a more challenging optimization problem---we demonstrate it can be solved efficiently using a specialized second-order optimization framework. A key innovation of our framework is the use of Hessian-free optimization to compute exact Newton descent steps without needing to compute or store the full Hessian matrix. A distinct advantage of SNOWS is that it can be readily applied on top of any sparse mask derived from prior methods, readjusting their weights to preserve deep feature representations. SNOWS obtains state-of-the-art results on various one-shot pruning benchmarks including residual networks and Vision Transformers (ViT/B-16 and ViT/L-16, 86m and 304m parameters respectively). Our open-source implementation is available at https://github.com/mazumder-lab/SNOWS.
  abstract_embedding: [0.24609375, 0.1630859375, 0.8828125]... (1536 items)
  authors: ['Ryan Lucas', 'Rahul Mazumder']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652570003
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Preserving_Deep_Representations_in_One-Shot_Pruning__A_Hessian-Free_Second-Order_Optimization_Framework.pdf
  sha_abstract: bc1a0a1a4c0cc54123c0a39e92efc492f5e2e8578ca7cdbc82128df114c52875
  title: Preserving Deep Representations in One-Shot Pruning: A Hessian-Free Second-Order Optimization Framework
  title_normalized: preserving_deep_representations_in_oneshot_pruning_a_hessianfree_secondorder_optimization_framework

================================================================================
Document #247 (ID: kOhHZpoBclM7MZc3wJO4)
================================================================================
  abstract: Reinforcement learning (RL) has increasingly been applied to solve real-world planning problems, with progress in handling large state spaces and time horizons. However, a key bottleneck in many domains is that RL methods cannot accommodate large, combinatorially structured action spaces. In such settings, even representing the set of feasible actions at a single step may require a complex discrete optimization formulation. We leverage recent advances in embedding trained neural networks into optimization problems to propose SEQUOIA, an RL algorithm that directly optimizes for long-term reward over the feasible action space. Our approach embeds a Q-network into a mixed-integer program to select a combinatorial action in each timestep. Here, we focus on planning over restless bandits, a class of planning problems which capture many real-world examples of sequential decision making. We introduce coRMAB, a broader class of restless bandits with combinatorial actions that cannot be decoupled across the arms of the restless bandit, requiring direct solving over the joint, exponentially large action space. We empirically validate SEQUOIA on four novel restless bandit problems with combinatorial constraints: multiple interventions, path constraints, bipartite matching, and capacity constraints. Our approach significantly outperforms existing methods—which cannot address sequential planning and combinatorial selection simultaneously—by an average of 24.8% on these difficult instances.
  abstract_embedding: [0.216796875, 0.298828125, 0.470703125]... (1536 items)
  authors: ['Lily Xu', 'Bryan Wilder', 'Elias Boutros Khalil']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652569777
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Reinforcement_learning_with_combinatorial_actions_for_coupled_restless_bandits.pdf
  sha_abstract: 81c750179b1fbf6318e2fa9498f02a4a26f32947da69aea321a42154728bfdf3
  title: Reinforcement learning with combinatorial actions for coupled restless bandits
  title_normalized: reinforcement_learning_with_combinatorial_actions_for_coupled_restless_bandits

================================================================================
Document #248 (ID: k-hHZpoBclM7MZc3w5Mq)
================================================================================
  abstract: Recent advances in Large Language Models (LLMs) have enabled the development of Video-LLMs, advancing multimodal learning by bridging video data with language tasks. However, current video understanding models struggle with processing long video sequences, supporting multi-turn dialogues, and adapting to real-world dynamic scenarios. To address these issues, we propose StreamChat, a training-free framework for streaming video reasoning and conversational interaction. StreamChat leverages a novel hierarchical memory system to efficiently process and compress video features over extended sequences, enabling real-time, multi-turn dialogue. Our framework incorporates a parallel system scheduling strategy that enhances processing speed and reduces latency, ensuring robust performance in real-world applications. Furthermore, we introduce StreamBench, a versatile benchmark that evaluates streaming video understanding across diverse media types and interactive scenarios, including multi-turn interactions and complex reasoning tasks.  Extensive evaluations on StreamBench and other public benchmarks demonstrate that  StreamChat significantly outperforms existing
state-of-the-art models in terms of accuracy and response times, confirming its effectiveness for streaming video understanding. Code is available at StreamChat.
  abstract_embedding: [0.020751953125, -0.1220703125, 0.83984375]... (1536 items)
  authors: ['Haomiao Xiong', 'Zongxin Yang', 'Jiazuo Yu']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652570403
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Streaming_Video_Understanding_and_Multi-round_Interaction_with_Memory-enhanced_Knowledge.pdf
  sha_abstract: a2d0a7b2d4f74ddcc2a445bccf871fe2d9a0b4be306ddb24e733117c3c126143
  title: Streaming Video Understanding and Multi-round Interaction with Memory-enhanced Knowledge
  title_normalized: streaming_video_understanding_and_multiround_interaction_with_memoryenhanced_knowledge

================================================================================
Document #249 (ID: j-hHZpoBclM7MZc3vpPD)
================================================================================
  abstract: Low-rank adaptation (LoRA) has become a prevalent method for adapting pre-trained large language models to downstream tasks. However, the simple low-rank decomposition form may constrain the optimization flexibility. To address this limitation, we introduce Location-aware Cosine Adaptation (LoCA), a novel frequency-domain parameter-efficient fine-tuning method based on inverse Discrete Cosine Transform (iDCT) with selective locations of learnable components. We begin with a comprehensive theoretical comparison between frequency-domain and low-rank decompositions for fine-tuning pre-trained large models. Our analysis reveals that frequency-domain decomposition with carefully selected frequency components can surpass the expressivity of traditional low-rank-based methods. Furthermore, we demonstrate that iDCT offers a more efficient implementation compared to inverse Discrete Fourier Transform (iDFT), allowing for better selection and tuning of frequency components while maintaining equivalent expressivity to the optimal iDFT-based adaptation. By employing finite-difference approximation to estimate gradients for discrete locations of learnable coefficients on the DCT spectrum, LoCA dynamically selects the most informative frequency components during training. Experiments on diverse language and vision fine-tuning tasks demonstrate that LoCA offers enhanced parameter efficiency while maintains computational feasibility comparable to low-rank-based methods.
  abstract_embedding: [-0.1806640625, 0.06689453125, 0.0693359375]... (1536 items)
  authors: ['Zhekai Du', 'Yinjie Min', 'Jingjing Li']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652569264
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: LoCA__Location-Aware_Cosine_Adaptation_for_Parameter-Efficient_Fine-Tuning.pdf
  sha_abstract: 7680878b7ce0e6abdbebbbe2b88ed600cfc1b3b6d21868ef52563ee1ea65a5a4
  title: LoCA: Location-Aware Cosine Adaptation for Parameter-Efficient Fine-Tuning
  title_normalized: loca_locationaware_cosine_adaptation_for_parameterefficient_finetuning

================================================================================
Document #250 (ID: lOhHZpoBclM7MZc3xJMS)
================================================================================
  abstract: We provide a convergence analysis of \emph{deep feature instrumental variable} (DFIV) regression (Xu et al., 2021), a nonparametric approach to IV regression using data-adaptive features learned by deep neural networks in two stages. We prove that the DFIV algorithm achieves the minimax optimal learning rate when the target structural function lies in a Besov space. This is shown under standard nonparametric IV assumptions, and an additional smoothness assumption on the regularity of the conditional distribution of the covariate given the instrument, which controls the difficulty of Stage 1. We further demonstrate that DFIV, as a data-adaptive algorithm, is superior to fixed-feature (kernel or sieve) IV methods in two ways. First, when the target function possesses low spatial homogeneity (i.e., it has both smooth and spiky/discontinuous regions), DFIV still achieves the optimal rate, while fixed-feature methods are shown to be strictly suboptimal. Second, comparing with kernel-based two-stage regression estimators, DFIV is provably more data efficient in the Stage 1 samples.
  abstract_embedding: [0.7109375, 0.267578125, 0.16015625]... (1536 items)
  authors: ['Juno Kim', 'Dimitri Meunier', 'Arthur Gretton']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652570602
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Optimality_and_Adaptivity_of_Deep_Neural_Features_for_Instrumental_Variable_Regression.pdf
  sha_abstract: 1acb1ec50af45cbaf71b8400d91eea396ea72a87ff43826f87e6a1f7630189a6
  title: Optimality and Adaptivity of Deep Neural Features for Instrumental Variable Regression
  title_normalized: optimality_and_adaptivity_of_deep_neural_features_for_instrumental_variable_regression

================================================================================
Document #251 (ID: nuhHZpoBclM7MZc3z5NF)
================================================================================
  abstract: 3D Gaussian Splatting (3DGS) has shown promising results for Novel View Synthesis. However, while it is quite effective when based on high-quality images, its performance declines as image quality degrades, due to lack of resolution, motion blur, noise, compression artifacts, or other factors common in real-world data collection. While some solutions have been proposed for specific types of degradation, general techniques are still missing. To address the problem, we propose a robust HQGS that significantly enhances the 3DGS under various degradation scenarios. We first analyze that 3DGS lacks sufficient attention in some detailed regions in low-quality scenes, leading to the absence of Gaussian primitives in those areas and resulting in loss of detail in the rendered images. To address this issue, we focus on leveraging edge structural information to provide additional guidance for 3DGS, enhancing its robustness. First, we introduce an edge-semantic fusion guidance module that combines rich texture information from high-frequency edge-aware maps with semantic information from images.  The fused features serve as prior guidance to capture detailed distribution across different regions, bringing more attention to areas with detailed edge information and allowing for a higher concentration of Gaussian primitives to be assigned to such areas. Additionally, we present a structural cosine similarity loss to complement pixel-level constraints, further improving the quality of the rendered images. Extensive experiments demonstrate that our method offers better robustness and achieves the best results across various degraded scenes. Source code and trained models are publicly available at: \url{https://github.com/linxin0/HQGS}.
  abstract_embedding: [0.1259765625, -0.0164794921875, 0.05322265625]... (1536 items)
  authors: ['Xin Lin', 'Shi Luo', 'Xiaojun Shan']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652573486
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: HQGS__High-Quality_Novel_View_Synthesis_with_Gaussian_Splatting_in_Degraded_Scenes.pdf
  sha_abstract: 0b54c2ad734134096cb5c733ef679b0d2c4c11c5d9a7a0c2a4ee718e9db521f3
  title: HQGS: High-Quality Novel View Synthesis with Gaussian Splatting in Degraded Scenes
  title_normalized: hqgs_highquality_novel_view_synthesis_with_gaussian_splatting_in_degraded_scenes

================================================================================
Document #252 (ID: nehHZpoBclM7MZc3zpN8)
================================================================================
  abstract: Understanding transition pathways between two meta-stable states of a molecular system is crucial to advance drug discovery and material design. However, unbiased molecular dynamics (MD) simulations are computationally infeasible because of the high energy barriers that separate these states. Although recent machine learning techniques are proposed to sample rare events, they are often limited to simple systems and rely on collective variables (CVs) derived from costly domain expertise. In this paper, we introduce a novel approach that trains diffusion path samplers (DPS) to address the transition path sampling (TPS) problem without requiring CVs. We reformulate the problem as an amortized sampling from the transition path distribution by minimizing the log-variance divergence between the path distribution induced by DPS and the transition path distribution. Based on the log-variance divergence, we propose learnable control variates to reduce the variance of gradient estimators and the off-policy training objective with replay buffers and simulated annealing techniques to improve sample efficiency and diversity. We also propose a scale-based equivariant parameterization of the bias forces to ensure scalability for large systems. We extensively evaluate our approach, termed TPS-DPS, on a synthetic system, small peptide, and challenging fast-folding proteins, demonstrating that it produces more realistic and diverse transition pathways than existing baselines. We also provide links to [project page](https://kiyoung98.github.io/tps-dps/) and [code](https://github.com/kiyoung98/tps-dps).
  abstract_embedding: [0.671875, 0.458984375, 0.61328125]... (1536 items)
  authors: ['Kiyoung Seong', 'Seonghyun Park', 'Seonghwan Kim']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652573301
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Transition_Path_Sampling_with_Improved_Off-Policy_Training_of_Diffusion_Path_Samplers.pdf
  sha_abstract: afd061729f6c176f3f6236c1fb67d2fa366488d62605a67afdbf1886546ff46e
  title: Transition Path Sampling with Improved Off-Policy Training of Diffusion Path Samplers
  title_normalized: transition_path_sampling_with_improved_offpolicy_training_of_diffusion_path_samplers

================================================================================
Document #253 (ID: n-hHZpoBclM7MZc30JMd)
================================================================================
  abstract: Graph Neural Networks (GNNs) have achieved remarkable success in various graph-based learning tasks. While their performance is often attributed to the powerful neighborhood aggregation mechanism, recent studies suggest that other components such as non-linear layers may also significantly affecting how GNNs process the input graph data in the spectral domain. Such evidence challenges the prevalent opinion that neighborhood aggregation mechanisms dominate the behavioral characteristics of GNNs in the spectral domain. To demystify such a conflict, this paper introduces a comprehensive benchmark to measure and evaluate GNNs' capability in capturing and leveraging the information encoded in different frequency components of the input graph data. Specifically, we first conduct an exploratory study demonstrating that GNNs can flexibly yield outputs with diverse frequency components even when certain frequencies are absent or filtered out from the input graph data. We then formulate a novel research problem of measuring and benchmarking the performance of GNNs from a spectral perspective. To take an initial step towards a comprehensive benchmark, we design an evaluation protocol supported by comprehensive theoretical analysis. Finally, we introduce a comprehensive benchmark on real-world datasets, revealing insights that challenge prevalent opinions from a spectral perspective. We believe that our findings will open new avenues for future advancements in this area. Our implementations can be found at: https://github.com/yushundong/Spectral-benchmark.
  abstract_embedding: [0.1875, 0.2275390625, 0.142578125]... (1536 items)
  authors: ['Yushun Dong', 'Patrick Soga', 'Yinhan He']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652573717
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Graph_Neural_Networks_Are_More_Than_Filters__Revisiting_and_Benchmarking_from_A_Spectral_Perspective.pdf
  sha_abstract: 165d3e13d1668804e8c3e60cd1b9d0d8c7644d68c90541848fcef1dd107d874c
  title: Graph Neural Networks Are More Than Filters: Revisiting and Benchmarking from A Spectral Perspective
  title_normalized: graph_neural_networks_are_more_than_filters_revisiting_and_benchmarking_from_a_spectral_perspective

================================================================================
Document #254 (ID: mOhHZpoBclM7MZc3yZMu)
================================================================================
  abstract: Deep neural networks are vulnerable to backdoor attacks, a type of adversarial attack that poisons the training data to manipulate the behavior of models trained on such data. 
Clean-label backdoor is a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data.
Early works on clean-label attacks added triggers to a random subset of the training set, ignoring the fact that samples contribute unequally to the attack's success. This results in high poisoning rates and low attack success rates.
To alleviate the problem, several supervised learning-based sample selection strategies have been proposed.
However, these methods assume access to the entire labeled training set and require training, which is expensive and may not always be practical.
This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g., in face recognition systems) and has no knowledge of the victim model or any other classes in the training set.
We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting. 
Our threat model poses a serious threat in training machine learning models with third-party datasets, since the attack can be performed effectively with limited information. Experiments on benchmark datasets illustrate the effectiveness of our strategies in improving clean-label backdoor attacks.
  abstract_embedding: [0.60546875, 0.96484375, 0.26171875]... (1536 items)
  authors: ['Nguyen Hung-Quang', 'Ngoc-Hieu Nguyen', 'The-Anh Ta']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652571943
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Wicked_Oddities__Selectively_Poisoning_for_Effective_Clean-Label_Backdoor_Attacks.pdf
  sha_abstract: fa0368afd2b3e9d8b77423346c6725bc43cad9fba5c21cd39a07bdbec61b10e8
  title: Wicked Oddities: Selectively Poisoning for Effective Clean-Label Backdoor Attacks
  title_normalized: wicked_oddities_selectively_poisoning_for_effective_cleanlabel_backdoor_attacks

================================================================================
Document #255 (ID: muhHZpoBclM7MZc3ypP1)
================================================================================
  abstract: Distributionally robust optimization (DRO) is a powerful technique to train robust machine learning models that perform well under distribution shifts. Compared with empirical risk minimization (ERM), DRO optimizes the expected loss under the worst-case distribution in
an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem, Jin et al. (2021) showed that its dual problem is generalized $(L_0, L_1)$-smooth condition and gradient noise satisfies the affine variance condition, designed an algorithm of mini-batch normalized gradient descent with momentum, and proved its convergence and complexity.   In this paper, we show that the dual problem and the gradient noise satisfy simpler yet more precise partially generalized smoothness condition and partially affine variance condition by studying the optimization variable and dual variable separately, which further yields much simpler algorithm design and convergence analysis. We develop a double stochastic gradient descent with clipping (D-SGD-C) algorithm that converges to an $\epsilon$-stationary point with $\mathcal O(\epsilon^{-4})$ gradient complexity, which matches with results in Jin et al. (2021). Our algorithm does not need to use momentum, and the proof is much simpler, thanks to the more precise characterization of partially generalized smoothness and partially affine variance noise. We further design a variance-reduced method that achieves a lower gradient complexity of $\mathcal O(\epsilon^{-3})$. Our theoretical results and insights are further verified numerically on a number of tasks, and our algorithms outperform the existing DRO method (Jin et al., 2021).
  abstract_embedding: [0.6875, 0.265625, -0.06884765625]... (1536 items)
  authors: ['Qi Zhang', 'Yi Zhou', 'Simon Khan']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652572397
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Revisiting_Large-Scale_Non-convex_Distributionally_Robust_Optimization.pdf
  sha_abstract: ac00ec278b8204c377f5fbc94e399e002c0ccf7de73aef0ca04609c4ea99a211
  title: Revisiting Large-Scale Non-convex Distributionally Robust Optimization
  title_normalized: revisiting_largescale_nonconvex_distributionally_robust_optimization

================================================================================
Document #256 (ID: m-hHZpoBclM7MZc3y5P3)
================================================================================
  abstract: Diffusion-based representation learning has achieved substantial attention due to its promising capabilities in latent representation and sample generation. Recent studies have employed an auxiliary encoder to identify a corresponding representation from data and to adjust the dimensionality of a latent variable $\mathbf{z}$. Meanwhile, this auxiliary structure invokes an *information split problem*; the information of each data instance $\mathbf{x}_0$ is divided into diffusion endpoint $\mathbf{x}_T$ and encoded $\mathbf{z}$ because there exist two inference paths starting from the data. The latent variable modeled by diffusion endpoint $\mathbf{x}_T$ has some disadvantages. The diffusion endpoint $\mathbf{x}_T$ is computationally expensive to obtain and inflexible in dimensionality. To address this problem, we introduce Diffusion Bridge AuteEncoders (DBAE), which enables $\mathbf{z}$-dependent endpoint $\mathbf{x}_T$ inference through a feed-forward architecture. This structure creates an information bottleneck at $\mathbf{z}$, so $\mathbf{x}_T$ becomes dependent on $\mathbf{z}$ in its generation. This results in $\mathbf{z}$ holding the full information of data. We propose an objective function for DBAE to enable both reconstruction and generative modeling, with their theoretical justification. Empirical evidence supports the effectiveness of the intended design in DBAE, which notably enhances downstream inference quality, reconstruction, and disentanglement. Additionally, DBAE generates high-fidelity samples in the unconditional generation. Our code is
available at https://github.com/aailab-kaist/DBAE.
  abstract_embedding: [0.423828125, 0.1923828125, 0.08056640625]... (1536 items)
  authors: ['Yeongmin Kim', 'Kwanghyeon Lee', 'Minsang Park']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652572643
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Diffusion_Bridge_AutoEncoders_for_Unsupervised_Representation_Learning.pdf
  sha_abstract: 4fe407b2510583848eaf50dccf7b21a5b908d12cd5bacac066c3f1f05139ba8e
  title: Diffusion Bridge AutoEncoders for Unsupervised Representation Learning
  title_normalized: diffusion_bridge_autoencoders_for_unsupervised_representation_learning

================================================================================
Document #257 (ID: l-hHZpoBclM7MZc3yJOG)
================================================================================
  abstract: Motion diffusion models and Reinforcement Learning (RL) based control for physics-based simulations have complementary strengths for human motion generation. The former is capable of generating a wide variety of motions, adhering to intuitive control such as text, while the latter offers physically plausible motion and direct interaction with the environment. In this work, we present a method that combines their respective strengths. CLoSD is a text-driven RL physics-based controller, guided by diffusion generation for various tasks. Our key insight is that motion diffusion can serve as an on-the-fly universal planner for a robust RL controller. To this end, CLoSD maintains a closed-loop interaction between two modules — a Diffusion Planner (DiP), and a tracking controller. DiP is a fast-responding autoregressive diffusion model, controlled by textual prompts and target locations, and the controller is a simple and robust motion imitator that continuously receives motion plans from DiP and provides feedback from the environment. CLoSD is capable of seamlessly performing a sequence of different tasks, including navigation to a goal location, striking an object with a hand or foot as specified in a text prompt, sitting down, and getting up.
  abstract_embedding: [0.421875, 0.359375, 0.21875]... (1536 items)
  authors: ['Guy Tevet', 'Sigal Raab', 'Setareh Cohan']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652571738
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CLoSD__Closing_the_Loop_between_Simulation_and_Diffusion_for_multi-task_character_control.pdf
  sha_abstract: fbab6225bfce7824fa3773240fd9aec3f6e350eee8afdc9471ee89e7d3f204a6
  title: CLoSD: Closing the Loop between Simulation and Diffusion for multi-task character control
  title_normalized: closd_closing_the_loop_between_simulation_and_diffusion_for_multitask_character_control

================================================================================
Document #258 (ID: nOhHZpoBclM7MZc3zJOy)
================================================================================
  abstract: The increasing demand for controllable outputs in text-to-image generation has spurred advancements in multi-instance generation (MIG), allowing users to define both instance layouts and attributes. However, unlike image-conditional generation methods such as ControlNet, MIG techniques have not been widely adopted in state-of-the-art models like SD2 and SDXL, primarily due to the challenge of building robust renderers that simultaneously handle instance positioning and attribute rendering. In this paper, we introduce Depth-Driven Decoupled Image Synthesis (3DIS), a novel framework that decouples the MIG process into two stages: (i) generating a coarse scene depth map for accurate instance positioning and scene composition, and (ii) rendering fine-grained attributes using pre-trained ControlNet on any foundational model, without additional training. Our 3DIS framework integrates a custom adapter into LDM3D for precise depth-based layouts and employs a finetuning-free method for enhanced instance-level attribute rendering. Extensive experiments on COCO-Position and COCO-MIG benchmarks demonstrate that 3DIS significantly outperforms existing methods in both layout precision and attribute rendering. Notably, 3DIS offers seamless compatibility with diverse foundational models, providing a robust, adaptable solution for advanced multi-instance generation. The code is available at: https://github.com/limuloo/3DIS.
  abstract_embedding: [0.36328125, -0.09130859375, 0.1796875]... (1536 items)
  authors: ['Dewei Zhou', 'Ji Xie', 'Zongxin Yang']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652572843
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: 3DIS__Depth-Driven_Decoupled_Image_Synthesis_for_Universal_Multi-Instance_Generation.pdf
  sha_abstract: 9c490766707f514aae9af8ecf1a1efbe79932b71d733533544f8b681359677f9
  title: 3DIS: Depth-Driven Decoupled Image Synthesis for Universal Multi-Instance Generation
  title_normalized: 3dis_depthdriven_decoupled_image_synthesis_for_universal_multiinstance_generation

================================================================================
Document #259 (ID: qOhHZpoBclM7MZc32pOU)
================================================================================
  abstract: Text-to-video (T2V) models have recently undergone rapid and substantial advancements. Nevertheless, due to limitations in data and computational resources, achieving efficient generation of long videos with rich motion dynamics remains a significant challenge. 
To generate high-quality, dynamic, and temporally consistent long videos, this paper presents ARLON,  a novel framework that boosts diffusion Transformers with autoregressive (\textbf{AR}) models for long (\textbf{LON}) video generation, by integrating the coarse spatial and long-range temporal information provided by the AR model to guide the DiT model effectively.
Specifically, ARLON incorporates several key innovations: 
1) A latent Vector Quantized Variational Autoencoder (VQ-VAE) compresses the input latent space of the DiT model into compact and highly quantized visual tokens, bridging the AR and DiT models and balancing the learning complexity and information density;
2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model, ensuring effective guidance during video generation; 
3) To enhance the tolerance capability of noise introduced from the AR inference, the DiT model is trained with coarser visual latent tokens incorporated with an uncertainty sampling module. 
Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench, with notable improvements in dynamic degree and aesthetic quality, while delivering competitive results on the remaining three and simultaneously accelerating the generation process. In addition, ARLON achieves state-of-the-art performance in long video generation, outperforming other open-source models in this domain. 
Detailed analyses of the improvements in inference efficiency are presented, alongside a practical application that demonstrates the generation of long videos using progressive text prompts. Project page: \url{http://aka.ms/arlon}.
  abstract_embedding: [0.0133056640625, 0.208984375, 0.47265625]... (1536 items)
  authors: ['Zongyi Li', 'Shujie HU', 'Shujie LIU']... (10 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652576397
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ARLON__Boosting_Diffusion_Transformers_with_Autoregressive_Models_for_Long_Video_Generation.pdf
  sha_abstract: e6260edea24b70ca7a8fbe9f6d6d7d28f775ef9b34e3145b4e035791dfef8397
  title: ARLON: Boosting Diffusion Transformers with Autoregressive Models for Long Video Generation
  title_normalized: arlon_boosting_diffusion_transformers_with_autoregressive_models_for_long_video_generation

================================================================================
Document #260 (ID: ouhHZpoBclM7MZc305Oo)
================================================================================
  abstract: Due to the rise in antimicrobial resistance, identifying novel compounds with antibiotic potential is crucial for combatting this global health issue. However, traditional drug development methods are costly and inefficient. Recognizing the pressing need for more effective solutions, researchers have turned to machine learning techniques to streamline the prediction and development of novel antibiotic compounds. While foundation models have shown promise in antibiotic discovery, current mainstream efforts still fall short of fully leveraging the potential of multimodal molecular data. Recent studies suggest that contrastive learning frameworks utilizing multimodal data exhibit excellent performance in representation learning across various domains. Building upon this, we introduce CL-MFAP, an unsupervised contrastive learning (CL)-based multimodal foundation (MF) model specifically tailored for discovering small molecules with potential antibiotic properties (AP) using three types of molecular data. This model employs 1.6 million bioactive molecules with drug-like properties from the ChEMBL dataset to jointly pretrain three encoders: (1) a transformer-based encoder with rotary position embedding for processing SMILES strings; (2) another transformer-based encoder, incorporating a novel bi-level routing attention mechanism to handle molecular graph representations; and (3) a Morgan fingerprint encoder using a multilayer perceptron, to achieve the contrastive learning purpose. The CL-MFAP outperforms baseline models in antibiotic property prediction by effectively utilizing different molecular modalities and demonstrates superior domain-specific performance when fine-tuned for antibiotic-related property prediction tasks.
  abstract_embedding: [0.59375, 0.58984375, -0.0004863739013671875]... (1536 items)
  authors: ['Gen Zhou', 'Sugitha Janarthanan', 'Yutong Lu']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652574625
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CL-MFAP__A_Contrastive_Learning-Based_Multimodal_Foundation_Model_for_Molecular_Property_Prediction_and_Antibiotic_Screening.pdf
  sha_abstract: 61b5994c3093a80b6ff72019519dcc394409de14d9eaac3db6e430a076f2d3af
  title: CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening
  title_normalized: clmfap_a_contrastive_learningbased_multimodal_foundation_model_for_molecular_property_prediction_and_antibiotic_screening

================================================================================
Document #261 (ID: p-hHZpoBclM7MZc32ZOQ)
================================================================================
  abstract: Synthetic tabular data generation has traditionally been a challenging problem due to the high complexity of the underlying distributions that characterise this type of data. Despite recent advances in deep generative models (DGMs), existing methods often fail to produce realistic datapoints that are well-aligned with available background knowledge.
In this paper, we address this limitation by introducing Disjunctive Refinement Layer (DRL), a novel layer designed
to enforce the alignment of generated data with the background knowledge specified in user-defined constraints.
DRL is the first method able to automatically make deep learning models inherently compliant with constraints as expressive as quantifier-free linear formulas, which can define non-convex and even disconnected spaces. 
Our experimental analysis shows that DRL not only guarantees constraint satisfaction but also improves efficacy in downstream tasks. Notably, when applied to DGMs that frequently violate constraints, DRL eliminates violations entirely. Further, it improves performance metrics by up to 21.4\% in F1-score and 20.9\% in Area Under the ROC Curve, thus demonstrating its practical impact on data generation.
  abstract_embedding: [0.482421875, 0.357421875, 0.43359375]... (1536 items)
  authors: ['Mihaela C. Stoian', 'Eleonora Giunchiglia']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652576137
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Beyond_the_convexity_assumption__Realistic_tabular_data_generation_under_quantifier-free_real_linear_constraints.pdf
  sha_abstract: 64eb50c4397f2cfe23988f6391cf3e3f402480a39d0cd71ee985df2c6787ff58
  title: Beyond the convexity assumption: Realistic tabular data generation under quantifier-free real linear constraints
  title_normalized: beyond_the_convexity_assumption_realistic_tabular_data_generation_under_quantifierfree_real_linear_constraints

================================================================================
Document #262 (ID: oOhHZpoBclM7MZc30ZP8)
================================================================================
  abstract: SMILES, a crucial textual representation of molecular structures, has garnered significant attention as a foundation for pre-trained language models (LMs). However, most existing pre-trained SMILES LMs focus solely on the single-token level supervision during pre-training, failing to fully leverage the substructural information of molecules. This limitation makes the pre-training task overly simplistic, preventing the models from capturing richer molecular semantic information. Moreover, during pre-training, these SMILES LMs only process corrupted SMILES inputs, never encountering any valid SMILES, which leads to a train-inference mismatch. To address these challenges, we propose SMI-Editor, a novel edit-based pre-trained SMILES LM. SMI-Editor disrupts substructures within a molecule at random and feeds the resulting SMILES back into the model, which then attempts to restore the original SMILES through an editing process. This approach not only introduces fragment-level training signals, but also enables the use of valid SMILES as inputs, allowing the model to learn how to reconstruct complete molecules from these incomplete structures. As a result, the model demonstrates improved scalability and an enhanced ability to capture fragment-level molecular information. Experimental results show that SMI-Editor achieves state-of-the-art performance across multiple downstream molecular tasks, and even outperforming several 3D molecular representation models.
  abstract_embedding: [0.353515625, 0.609375, -0.0059814453125]... (1536 items)
  authors: ['Kangjie Zheng', 'Siyue Liang', 'Junwei Yang']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652574184
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SMI-Editor__Edit-based_SMILES_Language_Model_with_Fragment-level_Supervision.pdf
  sha_abstract: ca34e6297c107f89070f58f3b10d197f0c90ab0d5bd33c77e887200ce5418862
  title: SMI-Editor: Edit-based SMILES Language Model with Fragment-level Supervision
  title_normalized: smieditor_editbased_smiles_language_model_with_fragmentlevel_supervision

================================================================================
Document #263 (ID: pehHZpoBclM7MZc31pP8)
================================================================================
  abstract: As the quality of image generators continues to improve, deepfakes become a topic of considerable societal debate. Image watermarking allows responsible model owners to detect and label their AI-generated content, which can mitigate the harm. Yet, current state-of-the-art methods in image watermarking remain vulnerable to forgery and removal attacks. 
This vulnerability occurs in part because watermarks distort the distribution of generated images, unintentionally revealing information about the watermarking techniques.

In this work, we first demonstrate a distortion-free watermarking method for images, based on a diffusion model's initial noise.
However, detecting the watermark requires comparing the initial noise reconstructed for an image to all previously used initial noises. 
To mitigate these issues, we propose a two-stage watermarking framework for efficient detection. During generation, we augment the initial noise with generated Fourier patterns to embed information about the group of initial noises we used. For detection, we (i) retrieve the relevant group of noises, and (ii) search within the given group for an initial noise that might match our image. This watermarking approach achieves state-of-the-art robustness to forgery and removal against a large battery of attacks. The project code is available at https://github.com/Kasraarabi/Hidden-in-the-Noise.
  abstract_embedding: [-0.004150390625, 0.68359375, 0.2119140625]... (1536 items)
  authors: ['Kasra Arabi', 'Benjamin Feuer', 'R. Teal Witter']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652575477
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Hidden_in_the_Noise__Two-Stage_Robust_Watermarking_for_Images.pdf
  sha_abstract: 8f2f4f6bf5001523ce13dc15752e3abdf53137a2fcb154dbd4b1011f6d221132
  title: Hidden in the Noise: Two-Stage Robust Watermarking for Images
  title_normalized: hidden_in_the_noise_twostage_robust_watermarking_for_images

================================================================================
Document #264 (ID: mehHZpoBclM7MZc3ypMa)
================================================================================
  abstract: Mutual Information (MI) is a fundamental measure of dependence between random variables, but its practical application is limited because it is difficult to calculate in many circumstances. Variational methods offer one approach by introducing an approximate distribution to create various bounds on MI, which in turn is an easier optimization problem to solve. In practice, the variational distribution chosen is often a Gaussian, which is convenient but lacks flexibility in modeling complicated distributions. In this paper, we introduce new classes of variational estimators based on Normalizing Flows that extend the previous Gaussian-based variational estimators. Our new estimators maintain many of the same theoretical guarantees while simultaneously enhancing the expressivity of the variational distribution. We experimentally verify that our new methods are effective on large MI problems where discriminative-based estimators, such as MINE and InfoNCE, are fundamentally limited. Furthermore, we compare against a diverse set of benchmarking tests to show that the flow-based estimators often perform as well, if not better, than the discriminative-based counterparts. Finally, we demonstrate how these estimators can be effectively utilized in the Bayesian Optimal Experimental Design setting for online sequential decision making.
  abstract_embedding: [0.1728515625, -0.22265625, -0.0615234375]... (1536 items)
  authors: ['Caleb Dahlke', 'Jason Pacheco']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652572177
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Flow-based_Variational_Mutual_Information__Fast_and_Flexible_Approximations.pdf
  sha_abstract: 87c5f4c4aebb447db0b4cfe28583276264113d3ad829945a7ecd0485e9e34440
  title: Flow-based Variational Mutual Information: Fast and Flexible Approximations
  title_normalized: flowbased_variational_mutual_information_fast_and_flexible_approximations

================================================================================
Document #265 (ID: pOhHZpoBclM7MZc31pM7)
================================================================================
  abstract: Reinforcement learning (RL) has made significant progress in various domains, but scaling it to long-horizon tasks with complex decision-making remains challenging. Skill learning attempts to address this by abstracting actions into higher-level behaviors. However, current approaches often fail to recognize semantically similar behaviors as the same skill and use fixed skill lengths, limiting flexibility and generalization. To address this, we propose Dynamic Contrastive Skill Learning (DCSL), a novel framework that redefines skill representation and learning. DCSL introduces three key ideas: state-transition based skill definition, skill similarity function learning, and dynamic skill length adjustment. By focusing on state transitions and leveraging contrastive learning, DCSL effectively captures the semantic context of behaviors and adapts skill lengths to match the appropriate temporal extent of behaviors. Our approach enables more flexible and adaptive skill extraction, particularly in complex or noisy datasets, and demonstrates competitive performance compared to existing methods in task completion and efficiency.
  abstract_embedding: [0.58984375, 0.236328125, 0.431640625]... (1536 items)
  authors: ['Jinwoo Choi', 'Seung-Woo Seo']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652575283
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Dynamic_Contrastive_Skill_Learning_with_State-Transition_Based_Skill_Clustering_and_Dynamic_Length_Adjustment.pdf
  sha_abstract: 95cc22737d21913176b66faee3ed85410b5d1f9c9da0b1f78513b893d2a27871
  title: Dynamic Contrastive Skill Learning with State-Transition Based Skill Clustering and Dynamic Length Adjustment
  title_normalized: dynamic_contrastive_skill_learning_with_statetransition_based_skill_clustering_and_dynamic_length_adjustment

================================================================================
Document #266 (ID: oehHZpoBclM7MZc30pPF)
================================================================================
  abstract: Multilingual large language models (LLMs) are great translators, but this is largely limited to high-resource languages. For many LLMs, translating in and out of low-resource languages remains a challenging task. To maximize data efficiency in this low-resource setting, we introduce Mufu, which includes a selection of automatically generated multilingual candidates and an instruction to correct inaccurate translations in the prompt. Mufu prompts turn a translation task into a postediting one, and seek to harness the LLM’s reasoning capability with auxiliary translation candidates, from which the model is required to assess the input quality, align the semantics cross-lingually, copy from relevant inputs and override instances that are incorrect. Our experiments on En-XX translations over the Flores-200 dataset show LLMs finetuned against Mufu-style prompts are robust to poor quality auxiliary translation candidates, achieving performance superior to NLLB 1.3B distilled model in 64% of low- and very-low-resource language pairs. We then distill these models to reduce inference cost, while maintaining on average 3.1 chrF improvement over finetune-only baseline in low-resource translations.
  abstract_embedding: [0.310546875, 0.419921875, 0.1337890625]... (1536 items)
  authors: ['Zheng Wei Lim', 'Nitish Gupta', 'Honglin Yu']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652574397
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Mufu___Multilingual_Fused_Learning_for_Low-Resource_Translation_with_LLM.pdf
  sha_abstract: 9e0306a186210d6b5127370786b642a629bff95a65fc51ae3a93a9bf7a55f249
  title: Mufu:  Multilingual Fused Learning for Low-Resource Translation with LLM
  title_normalized: mufu__multilingual_fused_learning_for_lowresource_translation_with_llm

================================================================================
Document #267 (ID: o-hHZpoBclM7MZc31ZOS)
================================================================================
  abstract: In this paper, we provide tight lower bounds for the oracle complexity of minimizing high-order Hölder smooth and uniformly convex functions. Specifically, for a function whose $p^{th}$-order derivatives are Hölder continuous with degree $\nu$ and parameter $H$, and that is uniformly convex with degree $q$ and parameter $\sigma$, we focus on two asymmetric cases: (1) $q > p + \nu$, and (2) $q < p+\nu$. Given up to $p^{th}$-order oracle access, we establish worst-case oracle complexities of $\Omega\left( \left( \frac{H}{\sigma}\right)^\frac{2}{3(p+\nu)-2}\left( \frac{\sigma}{\epsilon}\right)^\frac{2(q-p-\nu)}{q(3(p+\nu)-2)}\right)$ in the first case with an $\ell_\infty$-ball-truncated-Gaussian smoothed hard function and $\Omega\left(\left(\frac{H}{\sigma}\right)^\frac{2}{3(p+\nu)-2}+ \log\log\left(\left(\frac{\sigma^{p+\nu}}{H^q}\right)^\frac{1}{p+\nu-q}\frac{1}{\epsilon}\right)\right)$ in the second case, for reaching an $\epsilon$-approximate solution in terms of the optimality gap. Our analysis generalizes previous lower bounds for functions under first- and second-order smoothness as well as those for uniformly convex functions, and furthermore our results match the corresponding upper bounds in this general setting.
  abstract_embedding: [0.416015625, 0.392578125, 0.51171875]... (1536 items)
  authors: ['Site Bai', 'Brian Bullins']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652575082
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Tight_Lower_Bounds_under_Asymmetric_High-Order_Hölder_Smoothness_and_Uniform_Convexity.pdf
  sha_abstract: b26ad20620af768b95f75a58341fd629b02d11d82688fffd36792577f51c3507
  title: Tight Lower Bounds under Asymmetric High-Order Hölder Smoothness and Uniform Convexity
  title_normalized: tight_lower_bounds_under_asymmetric_highorder_hölder_smoothness_and_uniform_convexity

================================================================================
Document #268 (ID: puhHZpoBclM7MZc315O2)
================================================================================
  abstract: The tokenization of audio with neural audio codec models is a vital part of modern AI pipelines for the generation or understanding of speech, alone or in a multimodal context. Traditionally such tokenization models have concentrated on low parameter-count architectures using only components with strong inductive biases. In this work we show that by applying a transformer architecture with large parameter count to this problem, and applying a flexible Finite Scalar Quantization (FSQ) based bottleneck, it is possible to reach state-of-the-art speech quality at extremely low bit-rates of $400$ or $700$ bits-per-second. The trained models strongly out-perform existing baselines in both objective and subjective tests.
  abstract_embedding: [-0.1328125, 0.2001953125, 0.201171875]... (1536 items)
  authors: ['Julian D Parker', 'Anton Smirnov', 'Jordi Pons']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652575663
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Scaling_Transformers_for_Low-Bitrate_High-Quality_Speech_Coding.pdf
  sha_abstract: 1dc581d07a9ebada8b6d42cdcb95f959e0576b97eb879fec7b9a900b459faa9d
  title: Scaling Transformers for Low-Bitrate High-Quality Speech Coding
  title_normalized: scaling_transformers_for_lowbitrate_highquality_speech_coding

================================================================================
Document #269 (ID: rehHZpoBclM7MZc34ZM4)
================================================================================
  abstract: The brain's ability to transform sensory inputs into motor functions is central to neuroscience and crucial for the development of embodied intelligence. Sensory-motor integration involves complex neural circuits, diverse neuronal types, and intricate intercellular connections. Bridging the gap between biological realism and behavioral functionality presents a formidable challenge. In this study, we focus on the columnar structure of the superficial layers of mouse barrel cortex as a model system. We constructed a model comprising 4,218 neurons across 13 neuronal subtypes, with neural distribution and connection strengths constrained by anatomical experimental findings. A key innovation of our work is the development of an effective construction and training pipeline tailored for this biologically constrained model. Additionally, we converted an existing simulated whisker sweep dataset into a spiking-based format, enabling our network to be trained and tested on neural signals that more closely mimic those observed in biological systems. The results of object discrimination utilizing whisker signals demonstrate that our barrel cortex model, grounded in biological constraints, achieves a classification accuracy exceeds classical convolutional neural networks (CNNs), recurrent neural networks (RNNs), and long short-term memory networks (LSTMs), by an average of 8.6%, and is on par with recent spiking neural networks (SNNs) in performance. Interestingly, a whisker deprivation experiment, designed in accordance with neuroscience practices, further validates the perceptual capabilities of our model in behavioral tasks.
Critically, it offers significant biological interpretability: post-training analysis reveals that neurons within our model exhibit firing characteristics and distribution patterns similar to those observed in the actual neuronal systems of the barrel cortex. This study advances our understanding of neural processing in the barrel cortex and exemplifies how integrating detailed biological structures into neural network models can enhance both scientific inquiry and artificial intelligence applications. The code is available at https://github.com/fun0515/RSNN_bfd.
  abstract_embedding: [0.12451171875, -0.2001953125, 0.0072021484375]... (1536 items)
  authors: ['Tianfang Zhu', 'Dongli Hu', 'Jiandong Zhou']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652578097
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Biologically_Constrained_Barrel_Cortex_Model_Integrates_Whisker_Inputs_and_Replicates_Key_Brain_Network_Dynamics.pdf
  sha_abstract: 72d37a356c45540ca92ea8d2377e8254c3e3b838446700ef8c75471f072b93dd
  title: Biologically Constrained Barrel Cortex Model Integrates Whisker Inputs and Replicates Key Brain Network Dynamics
  title_normalized: biologically_constrained_barrel_cortex_model_integrates_whisker_inputs_and_replicates_key_brain_network_dynamics

================================================================================
Document #270 (ID: ruhHZpoBclM7MZc34pMa)
================================================================================
  abstract: Large language models (LLMs) have shown remarkable proficiency in generating text, benefiting from extensive training on vast textual corpora. However, LLMs may also acquire unwanted behaviors from the diverse and sensitive nature of their training data, which can include copyrighted and private content. Machine unlearning has been introduced as a viable solution to remove the influence of such problematic content without the need for costly and time-consuming retraining. This process aims to erase specific knowledge from LLMs while preserving as much model utility as possible. Despite the effectiveness of current unlearning methods, little attention has been given to whether existing unlearning methods for LLMs truly achieve forgetting or merely hide the knowledge, which current unlearning benchmarks fail to detect. This paper reveals that applying quantization to models that have undergone unlearning can restore the "forgotten" information. We conduct comprehensive experiments using various quantization techniques across multiple precision levels to thoroughly evaluate this phenomenon. We find that for unlearning methods with utility constraints, the unlearned model retains an average of 21\% of the intended forgotten knowledge in full precision, which significantly increases to 83\% after 4-bit quantization. Based on our empirical findings, we provide a theoretical explanation for the observed phenomenon and propose a quantization-robust unlearning strategy aimed at mitigating this intricate issue. Our results highlight a fundamental tension between preserving the utility of the unlearned model and preventing knowledge recovery through quantization, emphasizing the challenge of balancing these two objectives. Altogether, our study underscores a major failure in existing unlearning methods for LLMs, strongly advocating for more comprehensive and robust strategies to ensure authentic unlearning without compromising model utility. Our code is available at: https://github.com/zzwjames/FailureLLMUnlearning.
  abstract_embedding: [0.002288818359375, 0.384765625, 0.07177734375]... (1536 items)
  authors: ['Zhiwei Zhang', 'Fali Wang', 'Xiaomin Li']... (9 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652578323
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Catastrophic_Failure_of_LLM_Unlearning_via_Quantization.pdf
  sha_abstract: cef2ec87387938a378ab6f08693d2738d388bd163ee30158da99b2e2e79151b2
  title: Catastrophic Failure of LLM Unlearning via Quantization
  title_normalized: catastrophic_failure_of_llm_unlearning_via_quantization

================================================================================
Document #271 (ID: quhHZpoBclM7MZc33JNe)
================================================================================
  abstract: Kolmogorov–Arnold Network (KAN) is a network structure recently proposed in Liu et al. (2024) that offers improved interpretability and a more parsimonious design in many science-oriented tasks compared to multi-layer perceptrons. This work provides a rigorous theoretical analysis of KAN by establishing generalization bounds for KAN equipped with activation functions that are either represented by linear combinations of basis functions or lying in a low-rank Reproducing Kernel Hilbert Space (RKHS). In the first case, the generalization bound accommodates various choices of basis functions in forming the activation functions in each layer of KAN and is adapted to different operator norms at each layer. For a particular choice of operator norms, the bound scales with the $l_1$ norm of the coefficient matrices and the Lipschitz constants for the activation functions, and it has no dependence on combinatorial parameters (e.g., number of nodes) outside of logarithmic factors. Moreover, our result does not require the boundedness assumption on the loss function and, hence, is applicable to a general class of regression-type loss functions. In the low-rank case, the generalization bound scales polynomially with the underlying ranks as well as the Lipschitz constants of the activation functions in each layer. These bounds are empirically investigated for KANs trained with stochastic gradient descent on simulated and real data sets. The numerical results demonstrate the practical relevance of these bounds.
  abstract_embedding: [0.5234375, 0.388671875, -0.07958984375]... (1536 items)
  authors: ['Xianyang Zhang', 'Huijuan Zhou']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652576822
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Generalization_Bounds_and_Model_Complexity_for_Kolmogorov_Arnold_Networks.pdf
  sha_abstract: ddd2193cd2e8c068e81925a495968f2555640ffb45213705617fdd6b46d2397b
  title: Generalization Bounds and Model Complexity for Kolmogorov–Arnold Networks
  title_normalized: generalization_bounds_and_model_complexity_for_kolmogorovarnold_networks

================================================================================
Document #272 (ID: rOhHZpoBclM7MZc34JNI)
================================================================================
  abstract: LLM-as-a-Judge has been widely utilized as an evaluation method in various benchmarks and served as supervised rewards in model training. However, despite their excellence in many domains, potential issues are under-explored, undermining their reliability and the scope of their utility. 
Therefore, we identify 12 key potential biases and propose a new automated bias quantification framework—CALM—which systematically quantifies and analyzes each type of bias in LLM-as-a-Judge by using automated and principle-guided modification. Our experiments cover multiple popular language models, and the results indicate that while advanced models have achieved commendable overall performance, significant biases persist in certain specific tasks. Empirical results suggest that there remains room for improvement in the reliability of LLM-as-a-Judge. Moreover, we also discuss the explicit and implicit influence of these biases and give some suggestions for the reliable application of LLM-as-a-Judge. Our work highlights the need for stakeholders to address these issues and remind users to exercise caution in LLM-as-a-Judge applications.
  abstract_embedding: [0.419921875, 0.35546875, -0.1328125]... (1536 items)
  authors: ['Jiayi Ye', 'Yanbo Wang', 'Yue Huang']... (12 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652577848
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Justice_or_Prejudice__Quantifying_Biases_in_LLM-as-a-Judge.pdf
  sha_abstract: c58b0fd32d0341e94bcf2aaf16c83d548001c6eab0b6483865245fa1db63af99
  title: Justice or Prejudice? Quantifying Biases in LLM-as-a-Judge
  title_normalized: justice_or_prejudice_quantifying_biases_in_llmasajudge

================================================================================
Document #273 (ID: sOhHZpoBclM7MZc345PF)
================================================================================
  abstract: We present Perm, a learned parametric representation of human 3D hair designed to facilitate various hair-related applications. Unlike previous work that jointly models the global hair structure and local curl patterns, we propose to disentangle them using a PCA-based strand representation in the frequency domain, thereby allowing more precise editing and output control. Specifically, we leverage our strand representation to fit and decompose hair geometry textures into low- to high-frequency hair structures, termed guide textures and residual textures, respectively. These decomposed textures are later parameterized with different generative models, emulating common stages in the hair grooming process. We conduct extensive experiments to validate the architecture design of Perm, and finally deploy the trained model as a generic prior to solve task-agnostic problems, further showcasing its flexibility and superiority in tasks such as single-view hair reconstruction, hairstyle editing, and hair-conditioned image generation. More details can be found on our project page: https://cs.yale.edu/homes/che/projects/perm/.
  abstract_embedding: [-0.2216796875, 0.396484375, -0.11962890625]... (1536 items)
  authors: ['Chengan He', 'Xin Sun', 'Zhixin Shu']... (11 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652578751
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Perm__A_Parametric_Representation_for_Multi-Style_3D_Hair_Modeling.pdf
  sha_abstract: 0cdc1ebf940c6aaad554454dd8e3a9d2d1d50dfa31410b3d3fad4abb2de5bfce
  title: Perm: A Parametric Representation for Multi-Style 3D Hair Modeling
  title_normalized: perm_a_parametric_representation_for_multistyle_3d_hair_modeling

================================================================================
Document #274 (ID: qehHZpoBclM7MZc325Oc)
================================================================================
  abstract: Image tokenizers are crucial for visual generative models, \eg, diffusion models (DMs) and autoregressive (AR) models, as they construct the latent representation for modeling. Increasing token length is a common approach to improve image reconstruction quality. However, tokenizers with longer token lengths are not guaranteed to achieve better generation quality. There exists a trade-off between reconstruction and generation quality regarding token length. In this paper, we investigate the impact of token length on both image reconstruction and generation and provide a flexible solution to the tradeoff. We propose \textbf{ImageFolder}, a semantic tokenizer that provides spatially aligned image tokens that can be folded during autoregressive modeling to improve both efficiency and quality. To enhance the representative capability without increasing token length, we leverage dual-branch product quantization to capture different contexts of images. Specifically, semantic regularization is introduced in one branch to encourage compacted semantic information while another branch is designed to capture pixel-level details. Extensive experiments demonstrate the superior quality of image generation and shorter token length with ImageFolder tokenizer.
  abstract_embedding: [0.0230712890625, 0.2490234375, 0.20703125]... (1536 items)
  authors: ['Xiang Li', 'Kai Qiu', 'Hao Chen']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652576629
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ImageFolder__Autoregressive_Image_Generation_with_Folded_Tokens.pdf
  sha_abstract: 52f7ec61b5d45de995fbd284e4ebb7b828161d5190ed96ac16e5a08760ec133e
  title: ImageFolder: Autoregressive Image Generation with Folded Tokens
  title_normalized: imagefolder_autoregressive_image_generation_with_folded_tokens

================================================================================
Document #275 (ID: r-hHZpoBclM7MZc34pP5)
================================================================================
  abstract: Scene image editing is crucial for entertainment, photography, and advertising design. Existing methods solely focus on either 2D individual object or 3D global scene editing. This results in a lack of a unified approach to effectively control and manipulate scenes at the 3D level with different levels of granularity. In this work, we propose 3DitScene, a novel and unified scene editing framework leveraging language-guided disentangled Gaussian Splatting that enables seamless editing from 2D to 3D, allowing precise control over scene composition and individual objects. We first incorporate 3D Gaussians that are refined through generative priors and optimization techniques. Language features from CLIP then introduce semantics into 3D geometry for object disentanglement. With the disentangled Gaussians, 3DitScene allows for manipulation at both the global and individual levels, revolutionizing creative expression and empowering control over scenes and objects. Experimental results demonstrate the effectiveness and versatility of 3DitScene in scene image editing.
  abstract_embedding: [0.431640625, 0.1396484375, -0.138671875]... (1536 items)
  authors: ['Qihang Zhang', 'Yinghao Xu', 'Chaoyang Wang']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652578545
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: 3DitScene__Editing_Any_Scene_via_Language-guided_Disentangled_Gaussian_Splatting.pdf
  sha_abstract: 134685b4b3e7dbda50fd264b128d48d3868a6b45a8334f056f968a1a32d1ad2b
  title: 3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting
  title_normalized: 3ditscene_editing_any_scene_via_languageguided_disentangled_gaussian_splatting

================================================================================
Document #276 (ID: q-hHZpoBclM7MZc33ZMa)
================================================================================
  abstract: We study a class of decision-making problems with one-sided feedback, where outcomes are only observable for specific actions. A typical example is bank loans, where the repayment status is known only if a loan is approved and remains undefined if rejected. In such scenarios, conventional approaches to causal decision evaluation and learning from observational data are not directly applicable. In this paper, we introduce a novel value function to evaluate decision rules that addresses the issue of undefined counterfactual outcomes. Without assuming no unmeasured confounders, we establish the identification of the value function using shadow variables. Furthermore, leveraging semiparametric theory, we derive the efficiency bound for the proposed value function and develop efficient methods for decision evaluation and learning. Numerical experiments and a real-world data application demonstrate the empirical performance of our proposed methods.
  abstract_embedding: [0.77734375, 0.2197265625, -0.000621795654296875]... (1536 items)
  authors: ['Jianing Chu', 'Shu Yang', 'Wenbin Lu']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652577043
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Efficient_Causal_Decision_Making_with_One-sided_Feedback.pdf
  sha_abstract: 0e405da664001cd9c23883774b629bf8f4cf0e97eb32670c64dd5ecbf465e7dc
  title: Efficient Causal Decision Making with One-sided Feedback
  title_normalized: efficient_causal_decision_making_with_onesided_feedback

================================================================================
Document #277 (ID: sehHZpoBclM7MZc35ZN0)
================================================================================
  abstract: Human motion generation is a critical task with a wide spectrum of applications. Achieving high realism in generated motions requires naturalness, smoothness, and plausibility. However, current evaluation metrics often rely on simple heuristics or distribution distances and do not align well with human perceptions. In this work, we propose a data-driven approach to bridge this gap by introducing a large-scale human perceptual evaluation dataset, MotionPercept, and a human motion critic model, MotionCritic, that capture human perceptual preferences. Our critic model offers a more accurate metric for assessing motion quality and could be readily integrated into the motion generation pipeline to enhance generation quality. Extensive experiments demonstrate the effectiveness of our approach in both evaluating and improving the quality of generated human motions by aligning with human perceptions. Code and data are publicly available at https://motioncritic.github.io/.
  abstract_embedding: [0.1591796875, 0.578125, 0.3359375]... (1536 items)
  authors: ['Haoru Wang', 'Wentao Zhu', 'Luyi Miao']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652579003
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Aligning_Human_Motion_Generation_with_Human_Perceptions.pdf
  sha_abstract: 682aa0887a68dc7c941fccc84c79b4eb0d0599655a55f6abb2be18c81f98d151
  title: Aligning Human Motion Generation with Human Perceptions
  title_normalized: aligning_human_motion_generation_with_human_perceptions

================================================================================
Document #278 (ID: uOhHZpoBclM7MZc38JM3)
================================================================================
  abstract: The ability to reconstruct realistic and controllable upper body avatars from casual monocular videos is critical for various applications in communication and entertainment. By equipping the most recent 3D Gaussian Splatting representation with head 3D morphable models (3DMM), existing methods manage to create head avatars with high fidelity. However, most existing methods only reconstruct a head without the body, substantially limiting their application scenarios. We found that naively applying Gaussians to model the clothed chest and shoulders tends to result in blurry reconstruction and noisy floaters under novel poses. This is because of the fundamental limitation of Gaussians and point clouds -- each Gaussian or point can only have a single directional radiance without spatial variance, therefore an unnecessarily large number of them is required to represent complicated spatially varying texture, even for simple geometry. In contrast, we propose to model the body part with a neural texture that consists of coarse and pose-dependent fine colors. To properly render the body texture for each view and pose without accurate geometry nor UV mapping, we optimize another sparse set of Gaussians as anchors that constrain the neural warping field that maps image plane coordinates to the texture space. We demonstrate that Gaussian Head & Shoulders can fit the high-frequency details on the clothed upper body with high fidelity and potentially improve the accuracy and fidelity of the head region. We evaluate our method with casual phone-captured and internet videos and show our method archives superior reconstruction quality and robustness in both self and cross reenactment tasks. To fully utilize the efficient rendering speed of Gaussian splatting, we additionally propose an accelerated inference method of our trained model without Multi-Layer Perceptron (MLP) queries and reach a stable rendering speed of around 130 FPS for any subjects.
  abstract_embedding: [-0.037109375, 0.13671875, 0.298828125]... (1536 items)
  authors: ['Tianhao Walter Wu', 'Jing Yang', 'Zhilin Guo']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652581905
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Gaussian_Head___Shoulders__High_Fidelity_Neural_Upper_Body_Avatars_with_Anchor_Gaussian_Guided_Texture_Warping.pdf
  sha_abstract: fca6c082b612b2124472f1798c3b22f2c344bc23e578cbc8aa5d69ff60a67aa5
  title: Gaussian Head & Shoulders: High Fidelity Neural Upper Body Avatars with Anchor Gaussian Guided Texture Warping
  title_normalized: gaussian_head__shoulders_high_fidelity_neural_upper_body_avatars_with_anchor_gaussian_guided_texture_warping

================================================================================
Document #279 (ID: tOhHZpoBclM7MZc365N1)
================================================================================
  abstract: Large Language Models (LLMs) such as GPT-4 and Llama3 have significantly impacted various fields by enabling high-quality synthetic data generation and reducing dependence on expensive human-generated datasets. 
Despite this, challenges remain in the areas of generalization, controllability, diversity, and truthfulness within the existing generative frameworks. To address these challenges, this paper presents DataGen, a comprehensive LLM-powered framework designed to produce diverse, accurate, and highly controllable datasets. DataGen is adaptable, supporting all types of text datasets and enhancing the generative process through innovative mechanisms. To augment data diversity, DataGen incorporates an attribute-guided generation module and a group checking feature. For accuracy, it employs a code-based mathematical assessment for label verification alongside a retrieval-augmented generation technique for factual validation. The framework also allows for user-specified constraints, enabling customization of the data generation process to suit particular requirements. Extensive experiments demonstrate the superior quality of data generated by DataGen, and each module within DataGen plays a critical role in this enhancement. Additionally, DataGen is applied in two practical scenarios: benchmarking LLMs and data augmentation. The results indicate that DataGen effectively supports dynamic and evolving benchmarking and that data augmentation improves LLM capabilities in various domains, including agent-oriented abilities and reasoning skills.
  abstract_embedding: [0.2392578125, 0.19921875, 0.044921875]... (1536 items)
  authors: ['Yue Huang', 'Siyuan Wu', 'Chujie Gao']... (11 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652580717
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: DataGen__Unified_Synthetic_Dataset_Generation_via_Large_Language_Models.pdf
  sha_abstract: addbee4fbff7d109f759d0aac76c57ea27aa15cebc5f4d21a04f4bd9077d8f08
  title: DataGen: Unified Synthetic Dataset Generation via Large Language Models
  title_normalized: datagen_unified_synthetic_dataset_generation_via_large_language_models

================================================================================
Document #280 (ID: tehHZpoBclM7MZc37JNW)
================================================================================
  abstract: Transporting between arbitrary distributions is a fundamental goal in generative modeling.
Recently proposed diffusion bridge models provide a potential solution, but they rely on a joint distribution that is difficult to obtain in practice.
Furthermore, formulations based on continuous domains limit their applicability to discrete domains such as graphs.
To overcome these limitations, we propose Discrete Diffusion Schrödinger Bridge Matching (DDSBM), a novel framework that utilizes continuous-time Markov chains to solve the SB problem in a high-dimensional discrete state space.
Our approach extends Iterative Markovian Fitting to discrete domains, and we have proved its convergence to the SB.
Furthermore, we adapt our framework for the graph transformation, and show that our design choice of underlying dynamics characterized by independent modifications of nodes and edges can be interpreted as the entropy-regularized version of optimal transport with a cost function described by the graph edit distance.
To demonstrate the effectiveness of our framework, we have applied DDSBM to molecular optimization in the field of chemistry.
Experimental results demonstrate that DDSBM effectively optimizes molecules' property-of-interest with minimal graph transformation, successfully retaining other features. Source code is available [here](https://github.com/junhkim1226/DDSBM).
  abstract_embedding: [0.54296875, 0.2734375, 0.11279296875]... (1536 items)
  authors: ['Jun Hyeong Kim', 'Seonghwan Kim', 'Seokhyun Moon']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652580930
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Discrete_Diffusion_Schrödinger_Bridge_Matching_for_Graph_Transformation.pdf
  sha_abstract: 513e05c08c214eafb6a0a0b46258abe666723953af01e142fa93850c3a6ecccb
  title: Discrete Diffusion Schrödinger Bridge Matching for Graph Transformation
  title_normalized: discrete_diffusion_schrödinger_bridge_matching_for_graph_transformation

================================================================================
Document #281 (ID: uehHZpoBclM7MZc38ZNf)
================================================================================
  abstract: Electrocardiogram (ECG) is essential for the clinical diagnosis of arrhythmias and other heart diseases, but deep learning methods based on ECG often face limitations due to the need for high-quality annotations. Although previous ECG self-supervised learning (eSSL) methods have made significant progress in representation learning from unannotated ECG data, they typically treat ECG signals as ordinary time-series data, segmenting the signals using fixed-size and fixed-step time windows, which often ignore the form and rhythm characteristics and latent semantic relationships in ECG signals. In this work, we introduce a novel perspective on ECG signals, treating heartbeats as words and rhythms as sentences. Based on this perspective, we first designed the QRS-Tokenizer, which generates semantically meaningful ECG sentences from the raw ECG signals. Building on these, we then propose HeartLang, a novel self-supervised learning framework for ECG language processing, learning general representations at form and rhythm levels. Additionally, we construct the largest heartbeat-based ECG vocabulary to date, which will further advance the development of ECG language processing. We evaluated HeartLang across six public ECG datasets, where it demonstrated robust competitiveness against other eSSL methods. Our data and code are publicly available at https://github.com/PKUDigitalHealth/HeartLang.
  abstract_embedding: [-0.058349609375, 0.455078125, 0.380859375]... (1536 items)
  authors: ['Jiarui Jin', 'Haoyu Wang', 'Hongyan Li']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652582196
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Reading_Your_Heart__Learning_ECG_Words_and_Sentences_via_Pre-training_ECG_Language_Model.pdf
  sha_abstract: f528ca055a2db662893826494627b8054b7d8bab3086ddcf4d2f1ea5f51ad7b2
  title: Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG Language Model
  title_normalized: reading_your_heart_learning_ecg_words_and_sentences_via_pretraining_ecg_language_model

================================================================================
Document #282 (ID: t-hHZpoBclM7MZc37pMO)
================================================================================
  abstract: Training Large Language Models (LLMs) presents a significant communication bottleneck, predominantly due to the growing scale of the gradient to communicate across multi-device clusters. However, how to mitigate communication overhead in practice remains a formidable challenge due to the weakness of the methodology of the existing compression methods, especially the neglect of the characteristics of the gradient. In this paper, we consider and demonstrate the low-rank properties of gradient and Hessian observed in LLMs training dynamic, and take advantage of such natural properties to design SEPARATE, a simple low-rank projection for gradient compression in modern large-scale model training processes. SEPARATE realizes dimensional reduction by common random Gaussian variables and an improved moving average error-feedback technique. We theoretically demonstrate that SEPARATE-based optimizers maintain the original convergence rate for SGD and Adam-Type optimizers for general non-convex objectives. Experimental results show that SEPARATE accelerates training speed by up to 2× for GPT-2-Medium pre-training, and improves performance on various benchmarks for LLAMA2-7B fine-tuning.
  abstract_embedding: [0.53515625, -0.021728515625, 0.46875]... (1536 items)
  authors: ['Hanzhen Zhao', 'Xingyu Xie', 'Cong Fang']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652581359
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SEPARATE__A_Simple_Low-rank_Projection_for_Gradient_Compression_in_Modern_Large-scale_Model_Training_Process.pdf
  sha_abstract: 9c623cc84ba079ff04f49d648e40456fc65b7a9e8672541697d04b921b6fc25e
  title: SEPARATE: A Simple Low-rank Projection for Gradient Compression in Modern Large-scale Model Training Process
  title_normalized: separate_a_simple_lowrank_projection_for_gradient_compression_in_modern_largescale_model_training_process

================================================================================
Document #283 (ID: suhHZpoBclM7MZc36JPm)
================================================================================
  abstract: Modeling human-like action-to-reaction generation has significant real-world applications, like human-robot interaction and games.
Despite recent advancements in single-person motion generation, it is still challenging to well handle action-to-reaction generation, due to the difficulty of directly predicting reaction from action sequence without prompts, and the absence of a unified representation that effectively encodes multi-person motion.
To address these challenges, we introduce Think-Then-React (TTR), a large language-model-based framework designed to generate human-like reactions.
First, with our fine-grained multimodal training strategy, TTR is capable to unify two processes during inference: a thinking process that explicitly infers action intentions and reasons corresponding reaction description, which serve as semantic prompts, and a reacting process that predicts reactions based on input action and the inferred semantic prompts.
Second, to effectively represent multi-person motion in language models, we propose a unified motion tokenizer by decoupling egocentric pose and absolute space features, which effectively represents action and reaction motion with same encoding.
Extensive experiments demonstrate that TTR outperforms existing baselines, achieving significant improvements in evaluation metrics, such as reducing FID from 3.988 to 1.942.
  abstract_embedding: [0.373046875, 0.41796875, 0.51171875]... (1536 items)
  authors: ['Wenhui Tan', 'Boyuan Li', 'Chuhao Jin']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652580041
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Think_Then_React__Towards_Unconstrained_Action-to-Reaction_Motion_Generation.pdf
  sha_abstract: 7577f40e4d5f3806a6a4ff20610283795fd76729ff41f27cd6cc460191bf054d
  title: Think Then React: Towards Unconstrained Action-to-Reaction Motion Generation
  title_normalized: think_then_react_towards_unconstrained_actiontoreaction_motion_generation

================================================================================
Document #284 (ID: s-hHZpoBclM7MZc36ZPn)
================================================================================
  abstract: Low-rank adaptation, also known as LoRA, has emerged as a prominent method for parameter-efficient fine-tuning of foundation models.
Despite its computational efficiency, LoRA still yields inferior performance compared to full fine-tuning.
In this paper, we first uncover a fundamental connection between the optimization processes of LoRA and full fine-tuning: using LoRA for optimization is mathematically equivalent to full fine-tuning using a low-rank gradient for parameter updates.
And this low-rank gradient can be expressed in terms of the gradients of the two low-rank matrices in LoRA.
Leveraging this insight, we introduce LoRA-Pro, a method that enhances LoRA's performance by strategically adjusting the gradients of these low-rank matrices.
This adjustment allows the low-rank gradient to more accurately approximate the full fine-tuning gradient, thereby narrowing the performance gap between LoRA and full fine-tuning.
Furthermore, we theoretically derive the optimal solutions for adjusting the gradients of the low-rank matrices, applying them during fine-tuning in LoRA-Pro.
We conduct extensive experiments across natural language understanding, dialogue generation, mathematical reasoning, code generation, and image classification tasks, demonstrating that LoRA-Pro substantially improves LoRA's performance, effectively narrowing the gap with full fine-tuning.
Our code is publicly available at https://github.com/mrflogs/LoRA-Pro.
  abstract_embedding: [0.4609375, 0.10205078125, 0.21875]... (1536 items)
  authors: ['Zhengbo Wang', 'Jian Liang', 'Ran He']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652580263
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: LoRA-Pro__Are_Low-Rank_Adapters_Properly_Optimized_.pdf
  sha_abstract: d35e853e4eca260ec3d226c2515e488b8b62ab16a1ca826057dbfef31e2ae8e7
  title: LoRA-Pro: Are Low-Rank Adapters Properly Optimized?
  title_normalized: lorapro_are_lowrank_adapters_properly_optimized

================================================================================
Document #285 (ID: uuhHZpoBclM7MZc385Nu)
================================================================================
  abstract: Crowd counting and localization involve extracting the number and distribution of crowds from images or videos using computer vision techniques. Most counting methods are based on density regression and are based on an ``intersection'' hypothesis, *i.e.*, one pixel is influenced by multiple points in the ground truth, which is inconsistent with reality since one pixel would not contain two objects. This paper proposes Proximal Mapping Loss (PML), a density regression method that eliminates this hypothesis. {PML} divides the predicted density map into multiple point-neighbor cases through the nearest neighbor, and then dynamically constructs a learning target for each sub-case via proximal mapping, leading to more robust and accurate training. {Furthermore}, PML is theoretically linked to various existing loss functions, such as Gaussian-blurred L2 loss, Bayesian loss, and the training schemes in P2PNet and DMC, demonstrating its versatility and adaptability. Experimentally, PML significantly improves the performance of crowd counting and localization, and illustrates the robustness against annotation noise. The code is available at [https://github.com/Elin24/pml](https://github.com/Elin24/pml).
  abstract_embedding: [-0.326171875, 0.2578125, 0.35546875]... (1536 items)
  authors: ['Wei Lin', 'Jia Wan', 'Antoni B. Chan']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652582727
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Proximal_Mapping_Loss__Understanding_Loss_Functions_in_Crowd_Counting___Localization.pdf
  sha_abstract: 0864c730631025a088c232150950a6c1170cb7fc76fcb4d37ee8de69a7349cb9
  title: Proximal Mapping Loss: Understanding Loss Functions in Crowd Counting & Localization
  title_normalized: proximal_mapping_loss_understanding_loss_functions_in_crowd_counting__localization

================================================================================
Document #286 (ID: tuhHZpoBclM7MZc37ZMZ)
================================================================================
  abstract: Risk-sensitive reinforcement learning (RL) with an entropic risk measure typically requires knowledge of the transition kernel or performs unstable updates w.r.t. exponential Bellman equations. As a consequence, algorithms that optimize this objective have been restricted to tabular or low-dimensional continuous environments. In this work we leverage the connection between the entropic risk measure and the RL-as-inference framework to develop a risk-sensitive variational actor-critic algorithm (rsVAC). Our work extends the variational framework to incorporate stochastic rewards and proposes a variational model-based actor-critic approach that modulates policy risk via a risk parameter.  We consider, both, the risk-seeking and risk-averse regimes and present rsVAC learning variants for each setting.  Our experiments demonstrate that this approach produces risk-sensitive policies and yields improvements in both tabular and risk-aware variants of complex continuous control tasks in MuJoCo.
  abstract_embedding: [0.6875, 0.10595703125, 0.0216064453125]... (1536 items)
  authors: ['Alonso Granados', 'Reza Ebrahimi', 'Jason Pacheco']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652581137
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Risk-Sensitive_Variational_Actor-Critic__A_Model-Based_Approach.pdf
  sha_abstract: 32d217e2b5dfa544021888351a3808f56b8bcce646100cc102d1c0b224ea335f
  title: Risk-Sensitive Variational Actor-Critic: A Model-Based Approach
  title_normalized: risksensitive_variational_actorcritic_a_modelbased_approach

================================================================================
Document #287 (ID: vOhHZpoBclM7MZc39ZN7)
================================================================================
  abstract: Recently, Multimodal Large Language Models (MLLMs) have been used as agents to control keyboard and mouse inputs by directly perceiving the Graphical User Interface (GUI) and generating corresponding commands.
However, current agents primarily demonstrate strong understanding capabilities in static environments and are mainly applied to relatively simple domains, such as Web or mobile interfaces.
We argue that a robust GUI agent should be capable of perceiving temporal information on the GUI, including dynamic Web content and multi-step tasks.
Additionally, it should possess a comprehensive understanding of various GUI scenarios, including desktop software and multi-window interactions.
To this end, this paper introduces a new dataset, termed GUI-World, which features meticulously crafted Human-MLLM annotations, extensively covering six GUI scenarios and eight types of GUI-oriented questions in three formats.
We evaluate the capabilities of current state-of-the-art MLLMs, including Image LLMs and Video LLMs, in understanding various types of GUI content, especially dynamic and sequential content. Our findings reveal that current models struggle with dynamic GUI content without manually annotated keyframes or operation history. On the other hand, Video LLMs fall short in all GUI-oriented tasks given the sparse GUI video dataset. Therefore, we take the initial step of leveraging a fine-tuned Video LLM, GUI-Vid, as a GUI-oriented assistant, demonstrating an improved understanding of various GUI tasks. However, due to the limitations in the performance of base LLMs, we conclude that using video LLMs as GUI agents remains a significant challenge. We believe our work provides valuable insights for future research in dynamic GUI content understanding. All the dataset and code are publicly available at: https://gui-world.github.io.
  abstract_embedding: [0.251953125, -0.1640625, 0.322265625]... (1536 items)
  authors: ['Dongping Chen', 'Yue Huang', 'Siyuan Wu']... (20 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652583268
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: GUI-World__A_Video_Benchmark_and_Dataset_for_Multimodal_GUI-oriented_Understanding.pdf
  sha_abstract: 4953ea8f30417e55cd0167435f84da452b1dd385042dba0ee5808eefe7abcd00
  title: GUI-World: A Video Benchmark and Dataset for Multimodal GUI-oriented Understanding
  title_normalized: guiworld_a_video_benchmark_and_dataset_for_multimodal_guioriented_understanding

================================================================================
Document #288 (ID: w-hIZpoBclM7MZc3AZMe)
================================================================================
  abstract: Model extraction aims to acquire a pre-trained black-box model concealed behind a black-box API. 
Existing defense strategies against model extraction primarily concentrate on preventing the unauthorized extraction of API functionality. However, two significant challenges still need to be solved: (i) Neural network architecture of the API constitutes a form of intellectual property that also requires protection; (ii) The current practice of allocating the same network architecture to both attack and benign queries results in substantial resource wastage. To address these challenges, we propose a novel \textit{Dynamic Neural Fortresses} (DNF) defense method, employing a dynamic Early-Exit neural network, deviating from the conventional fixed architecture. Firstly, we facilitate the random exit of attack queries from the network at earlier layers. This strategic exit point selection significantly reduces the computational cost for attack queries. Furthermore, the random exit of attack queries from earlier layers introduces increased uncertainty for attackers attempting to discern the exact architecture, thereby enhancing architectural protection. On the contrary, we aim to facilitate benign queries to exit at later layers, preserving model utility, as these layers typically yield meaningful information. 
Extensive experiments on defending against various model extraction scenarios and datasets demonstrate the effectiveness of DNF, achieving a notable 2$\times$ improvement in efficiency and an impressive reduction of up to 12\% in clone model accuracy compared to SOTA defense methods. Additionally, DNF provides strong protection against neural architecture theft, effectively safeguarding network architecture from being stolen.
  abstract_embedding: [0.47265625, 0.5859375, 0.75390625]... (1536 items)
  authors: ['Siyu Luan', 'Zhenyi Wang', 'Li Shen']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652586221
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Dynamic_Neural_Fortresses__An_Adaptive_Shield_for_Model_Extraction_Defense.pdf
  sha_abstract: 416ecf6c671a790ff7c092459402c3c4e821c7fefed3c6ee4f7bfaddea6227b2
  title: Dynamic Neural Fortresses: An Adaptive Shield for Model Extraction Defense
  title_normalized: dynamic_neural_fortresses_an_adaptive_shield_for_model_extraction_defense

================================================================================
Document #289 (ID: wOhHZpoBclM7MZc3-ZN9)
================================================================================
  abstract: Self-supervision has the potential to transform reinforcement learning (RL), paralleling the breakthroughs it has enabled in other areas of machine learning. While self-supervised learning in other domains aims to find patterns in a fixed dataset, self-supervised goal-conditioned reinforcement learning (GCRL) agents discover *new* behaviors by learning from the goals achieved during unstructured interaction with the environment. However, these methods have failed to see similar success, both due to a lack of data from slow environment simulations as well as a lack of stable algorithms. We take a step toward addressing both of these issues by releasing a high-performance codebase and benchmark (`JaxGCRL`) for self-supervised GCRL, enabling researchers to train agents for millions of environment steps in minutes on a single GPU. By utilizing GPU-accelerated replay buffers, environments, and a stable contrastive RL algorithm, we reduce training time by up to $22\times$. Additionally, we assess key design choices in contrastive RL, identifying those that most effectively stabilize and enhance training performance. With this approach, we provide a foundation for future research in self-supervised GCRL, enabling researchers to quickly iterate on new ideas and evaluate them in diverse and challenging environments. Code: [https://anonymous.4open.science/r/JaxGCRL-2316/README.md](https://anonymous.4open.science/r/JaxGCRL-2316/README.md)
  abstract_embedding: [0.67578125, 0.32421875, 0.033203125]... (1536 items)
  authors: ['Michał Bortkiewicz', 'Władysław Pałucki', 'Vivek Myers']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652584303
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Accelerating_Goal-Conditioned_Reinforcement_Learning_Algorithms_and_Research.pdf
  sha_abstract: 66c57f2f9b4dcd87217625cf8a924b87b9a23c2a74a334d4f701f085b431c22b
  title: Accelerating Goal-Conditioned Reinforcement Learning Algorithms and Research
  title_normalized: accelerating_goalconditioned_reinforcement_learning_algorithms_and_research

================================================================================
Document #290 (ID: vehHZpoBclM7MZc39pOS)
================================================================================
  abstract: Diffusion-based video generation technology has advanced significantly, catalyzing a proliferation of research in human animation. While breakthroughs have been made in driving human animation through various modalities for portraits, most of current solutions for human body animation still focus on video-driven methods, leaving audio-driven taking body generation relatively underexplored. In this paper, we introduce CyberHost, a one-stage audio-driven talking body generation framework that addresses common synthesis degradations in half-body animation, including hand integrity, identity consistency, and natural motion.
CyberHost's key designs are twofold. Firstly, the Region Attention Module (RAM) maintains a set of learnable, implicit, identity-agnostic latent features and combines them with identity-specific local visual features to enhance the synthesis of critical local regions. Secondly, the Human-Prior-Guided Conditions introduce more human structural priors into the model, reducing uncertainty in generated motion patterns and thereby improving the stability of the generated videos.
To our knowledge, CyberHost is the first one-stage audio-driven human diffusion model capable of zero-shot video generation for the human body. Extensive experiments demonstrate that CyberHost surpasses previous works in both quantitative and qualitative aspects. CyberHost can also be extended to video-driven and audio-video hybrid-driven scenarios, achieving similarly satisfactory results.
  abstract_embedding: [0.365234375, 0.3984375, 0.1376953125]... (1536 items)
  authors: ['Gaojie Lin', 'Jianwen Jiang', 'Chao Liang']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652583503
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CyberHost__A_One-stage_Diffusion_Framework_for_Audio-driven_Talking_Body_Generation.pdf
  sha_abstract: 4af083e52131672039a52aebd1b1f2067ba6d068e414cd421968a1cf716c46d1
  title: CyberHost: A One-stage Diffusion Framework for Audio-driven Talking Body Generation
  title_normalized: cyberhost_a_onestage_diffusion_framework_for_audiodriven_talking_body_generation

================================================================================
Document #291 (ID: wuhHZpoBclM7MZc3_pPy)
================================================================================
  abstract: Large language models (LLMs) have transformed natural language processing, with frameworks like Chatbot Arena providing pioneering platforms for evaluating these models. By facilitating millions of pairwise comparisons based on human judgments, Chatbot Arena has become a cornerstone in LLM evaluation, offering rich datasets for ranking models in open-ended conversational tasks. Building upon this foundation, we propose a statistical framework that incorporates key advancements to address specific challenges in pairwise comparison analysis. First, we introduce a factored tie model that enhances the ability to handle ties—an integral aspect of human-judged comparisons—significantly improving the model's fit to observed data. Second, we extend the framework to model covariance between competitors, enabling deeper insights into performance relationships and facilitating intuitive groupings into performance tiers. Third, we resolve optimization challenges arising from parameter non-uniqueness by introducing novel constraints, ensuring stable and interpretable parameter estimation. Through rigorous evaluation and extensive experimentation, our framework demonstrates substantial improvements over existing methods in modeling pairwise comparison data. To support reproducibility and practical adoption, we release leaderbot, an open-source Python package implementing our models and analyses.
  abstract_embedding: [0.34765625, 0.30078125, -0.06689453125]... (1536 items)
  authors: ['Siavash Ameli', 'Siyuan Zhuang', 'Ion Stoica']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652585703
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: A_Statistical_Framework_for_Ranking_LLM-based_Chatbots.pdf
  sha_abstract: 2113c09c3cc5d2e362724c442f349e39d8d8326c9c63fa7d58b443a48d7bfb6e
  title: A Statistical Framework for Ranking LLM-based Chatbots
  title_normalized: a_statistical_framework_for_ranking_llmbased_chatbots

================================================================================
Document #292 (ID: u-hHZpoBclM7MZc39JOA)
================================================================================
  abstract: Building a generalist model for user interface (UI) understanding is challenging due to various foundational issues, such as platform diversity, resolution variation, and data limitation. In this paper, we introduce Ferret-UI 2, a multimodal large language model (MLLM) designed for universal UI understanding across a wide range of platforms, including iPhone, Android, iPad, Webpage, and AppleTV. Building on the foundation of Ferret-UI, Ferret-UI 2 introduces three key innovations: support for multiple platform types, high-resolution perception through adaptive scaling, and advanced task training data generation powered by GPT-4o with set-of-mark visual prompting. These advancements enable Ferret-UI 2 to perform complex, user-centered interactions, making it highly versatile and adaptable for the expanding diversity of platform ecosystems. Extensive empirical experiments on referring, grounding, user-centric advanced tasks (comprising 9 subtasks $\times$ 5 platforms), GUIDE next-action prediction dataset, and GUI-World multi-platform benchmark demonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and also shows strong cross-platform transfer capabilities.
  abstract_embedding: [0.435546875, -0.28125, 0.248046875]... (1536 items)
  authors: ['Zhangheng LI', 'Keen You', 'Haotian Zhang']... (10 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652583023
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Ferret-UI_2__Mastering_Universal_User_Interface_Understanding_Across_Platforms.pdf
  sha_abstract: 299b7c631468e259ac9d25a1c4ebf507be57b7ee478c611d0a2597b588f6c4c8
  title: Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms
  title_normalized: ferretui_2_mastering_universal_user_interface_understanding_across_platforms

================================================================================
Document #293 (ID: vuhHZpoBclM7MZc395N6)
================================================================================
  abstract: Sampling algorithms play an important role in controlling the quality and runtime of diffusion model inference. In recent years, a number of works (Chen et al., 2023c;b; Benton et al., 2023; Lee et al., 2022) have analyzed algorithms for diffusion sampling with provable guarantees; these works show that for essentially any data distribution, one can approximately sample in polynomial time given a sufficiently accurate estimate of its score functions at different noise levels. 

In this work, we propose a new scheme inspired by Shen and Lee's randomized midpoint method for log-concave sampling  (Shen & Lee, 2019). We prove that this approach achieves the best known dimension dependence for sampling from arbitrary smooth distributions in total variation distance ($\widetilde O(d^{5/12})$ compared to $\widetilde O(\sqrt{d})$ from prior work). We also show that our algorithm can be parallelized to run in only $\widetilde O(\log^2 d)$ parallel rounds, constituting the first provable guarantees for parallel sampling with diffusion models.
    
As a byproduct of our methods, for the well-studied problem of log-concave sampling in total variation distance, we give an algorithm and simple analysis achieving dimension dependence $\widetilde O(d^{5/12})$ compared to $\widetilde O(\sqrt{d})$ from prior work.
  abstract_embedding: [0.10546875, 0.51171875, 0.38671875]... (1536 items)
  authors: ['Shivam Gupta', 'Linda Cai', 'Sitan Chen']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652583787
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Faster_Diffusion_Sampling_with_Randomized_Midpoints__Sequential_and_Parallel.pdf
  sha_abstract: 9b122cd657c9e89e19f50bef09c59f5b62735e5f59d424e18b17dabb8d577f1e
  title: Faster Diffusion Sampling with Randomized Midpoints: Sequential and Parallel
  title_normalized: faster_diffusion_sampling_with_randomized_midpoints_sequential_and_parallel

================================================================================
Document #294 (ID: v-hHZpoBclM7MZc3-JOh)
================================================================================
  abstract: Graph Neural Networks (GNNs) have achieved promising results in tasks such as node classification and graph classification. However, recent studies reveal that GNNs are vulnerable to backdoor attacks, posing a significant threat to their real-world adoption. Despite initial efforts to defend against specific graph backdoor attacks, there is no work on defending against various types of backdoor attacks where generated triggers have different properties. Hence, we first empirically verify that prediction variance under edge dropping is a crucial indicator for identifying poisoned nodes. With this observation, we propose using random edge dropping to detect backdoors and theoretically show that it can efficiently distinguish poisoned nodes from clean ones. Furthermore, we introduce a novel robust training strategy to efficiently counteract the impact of the triggers. Extensive experiments on real-world datasets show that our framework can effectively identify poisoned nodes, significantly degrade the attack success rate, and maintain clean accuracy when defending against various types of graph backdoor attacks with different properties. Our code is available at: https://github.com/zzwjames/RIGBD.
  abstract_embedding: [0.4609375, 1.0078125, 0.0235595703125]... (1536 items)
  authors: ['Zhiwei Zhang', 'Minhua Lin', 'Junjie Xu']... (6 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652584044
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Robustness_Inspired_Graph_Backdoor_Defense.pdf
  sha_abstract: 8d57e1290400b8ea90bce616de65071c6423a0bdb8fc0e6ec2c6df76c136d38c
  title: Robustness Inspired Graph Backdoor Defense
  title_normalized: robustness_inspired_graph_backdoor_defense

================================================================================
Document #295 (ID: wehHZpoBclM7MZc3-pNj)
================================================================================
  abstract: Self-supervised learning has the potential of lifting several of the key challenges in reinforcement learning today, such as exploration, representation learning, and reward design. Recent work (METRA) has effectively argued that moving away from mutual information and instead optimizing a certain Wasserstein distance is important for good performance. In this paper, we argue that the benefits seen in that paper can largely be explained within the existing framework of mutual information skill learning (MISL).
Our analysis suggests a new MISL method (contrastive successor features) that retains the excellent performance of METRA with fewer moving parts, and highlights connections between skill learning, contrastive representation learning, and successor features. Finally, through careful ablation studies, we provide further insight into some of the key ingredients for both our method and METRA.
  abstract_embedding: [0.291015625, -0.11669921875, -0.055419921875]... (1536 items)
  authors: ['Chongyi Zheng', 'Jens Tuyls', 'Joanne Peng']... (4 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652584506
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Can_a_MISL_Fly__Analysis_and_Ingredients_for_Mutual_Information_Skill_Learning.pdf
  sha_abstract: b2a861b1f2ced633a2e227ab80d96df133177dc809f8b88ee69729fdc2d8e2cb
  title: Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning
  title_normalized: can_a_misl_fly_analysis_and_ingredients_for_mutual_information_skill_learning

================================================================================
Document #296 (ID: xOhIZpoBclM7MZc3ApOw)
================================================================================
  abstract: Multi-armed bandits (MAB) are commonly used in sequential online decision-making when the reward of each decision is an unknown random variable. In practice however, the typical goal of maximizing total reward may be less important than minimizing the total cost of the decisions taken, subject to a reward constraint. For example, we may seek to make decisions that have at least the reward of a reference ``default'' decision, with as low a cost as possible. This problem was recently introduced in the Multi-Armed Bandits with Cost Subsidy (MAB-CS) framework. MAB-CS is broadly applicable to problem domains where a primary metric (cost) is constrained by a secondary metric (reward), and the rewards are unknown. In our work, we address variants of MAB-CS including ones with reward constrained by the reward of a known reference arm or by the subsidized best reward. We introduce the Pairwise-Elimination (PE) algorithm for the known reference arm variant and generalize PE to PE-CS for the subsidized best reward variant. Our instance-dependent analysis of PE and PE-CS reveals that both algorithms have an order-wise logarithmic upper bound on Cost and Quality Regret, making our policies the first with such a guarantee. Moreover, by comparing our upper and lower bound results we establish that PE is order-optimal for all known reference arm problem instances. Finally, experiments are conducted using the MovieLens 25M and Goodreads datasets for both PE and PE-CS revealing the effectiveness of PE and the superior balance between performance and reliability offered by PE-CS compared to baselines from the literature.
  abstract_embedding: [-0.208984375, 0.2001953125, 0.46484375]... (1536 items)
  authors: ['Ishank Juneja', 'Carlee Joe-Wong', 'Osman Yagan']
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652586657
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Pairwise_Elimination_with_Instance-Dependent_Guarantees_for_Bandits_with_Cost_Subsidy.pdf
  sha_abstract: 642258fe25843add8a041b70f72a8b06f143bd3b7b66f7274ce265b110ae7c5d
  title: Pairwise Elimination with Instance-Dependent Guarantees for Bandits with Cost Subsidy
  title_normalized: pairwise_elimination_with_instancedependent_guarantees_for_bandits_with_cost_subsidy

================================================================================
Document #297 (ID: y-hIZpoBclM7MZc3DZPF)
================================================================================
  abstract: Learned image compression (LIC) has demonstrated superior rate-distortion (R-D) performance compared to traditional codecs, but is challenged by training inefficiency that could incur more than two weeks to train a state-of-the-art model from scratch. Existing LIC methods overlook the slow convergence caused by compacting energy in learning nonlinear transforms. In this paper, we first reveal that such energy compaction consists of two components, \emph{i.e.}, feature decorrelation and uneven energy modulation. On such basis, we propose a linear auxiliary transform (AuxT) to disentangle energy compaction in training nonlinear transforms. The proposed AuxT obtains coarse approximation to achieve efficient energy compaction such that distribution fitting with the nonlinear transforms can be simplified to fine details. We then develop wavelet-based linear shortcuts (WLSs) for AuxT that leverages wavelet-based downsampling and orthogonal linear projection for feature decorrelation and subband-aware scaling for uneven energy modulation. AuxT is lightweight and plug-and-play to be integrated into diverse LIC models to address the slow convergence issue. Experimental results demonstrate that the proposed approach can accelerate training of LIC models by 2  times and simultaneously achieves an average 1\% BD-rate reduction. To our best knowledge, this is one of the first successful attempt that can significantly improve the convergence of LIC with comparable or superior rate-distortion performance.
  abstract_embedding: [-0.146484375, -0.220703125, 0.24609375]... (1536 items)
  authors: ['Han Li', 'Shaohui Li', 'Wenrui Dai']... (8 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652589476
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: On_Disentangled_Training_for_Nonlinear_Transform_in_Learned_Image_Compression.pdf
  sha_abstract: 5f109f0302211769b18e450131ddf2b4debfff928a2f5b66785025bb1a3cc20c
  title: On Disentangled Training for Nonlinear Transform in Learned Image Compression
  title_normalized: on_disentangled_training_for_nonlinear_transform_in_learned_image_compression

================================================================================
Document #298 (ID: xehIZpoBclM7MZc3A5PC)
================================================================================
  abstract: Connectionist Temporal Classification (CTC) is a widely used method for automatic speech recognition (ASR), renowned for its simplicity and computational efficiency. However, it often falls short in recognition performance.  In this work, we propose the Consistency-Regularized CTC (CR-CTC), which enforces consistency between two CTC distributions obtained from different augmented views of the input speech mel-spectrogram. We provide in-depth insights into its essential behaviors from three perspectives: 1) it conducts self-distillation between random pairs of sub-models that process different augmented views; 2) it learns contextual representation through masked prediction for positions within time-masked regions, especially when we increase the amount of time masking; 3) it suppresses the extremely peaky CTC distributions, thereby reducing overfitting and improving the generalization ability. Extensive experiments on LibriSpeech, Aishell-1, and GigaSpeech datasets demonstrate the effectiveness of our CR-CTC. It significantly improves the CTC performance, achieving state-of-the-art results comparable to those attained by transducer or systems combining CTC and attention-based encoder-decoder (CTC/AED). We release our code at \url{https://github.com/k2-fsa/icefall}.
  abstract_embedding: [0.263671875, 0.423828125, 0.57421875]... (1536 items)
  authors: ['Zengwei Yao', 'Wei Kang', 'Xiaoyu Yang']... (10 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652586930
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CR-CTC__Consistency_regularization_on_CTC_for_improved_speech_recognition.pdf
  sha_abstract: 3ee7e607019fa5a6ebde8adfb64c2ccbbb01554d8482f6eda77f55a20f97a9c5
  title: CR-CTC: Consistency regularization on CTC for improved speech recognition
  title_normalized: crctc_consistency_regularization_on_ctc_for_improved_speech_recognition

================================================================================
Document #299 (ID: xuhIZpoBclM7MZc3BZMg)
================================================================================
  abstract: Following its success for vision and text, the "foundation model" (FM) paradigm&#151;pretraining large models on massive data, then fine-tuning on target tasks&#151;has rapidly expanded to domains in the sciences, engineering, healthcare, and beyond. Has this achieved what the original FMs accomplished, i.e. the supplanting of traditional supervised learning in their domains? To answer we look at three modalities&#151;genomics, satellite imaging, and time series&#151;with multiple recent FMs and compare them to a standard supervised learning workflow: model development, hyperparameter tuning, and training, all using only data from the target task. Across these three specialized domains, we find that it is consistently possible to train simple supervised models&#151;no more complicated than a lightly modified wide ResNet or UNet&#151;that match or even outperform the latest foundation models. Our work demonstrates that the benefits of large-scale pretraining have yet to be realized in many specialized areas, reinforces the need to compare new FMs to strong, well-tuned baselines, and introduces two new, easy-to-use, open-source, and automated workflows for doing so.
  abstract_embedding: [0.33203125, 0.3828125, 0.369140625]... (1536 items)
  authors: ['Zongzhe Xu', 'Ritvik Gupta', 'Wenduo Cheng']... (7 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652587283
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Specialized_Foundation_Models_Struggle_to_Beat_Supervised_Baselines.pdf
  sha_abstract: 3af36e9f725fb80b9188fdaf2ee225f65aec94b8a792ea598bf34a4657e659a7
  title: Specialized Foundation Models Struggle to Beat Supervised Baselines
  title_normalized: specialized_foundation_models_struggle_to_beat_supervised_baselines

================================================================================
Document #300 (ID: x-hIZpoBclM7MZc3B5Mt)
================================================================================
  abstract: Computationally intensive decoding procedures---including search, reranking, and self-critique---can improve the quality of language model (LM) outputs in problems spanning code generation, numerical reasoning, and dialog.
Existing work typically applies the same decoding procedure for every input to an LM. But not all inputs require the same amount of computation to process. Can we allocate decoding computation adaptively, using more resources to answer questions whose answers will be harder to compute? We present an approach that predicts the distribution of rewards given an input and computation budget, then allocates additional computation to inputs for which it is predicted to be most useful. We apply this approach in two decoding procedures: first, an adaptive best-of-$k$ procedure that dynamically selects the number of samples to generate as input to a reranker; second, a routing procedure that dynamically responds to a query using a decoding procedure that is expensive but accurate, or one that is cheaper but less capable. Across a suite of programming, mathematics, and dialog tasks, we show that accurate computation-allocation procedures can be learned, and reduce computation by up to 50% at no cost to quality.
  abstract_embedding: [0.0810546875, 0.2734375, 0.224609375]... (1536 items)
  authors: ['Mehul Damani', 'Idan Shenfeld', 'Andi Peng']... (5 items)
  date: 2024-10-04
  decision: accept
  ingested_at: 1762652587746
  novelty: yes
  reason: Auto-accepted for testing purposes only.
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Learning_How_Hard_to_Think__Input-Adaptive_Allocation_of_LM_Computation.pdf
  sha_abstract: ffdd9d00c028857ff1fbf8b999816800c84bfa3efd783d3bbe37b4760d8d104b
  title: Learning How Hard to Think: Input-Adaptive Allocation of LM Computation
  title_normalized: learning_how_hard_to_think_inputadaptive_allocation_of_lm_computation
