
✅ Cluster Health:
{
  "cluster_name": "478852001205:research-papers",
  "status": "yellow",
  "timed_out": false,
  "number_of_nodes": 1,
  "number_of_data_nodes": 1,
  "discovered_master": true,
  "discovered_cluster_manager": true,
  "active_primary_shards": 16,
  "active_shards": 16,
  "relocating_shards": 0,
  "initializing_shards": 0,
  "unassigned_shards": 3,
  "delayed_unassigned_shards": 0,
  "number_of_pending_tasks": 0,
  "number_of_in_flight_fetch": 0,
  "task_max_waiting_in_queue_millis": 0,
  "active_shards_percent_as_number": 84.21052631578947
}

Indices:
- .plugins-ml-config (1 docs, status=green)
- .opensearch-observability (0 docs, status=green)
- research-papers-v3 (268 docs, status=yellow)
- research-papers-v2 (373 docs, status=yellow)
- .kibana_1 (1 docs, status=green)
- .opendistro_security (10 docs, status=green)
- research-papers (2 docs, status=yellow)

Documents from 'research-papers-v3':

================================================================================
Document #1 (ID: 28b68893469a4a927fc40347207a2e278568ba72f1e762f37b829e70df951101)
================================================================================
  abstract: In pretraining data detection, the goal is to detect whether a given sentence is in the dataset used for training a Large Language Model LLM). Recent methods (such as Min-K % and Min-K%++) reveal that most training corpora are likely contaminated with both sensitive content and evaluation benchmarks, leading to inflated test set performance. These methods sometimes fail to detect samples from the pretraining data, primarily because they depend on statistics composed of causal token likelihoods. We introduce Infilling Score, a new test-statistic based on non-causal token likelihoods. Infilling Score can be computed for autoregressive models without re-training using Bayes rule. A naive application of Bayes rule scales linearly with the vocabulary size. However, we propose a ratio test-statistic whose computation is invariant to vocabulary size. Empirically, our method achieves a significant accuracy gain over state-of-the-art methods including Min-K%, and Min-K%++ on the WikiMIA benchmark across seven models with different parameter sizes. Further, we achieve higher AUC compared to reference-free methods on the challenging MIMIR benchmark. Finally, we create a benchmark dataset consisting of recent data sources published after the release of Llama-3; this benchmark provides a statistical baseline to indicate potential corpora used for Llama-3 training.
  abstract_embedding: [0.259765625, 0.50390625, 0.193359375]... (1536 items)
  authors: ['Negin Raoof', 'Litu Rout', 'Giannis Daras']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804652966
  novelty: yes
  reason: Relevance: The paper proposes a novel pretraining data detection algorithm, Infilling Score, which is an innovative technique for improving the efficiency and accuracy of large language model training...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Infilling_Score__A_Pretraining_Data_Detection_Algorithm_for_Large_Language_Models.pdf
  sha_abstract: 7338a791968bb05e419ab839e29a2be132c461602c466e2981cd69b04d8f54fe
  title: Infilling Score: A Pretraining Data Detection Algorithm for Large Language Models
  title_normalized: infilling_score_a_pretraining_data_detection_algorithm_for_large_language_models

================================================================================
Document #2 (ID: e17b611b8200bb44658bb061518884793d1b215d1fc04cfbe5cd4585fcd3151d)
================================================================================
  abstract: This work tackles the information loss bottleneck of vector-quantization (VQ) autoregressive image generation by introducing a novel model architecture called the 2-Dimensional Autoregression (DnD) Transformer. The DnD-Transformer predicts more codes for an image by introducing a new direction, **model depth**, along with the sequence length. Compared to 1D autoregression and previous work using similar 2D image decomposition such as RQ-Transformer, the DnD-Transformer is an end-to-end model that can generate higher quality images with the same backbone model size and sequence length, opening a new optimization perspective for autoregressive image generation. Furthermore, our experiments reveal that the DnD-Transformer's potential extends beyond generating natural images. It can even generate images with rich text and graphical elements in a self-supervised manner, demonstrating an understanding of these combined modalities. This has not been previously demonstrated for popular vision generative models such as diffusion models, showing a spark of vision-language intelligence when trained solely on images. Code, datasets and models are open at https://github.com/chenllliang/DnD-Transformer.
  abstract_embedding: [0.154296875, -0.0830078125, 0.455078125]... (1536 items)
  authors: ['Liang Chen', 'Sinan Tan', 'Zefan Cai']... (10 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804650664
  novelty: yes
  reason: Relevance: The paper proposes a novel 2D autoregressive transformer architecture for efficient fine-grained image generation, which is an innovative new model architecture. | Novelty: The 2D autoregre...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: A_Spark_of_Vision-Language_Intelligence__2-Dimensional_Autoregressive_Transformer_for_Efficient_Finegrained_Image_Generation.pdf
  sha_abstract: 5b290a336ac314c12b8ac66e7a633742ef8a5eaf1a1c408d0919bc86b243e340
  title: A Spark of Vision-Language Intelligence: 2-Dimensional Autoregressive Transformer for Efficient Finegrained Image Generation
  title_normalized: a_spark_of_visionlanguage_intelligence_2dimensional_autoregressive_transformer_for_efficient_finegrained_image_generation

================================================================================
Document #3 (ID: eb94a50e1b987da5acf06f9673610aa780c9dcc53c2a722565948ec8cc1b8cc0)
================================================================================
  abstract: The ability to construct transferable descriptors for molecular and biological systems has broad applications in drug discovery, molecular dynamics, and protein analysis. Geometric graph neural networks (Geom-GNNs) utilizing all-atom information have revolutionized atomistic simulations by enabling the prediction of interatomic potentials and molecular properties. Despite these advances, the application of all-atom Geom-GNNs in protein modeling remains limited due to computational constraints. In this work, we first demonstrate the potential of pre-trained Geom-GNNs as zero-shot transfer learners, effectively modeling protein systems with all-atom granularity. Through extensive experimentation to evaluate their expressive power, we characterize the scaling behaviors of Geom-GNNs across self-supervised, supervised, and unsupervised setups. Interestingly, we find that Geom-GNNs deviate from conventional power-law scaling observed in other domains, with no predictable scaling principles for molecular representation learning. Furthermore, we show how pre-trained graph embeddings can be directly used for analysis and synergize with other architectures to enhance expressive power for protein modeling.
  abstract_embedding: [-0.0260009765625, 0.486328125, 0.099609375]... (1536 items)
  authors: ['Zihan Pengmei', 'Zhengyuan Shen', 'Zichen Wang']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804641465
  novelty: yes
  reason: Relevance: The paper proposes a novel all-atom geometric graph neural network (Geom-GNN) architecture and explores its scaling behavior and zero-shot transfer capabilities for protein modeling, which ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Pushing_the_Limits_of_All-Atom_Geometric_Graph_Neural_Networks__Pre-Training__Scaling__and_Zero-Shot_Transfer.pdf
  sha_abstract: 6cd786019e8605c8e1c19a82037d407d4ea8b8da3b9aa694d44c3f7479c584c7
  title: Pushing the Limits of All-Atom Geometric Graph Neural Networks: Pre-Training, Scaling, and Zero-Shot Transfer
  title_normalized: pushing_the_limits_of_allatom_geometric_graph_neural_networks_pretraining_scaling_and_zeroshot_transfer

================================================================================
Document #4 (ID: 0a6a4a108ad627083ec50084c4a70325583caf9f39fc4ff454f6d78af1f5c376)
================================================================================
  abstract: With the rise of medical foundation models and the growing availability of imaging data, scalable pretraining techniques offer a promising way to identify imaging biomarkers predictive of future disease risk. While current self-supervised methods for 3D medical imaging models capture local structural features like organ morphology, they fail to link pixel biomarkers with long-term health outcomes due to a missing context problem. Current approaches lack the temporal context necessary to identify biomarkers correlated with disease progression, as they rely on supervision derived only from images and concurrent text descriptions. To address this, we introduce time-to-event pretraining, a pretraining framework for 3D medical imaging models that leverages large-scale temporal supervision from paired, longitudinal electronic health records (EHRs). Using a dataset of 18,945 CT scans (4.2 million 2D images) and time-to-event distributions across thousands of EHR-derived tasks, our method improves outcome prediction, achieving an average AUROC increase of 23.7% and a 29.4% gain in Harrell’s C-index across 8 benchmark tasks. Importantly, these gains are achieved without sacrificing diagnostic classification performance. This study lays the foundation for integrating longitudinal EHR and 3D imaging data to advance clinical risk prediction.
  abstract_embedding: [0.35546875, 0.01171875, 0.0201416015625]... (1536 items)
  authors: ['Zepeng Frazier Huo', 'Jason Alan Fries', 'Alejandro Lozano']... (9 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804657299
  novelty: yes
  reason: Relevance: The paper proposes a novel pretraining framework for 3D medical imaging models that leverages temporal supervision from electronic health records to improve outcome prediction. | Novelty: T...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Time-to-Event_Pretraining_for_3D_Medical_Imaging.pdf
  sha_abstract: 37e1f31ea127119e2a47b580602aa5e79b237cbc8a0ab7b53216cdabc9187719
  title: Time-to-Event Pretraining for 3D Medical Imaging
  title_normalized: timetoevent_pretraining_for_3d_medical_imaging

================================================================================
Document #5 (ID: c5f28303489c3c3ffbf227ad6bf2a3272a84f9c0236a4321026182bbcb5007d3)
================================================================================
  abstract: Universal dexterous grasping across diverse objects presents a fundamental yet formidable challenge in robot learning. Existing approaches using reinforcement learning (RL) to develop policies on extensive object datasets face critical limitations, including complex curriculum design for multi-task learning and limited generalization to unseen objects. 
To overcome these challenges, we introduce ResDex, a novel approach that integrates residual policy learning with a mixture-of-experts (MoE) framework. ResDex is distinguished by its use of geometry-agnostic base policies that are efficiently acquired on individual objects and capable of generalizing across a wide range of unseen objects. Our MoE framework incorporates several base policies to facilitate diverse grasping styles suitable for various objects. By learning residual actions alongside weights that combine these base policies, ResDex enables efficient multi-task RL for universal dexterous grasping.
ResDex achieves state-of-the-art performance on the DexGraspNet dataset comprising 3,200 objects with an 88.8% success rate. It exhibits no generalization gap with unseen objects and demonstrates superior training efficiency, mastering all tasks within only 12 hours on a single GPU. For further details and videos, visit our project page.
  abstract_embedding: [1.28125, 0.1572265625, 0.36328125]... (1536 items)
  authors: ['Ziye Huang', 'Haoqi Yuan', 'Yuhui Fu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804655347
  novelty: yes
  reason: Relevance: The paper proposes a novel mixture-of-experts (MoE) framework with residual policy learning for efficient multi-task reinforcement learning for universal dexterous grasping, which is a rele...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Efficient_Residual_Learning_with_Mixture-of-Experts_for_Universal_Dexterous_Grasping.pdf
  sha_abstract: 2f16f58a6f28a8679c786c64f6c41843321ff5bb0091e34714fe6b07b4dc07c7
  title: Efficient Residual Learning with Mixture-of-Experts for Universal Dexterous Grasping
  title_normalized: efficient_residual_learning_with_mixtureofexperts_for_universal_dexterous_grasping

================================================================================
Document #6 (ID: a102775430ed26e848ecf2ceb61255cc88abd8c83e506f556fd0e8ca28be4f94)
================================================================================
  abstract: Video generation requires modeling a vast spatiotemporal space, which demands significant computational resources and data usage. To reduce the complexity, the prevailing approaches employ a cascaded architecture to avoid direct training with full resolution latent. Despite reducing computational demands, the separate optimization of each sub-stage hinders knowledge sharing and sacrifices flexibility. This work introduces a unified pyramidal flow matching algorithm. It reinterprets the original denoising trajectory as a series of pyramid stages, where only the final stage operates at the full resolution, thereby enabling more efficient video generative modeling. Through our sophisticated design, the flows of different pyramid stages can be interlinked to maintain continuity. Moreover, we craft autoregressive video generation with a temporal pyramid to compress the full-resolution history. The entire framework can be optimized in an end-to-end manner and with a single unified Diffusion Transformer (DiT). Extensive experiments demonstrate that our method supports generating high-quality 5-second (up to 10-second) videos at 768p resolution and 24 FPS within 20.7k A100 GPU training hours. All code and models are open-sourced at https://pyramid-flow.github.io.
  abstract_embedding: [0.01025390625, -0.052001953125, 0.44140625]... (1536 items)
  authors: ['Yang Jin', 'Zhicheng Sun', 'Ningyuan Li']... (11 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804658965
  novelty: yes
  reason: Relevance: The paper proposes a novel pyramidal flow matching algorithm for efficient video generative modeling, which is a new model architecture and training approach. | Novelty: The pyramidal flow ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Pyramidal_Flow_Matching_for_Efficient_Video_Generative_Modeling.pdf
  sha_abstract: fc51f69814967dd25ebdc0060f19aefd8f3b4b9b096d373d6e2a1357fe41869f
  title: Pyramidal Flow Matching for Efficient Video Generative Modeling
  title_normalized: pyramidal_flow_matching_for_efficient_video_generative_modeling

================================================================================
Document #7 (ID: 489e9ae777b1c1f18657434c4588ad5f312f00a5e9ca37a214f578eb0c901dce)
================================================================================
  abstract: The dynamics of information diffusion within graphs is a critical open issue that heavily influences graph representation learning, especially when considering long-range propagation. This calls for principled approaches that control and regulate the degree of propagation and dissipation of information throughout the neural flow. Motivated by this, we introduce port-Hamiltonian Deep Graph Networks, a novel framework that models neural information flow in graphs by building on the laws of conservation of Hamiltonian dynamical systems. We reconcile under a single theoretical and practical framework both non-dissipative long-range propagation and non-conservative behaviors, introducing tools from mechanical systems to gauge the equilibrium between the two components. Our approach can be applied to general message-passing architectures, and it provides theoretical guarantees on information conservation in time. Empirical results prove the effectiveness of our port-Hamiltonian scheme in pushing simple graph convolutional architectures to state-of-the-art performance in long-range benchmarks.
  abstract_embedding: [0.59765625, 0.318359375, -0.0189208984375]... (1536 items)
  authors: ['Simon Heilig', 'Alessio Gravina', 'Alessandro Trenta']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804646794
  novelty: yes
  reason: Relevance: The paper proposes a novel port-Hamiltonian deep graph network architecture that aims to improve long-range propagation in graph neural networks, which is a relevant and important problem. ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Port-Hamiltonian_Architectural_Bias_for_Long-Range_Propagation_in_Deep_Graph_Networks.pdf
  sha_abstract: d9b47761e54c4140622ea15eb058b1db477fc309e9ef0d92b3597e3d7e1f5b0d
  title: Port-Hamiltonian Architectural Bias for Long-Range Propagation in Deep Graph Networks
  title_normalized: porthamiltonian_architectural_bias_for_longrange_propagation_in_deep_graph_networks

================================================================================
Document #8 (ID: 0db22a7c6aa7795122412b6918cbc0e626be3f3b1c0e6ead704aa12352665745)
================================================================================
  abstract: Existing Video Scene Graph Generation (VidSGG) studies are trained in a fully supervised manner, which requires all frames in a video to be annotated, thereby incurring high annotation cost compared to Image Scene Graph Generation (ImgSGG). Although the annotation cost of VidSGG can be alleviated by adopting a weakly supervised approach commonly used for ImgSGG (WS-ImgSGG) that uses image captions, there are two key reasons that hinder such a naive adoption: 1) Temporality within video captions, i.e., unlike image captions, video captions include temporal markers (e.g., before, while, then, after) that indicate time-related details, and 2) Variability in action duration, i.e., unlike human actions in image captions, human actions in video captions unfold over varying duration. To address these issues, we propose a Natural Language-based Video Scene Graph Generation (NL-VSGG) framework that only utilizes the readily available video captions for training a VidSGG model. NL-VSGG consists of two key modules: Temporality-aware Caption Segmentation (TCS) module and Action Duration Variability-aware caption-frame alignment (ADV) module. Specifically, TCS segments the video captions into multiple sentences in a temporal order based on a Large Language Model (LLM), and ADV aligns each segmented sentence with appropriate frames considering the variability in action duration. Our approach leads to a significant enhancement in performance compared to simply applying the WS-ImgSGG pipeline to VidSGG on the Action Genome dataset. As a further benefit of utilizing the video captions as weak supervision, we show that the VidSGG model trained by NL-VSGG is able to predict a broader range of action classes that are not included in the training data, which makes our framework practical in reality.
  abstract_embedding: [-0.0069580078125, 0.51953125, 0.23046875]... (1536 items)
  authors: ['Kibum Kim', 'Kanghoon Yoon', 'Yeonjun In']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804686529
  novelty: yes
  reason: Relevance: The paper proposes a novel weakly supervised video scene graph generation framework that leverages video captions, which is a relevant and practical technique for efficient video understand...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Weakly_Supervised_Video_Scene_Graph_Generation_via_Natural_Language_Supervision.pdf
  sha_abstract: dccea06ed98bbecc61f47cd6aae9b5957f699408ce1e83374524ca397a818858
  title: Weakly Supervised Video Scene Graph Generation via Natural Language Supervision
  title_normalized: weakly_supervised_video_scene_graph_generation_via_natural_language_supervision

================================================================================
Document #9 (ID: bc6b7d0b9544ddfc29af52a9eb274e025107826b896287968dfec3e47743e0e2)
================================================================================
  abstract: The growth in the number of parameters of Large Language Models (LLMs) has led to a significant surge in computational requirements, making them challenging and costly to deploy.
Speculative decoding (SD) leverages smaller models to efficiently propose future tokens, which are then verified by the LLM in parallel.
Small models that utilise activations from the LLM currently achieve the fastest decoding speeds.
However, we identify several limitations of SD models including the lack of on-policyness during training and partial observability. 
To address these shortcomings, we propose a more grounded architecture for small models by introducing a Mixture of Attentions for SD.
Our novel architecture can be applied in two scenarios: a conventional single device deployment and a novel client-server deployment where the small model is hosted on a consumer device and the LLM on a server.
In a single-device scenario, we demonstrate state-of-the-art speedups improving EAGLE-2 by 9.5% and its acceptance length by 25%.
In a client-server setting, our experiments demonstrate: 1) state-of-the-art latencies with minimal calls to the server for different network conditions, and 2) in the event of a complete disconnection, our approach can maintain higher accuracy compared to other SD methods and demonstrates advantages over API calls to LLMs, which would otherwise be unable to continue the generation process.
  abstract_embedding: [0.23046875, 0.33984375, 0.392578125]... (1536 items)
  authors: ['Matthieu Zimmer', 'Milan Gritta', 'Gerasimos Lampouras']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804703155
  novelty: yes
  reason: Relevance: The paper proposes a novel mixture of attention models for speculative decoding, which is an innovative approach to improving the efficiency of large language models. | Novelty: The propose...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Mixture_of_Attentions_For_Speculative_Decoding.pdf
  sha_abstract: ca663163724fcd4eeb6907e8073974adfbc0e88de24f12a6dedab29ce699fe69
  title: Mixture of Attentions For Speculative Decoding
  title_normalized: mixture_of_attentions_for_speculative_decoding

================================================================================
Document #10 (ID: 5a7d282bf5e1f21616deb6721ec9375a4e5302937146e4d99bf0b88626d4bf00)
================================================================================
  abstract: The composition of pretraining data is a key determinant of foundation models' performance, but there is no standard guideline for allocating a limited computational budget across different data sources. Most current approaches either rely on extensive experiments with smaller models or dynamic data adjustments that also require proxy models, both of which significantly increase the workflow complexity and computational overhead. In this paper, we introduce Adaptive Data Optimization (ADO), an algorithm that optimizes data distributions in an online fashion, concurrent with model training. Unlike existing techniques, ADO does not require external knowledge, proxy models, or modifications to the model update. Instead, ADO uses per-domain scaling laws to estimate the learning potential of each domain during training and adjusts the data mixture accordingly, making it more scalable and easier to integrate. Experiments demonstrate that ADO can achieve comparable or better performance than prior methods while maintaining computational efficiency across different computation scales, offering a practical solution for dynamically adjusting data distribution without sacrificing flexibility or increasing costs. Beyond its practical benefits, ADO also provides a new perspective on data collection strategies via scaling laws.
  abstract_embedding: [0.40625, 0.2041015625, 0.474609375]... (1536 items)
  authors: ['Yiding Jiang', 'Allan Zhou', 'Zhili Feng']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804681390
  novelty: yes
  reason: Relevance: The paper proposes a novel algorithm, Adaptive Data Optimization (ADO), that dynamically adjusts the data distribution during model training to optimize performance, which is a relevant tec...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Adaptive_Data_Optimization__Dynamic_Sample_Selection_with_Scaling_Laws.pdf
  sha_abstract: c4902c4850a377de50bb4fd6ba922c5296f41298277455585e6aafe05e879c19
  title: Adaptive Data Optimization: Dynamic Sample Selection with Scaling Laws
  title_normalized: adaptive_data_optimization_dynamic_sample_selection_with_scaling_laws

================================================================================
Document #11 (ID: 6e182202f1d007ad2faedff88e34603e9a9b612ead01417b17349fa50fc0598c)
================================================================================
  abstract: MLLM agents demonstrate potential for complex embodied tasks by retrieving multimodal task-relevant trajectory data. However, current retrieval methods primarily focus on surface-level similarities of textual or visual cues in trajectories, neglecting their effectiveness for the specific task at hand. To address this issue, we propose a novel method, MART, which enhances the performance of embodied agents by utilizing interaction data to fine-tune an MLLM retriever based on preference learning, such that the retriever fully considers the effectiveness of trajectories and prioritize them for unseen tasks. We also introduce Trajectory Abstraction, a mechanism that leverages MLLMs' summarization capabilities to represent trajectories with fewer tokens while preserving key information, enabling agents to better comprehend milestones in the trajectory. Experimental results across various environments demonstrate our method significantly improves task success rates in unseen scenes compared to baseline methods. This work presents a new paradigm for multimodal retrieval in embodied agents, by fine-tuning a general-purpose MLLM as the retriever to assess trajectory effectiveness. All the code for benchmark tasks, simulator modifications and the MLLM retriever is available at https://github.com/PKU-RL/MART.
  abstract_embedding: [0.87890625, 0.41015625, 0.5234375]... (1536 items)
  authors: ['Junpeng Yue', 'Xinrun Xu', 'Börje F. Karlsson']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804688983
  novelty: yes
  reason: Relevance: The paper proposes a novel method, MART, that enhances the performance of embodied agents by fine-tuning a multimodal language model (MLLM) as a retriever based on preference learning, and ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MLLM_as_Retriever__Interactively_Learning_Multimodal_Retrieval_for_Embodied_Agents.pdf
  sha_abstract: 558d1922093521ab1cd4a80009828852d0e75204515578663805e8895beeec44
  title: MLLM as Retriever: Interactively Learning Multimodal Retrieval for Embodied Agents
  title_normalized: mllm_as_retriever_interactively_learning_multimodal_retrieval_for_embodied_agents

================================================================================
Document #12 (ID: c15935e6a2a8721f274c2a1ecaea06c0d92ee4902e8e644d5ed74eb94965b163)
================================================================================
  abstract: We propose Framer for interactive frame interpolation, which targets producing smoothly transitioning frames between two images as per user creativity. Concretely, besides taking the start and end frames as inputs, our approach supports customizing the transition process by tailoring the trajectory of some selected keypoints. Such a design enjoys two clear benefits. First, incorporating human interaction mitigates the issue arising from numerous possibilities of transforming one image to another, and in turn enables finer control of local motions. Second, as the most basic form of interaction, keypoints help establish the correspondence across frames, enhancing the model to handle challenging cases (e.g., objects on the start and end frames are of different shapes and styles). It is noteworthy that our system also offers an "autopilot" mode, where we introduce a module to estimate the keypoints and refine the trajectory automatically, to simplify the usage in practice. Extensive experimental results demonstrate the appealing performance of Framer on various applications, such as image morphing, time-lapse video generation, cartoon interpolation, etc. The code, model, and interface are publicly accessible at https://github.com/aim-uofa/Framer.
  abstract_embedding: [0.31640625, 0.375, 0.130859375]... (1536 items)
  authors: ['Wen Wang', 'Qiuyu Wang', 'Kecheng Zheng']... (9 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804698146
  novelty: yes
  reason: Relevance: The paper proposes a novel interactive frame interpolation model that allows users to customize the transition process by adjusting keypoints, which is an innovative approach to address the...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Framer__Interactive_Frame_Interpolation.pdf
  sha_abstract: 79f7cda9d3e369c5f40cc1f1859cffb263308a12d1f02167e673f07e665edb37
  title: Framer: Interactive Frame Interpolation
  title_normalized: framer_interactive_frame_interpolation

================================================================================
Document #13 (ID: 2c20d681ab6d845dcfcb4e0b8ae74b9cfac4d322caf165c846b7b1467409dfa1)
================================================================================
  abstract: Inspired by the Kolmogorov-Arnold representation theorem, we propose Kolmogorov-Arnold Networks (KANs) as promising alternatives to Multi-Layer Perceptrons (MLPs). While MLPs have fixed activation functions on nodes ("neurons''), KANs have learnable activation functions on edges ("weights''). KANs have no linear weights at all -- every weight parameter is replaced by a univariate function parametrized as a spline. We show that this seemingly simple change makes KANs outperform MLPs in terms of accuracy and interpretability, on small-scale AI + Science tasks. For accuracy, smaller KANs can achieve comparable or better accuracy than larger MLPs in function fitting tasks. Theoretically and empirically, KANs possess faster neural scaling laws than MLPs. For interpretability, KANs can be intuitively visualized and can easily interact with human users. Through two examples in mathematics and physics, KANs are shown to be useful ``collaborators'' helping scientists (re)discover mathematical and physical laws. In summary, KANs are promising alternatives for MLPs. Despite the slow training of KANs, their improved accuracy and interpretability show the potential to improve today's deep learning models which rely heavily on MLPs. More research is necessary to make KANs' training more efficient.
  abstract_embedding: [0.4296875, 0.267578125, -0.125]... (1536 items)
  authors: ['Ziming Liu', 'Yixuan Wang', 'Sachin Vaidya']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804691475
  novelty: yes
  reason: Relevance: The paper proposes a novel neural network architecture called Kolmogorov-Arnold Networks (KANs) that use learnable activation functions instead of fixed ones, which could lead to improved a...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: KAN__Kolmogorov_Arnold_Networks.pdf
  sha_abstract: be0400dff60b35692e8f9c57f03bbd5d57d1bd57ad47a8ac05107de9dd8fd958
  title: KAN: Kolmogorov–Arnold Networks
  title_normalized: kan_kolmogorovarnold_networks

================================================================================
Document #14 (ID: 36956309618a4a996b7f41cfea9e831112e063ee794183c8d799f8b6b3a4392b)
================================================================================
  abstract: Why do larger language models generalize better? To explore this question, we develop generalization bounds on the pretraining objective of large language models (LLMs) in the compute-optimal regime, as described by the Chinchilla scaling laws. We introduce a novel, fully empirical Freedman-type martingale concentration inequality that tightens existing bounds by accounting for the variance of the loss function. The generalization bound can be broken into three contributions: the number of parameters per token, the loss variance, and the quantization error at a fixed bitrate. As language models are scaled up, the number of parameters per data point stays constant; however, both the loss variance and the quantization error decrease, implying that larger models should have \emph{smaller} generalization gaps. We examine why larger models tend to be more quantizable from an information theoretic perspective, showing that the rate at which they can integrate new information grows slower than their capacity on the compute optimal frontier. From these findings we produce a scaling law for the generalization gap, showing that our bounds decrease in a predictable way.
  abstract_embedding: [0.0849609375, 0.2490234375, 0.1728515625]... (1536 items)
  authors: ['Marc Anton Finzi', 'Sanyam Kapoor', 'Diego Granziol']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804700001
  novelty: yes
  reason: Relevance: The paper proposes a novel theoretical framework for understanding why larger language models generalize better, which could inform the design of more efficient and effective models. | Nove...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Compute-Optimal_LLMs_Provably_Generalize_Better_with_Scale.pdf
  sha_abstract: b1f48346893cc97894134708442d6e2b754391da8abe3e023129a45c250fd82b
  title: Compute-Optimal LLMs Provably Generalize Better with Scale
  title_normalized: computeoptimal_llms_provably_generalize_better_with_scale

================================================================================
Document #15 (ID: 9ef532ca34c85521efff81919a3e6f15b2b8ce1525e33c92c1d88069d1452fe5)
================================================================================
  abstract: We present Pyramid Attention Broadcast (PAB), a real-time, high quality and training-free approach for DiT-based video generation. Our method is founded on the observation that attention difference in the diffusion process exhibits a U-shaped pattern, indicating significant redundancy. We mitigate this by broadcasting attention outputs to subsequent steps in a pyramid style. It applies different broadcast strategies to each attention based on their variance for best efficiency. We further introduce broadcast sequence parallel for more efficient distributed inference. PAB demonstrates up to 10.5x speedup across three models compared to baselines, achieving real-time generation for up to 720p videos. We anticipate that our simple yet effective method will serve as a robust baseline and facilitate future research and application for video generation.
  abstract_embedding: [0.005218505859375, 0.279296875, 0.275390625]... (1536 items)
  authors: ['Xuanlei Zhao', 'Xiaolong Jin', 'Kai Wang']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804684767
  novelty: yes
  reason: Relevance: The paper proposes a novel attention-based video generation method called Pyramid Attention Broadcast (PAB) that achieves significant speedups over baselines, enabling real-time video gener...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Real-Time_Video_Generation_with_Pyramid_Attention_Broadcast.pdf
  sha_abstract: 9bf817c5065ea20b9acdf562a1ccb1c720730fb3642b059bb0145e21ec968c7d
  title: Real-Time Video Generation with Pyramid Attention Broadcast
  title_normalized: realtime_video_generation_with_pyramid_attention_broadcast

================================================================================
Document #16 (ID: 7ecc4f0aaa519a4a663bd06c4b3fee847f26bee85ca4d483c45467bc29694e7e)
================================================================================
  abstract: Although it is traditionally believed that lossy image compression, such as JPEG compression, has a negative impact on the performance of deep neural networks (DNNs), it is shown by recent works that well-crafted JPEG compression can actually improve the performance of deep learning (DL). Inspired by this, we propose JPEG-DL, a novel DL framework that prepends any underlying DNN architecture with a trainable JPEG compression layer. To make the quantization operation in JPEG compression trainable, a new differentiable soft quantizer is employed at the JPEG layer, and then the quantization operation and underlying DNN are jointly trained. Extensive experiments show that in comparison with the standard DL,  JPEG-DL delivers significant accuracy improvements across various datasets and model architectures while enhancing robustness against adversarial attacks. Particularly, on some fine-grained image classification datasets, JPEG-DL can increase prediction accuracy by as much as 20.9%. Our code is available on https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL.git.
  abstract_embedding: [0.0634765625, 0.55078125, 0.447265625]... (1536 items)
  authors: ['Ahmed H. Salamah', 'Kaixiang Zheng', 'Yiwen Liu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804696047
  novelty: yes
  reason: Relevance: The paper proposes a novel DL framework that integrates a trainable JPEG compression layer into any underlying DNN architecture, which can improve accuracy and robustness. | Novelty: The pr...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: JPEG_Inspired_Deep_Learning.pdf
  sha_abstract: 15e3779394814e5f249cf98e8a04665437e795ff9a6da8eeb1c6577509aa4092
  title: JPEG Inspired Deep Learning
  title_normalized: jpeg_inspired_deep_learning

================================================================================
Document #17 (ID: 1d2c708deb75b73bb99dec4a0a3b447d6db1ecb6480a326ec728781bcfe39a5c)
================================================================================
  abstract: In this work, we introduce ChatQA 2, an Llama 3.0-based model with a 128K
context window, designed to bridge the gap between open-source LLMs and
leading proprietary models (e.g., GPT-4-Turbo-2024-04-09) in long context un-
derstanding and retrieval-augmented generation (RAG) capabilities. These two
capabilities are complementary to each other and essential for LLMs to process
large volumes of information that cannot fit into a single prompt. We present
a detailed continued training recipe to extend the context window of Llama3-
70B-base from 8K to 128K tokens, along with a three-stage instruction tun-
ing process to enhance the model’s instruction-following, RAG performance,
and long-context understanding capabilities. Our results demonstrate that the
Llama3-ChatQA-2-70B model outperforms most existing state-of-the-art models,
including GPT-4-Turbo-2024-04-09, Qwen2-72B-Instruct, and Llama3.1-70B-
Instruct, on ultra-long tasks beyond 100K tokens, as well as on the RAG benchmark
using only a 4K context window, showing the strong long context capability across
varying sequence lengths. We further provide extensive comparisons between
direct long-context and RAG solutions using the same state-of-the-art long-context
LLMs. Interestingly, we find that the performance of strong long-context LLMs
using RAG improves when retrieving a larger number of chunks. With a large set
of top-k chunks, RAG consistently outperforms direct long-context solution using
the same state-of-the-art long-context models (e.g., Llama3-ChatQA-2-70B and
Qwen2-72B-Instruct) on both 32K and 128K benchmarks. We open-source the
model weights, training data, and the evaluation setup for the for the community:
https://chatqa2-project.github.io/
  abstract_embedding: [0.12158203125, 0.017333984375, 0.1826171875]... (1536 items)
  authors: ['Peng Xu', 'Wei Ping', 'Xianchao Wu']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804768112
  novelty: yes
  reason: Relevance: The paper proposes a novel model architecture, ChatQA 2, that extends the context window of LLMs to 128K tokens and enhances their retrieval-augmented generation (RAG) capabilities, which a...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ChatQA_2__Bridging_the_Gap_to_Proprietary_LLMs_in_Long_Context_and_RAG_Capabilities.pdf
  sha_abstract: 7cb6dbfa45647dad72507a06bb7d8fcbe07816050d3642130487159f647e3f7c
  title: ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG Capabilities
  title_normalized: chatqa_2_bridging_the_gap_to_proprietary_llms_in_long_context_and_rag_capabilities

================================================================================
Document #18 (ID: 93fa62d87f4056527a67248de823000e79123e5ef5e95b753a2f976fbeb5ede9)
================================================================================
  abstract: First-order logic (FOL) reasoning, which involves sequential deduction, is pivotal for intelligent systems and serves as a valuable task for evaluating reasoning capabilities, particularly in chain-of-thought (CoT) contexts. Existing benchmarks often rely on extensive human annotation or handcrafted templates, making it difficult to achieve the necessary complexity, scalability, and diversity for robust evaluation. To address these limitations, we propose a novel framework called ProverGen that synergizes the generative strengths of Large Language Models (LLMs) with the rigor and precision of symbolic provers, enabling the creation of a scalable, diverse, and high-quality FOL reasoning dataset, ProverQA. ProverQA is also distinguished by its inclusion of accessible and logically coherent intermediate reasoning steps for each problem. Our evaluation shows that state-of-the-art LLMs struggle to solve ProverQA problems, even with CoT prompting, highlighting the dataset's challenging nature. We also finetune Llama3.1-8B-Instruct on a separate training set generated by our framework.
The finetuned model demonstrates consistent improvements on both in-distribution and out-of-distribution test sets, suggesting the value of our proposed data generation framework. Code available at: \url{https://github.com/opendatalab/ProverGen}
  abstract_embedding: [0.23828125, 0.443359375, 0.07080078125]... (1536 items)
  authors: ['Chengwen Qi', 'Ren Ma', 'Bowen Li']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804760955
  novelty: yes
  reason: Relevance: The paper proposes a novel framework called ProverGen that combines the strengths of large language models and symbolic provers to generate a scalable and diverse dataset for first-order lo...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Large_Language_Models_Meet_Symbolic_Provers_for_Logical_Reasoning_Evaluation.pdf
  sha_abstract: b644c34c9c0e4766fc8f7b20535638636e876085f3ad3e0f2db94e88c30a7b7e
  title: Large Language Models Meet Symbolic Provers for Logical Reasoning Evaluation
  title_normalized: large_language_models_meet_symbolic_provers_for_logical_reasoning_evaluation

================================================================================
Document #19 (ID: 5e90f161e1e978fac568e563925b9fd30bfc819dd8f453105c18dad2b4b22930)
================================================================================
  abstract: Designing synthetically accessible molecules and recommending analogs to unsynthesizable molecules are important problems for accelerating molecular discovery. We reconceptualize both problems using ideas from program synthesis. Drawing inspiration from syntax-guided synthesis approaches, we decouple the syntactic skeleton from the semantics of a synthetic tree to create a bilevel framework for reasoning about the combinatorial space of synthesis pathways. Given a molecule we aim to generate analogs for, we iteratively refine its skeletal characteristics via Markov Chain Monte Carlo simulations over the space of syntactic skeletons. Given a black-box oracle to optimize, we formulate a joint design space over syntactic templates and molecular descriptors and introduce evolutionary algorithms that optimize both syntactic and semantic dimensions synergistically. Our key insight is that once the syntactic skeleton is set, we can amortize over the search complexity of deriving the program's semantics by training policies to fully utilize the fixed horizon Markov Decision Process imposed by the syntactic template. We demonstrate performance advantages of our bilevel framework for synthesizable analog generation and synthesizable molecule design. Notably, our approach offers the user explicit control over the resources required to perform synthesis and biases the design space towards simpler solutions, making it particularly promising for autonomous synthesis platforms. Supporting code is at https://github.com/shiningsunnyday/SynthesisNet.
  abstract_embedding: [0.90625, 0.2099609375, 0.125]... (1536 items)
  authors: ['Michael Sun', 'Alston Lo', 'Minghao Guo']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804763190
  novelty: yes
  reason: Relevance: The paper proposes a novel bilevel framework for generating synthetically accessible molecules and analogs, which involves optimizing both the syntactic skeleton and molecular descriptors. ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Procedural_Synthesis_of_Synthesizable_Molecules.pdf
  sha_abstract: e043c423ee94a8ba743e74879ed46fb2df4b596e20f1b89b2f730b07e8a78d8b
  title: Procedural Synthesis of Synthesizable Molecules
  title_normalized: procedural_synthesis_of_synthesizable_molecules

================================================================================
Document #20 (ID: 7af1339f18c8e22a85d4e919ee096fbaab5c2687c8f324df56f74ceaa04b7b7b)
================================================================================
  abstract: Despite extensive research, recovering PDE expressions from experimental observations often involves symbolic regression. This method generally lacks the incorporation of meaningful physical insights, resulting in outcomes lacking clear physical interpretations. Recognizing that the primary interest of Machine Learning for Science (ML4Sci) often lies in understanding the underlying physical mechanisms or even discovering new physical laws rather than simply obtaining mathematical expressions, this paper introduces a novel ML4Sci task paradigm. This paradigm focuses on interpreting experimental data within the framework of prior physical hypotheses and theories, thereby guiding and constraining the discovery of PDE expressions. We have formulated this approach as a nonlinear mixed-integer programming (MIP) problem, addressed through an efficient search scheme developed for this purpose. Our experiments on newly designed Fluid Mechanics and Laser Fusion datasets demonstrate the interpretability and feasibility of this method.
  abstract_embedding: [0.337890625, 0.1181640625, -0.12060546875]... (1536 items)
  authors: ['Mingquan Feng', 'Yixin Huang', 'Yizhou Liu']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804765594
  novelty: yes
  reason: Relevance: The paper proposes a novel ML4Sci task paradigm that focuses on interpreting experimental data within the framework of prior physical hypotheses and theories, which could lead to more inter...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: PhysPDE__Rethinking_PDE_Discovery_and_a_Physical_HYpothesis_Selection_Benchmark.pdf
  sha_abstract: 33c054c02e54d51c654da4c978d0c79c569da73345e9225f21cf57f089d47316
  title: PhysPDE: Rethinking PDE Discovery and a Physical HYpothesis Selection Benchmark
  title_normalized: physpde_rethinking_pde_discovery_and_a_physical_hypothesis_selection_benchmark

================================================================================
Document #21 (ID: cc4564fc6d1b187be80f7564f85c4a67ddb03632e219f372a5611ccb709b3345)
================================================================================
  abstract: Multimodal Large Language Models have made significant strides in integrating visual and textual information, yet they often struggle with effectively aligning these modalities. We introduce a novel image tokenizer that bridges this gap by applying the principle of Byte-Pair Encoding (BPE) to visual data. Unlike conventional approaches that rely on separate visual encoders, our method directly incorporates structural prior information into image tokens, mirroring the successful tokenization strategies used in text-only Large Language Models. This innovative approach enables Transformer models to more effectively learn and reason across modalities. Through theoretical analysis and extensive experiments, we demonstrate that our BPE Image Tokenizer significantly enhances MLLMs' multimodal understanding capabilities, even with limited training data. Leveraging this method, we develop Being-VL-0, a model that demonstrates superior performance across various benchmarks and shows promising scalability, potentially paving the way for more efficient and capable multimodal foundation models. For further details, visit our website https://github.com/BeingBeyond/Being-VL-0.
  abstract_embedding: [0.19921875, 0.158203125, 0.34375]... (1536 items)
  authors: ['Wanpeng Zhang', 'Zilong Xie', 'Yicheng Feng']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804751093
  novelty: yes
  reason: Relevance: The paper proposes a novel image tokenizer based on Byte-Pair Encoding, which could enable more effective multimodal learning and reasoning in Transformer models. | Novelty: The proposed BP...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: From_Pixels_to_Tokens__Byte-Pair_Encoding_on_Quantized_Visual_Modalities.pdf
  sha_abstract: 177834435c5de790d44e011c3a698e6c129ff5113f609732a1c604b0cb9d8f6a
  title: From Pixels to Tokens: Byte-Pair Encoding on Quantized Visual Modalities
  title_normalized: from_pixels_to_tokens_bytepair_encoding_on_quantized_visual_modalities

================================================================================
Document #22 (ID: 5fdc8aa5fc6a5c97d6d1d06e38836bdd790fff75d04716b665b0316e8d46085a)
================================================================================
  abstract: Diffusion models have become the dominant approach for visual generation. They are trained by denoising a Markovian process which gradually adds noise to the input. We argue that the Markovian property limits the model’s ability to fully utilize the generation trajectory, leading to inefficiencies during training and inference. In this paper, we propose DART, a transformer-based model that unifies autoregressive (AR) and diffusion within a non-Markovian framework.  DART iteratively denoises image patches spatially and spectrally using an AR model that has the same architecture as standard language models. DART does not rely on image quantization, which enables more effective image modeling while maintaining flexibility. Furthermore, DART seamlessly trains with both text and image data in a unified model. Our approach demonstrates competitive performance on class-conditioned and text-to-image generation tasks, offering a scalable, efficient alternative to traditional diffusion models. Through this unified framework, DART sets a new benchmark for scalable, high-quality image synthesis.
  abstract_embedding: [0.1337890625, 0.1708984375, 0.408203125]... (1536 items)
  authors: ['Jiatao Gu', 'Yuyang Wang', 'Yizhe Zhang']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804754487
  novelty: yes
  reason: Relevance: The paper proposes a novel transformer-based model, DART, that unifies autoregressive and diffusion approaches for text-to-image generation, which is relevant for innovative model architect...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Denoising_Autoregressive_Transformers_for_Scalable_Text-to-Image_Generation.pdf
  sha_abstract: 5b7c5b7433d94f34a10098f6d6ad399d34ac264e15c2a1f3b0379b5b2487693e
  title: Denoising Autoregressive Transformers for Scalable Text-to-Image Generation
  title_normalized: denoising_autoregressive_transformers_for_scalable_texttoimage_generation

================================================================================
Document #23 (ID: c2a4270f4238334ffa8ef4b06526f7f0e85652cd5653ee253f099e5c1e871ba5)
================================================================================
  abstract: Generative Foundation Models (GFMs) have achieved remarkable success in producing high-quality synthetic data for images and text. However, their application to tabular data presents significant challenges due to the heterogeneous nature of table features. Current cross-table learning frameworks struggle because they lack a generative model backbone and an effective mechanism to decode heterogeneous feature values. To address these challenges, we propose the Cross-Table Synthesizer (CTSyn), a diffusion-based generative foundation model for tabular data generation. CTSyn comprises two key components. The first is an autoencoder network that consolidates diverse tables into a unified latent space. It dynamically reconstructs table values using a table schema embedding, allowing adaptation to heterogeneous datasets. The second is a conditional latent diffusion model that generates samples from the learned latent space, conditioned on the table schema. Through large-scale pre-training, CTSyn outperforms existing table synthesizers on standard benchmarks in both utility and diversity.  These results position CTSyn as a promising framework for synthetic table generation and lay the groundwork for developing large-scale tabular foundation models.
  abstract_embedding: [0.5078125, -0.0234375, 0.40625]... (1536 items)
  authors: ['Xiaofeng Lin', 'Chenheng Xu', 'Matthew Yang']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804758365
  novelty: yes
  reason: Relevance: The paper proposes a novel diffusion-based generative foundation model (CTSyn) for tabular data generation, which addresses key challenges in applying generative models to heterogeneous tab...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CTSyn__A_Foundation_Model_for_Cross_Tabular_Data_Generation.pdf
  sha_abstract: 0e3f1b904ae346acd8fce51a3ae0d89546340f4927c6fa95bf92b06fe5b012d3
  title: CTSyn: A Foundation Model for Cross Tabular Data Generation
  title_normalized: ctsyn_a_foundation_model_for_cross_tabular_data_generation

================================================================================
Document #24 (ID: 5dd3ef6489f6b7f1d1f5534dccbb5b74dad0ab9cb3ca2fa29669628b7dd431f3)
================================================================================
  abstract: Data Shapley offers a principled framework for attributing the contribution of data within machine learning contexts. However, the traditional notion of Data Shapley requires re-training models on various data subsets, which becomes computationally infeasible for large-scale models. Additionally, this retraining-based definition cannot evaluate the contribution of data for a specific model training run, which may often be of interest in practice. This paper introduces a novel concept, In-Run Data Shapley, which eliminates the need for model retraining and is specifically designed for assessing data contribution for a particular model of interest. In-Run Data Shapley calculates the Shapley value for each gradient update iteration and accumulates these values throughout the training process. We present several techniques that allow the efficient scaling of In-Run Data Shapley to the size of foundation models. In its most optimized implementation, our method adds negligible runtime overhead compared to standard model training. This dramatic efficiency improvement makes it possible to perform data attribution for the foundation model pretraining stage. We present several case studies that offer fresh insights into pretraining data's contribution and discuss their implications for copyright in generative AI and pretraining data curation.
  abstract_embedding: [0.40625, 0.17578125, 0.345703125]... (1536 items)
  authors: ['Jiachen T. Wang', 'Prateek Mittal', 'Dawn Song']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804748287
  novelty: yes
  reason: Relevance: The paper proposes a novel method called In-Run Data Shapley that can efficiently attribute the contribution of data for a specific model training run, which is a valuable technique for und...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Data_Shapley_in_One_Training_Run.pdf
  sha_abstract: a5a382072c0323edc4b255b358ddfd0a372fce780d8f06753b5cbf88ac3b7cb1
  title: Data Shapley in One Training Run
  title_normalized: data_shapley_in_one_training_run

================================================================================
Document #25 (ID: 2069cda7cfeb1ea6783ff19e3330866d85eceb3b91af16654323d4b7e6ab8b6b)
================================================================================
  abstract: Multimodal foundation models, such as Gemini and ChatGPT, have revolutionized human-machine interactions by seamlessly integrating various forms of data. Developing a universal spoken language model that comprehends a wide range of natural language instructions is critical for bridging communication gaps and facilitating more intuitive interactions. However, the absence of a comprehensive evaluation benchmark poses a significant challenge. We present Dynamic-SUPERB Phase-2, an open and evolving benchmark for the comprehensive evaluation of instruction-based universal speech models. Building upon the first generation, this second version incorporates 125 new tasks contributed collaboratively by the global research community, expanding the benchmark to a total of 180 tasks, making it the largest benchmark for speech and audio evaluation. While the first generation of Dynamic-SUPERB was limited to classification tasks, Dynamic-SUPERB Phase-2 broadens its evaluation capabilities by introducing a wide array of novel and diverse tasks, including regression and sequence generation, across speech, music, and environmental audio. Evaluation results show that no model performed well universally. SALMONN-13B excelled in English ASR and Qwen2-Audio-7B-Instruct showed high accuracy in emotion recognition, but current models still require further innovations to handle a broader range of tasks. We open-source all task data and the evaluation pipeline at https://github.com/dynamic-superb/dynamic-superb.
  abstract_embedding: [0.322265625, 0.2099609375, 0.1748046875]... (1536 items)
  authors: ['Chien-yu Huang', 'Wei-Chih Chen', 'Shu-wen Yang']... (76 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804788996
  novelty: yes
  reason: Relevance: The paper proposes a new, large-scale benchmark for evaluating spoken language models, which is relevant for developing advanced multimodal AI systems. | Novelty: The Dynamic-SUPERB Phase-2...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Dynamic-SUPERB_Phase-2__A_Collaboratively_Expanding_Benchmark_for_Measuring_the_Capabilities_of_Spoken_Language_Models_with_180_Tasks.pdf
  sha_abstract: 576677b90014246ea56e6377405276e6d0b969d3466acfde2b03b5d416b88677
  title: Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks
  title_normalized: dynamicsuperb_phase2_a_collaboratively_expanding_benchmark_for_measuring_the_capabilities_of_spoken_language_models_with_180_tasks

================================================================================
Document #26 (ID: 5ea8ed368c9d8904bb37318dafd1cca034b404ec6d6cd95cc1fc074d5a3ac09f)
================================================================================
  abstract: Transformer has attracted increasing interest in spatio-temporal video grounding, or STVG, owing to its end-to-end pipeline and promising result. Existing Transformer-based STVG approaches often leverage a set of object queries, which are initialized simply using zeros and then gradually learn target position information via iterative interactions with multimodal features, for spatial and temporal localization. Despite simplicity, these zero object queries, due to lacking target-specific cues, are hard to learn discriminative target information from interactions with multimodal features in complicated scenarios (e.g., with distractors or occlusion), resulting in degradation. Addressing this, we introduce a novel $\textbf{T}$arget-$\textbf{A}$ware Transformer for $\textbf{STVG}$ ($\textbf{TA-STVG}$), which seeks to adaptively generate object queries via exploring target-specific cues from the given video-text pair, for improving STVG. The key lies in two simple yet effective modules, comprising text-guided temporal sampling (TTS) and attribute-aware spatial activation (ASA), working in a cascade. The former focuses on selecting target-relevant temporal cues from a video utilizing holistic text information, while the latter aims at further exploiting the fine-grained visual attribute information of the object from previous target-aware temporal cues, which is applied for object query initialization. Compared to existing methods leveraging zero-initialized queries, object queries in our TA-STVG, directly generated from a given video-text pair, naturally carry target-specific cues, making them adaptive and better interact with multimodal features for learning more discriminative information to improve STVG. In our experiments on three benchmarks, including HCSTVG-v1/-v2 and VidSTG, TA-STVG achieves state-of-the-art performance and significantly outperforms the baseline, validating its efficacy. Moreover, TTS and ASA are designed for general purpose. When applied to existing methods such as TubeDETR and STCAT, we show substantial performance gains, verifying its generality. Code is released at https://github.com/HengLan/TA-STVG.
  abstract_embedding: [-0.03857421875, -0.2392578125, 0.6640625]... (1536 items)
  authors: ['Xin Gu', 'Yaojie Shen', 'Chenxi Luo']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804778819
  novelty: yes
  reason: Relevance: The paper proposes a novel Transformer-based architecture called TA-STVG that introduces target-aware object queries for spatio-temporal video grounding, which is a relevant and innovative ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Knowing_Your_Target__Target-Aware_Transformer_Makes_Better_Spatio-Temporal_Video_Grounding.pdf
  sha_abstract: 9079f20379fbd9e16626c72c29cce90ea1733efc0a4cd05222f2ee39c93512a3
  title: Knowing Your Target: Target-Aware Transformer Makes Better Spatio-Temporal Video Grounding
  title_normalized: knowing_your_target_targetaware_transformer_makes_better_spatiotemporal_video_grounding

================================================================================
Document #27 (ID: c23465adcb21013e3ad2d6bb4256855736be003d9db582b24ce1bc16faa3970f)
================================================================================
  abstract: We propose Few-Class Arena (FCA), as a unified benchmark with focus on testing efficient image classification models for few classes. A wide variety of benchmark datasets with many classes (80-1000) have been created to assist Computer Vision architectural evolution. An increasing number of vision models are evaluated with these many-class datasets. However, real-world applications often involve substantially fewer classes of interest (2-10). This gap between many and few classes makes it difficult to predict performance of the few-class applications using models trained on the available many-class datasets. To date, little has been offered to evaluate models in this Few-Class Regime. We conduct a systematic evaluation of the ResNet family trained on ImageNet subsets from 2 to 1000 classes, and test a wide spectrum of Convolutional Neural Networks and Transformer architectures over ten datasets by using our newly proposed FCA tool. Furthermore, to aid an up-front assessment of dataset difficulty and a more efficient selection of models, we incorporate a difficulty measure as a function of class similarity. FCA offers a new tool for efficient machine learning in the Few-Class Regime, with goals ranging from a new efficient class similarity proposal, to lightweight model architecture design, to a new scaling law. FCA is user-friendly and can be easily extended to new models and datasets, facilitating future research work. Our benchmark is available at https://github.com/bryanbocao/fca.
  abstract_embedding: [-0.2890625, 0.46875, 0.5703125]... (1536 items)
  authors: ['Bryan Bo Cao', "Lawrence O'Gorman", 'Michael Coss']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804776287
  novelty: yes
  reason: Relevance: The paper proposes a new benchmark for efficient image classification models in the few-class regime, which is a relevant and practical problem for real-world applications. | Novelty: The p...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Few-Class_Arena__A_Benchmark_for_Efficient_Selection_of_Vision_Models_and_Dataset_Difficulty_Measurement.pdf
  sha_abstract: 7350e14f29d9a72c379b927144abb25d0cc8fbcfafd17cf62b0bc6ac2f70e570
  title: Few-Class Arena: A Benchmark for Efficient Selection of Vision Models and Dataset Difficulty Measurement
  title_normalized: fewclass_arena_a_benchmark_for_efficient_selection_of_vision_models_and_dataset_difficulty_measurement

================================================================================
Document #28 (ID: 7315a82d301f01159400a2ab15977cf5112cd3f6080d53ad71d15478a2a36f38)
================================================================================
  abstract: Recent studies have discovered that widely used text-to-image diffusion models can replicate training samples during image generation, a phenomenon known as memorization. Existing detection methods primarily focus on identifying memorized prompts. However, in real-world scenarios, image owners may need to verify whether their proprietary or personal images have been memorized by the model, even in the absence of paired prompts or related metadata. We refer to this challenge as image-level memorization detection, where current methods relying on original prompts fall short. In this work, we uncover two characteristics of memorized images after perturbing the inference procedure: lower similarity of the original images and larger magnitudes of TCNP.
Building on these insights, we propose Inversion-based Inference Perturbation (IIP), a new framework for image-level memorization detection. Our approach uses unconditional DDIM inversion to derive latent codes that contain core semantic information of original images and optimizes random prompt embeddings to introduce effective perturbation. Memorized images exhibit distinct characteristics within the proposed pipeline, providing a robust basis for detection. To support this task, we construct a comprehensive setup for the image-level memorization detection, carefully curating datasets to simulate realistic memorization scenarios. Using this setup, we evaluate our IIP framework across three different memorization settings, demonstrating its state-of-the-art performance in identifying memorized images in various settings, even in the presence of data augmentation attacks.
  abstract_embedding: [0.5078125, 0.435546875, -0.13671875]... (1536 items)
  authors: ['Yue Jiang', 'Haokun Lin', 'Yang Bai']... (9 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804796494
  novelty: yes
  reason: Relevance: The paper proposes a new framework for image-level memorization detection, which is an important and novel problem in the context of diffusion models. | Novelty: The proposed Inversion-base...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Image-level_Memorization_Detection_via_Inversion-based_Inference_Perturbation.pdf
  sha_abstract: 64b0fcaedb9f52a834e8c867294bc80a9fcd3896a15024117c22691f983bcef8
  title: Image-level Memorization Detection via Inversion-based Inference Perturbation
  title_normalized: imagelevel_memorization_detection_via_inversionbased_inference_perturbation

================================================================================
Document #29 (ID: 676ea5d7923cbd2873f6a1f964aeba73e70c432f2358e3e7645c1ed24d1f2441)
================================================================================
  abstract: We explore cross-domain offline reinforcement learning (RL) where offline datasets from another domain can be accessed to facilitate policy learning. However, the underlying environments of the two datasets may have dynamics mismatches, incurring inferior performance when simply merging the data of two domains. Existing methods mitigate this issue by training domain classifiers, using contrastive learning methods, etc. Nevertheless, they still rely on a large amount of target domain data to function well. Instead, we address this problem by establishing a concrete performance bound of a policy given datasets from two domains. Motivated by the theoretical insights, we propose to align transitions in the two datasets using optimal transport and selectively share source domain samples, without training any neural networks. This enables reliable data filtering even given a few target domain data. Additionally, we introduce a dataset regularization term that ensures the learned policy remains within the scope of the target domain dataset, preventing it from being biased towards the source domain data. Consequently, we propose the Optimal Transport Data Filtering (dubbed OTDF) method and examine its effectiveness by conducting extensive experiments across various dynamics shift conditions (e.g., gravity shift), given limited target domain data. It turns out that OTDF exhibits superior performance on many tasks and dataset qualities, often surpassing prior strong baselines by a large margin.
  abstract_embedding: [0.66015625, 0.2216796875, 0.345703125]... (1536 items)
  authors: ['Jiafei Lyu', 'Mengbei Yan', 'Zhongjian Qiao']... (9 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804798509
  novelty: yes
  reason: Relevance: The paper proposes a novel offline policy adaptation method that uses optimal transport and dataset regularization, which are directly implementable ML techniques. | Novelty: The proposed O...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Cross-Domain_Offline_Policy_Adaptation_with_Optimal_Transport_and_Dataset_Constraint.pdf
  sha_abstract: fdbc443a76c2a7bb3cdfffd21d51bd106ed782589934adc16feceaf5d740c0d2
  title: Cross-Domain Offline Policy Adaptation with Optimal Transport and Dataset Constraint
  title_normalized: crossdomain_offline_policy_adaptation_with_optimal_transport_and_dataset_constraint

================================================================================
Document #30 (ID: 401e9897149c1bccfc95dc289526beeeaee041a4528702ce87480e5c0d0840ca)
================================================================================
  abstract: Policy Mirror Descent (PMD) is a popular framework in reinforcement learning, serving as a unifying perspective that encompasses numerous algorithms. These algorithms are derived through the selection of a mirror map and enjoy finite-time convergence guarantees. Despite its popularity, the exploration of PMD's full potential is limited, with the majority of research focusing on a particular mirror map---namely, the negative entropy---which gives rise to the renowned Natural Policy Gradient (NPG) method. It remains uncertain from existing theoretical studies whether the choice of mirror map significantly influences PMD's efficacy. In our work, we conduct empirical investigations to show that the conventional mirror map choice (NPG) often yields less-than-optimal outcomes across several standard benchmark environments. Using evolutionary strategies, we identify more efficient mirror maps that enhance the performance of PMD. We first focus on a tabular environment, i.e.\ Grid-World, where we relate existing theoretical bounds with the performance of PMD for a few standard mirror maps and the learned one. We then show that it is possible to learn a mirror map that outperforms the negative entropy in more complex environments, such as the MinAtar suite. Additionally, we demonstrate that the learned mirror maps generalize effectively to different tasks by testing each map across various other environments.
  abstract_embedding: [0.9375, 0.5625, 0.05908203125]... (1536 items)
  authors: ['Carlo Alfano', 'Sebastian Rene Towers', 'Silvia Sapora']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804780883
  novelty: yes
  reason: Relevance: The paper proposes a novel method for learning efficient mirror maps to improve the performance of Policy Mirror Descent, which is a key algorithm in reinforcement learning. | Novelty: The ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Learning_mirror_maps_in_policy_mirror_descent.pdf
  sha_abstract: 46b3d71542c2cb31f9802e0047593be6abe7594059d25028a51bca0493ee2e29
  title: Learning mirror maps in policy mirror descent
  title_normalized: learning_mirror_maps_in_policy_mirror_descent

================================================================================
Document #31 (ID: 8f513096122bda536a7118604480b2efde748d95664d7d5c9be15fc7c2e191f0)
================================================================================
  abstract: Audio is essential for multimodal video understanding. On the one hand, video inherently contains audio, which supplies complementary information to vision. Besides, video large language models (Video-LLMs) can encounter many audio-centric settings. However, existing Video-LLMs and Audio-Visual Large Language Models (AV-LLMs) exhibit deficiencies in exploiting audio information, leading to weak understanding and hallucinations. To solve the issues, we delve into the model architecture and dataset. (1) From the architectural perspective, we propose a fine-grained AV-LLM, namely Dolphin. The concurrent alignment of audio and visual modalities in both temporal and spatial dimensions ensures a comprehensive and accurate understanding of videos. Specifically, we devise an audio-visual multi-scale adapter for multi-scale information aggregation, which achieves spatial alignment. For temporal alignment, we propose audio-visual interleaved merging. (2) From the dataset perspective, we curate an audio-visual caption \& instruction-tuning dataset, called AVU. It comprises 5.2 million diverse, open-ended data tuples (video, audio, question, answer) and introduces a novel data partitioning strategy. Extensive experiments show our model not only achieves remarkable performance in audio-visual understanding, but also mitigates potential hallucinations.
  abstract_embedding: [0.2314453125, -0.04052734375, 0.4375]... (1536 items)
  authors: ['Yuxin Guo', 'Shuailei Ma', 'Shijie Ma']... (10 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804783090
  novelty: yes
  reason: Relevance: The paper proposes a novel audio-visual large language model architecture and a new dataset for audio-visual understanding, which are directly relevant to ML research and training on AWS Tr...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Aligned_Better__Listen_Better_for_Audio-Visual_Large_Language_Models.pdf
  sha_abstract: aea160d31c518a004e227ae3e8b13321f328b817bd3feeb19d57c6b24724e83c
  title: Aligned Better, Listen Better for Audio-Visual Large Language Models
  title_normalized: aligned_better_listen_better_for_audiovisual_large_language_models

================================================================================
Document #32 (ID: e74759b6b4c2aa93b49df388c83d2b9349c050eab0880c092b2008c55c4032fe)
================================================================================
  abstract: Explaining Graph Neural Network (XGNN) has gained growing attention to facilitate the trust of using GNNs, which is the mainstream method to learn graph data. Despite their growing attention, Existing XGNNs focus on improving the explanation performance, and its robustness under attacks is largely unexplored. We noticed that an adversary can slightly perturb the graph structure such that the explanation result of XGNNs is largely changed. Such vulnerability of XGNNs could cause serious issues particularly in safety/security-critical applications. In this paper, we take the first step to study the robustness of XGNN against graph perturbation attacks, and propose XGNNCert, the first provably robust XGNN. Particularly, our XGNNCert can provably ensure the explanation result for a graph under the worst-case graph perturbation attack is close to that without the attack, while not affecting the GNN prediction, when the number of perturbed edges is bounded. Evaluation results on multiple graph datasets and GNN explainers show the effectiveness of XGNNCert.
  abstract_embedding: [0.384765625, 0.671875, -0.5]... (1536 items)
  authors: ['Jiate Li', 'Meng Pang', 'Yun Dong']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804794353
  novelty: yes
  reason: Relevance: The paper proposes a novel method, XGNNCert, to improve the robustness of graph neural network (GNN) explanation techniques against graph perturbation attacks, which is an important problem...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Provably_Robust_Explainable_Graph_Neural_Networks_against_Graph_Perturbation_Attacks.pdf
  sha_abstract: 8d33b7506b01ba61f098b7d0510ea638fb8fa051fb0ff8bd1dd4195e4d436957
  title: Provably Robust Explainable Graph Neural Networks against Graph Perturbation Attacks
  title_normalized: provably_robust_explainable_graph_neural_networks_against_graph_perturbation_attacks

================================================================================
Document #33 (ID: f43970e87496d4834e2c876a46e0d28fb654159cf837ac5aa65d5a8a79e835e9)
================================================================================
  abstract: Consistency models (CMs) are a powerful class of diffusion-based generative models optimized for fast sampling. Most existing CMs are trained using discretized timesteps, which introduce additional hyperparameters and are prone to discretization errors. While continuous-time formulations can mitigate these issues, their success has been limited by training instability. To address this, we propose a simplified theoretical framework that unifies previous parameterizations of diffusion models and CMs, identifying the root causes of instability. Based on this analysis, we introduce key improvements in diffusion process parameterization, network architecture, and training objectives. These changes enable us to train continuous-time CMs at an unprecedented scale, reaching 1.5B parameters on ImageNet 512×512. Our proposed training algorithm, using only two sampling steps, achieves FID scores of 2.06 on CIFAR-10, 1.48 on ImageNet 64×64, and 1.88 on ImageNet 512×512, narrowing the gap in FID scores with the best existing diffusion models to within 10\%.
  abstract_embedding: [0.51171875, 0.578125, 0.41796875]... (1536 items)
  authors: ['Cheng Lu', 'Yang Song']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804791689
  novelty: yes
  reason: Relevance: The paper proposes a new continuous-time consistency model architecture and training algorithm, which is relevant for innovative generative models. | Novelty: The paper introduces key impro...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Simplifying__Stabilizing_and_Scaling_Continuous-time_Consistency_Models.pdf
  sha_abstract: 25a29c7849c1e35f7eeb620d0cfbdefcd7946935053f7c36a08a14079e598a2c
  title: Simplifying, Stabilizing and Scaling Continuous-time Consistency Models
  title_normalized: simplifying_stabilizing_and_scaling_continuoustime_consistency_models

================================================================================
Document #34 (ID: 19a528b321924c8d6ae8b5b335c568e9eac213516e085984935872dac4bc4329)
================================================================================
  abstract: We give online algorithms for $k$-Means(more generally, $(k, z)$-Clustering) with nearly optimal consistency (a notion suggested by Lattanzi & Vassilvitskii (2017)). 
Our result turns any $\alpha$-approximate offline algorithm for clustering into an $(1+\epsilon)\alpha^2$-competitive online algorithm for clustering with $O(k \text{poly} \log n)$ consistency. 
This consistency bound is optimal up to $\text{poly} \log(n)$ factors. 
Plugging in the offline algorithm that returns the exact optimal solution, 
we obtain the first
$(1 + \epsilon)$-competitive online algorithm for clustering that achieves a linear in $k$ consistency.
This simultaneously improves several previous results (Lattanzi & Vassilvitskii, 2017; Fichtenberger et al., 2021). 
We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm. 
Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.
  abstract_embedding: [0.123046875, 0.51953125, 0.232421875]... (1536 items)
  authors: ['T-H. Hubert Chan', 'Shaofeng H.-C. Jiang', 'Tianyi Wu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804756329
  novelty: yes
  reason: Relevance: The paper proposes a new online clustering algorithm that can be used to improve the efficiency and consistency of k-Means clustering, which is a widely used technique in ML. | Novelty: The...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Online_Clustering_with_Nearly_Optimal_Consistency.pdf
  sha_abstract: f7d0fbad591092b695a6d038cecea62bc20ed3b8cd3de4db0effa07fe72f4ab8
  title: Online Clustering with Nearly Optimal Consistency
  title_normalized: online_clustering_with_nearly_optimal_consistency

================================================================================
Document #35 (ID: 6491b012b783604b4399680c4ac04de1dfef2705515313330bacdddccfacff50)
================================================================================
  abstract: Large-scale pre-trained language models (PLMs) require significant computational resources to train from scratch on large volumes of data. But in the real world, emerging data from diverse sources may not be initially available for pre-training. Recent studies on lifelong learning have tried to solve this problem by exploring the use of model growth techniques to effectively incorporate new knowledge without the need for complete re-training. However, model growth approaches utilized have issues with growth operators that do not ensure strict function preservation or growth schedules that only include a few growth dimensions, reducing lifelong learning's effect. Furthermore, existing approaches often assume that emerging data has the same distribution as pre-training data, causing catastrophic forgetting of previously acquired knowledge. To address the aforementioned issues, we introduce LOIRE, a framework for lifelong learning that enables PLMs to effectively grow their capacity using incremental data. LOIRE employs growth operators for all feasible dimensions and a growth schedule to generate the optimal expansion sequence in the field of lifelong learning. Specifically, we present a novel plug-in layer growth operator with residual connections that skip the newly added layer during initial training while ensuring function preservation. We additionally propose an iterative distillation strategy for LOIRE that allows an intermediate model in the growth stages to switch between being a student and a teacher, reducing catastrophic forgetting during growth. Experiments show that LOIRE can reduce computational expenses by an average of 29.22\% while retaining equivalent or better downstream performance.
  abstract_embedding: [0.302734375, -0.091796875, 0.1240234375]... (1536 items)
  authors: ['Xue Han', 'Yitong Wang', 'Junlan Feng']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804813713
  novelty: yes
  reason: Relevance: The paper proposes a novel lifelong learning framework, LOIRE, that enables pre-trained language models to effectively grow their capacity using incremental data, which is relevant for effi...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: LOIRE__LifelOng_learning_on_Incremental_data_via_pre-trained_language_model_gRowth_Efficiently.pdf
  sha_abstract: f852b41e8ca41c243a60b369edceeec52f3c5291e32b0ce076ddf3b1aff8605d
  title: LOIRE: LifelOng learning on Incremental data via pre-trained language model gRowth Efficiently
  title_normalized: loire_lifelong_learning_on_incremental_data_via_pretrained_language_model_growth_efficiently

================================================================================
Document #36 (ID: a62aa017bd7010f69f040a8cf496d121ea10f386310e3a70c29449cfb1b1ad80)
================================================================================
  abstract: Recent advances in Code Large Language Models (CodeLLMs) have primarily focused on open-ended code generation, often overlooking the crucial aspect of code understanding & reasoning. To bridge this gap, we introduce CodeMMLU, a comprehensive multiple-choice benchmark designed to evaluate the depth of software and code comprehension in LLMs. CodeMMLU includes nearly 20,000 questions spanning diverse domains, including code analysis, defect detection, and software engineering principles across multiple programming languages. Unlike traditional benchmarks that emphasize code generation, CodeMMLU assesses a model’s ability to reason about programs across a wide-range of tasks such as code repair, execution reasoning, and fill-in-the-blank challenges. Our extensive evaluation reveals that even state-of-the-art models struggle with CodeMMLU, highlighting significant gaps in comprehension beyond generation. By emphasizing the essential connection between code understanding and effective AI-assisted development, CodeMMLU provides a critical resource for advancing more reliable and capable coding assistants.
  abstract_embedding: [0.4375, 0.0291748046875, 0.390625]... (1536 items)
  authors: ['Dung Manh Nguyen', 'Thang Chau Phan', 'Nam Le Hai']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804825171
  novelty: yes
  reason: Relevance: The paper proposes a new benchmark, CodeMMLU, to evaluate code understanding and reasoning capabilities of CodeLLMs, which is a relevant and important task for AI-assisted development. | No...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CodeMMLU__A_Multi-Task_Benchmark_for_Assessing_Code_Understanding___Reasoning_Capabilities_of_CodeLLMs.pdf
  sha_abstract: 7c84a259afc65efa679d9499ff6a900f1586d356dd47469613a886e159221043
  title: CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding & Reasoning Capabilities of CodeLLMs
  title_normalized: codemmlu_a_multitask_benchmark_for_assessing_code_understanding__reasoning_capabilities_of_codellms

================================================================================
Document #37 (ID: 963aed79017c5346acc77f189bc5da554592bba67fc848c993ead8a151551272)
================================================================================
  abstract: Large-scale latent diffusion models (LDMs) excel in content generation across various modalities, but their reliance on phonemes and durations in text-to-speech (TTS) limits scalability and access from other fields. While recent studies show potential in removing these domain-specific factors, performance remains suboptimal. In this work, we introduce DiTTo-TTS, a Diffusion Transformer (DiT)-based TTS model, to investigate whether LDM-based TTS can achieve state-of-the-art performance without domain-specific factors. Through rigorous analysis and empirical exploration, we find that (1) DiT with minimal modifications outperforms U-Net, (2) variable-length modeling with a speech length predictor significantly improves results over fixed-length approaches, and (3) conditions like semantic alignment in speech latent representations are key to further enhancement. By scaling our training data to 82K hours and the model size to 790M parameters, we achieve superior or comparable zero-shot performance to state-of-the-art TTS models in naturalness, intelligibility, and speaker similarity, all without relying on domain-specific factors. Speech samples are available at https://ditto-tts.github.io.
  abstract_embedding: [0.3125, 0.392578125, 0.1328125]... (1536 items)
  authors: ['Keon Lee', 'Dong Won Kim', 'Jaehyeon Kim']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804811694
  novelty: yes
  reason: Relevance: The paper proposes a novel Diffusion Transformer (DiT)-based TTS model that achieves state-of-the-art performance without relying on domain-specific factors, which is relevant for building ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: DiTTo-TTS__Diffusion_Transformers_for_Scalable_Text-to-Speech_without_Domain-Specific_Factors.pdf
  sha_abstract: 73fd9e3269f52eca5ac6eca6d24e70d4e8dec5781900c25a45bf24bc58a4a45d
  title: DiTTo-TTS: Diffusion Transformers for Scalable Text-to-Speech without Domain-Specific Factors
  title_normalized: dittotts_diffusion_transformers_for_scalable_texttospeech_without_domainspecific_factors

================================================================================
Document #38 (ID: 4367003355d0e5fd094f33d83a7866859a5f6d84a4105070f8de816a1817ef6e)
================================================================================
  abstract: Computational RNA design tasks are often posed as inverse problems, where sequences are designed based on adopting a single desired secondary structure without considering 3D conformational diversity. We introduce gRNAde, a geometric RNA design pipeline operating on 3D RNA backbones to design sequences that explicitly account for structure and dynamics. gRNAde uses a multi-state Graph Neural Network and autoregressive decoding to generates candidate RNA sequences conditioned on one or more 3D backbone structures where the identities of the bases are unknown. On a single-state fixed backbone re-design benchmark of 14 RNA structures from the PDB identified by Das et al. (2010), gRNAde obtains higher native sequence recovery rates (56% on average) compared to Rosetta (45% on average), taking under a second to produce designs compared to the reported hours for Rosetta. We further demonstrate the utility of gRNAde on a new benchmark of multi-state design for structurally flexible RNAs, as well as zero-shot ranking of mutational fitness landscapes in a retrospective analysis of a recent ribozyme. Experimental wet lab validation on 10 different structured RNA backbones finds that gRNAde has a success rate of 50% at designing pseudoknotted RNA structures, a significant advance over 35% for Rosetta. Open source code and tutorials are available at: github.com/chaitjo/geometric-rna-design
  abstract_embedding: [0.421875, 0.61328125, 0.01116943359375]... (1536 items)
  authors: ['Chaitanya K. Joshi', 'Arian Rokkum Jamasb', 'Ramon Viñas Torné']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804822376
  novelty: yes
  reason: Relevance: The paper proposes a novel geometric deep learning model for 3D RNA inverse design, which is a relevant and important problem in computational biology. | Novelty: The proposed gRNAde model ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: gRNAde__Geometric_Deep_Learning_for_3D_RNA_inverse_design.pdf
  sha_abstract: 0c31c653ef5c9e6068f4776a9542c5baef22f8e0ba7a7402670054fb8c72d432
  title: gRNAde: Geometric Deep Learning for 3D RNA inverse design
  title_normalized: grnade_geometric_deep_learning_for_3d_rna_inverse_design

================================================================================
Document #39 (ID: 06a622ef7958c8d898506084e59d55fd3805c7776e1ebcd5fba184fbf85f7d6f)
================================================================================
  abstract: Knowledge distillation (KD) is widely used to train small, high-performing student language models (LMs) using large teacher LMs. 
While effective in fine-tuning, KD during pre-training faces efficiency, flexibility, and effectiveness issues. 
Existing methods either incur high computational costs due to online teacher inference, require tokenization matching between teacher and student LMs, or risk losing the difficulty and diversity of the teacher-generated training data.
In this work, we propose **MiniPLM**, a KD framework for pre-training LMs by refining the training data distribution with the teacher LM's knowledge.
For efficiency, MiniPLM performs offline teacher inference, allowing KD for multiple student LMs without adding training costs.
For flexibility, MiniPLM operates solely on the training corpus, enabling KD across model families.
For effectiveness, MiniPLM leverages the differences between large and small LMs to enhance the training data difficulty and diversity, helping student LMs acquire versatile and sophisticated knowledge.
Extensive experiments demonstrate that MiniPLM boosts the student LMs' performance on 9 common downstream tasks, improves language modeling capabilities, and reduces pre-training computation. 
The benefit of MiniPLM extends to larger training scales, evidenced by the scaling curve extrapolation.
Further analysis reveals that MiniPLM supports KD across model families and enhances the pre-training data utilization. Our code, data, and models can be found at https://github.com/thu-coai/MiniPLM.
  abstract_embedding: [0.4296875, 0.44921875, 0.392578125]... (1536 items)
  authors: ['Yuxian Gu', 'Hao Zhou', 'Fandong Meng']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804804019
  novelty: yes
  reason: Relevance: The paper proposes a novel knowledge distillation framework for pre-training language models, which can improve the performance of small student models while reducing pre-training computati...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MiniPLM__Knowledge_Distillation_for_Pre-training_Language_Models.pdf
  sha_abstract: 23c4a07f43020622c025e4aecec48dd5be474aeb05ee40c87ab7d2d8cc02dfee
  title: MiniPLM: Knowledge Distillation for Pre-training Language Models
  title_normalized: miniplm_knowledge_distillation_for_pretraining_language_models

================================================================================
Document #40 (ID: 73187e15541795259cde374882aece3a615422d583100f9e6f002f81e4ed0eaf)
================================================================================
  abstract: Source-Free Domain Adaptation (SFDA) seeks to adapt a pre-trained source model to the target domain using only unlabeled target data, without access to the original source data. While current state-of-the-art (SOTA) methods rely on leveraging weak supervision from the source model to extract reliable information for self-supervised adaptation, they often overlook the uncertainty that arises during the transfer process.  In this paper, we conduct a systematic and theoretical analysis of the uncertainty inherent in existing SFDA methods and demonstrate its impact on transfer performance through the lens of Distributionally Robust Optimization (DRO). Building upon the theoretical results, we propose a novel instance-dependent uncertainty control algorithm for SFDA.  Our method is designed to quantify and exploit the uncertainty during the adaptation process, significantly improving the model performance.  Extensive experiments on benchmark datasets and empirical analyses confirm the validity of our theoretical findings and the effectiveness of the proposed method. 
This work offers new insights into understanding and advancing SFDA performance.
  abstract_embedding: [0.059326171875, 0.1708984375, 0.2421875]... (1536 items)
  authors: ['Gezheng Xu', 'Hui Guo', 'Li Yi']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804818348
  novelty: yes
  reason: Relevance: The paper proposes a novel uncertainty-aware algorithm for source-free domain adaptation, which is a relevant technique for improving the efficiency and performance of ML models. | Novelty:...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Revisiting_Source-Free_Domain_Adaptation__a_New_Perspective_via_Uncertainty_Control.pdf
  sha_abstract: 9edd2cbee5eee62d631d4d75352e59f0afa372e1f47aa713247598b6116d5eeb
  title: Revisiting Source-Free Domain Adaptation: a New Perspective via Uncertainty Control
  title_normalized: revisiting_sourcefree_domain_adaptation_a_new_perspective_via_uncertainty_control

================================================================================
Document #41 (ID: d71157c3ec07008d2b2d98367274bcf16525dfb2cb84cbc72aaf5b6ed0738042)
================================================================================
  abstract: The linear representation hypothesis is the informal idea that semantic concepts are encoded as linear directions in the representation spaces of large language models (LLMs). Previous work has shown how to make this notion precise for representing binary concepts that have natural contrasts (e.g., {male, female}) as _directions_ in representation space. However, many natural concepts do not have natural contrasts (e.g., whether the output is about an animal). In this work, we show how to extend the formalization of the linear representation hypothesis to represent features (e.g., is_animal) as _vectors_. This allows us to immediately formalize the representation of categorical concepts as polytopes in the representation space. Further, we use the formalization to prove a relationship between the hierarchical structure of concepts and the geometry of their representations. We validate these theoretical results on the Gemma and LLaMA-3 large language models, estimating representations for 900+ hierarchically related concepts using data from WordNet.
  abstract_embedding: [0.375, 0.310546875, 0.162109375]... (1536 items)
  authors: ['Kiho Park', 'Yo Joong Choe', 'Yibo Jiang']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804816067
  novelty: yes
  reason: Relevance: The paper proposes a novel formalization of the linear representation hypothesis to represent categorical and hierarchical concepts in large language models, which is relevant for innovativ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: The_Geometry_of_Categorical_and_Hierarchical_Concepts_in_Large_Language_Models.pdf
  sha_abstract: ff9619a534f988084b6fe5f74f7ab4d483ce2bee2270b198b94dc11b65fb3240
  title: The Geometry of Categorical and Hierarchical Concepts in Large Language Models
  title_normalized: the_geometry_of_categorical_and_hierarchical_concepts_in_large_language_models

================================================================================
Document #42 (ID: 3bc1d826e01670448405a8ffdde8ceaadb230cd30b0bed3c4a16c826f485d092)
================================================================================
  abstract: Existing score-based adversarial attacks mainly focus on crafting $top$-1 adversarial examples against classifiers with single-label classification. Their attack success rate and query efficiency are often less than satisfactory, particularly under small perturbation requirements; moreover, the vulnerability of classifiers with multi-label learning is yet to be studied. In this paper, we propose a comprehensive surrogate free score-based attack, named \b geometric \b score-based \b black-box \b attack (GSBA$^K$), to craft adversarial examples in an aggressive $top$-$K$ setting for both untargeted and targeted attacks, where the goal is to change the $top$-$K$ predictions of the target classifier. We introduce novel gradient-based methods to find a good initial boundary point to attack. Our iterative method employs novel gradient estimation techniques, particularly effective in $top$-$K$ setting, on the decision boundary to effectively exploit the geometry of the decision boundary. Additionally, GSBA$^K$ can be used to attack against classifiers with $top$-$K$ multi-label learning. Extensive experiential results on ImageNet and PASCAL VOC datasets validate the effectiveness of GSBA$^K$ in crafting $top$-$K$ adversarial examples.
  abstract_embedding: [0.765625, 0.67578125, -0.051025390625]... (1536 items)
  authors: ['Md Farhamdur Reza', 'Richeng Jin', 'Tianfu Wu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804820431
  novelty: yes
  reason: Relevance: The paper proposes a novel score-based black-box attack method, GSBA^K, that can craft adversarial examples in a top-K setting for both untargeted and targeted attacks, including for multi-...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: GSBA__K____top_-_K__Geometric_Score-based_Black-box_Attack.pdf
  sha_abstract: f09b3395f84981e9b7b337ab65749e2dd3b2c124f2d47ce7bed7f13f80b627e0
  title: GSBA$^K$: $top$-$K$ Geometric Score-based Black-box Attack
  title_normalized: gsbak_topk_geometric_scorebased_blackbox_attack

================================================================================
Document #43 (ID: 4c66fc83d2b7b17518428fa1be22dfcf037ca1a34f313035c8a9c6817d7bdbc2)
================================================================================
  abstract: We present a novel framework, StochastIc Network Graph Evolving operatoR (SINGER), for learning the evolution operator of high-dimensional partial differential equations (PDEs). The framework uses a sub-network to approximate the solution at the initial time step and stochastically evolves the sub-network parameters over time by a graph neural network to approximate the solution at later time steps. The framework is designed to inherit the desirable properties of the parametric solution operator, including graph topology, semigroup, and stability, with a theoretical guarantee. Numerical experiments on 8 evolution PDEs of 5,10,15,20-dimensions show that our method outperforms existing baselines in almost all cases (31 out of 32), and that our method generalizes well to unseen initial conditions, equation dimensions, sub-network width, and time steps.
  abstract_embedding: [0.291015625, 0.4453125, -0.212890625]... (1536 items)
  authors: ['Mingquan Feng', 'Yixin Huang', 'Weixin Liao']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804809319
  novelty: yes
  reason: Relevance: The paper proposes a novel graph neural network-based framework for learning the evolution operator of high-dimensional PDEs, which is relevant for innovative model architectures and traini...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SINGER__Stochastic_Network_Graph_Evolving_Operator_for_High_Dimensional_PDEs.pdf
  sha_abstract: b04c6c4799ed42a5aae0b811473dfe01f0a9bac59403e97dd062a9b07ba0afa5
  title: SINGER: Stochastic Network Graph Evolving Operator for High Dimensional PDEs
  title_normalized: singer_stochastic_network_graph_evolving_operator_for_high_dimensional_pdes

================================================================================
Document #44 (ID: 1320992d439d2e878c85e12fd0ca9b908a74f7cd1cf70f9f0dd6b4e7ce2de034)
================================================================================
  abstract: While large models trained with self-supervised learning on offline datasets have shown remarkable capabilities in text and image domains, achieving the same generalisation for agents that act in sequential decision problems remains an open challenge.
In this work, we take a step towards this goal by procedurally generating tens of millions of 2D physics-based tasks and using these to train a general reinforcement learning (RL) agent for physical control.
To this end, we introduce Kinetix: an open-ended space of physics-based RL environments that can represent tasks ranging from robotic locomotion and grasping to video games and classic RL environments, all within a unified framework.
Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.
Our trained agent exhibits strong physical reasoning capabilities in 2D space, being able to zero-shot solve unseen human-designed environments.  Furthermore, fine-tuning this general agent on tasks of interest shows significantly stronger performance than training an RL agent *tabula rasa*.  This includes solving some environments that standard RL training completely fails at.
We believe this demonstrates the feasibility of large scale, mixed-quality pre-training for online RL and we hope that Kinetix will serve as a useful framework to investigate this further.
  abstract_embedding: [0.8203125, 0.0703125, 0.2216796875]... (1536 items)
  authors: ['Michael Matthews', 'Michael Beukman', 'Chris Lu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804833856
  novelty: yes
  reason: Relevance: The paper proposes a novel open-ended physics-based reinforcement learning environment called Kinetix, which can be used to train general agents for physical control tasks. | Novelty: The K...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Kinetix__Investigating_the_Training_of_General_Agents_through_Open-Ended_Physics-Based_Control_Tasks.pdf
  sha_abstract: f9d2afdf2f1cea0add90a53b65ba25d7fde924656920b7edd8562aadb7f0567a
  title: Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks
  title_normalized: kinetix_investigating_the_training_of_general_agents_through_openended_physicsbased_control_tasks

================================================================================
Document #45 (ID: 1cff8ae64db30bcb2494171c22828f3ae4f22ca0ff1081950e7bde6b759068f2)
================================================================================
  abstract: The goal of the AlgoPerf: Training Algorithms competition is to evaluate practical speed-ups in neural network training achieved solely by improving the underlying training algorithms. In the external tuning ruleset, submissions must provide workload-agnostic hyperparameter search spaces, while in the self-tuning ruleset they must be completely hyperparameter-free. In both rulesets, submissions are compared on time-to-result across multiple deep learning workloads, training on fixed hardware. This paper presents the inaugural AlgoPerf competition's results, which drew 18 diverse submissions from 10 teams. Our investigation reveals several key findings: (1) The winning submission in the external tuning ruleset, using Distributed Shampoo, demonstrates the effectiveness of non-diagonal preconditioning over popular methods like Adam, even when compared on wall-clock runtime. (2) The winning submission in the self-tuning ruleset, based on the Schedule Free AdamW algorithm, demonstrates a new level of effectiveness for completely hyperparameter-free training algorithms. (3) The top-scoring submissions were surprisingly robust to workload changes. We also discuss the engineering challenges encountered in ensuring a fair comparison between different training algorithms. These results highlight both the significant progress so far, and the considerable room for further improvements.
  abstract_embedding: [0.25390625, 0.423828125, 0.2265625]... (1536 items)
  authors: ['Priya Kasimbeg', 'Frank Schneider', 'Runa Eschenhagen']... (14 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804847765
  novelty: yes
  reason: Relevance: The paper proposes new training algorithms, Distributed Shampoo and Schedule Free AdamW, which demonstrate significant improvements in training speed and efficiency. | Novelty: The proposed...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Accelerating_neural_network_training__An_analysis_of_the_AlgoPerf_competition.pdf
  sha_abstract: 9fb05590bc9e1220bd9a98d70ee6831abce0b997134773d382eac86d490524ac
  title: Accelerating neural network training: An analysis of the AlgoPerf competition
  title_normalized: accelerating_neural_network_training_an_analysis_of_the_algoperf_competition

================================================================================
Document #46 (ID: 36840e0f13b614ff77e8a461a961731dacd85d8356329dcaa8d12e14f8793ed4)
================================================================================
  abstract: In response to the call for agent-based solutions that leverage the ever-increasing capabilities of the deep models' ecosystem, we introduce a comprehensive solution for selecting appropriate models and subsequently planning a set of atomic actions to satisfy the end-users' instructions.

Our system, Hive, operates over sets of models and, upon receiving natural language instructions, schedules and executes, explainable plans of atomic actions. These actions can involve one or more of the available models to achieve the overall task, while respecting end-users specific constraints. Hive is able to plan complex chains of actions while guaranteeing explainability, using an LLM-based formal logic backbone empowered by PDDL operations. We introduce the MuSE benchmark in order to offer a comprehensive evaluation of the multi-modal capabilities of agent systems. Our findings show that our framework redefines the state-of-the-art for task selection, outperforming other competing systems that plan operations across multiple models while offering transparency guarantees while fully adhering to user constraints.
  abstract_embedding: [0.8515625, 0.06103515625, 0.447265625]... (1536 items)
  authors: ['Kaustubh Vyas', 'Damien Graux', 'Yijun Yang']... (11 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804829438
  novelty: yes
  reason: Relevance: The paper proposes a novel system, Hive, that leverages multiple models to plan and execute complex sequences of actions to satisfy user instructions, while providing explainability and adh...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: From_an_LLM_Swarm_to_a_PDDL-empowered_Hive__Planning_Self-executed_Instructions_in_a_Multi-modal_Jungle.pdf
  sha_abstract: b4a622954b6e7560e33006a2eb89c6174322b980169809f88b9b2a00cd3663dd
  title: From an LLM Swarm to a PDDL-empowered Hive: Planning Self-executed Instructions in a Multi-modal Jungle
  title_normalized: from_an_llm_swarm_to_a_pddlempowered_hive_planning_selfexecuted_instructions_in_a_multimodal_jungle

================================================================================
Document #47 (ID: 0397c3b3c2aa2b09553687ea02531f5bbfa36675d3e4718a8e78d2d7ddc5fb76)
================================================================================
  abstract: Real-time instruction-based portrait image editing is crucial in various applications, including filters, augmented reality, and video communications, etc. However, real-time portrait editing presents three significant challenges: identity preservation, fidelity to editing instructions, and fast model inference. Given that these aspects often present a trade-off, concurrently addressing them poses an even greater challenge. While diffusion-based image editing methods have shown promising capabilities in personalized image editing in recent years, they lack a dedicated focus on portrait editing and thus suffer from the aforementioned problems as well. To address the gap, this paper introduces an Instant-Portrait Network (IPNet), the first one-step diffusion-based model for portrait editing. We train the network in two stages. We first employ an annealing identity loss to train an Identity Enhancement Network (IDE-Net), to ensure robust identity preservation. We then train the IPNet using a novel diffusion Multi-Objective Distillation approach that integrates adversarial loss, identity distillation loss, and a novel Facial-Style Enhancing loss. The Diffusion Multi-Objective Distillation approach efficiently reduces inference steps, ensures identity consistency, and enhances the precision of instruction-based editing. Extensive comparison with prior models demonstrates IPNet as a superior model in terms of identity preservation, text fidelity, and inference speed.
  abstract_embedding: [0.031494140625, 0.60546875, 0.039306640625]... (1536 items)
  authors: ['Zhixin Lai', 'Keqiang Sun', 'Fu-Yun Wang']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804831947
  novelty: yes
  reason: Relevance: The paper proposes a novel diffusion-based model for real-time portrait editing, addressing key challenges like identity preservation, fidelity to editing instructions, and fast inference. ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: InstantPortrait__One-Step_Portrait_Editing_via_Diffusion_Multi-Objective_Distillation.pdf
  sha_abstract: a96a8d7ce5169f7c148e3963356c95e372419b327c7c667c395ace49f4ed295b
  title: InstantPortrait: One-Step Portrait Editing via Diffusion Multi-Objective Distillation
  title_normalized: instantportrait_onestep_portrait_editing_via_diffusion_multiobjective_distillation

================================================================================
Document #48 (ID: 5cc7cccd445ee7c040c4d528753144c502db3ae08bd3131306fd1aa7e63fdf8c)
================================================================================
  abstract: Policy gradient methods have become a staple of any single-agent reinforcement learning toolbox, due to their combination of desirable properties: iterate convergence, efficient use of stochastic trajectory feedback, and theoretically-sound avoidance of importance sampling corrections. In multi-agent imperfect-information settings (extensive-form games), however, it is still unknown whether the same desiderata can be guaranteed while retaining theoretical guarantees. Instead, sound methods for extensive-form games rely on approximating \emph{counterfactual} values (as opposed to Q values), which are incompatible with policy gradient methodologies. In this paper, we investigate whether policy gradient can be safely used in two-player zero-sum imperfect-information extensive-form games (EFGs). We establish positive results, showing for the first time that a policy gradient method leads to provable best-iterate convergence to a regularized Nash equilibrium in self-play.
  abstract_embedding: [0.82421875, 0.58203125, 0.04052734375]... (1536 items)
  authors: ['Mingyang Liu', 'Gabriele Farina', 'Asuman E. Ozdaglar']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804839610
  novelty: yes
  reason: Relevance: The paper proposes a novel policy gradient method for solving imperfect-information games, which is relevant to ML research and applications. | Novelty: The paper claims to be the first to ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: A_Policy-Gradient_Approach_to_Solving_Imperfect-Information_Games_with_Best-Iterate_Convergence.pdf
  sha_abstract: dd9845131d8bb2a36793379f26ab197675b30b0e5e8bd9ea51e564092fc8488e
  title: A Policy-Gradient Approach to Solving Imperfect-Information Games with Best-Iterate Convergence
  title_normalized: a_policygradient_approach_to_solving_imperfectinformation_games_with_bestiterate_convergence

================================================================================
Document #49 (ID: 8ecffa150f5bd90b0540b663ad572b13ba7146f4cc35cb7649405d25d2ab424c)
================================================================================
  abstract: We study how to subvert large language models (LLMs) from following prompt-specified rules.
We first formalize rule-following as inference in propositional Horn logic, a mathematical system in which rules have the form "if $P$ and $Q$, then $R$" for some propositions $P$, $Q$, and $R$.
Next, we prove that although small transformers can faithfully follow such rules, maliciously crafted prompts can still mislead both theoretical constructions and models learned from data.
Furthermore, we demonstrate that popular attack algorithms on LLMs find adversarial prompts and induce attention patterns that align with our theory.
Our novel logic-based framework provides a foundation for studying LLMs in rule-based settings, enabling a formal analysis of tasks like logical reasoning and jailbreak attacks.
  abstract_embedding: [0.451171875, 0.484375, 0.123046875]... (1536 items)
  authors: ['Anton Xue', 'Avishree Khare', 'Rajeev Alur']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804837559
  novelty: yes
  reason: Relevance: The paper proposes a novel framework for studying the subversion of rule-based inference in large language models, which is relevant for understanding the limitations and potential vulnerab...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Logicbreaks__A_Framework_for_Understanding_Subversion_of_Rule-based_Inference.pdf
  sha_abstract: c982b81ee78494ed44f81e4941d28b05bdcbd6f99ab84bc6cf2ce91582dae93c
  title: Logicbreaks: A Framework for Understanding Subversion of Rule-based Inference
  title_normalized: logicbreaks_a_framework_for_understanding_subversion_of_rulebased_inference

================================================================================
Document #50 (ID: 689acbe839ae3069e9bae9941a3e8eac6fcda10c02bb97b9b141e2d3ec1150aa)
================================================================================
  abstract: Uncertainty quantification in time series prediction is challenging due to the temporal dependence and distribution shift on sequential data. Conformal prediction provides a pivotal and flexible instrument for assessing the uncertainty of machine learning models through prediction sets. Recently, a series of online conformal inference methods updated thresholds of prediction sets by performing online gradient descent on a sequence of quantile loss functions. A drawback of such methods is that they only use the information of revealed non-conformity scores via miscoverage indicators but ignore error quantification, namely the distance between the non-conformity score and the current threshold. To accurately leverage the dynamic of miscoverage error, we propose Error-quantified Conformal Inference (ECI) by smoothing the quantile loss function. ECI introduces a continuous and adaptive feedback scale with the miscoverage error, rather than simple binary feedback in existing methods. We establish a long-term coverage guarantee for ECI under arbitrary dependence and distribution shift. The extensive experimental results show that ECI can achieve valid miscoverage control and output tighter prediction sets than other baselines.
  abstract_embedding: [0.54296875, 0.439453125, 0.62109375]... (1536 items)
  authors: ['Junxi Wu', 'Dongjian Hu', 'Yajie Bao']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804852071
  novelty: yes
  reason: Relevance: The paper proposes a new conformal inference method for time series prediction that leverages error quantification to improve uncertainty quantification. | Novelty: The proposed Error-quant...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Error-quantified_Conformal_Inference_for_Time_Series.pdf
  sha_abstract: be0cd2ad4210cab9a8aa0cab80ba26703c58ab0ad93709d52258aea4d0a3522e
  title: Error-quantified Conformal Inference for Time Series
  title_normalized: errorquantified_conformal_inference_for_time_series

================================================================================
Document #51 (ID: 93b6a0d1cc6d52e1038eacce505fc414c2c7fcbfe870847dfe84d0a972e8fdd1)
================================================================================
  abstract: Memorization in language models is typically treated as a homogenous phenomenon, neglecting the specifics of the memorized data. We instead model memorization as the effect of a set of complex factors that describe each sample and relate it to the model and corpus. To build intuition around these factors, we break memorization down into a taxonomy: recitation of highly duplicated sequences, reconstruction of inherently predictable sequences, and recollection of sequences that are neither. We demonstrate the usefulness of our taxonomy by using it to construct a predictive model for memorization. By analyzing dependencies and inspecting the weights of the predictive model, we find that different factors have different influences on the likelihood of memorization depending on the taxonomic category.
  abstract_embedding: [0.30859375, 0.30859375, -0.263671875]... (1536 items)
  authors: ['USVSN Sai Prashanth', 'Alvin Deng', "Kyle O'Brien"]... (12 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804841159
  novelty: yes
  reason: Relevance: The paper proposes a novel taxonomy for modeling memorization in language models, which could lead to innovative training and fine-tuning techniques. | Novelty: The proposed taxonomy for un...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Recite__Reconstruct__Recollect__Memorization_in_LMs_as_a_Multifaceted_Phenomenon.pdf
  sha_abstract: f478eb2ea9eaebe040e47758bd9f448039cb741aa313358df9d9c28a00a004be
  title: Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon
  title_normalized: recite_reconstruct_recollect_memorization_in_lms_as_a_multifaceted_phenomenon

================================================================================
Document #52 (ID: 787f26f78fc1d5ef95526d4f2869d2f778f23a545eb95242aa131be4e07ca7ae)
================================================================================
  abstract: High-quality sentence embeddings are fundamental in many natural language processing (NLP) tasks, such as semantic textual similarity (STS) and retrieval-augmented generation (RAG). However, most existing methods leverage fixed-length sentence embeddings from full-layer language models, which lack the scalability to accommodate the diverse available resources across various applications. Viewing this gap, we propose a novel sentence embedding model Espresso Sentence Embeddings (ESE) with two learning processes. First, the learn-to-express process encodes more salient representations to shallow layers. Second, the learn-to-compress process compacts essential features into the initial dimensions using Principal Component Analysis (PCA). This way, ESE can scale model depth via the former process and embedding size via the latter. Extensive experiments on STS and RAG suggest that ESE can effectively produce high-quality sentence embeddings with less model depth and embedding size, enhancing inference efficiency. The code is available at https://github.com/SeanLee97/AnglE/blob/main/README_ESE.md.
  abstract_embedding: [-0.000263214111328125, 0.17578125, 0.181640625]... (1536 items)
  authors: ['Xianming LI', 'Zongxi Li', 'Jing Li']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804835750
  novelty: yes
  reason: Relevance: The paper proposes a novel sentence embedding model, ESE, that improves inference efficiency through two learning processes. | Novelty: ESE introduces a new approach to sentence embedding t...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ESE__Espresso_Sentence_Embeddings.pdf
  sha_abstract: 92e9e57e8e4c12d3c026452753744eb6b2fee5606dbe57c9d2738d5d4e9edd26
  title: ESE: Espresso Sentence Embeddings
  title_normalized: ese_espresso_sentence_embeddings

================================================================================
Document #53 (ID: 3cb68a3b0ff1508e031a267a52796259ee8d8976665e4e661c5f02821f365daf)
================================================================================
  abstract: Large Language Models (LLMs) demonstrate strong reasoning abilities but face limitations such as hallucinations and outdated knowledge. Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by grounding LLM outputs in structured external knowledge from KGs. However, current KG-based RAG frameworks still struggle to optimize the trade-off between retrieval effectiveness and efficiency in identifying a suitable amount of relevant graph information for the LLM to digest. We introduce SubgraphRAG, extending the KG-based RAG framework that retrieves subgraphs and leverages LLMs for reasoning and answer prediction. Our approach innovatively integrates a lightweight multilayer perceptron (MLP) with a parallel triple-scoring mechanism for efficient and flexible subgraph retrieval while encoding directional structural distances to enhance retrieval effectiveness. The size of retrieved subgraphs can be flexibly adjusted to match the query's needs and the downstream LLM's capabilities. This design strikes a balance between model complexity and reasoning power, enabling scalable and generalizable retrieval processes. Notably, based on our retrieved subgraphs, smaller LLMs like Llama3.1-8B-Instruct deliver competitive results with explainable reasoning, while larger models like GPT-4o achieve state-of-the-art accuracy compared with previous baselines—all without fine-tuning. Extensive evaluations on the WebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency, accuracy, and reliability by reducing hallucinations and improving response grounding.
  abstract_embedding: [0.291015625, 0.5390625, 0.1103515625]... (1536 items)
  authors: ['Mufei Li', 'Siqi Miao', 'Pan Li']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804854454
  novelty: yes
  reason: Relevance: The paper proposes a novel KG-based retrieval-augmented generation framework that integrates a lightweight MLP and a parallel triple-scoring mechanism for efficient and flexible subgraph re...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Simple_is_Effective__The_Roles_of_Graphs_and_Large_Language_Models_in_Knowledge-Graph-Based_Retrieval-Augmented_Generation.pdf
  sha_abstract: 769e9d84cbba59762d0169d2ab6a7c2054036dee91322204bc5ba0606ad0194c
  title: Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation
  title_normalized: simple_is_effective_the_roles_of_graphs_and_large_language_models_in_knowledgegraphbased_retrievalaugmented_generation

================================================================================
Document #54 (ID: 7f11ad60155f8a7705122359898366cbe1b28ceb74888cf940827a357d77508b)
================================================================================
  abstract: Large language models (LLMs) have achieved reasonable quality improvements in machine translation (MT).
However, most current research on MT-LLMs still faces significant challenges in maintaining translation consistency and accuracy when processing entire documents.
In this paper, we introduce DelTA, a Document-levEL Translation Agent designed to overcome these limitations.
DelTA features a multi-level memory structure that stores information across various granularities and spans, including Proper Noun Records, Bilingual Summary, Long-Term Memory, and Short-Term Memory, which are continuously retrieved and updated by auxiliary LLM-based components.
Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets, achieving an increase in consistency scores by up to 4.58 percentage points and in COMET scores by up to 3.16 points on average.
DelTA employs a sentence-by-sentence translation strategy, ensuring no sentence omissions and offering a memory-efficient solution compared to the mainstream method.
Furthermore, DelTA improves pronoun and context-dependent translation accuracy, and the summary component of the agent also shows promise as a tool for query-based summarization tasks.
The code and data of our approach are released at https://github.com/YutongWang1216/DocMTAgent.
  abstract_embedding: [0.89453125, 0.0247802734375, -0.04833984375]... (1536 items)
  authors: ['Yutong Wang', 'Jiali Zeng', 'Xuebo Liu']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804860457
  novelty: yes
  reason: Relevance: The paper proposes a novel multi-level memory architecture for document-level machine translation, which is an innovative model architecture that could be valuable to implement and train on...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: DelTA__An_Online_Document-Level_Translation_Agent_Based_on_Multi-Level_Memory.pdf
  sha_abstract: f5aee9f167eb47888090f3c8ed664c0fea08c93410f1296da9a2eaf3e0521126
  title: DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory
  title_normalized: delta_an_online_documentlevel_translation_agent_based_on_multilevel_memory

================================================================================
Document #55 (ID: 95146dad3e5e58eca6ab18d7ef89b61cf045e5d5f12db2953525c1520b431738)
================================================================================
  abstract: There have been extensive studies on learning in zero-sum games, focusing on the analysis of the existence and algorithmic convergence of Nash equilibrium (NE). Existing studies mainly focus on symmetric games where the strategy spaces of the players are of the same type and size. For the few studies that do consider asymmetric games, they are mostly restricted to matrix games. In this paper, we define and study a new practical class of asymmetric games called two-player Asymmetric Combinatorial-Continuous zEro-Sum (ACCES) games, featuring a combinatorial action space for one player and an infinite compact space for the other. Such ACCES games have broad implications in the real world, particularly in combinatorial optimization problems (COPs) where one player optimizes a solution in a combinatorial space, and the opponent plays against it in an infinite (continuous) compact space (e.g., a nature player deciding epistemic parameters of the environmental model). Our first key contribution is to prove the existence of NE for two-player ACCES games, using the idea of essentially finite game approximation. Building on the theoretical insights and double oracle (DO)-based solutions to complex zero-sum games, our second contribution is to design the novel algorithm, Combinatorial Continuous DO (CCDO), to solve ACCES games, and prove the convergence of the proposed algorithm. Considering the NP-hardness of most COPs and recent advancements in reinforcement learning (RL)-based solutions to COPs, our third contribution is to propose a practical algorithm to solve NE in the real world, CCDORL (based on CCDO) and provide the novel convergence analysis in the ACCES game. Experimental results across diverse instances of COPs demonstrate the empirical effectiveness of our algorithms.
  abstract_embedding: [0.66015625, 0.6015625, 0.041015625]... (1536 items)
  authors: ['Yuheng Li', 'Wang Panpan', 'Haipeng Chen']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804870453
  novelty: yes
  reason: Relevance: The paper proposes a novel algorithm (CCDO) to solve asymmetric combinatorial-continuous zero-sum games, which is relevant for combinatorial optimization problems. | Novelty: The paper intr...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Can_Reinforcement_Learning_Solve_Asymmetric_Combinatorial-Continuous_Zero-Sum_Games_.pdf
  sha_abstract: 54382e7b22f4f15396731719718759210758e9f412e53e0fdf923bbe5e93ea1a
  title: Can Reinforcement Learning Solve Asymmetric Combinatorial-Continuous Zero-Sum Games?
  title_normalized: can_reinforcement_learning_solve_asymmetric_combinatorialcontinuous_zerosum_games

================================================================================
Document #56 (ID: a2b92be0bbfdb0572159213f1c076a63008d0f5c999212e2a365b55ee353d115)
================================================================================
  abstract: Ensuring that generative AI systems align with human values is essential but challenging, especially when considering multiple human values and their potential trade-offs. Since human values can be personalized and dynamically change over time, the desirable levels of value alignment vary across different ethnic groups, industry sectors, and user cohorts. Within existing frameworks, it is hard to define human values and align AI systems accordingly across different directions simultaneously, such as harmlessness, helpfulness, and positiveness. To address this, we develop a novel, first-principle approach called Multi-Human-Value Alignment Palette (MAP), which navigates the alignment across multiple human values in a structured and reliable way. MAP formulates the alignment problem as an optimization task with user-defined constraints, which define human value targets. It can be efficiently solved via a primal-dual approach, which determines whether a user-defined alignment target is achievable and how to achieve it. We conduct a detailed theoretical analysis of MAP by quantifying the trade-offs between values, the sensitivity to constraints, the fundamental connection between multi-value alignment and sequential alignment, and proving that linear weighted rewards are sufficient for multi-value alignment. Extensive experiments demonstrate MAP's ability to align multiple values in a principled manner while delivering strong empirical performance across various tasks.
  abstract_embedding: [1.2578125, 0.490234375, 0.259765625]... (1536 items)
  authors: ['Xinran Wang', 'Qi Le', 'Ammar Ahmed']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804863547
  novelty: yes
  reason: Relevance: The paper proposes a novel approach called Multi-Human-Value Alignment Palette (MAP) that aims to align generative AI systems with multiple human values, which is a relevant and important p...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MAP__Multi-Human-Value_Alignment_Palette.pdf
  sha_abstract: a65c1b15145123c0b86f1dbd80ffb6423b7733a839681a30f91c9c5deaebdce8
  title: MAP: Multi-Human-Value Alignment Palette
  title_normalized: map_multihumanvalue_alignment_palette

================================================================================
Document #57 (ID: e37b4dc5f16d6eb0dc8a8e02f4e4734e766483fcab0fbcd18ca7777f83909e29)
================================================================================
  abstract: Autoregressive (AR) Large Language Models (LLMs) have demonstrated significant success across numerous tasks. However, the AR modeling paradigm presents certain limitations; for instance, contemporary autoregressive LLMs are trained to generate one token at a time, which can result in noticeable latency. Recent advances have indicated that search and repeated sampling can enhance performance in various applications, such as theorem proving, code generation, and alignment, by utilizing greater computational resources during inference. In this study, we demonstrate that diffusion language models are capable of generating at least 32 tokens simultaneously, while exceeding the performance of AR models in text quality and on the LAMBADA natural language understanding benchmark. This outcome is achieved through a novel distillation method for discrete diffusion models, which reduces the number of inference steps by a factor of 32-64. Practically, at the 1.3B parameters scale, diffusion models, even without caching, can generate tokens at a rate that is up to 8 times faster than AR models employing KV-caching, and we anticipate further improvements with the inclusion of caching. Moreover, we demonstrate the efficacy of our approach for diffusion language models with up to 860M parameters.
  abstract_embedding: [0.33203125, 0.4140625, 0.388671875]... (1536 items)
  authors: ['Justin Deschenaux', 'Caglar Gulcehre']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804872429
  novelty: yes
  reason: Relevance: The paper proposes a novel distillation method for discrete diffusion language models that can generate multiple tokens simultaneously, improving performance and inference speed compared to...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Beyond_Autoregression__Fast_LLMs_via_Self-Distillation_Through_Time.pdf
  sha_abstract: 6b0f0cb1f749c4c6c02f0505c93b074859e385a2286ec43f87add1f4451d7d21
  title: Beyond Autoregression: Fast LLMs via Self-Distillation Through Time
  title_normalized: beyond_autoregression_fast_llms_via_selfdistillation_through_time

================================================================================
Document #58 (ID: 48b5345129512d9925889cc5078e1fee97d1c6517b48052884dc5f8e5b1f82dd)
================================================================================
  abstract: Data heterogeneity and backdoor attacks rank among the most significant challenges facing federated learning (FL). For data heterogeneity, personalized federated learning (PFL) enables each client to maintain a private personalized model to cater to client-specific knowledge. Meanwhile, vanilla FL has proven vulnerable to backdoor attacks. However, recent advancements in PFL community have demonstrated a potential immunity against such attacks. This paper explores this intersection further, revealing that existing federated backdoor attacks fail in PFL because backdoors about manually designed triggers struggle to survive in personalized models. To tackle this, we degisn Bad-PFL, which employs features from natural data as our trigger. As long as the model is trained on natural data, it inevitably embeds the backdoor associated with our trigger, ensuring its longevity in personalized models. Moreover, our trigger undergoes mutual reinforcement training with the model, further solidifying the backdoor's durability and enhancing attack effectiveness. The large-scale experiments across three benchmark datasets demonstrate the superior performance of Bad-PFL against various PFL methods, even when equipped with state-of-the-art defense mechanisms.
  abstract_embedding: [0.36328125, 1.09375, -0.045654296875]... (1536 items)
  authors: ['Mingyuan Fan', 'Zhanyi Hu', 'Fuyi Wang']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804856739
  novelty: yes
  reason: Relevance: The paper proposes a new backdoor attack technique, Bad-PFL, that exploits personalized federated learning models, which is a novel and relevant ML technique. | Novelty: The proposed Bad-PF...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Bad-PFL__Exploiting_Backdoor_Attacks_against_Personalized_Federated_Learning.pdf
  sha_abstract: a8f5ec28d25113135fac317e7d8093af5019b552e899e1d3ce3cf46b3d98c4e8
  title: Bad-PFL: Exploiting Backdoor Attacks against Personalized Federated Learning
  title_normalized: badpfl_exploiting_backdoor_attacks_against_personalized_federated_learning

================================================================================
Document #59 (ID: 96b199de2111b7f4f4983c52c757116ca9be8d5a8d13248c301e79904b3cd62e)
================================================================================
  abstract: As language models (LMs) approach human-level performance, a comprehensive understanding of their behavior becomes crucial. 
This includes evaluating capabilities, biases, task performance, and alignment with societal values. Extensive initial evaluations, including red teaming and diverse benchmarking, can establish a model’s behavioral profile. However, subsequent fine-tuning or deployment modifications may alter these behaviors in unintended ways. We present an efficient statistical test to tackle Behavioral Shift Auditing (BSA) in LMs, which we define as detecting distribution shifts in qualitative properties of the output distributions of LMs. Our test compares model generations from a baseline model to those of the model under scrutiny and provides theoretical guarantees for change detection while controlling false positives. The test features a configurable tolerance parameter that adjusts sensitivity to behavioral changes for different use cases. We evaluate our approach using two case studies: monitoring changes in (a) toxicity and (b) translation performance. We find that the test is able to detect meaningful changes in behavior distributions using just hundreds of examples.
  abstract_embedding: [0.65234375, 0.2138671875, 0.1953125]... (1536 items)
  authors: ['Leo Richter', 'Xuanli He', 'Pasquale Minervini']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804868478
  novelty: yes
  reason: Relevance: The paper proposes a novel statistical test to detect behavioral shifts in language models, which is a critical capability for monitoring and maintaining model alignment. | Novelty: The pro...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: An_Auditing_Test_to_Detect_Behavioral_Shift_in_Language_Models.pdf
  sha_abstract: ef85147ce8f1a88c04e272d3a7db87431f5f4acd43e0e59f2d0f5fad7e574a35
  title: An Auditing Test to Detect Behavioral Shift in Language Models
  title_normalized: an_auditing_test_to_detect_behavioral_shift_in_language_models

================================================================================
Document #60 (ID: 6a0e3c96f5d18a770da676e5db3d6cfb64ec1083ebbd9d513414433234641b98)
================================================================================
  abstract: Accurate prediction of thermodynamic properties is essential in drug discovery and materials science. Molecular dynamics (MD) simulations provide a principled approach to this task, yet they typically rely on prohibitively long sequential simulations. Implicit Transfer Operator (ITO) Learning offers a promising approach to address this limitation by enabling stable simulation with time steps orders of magnitude larger than MD. However, to train ITOs, we need extensive, unbiased MD data, limiting the scope of this framework. Here, we introduce Boltzmann Priors for ITO (BoPITO) to enhance ITO learning in two ways. First, BoPITO enables more efficient data generation, and second, it embeds inductive biases for long-term dynamical behavior, simultaneously improving sample efficiency by one order of magnitude and guaranteeing asymptotically unbiased equilibrium statistics. Furthermore, we showcase the use of BoPITO in a new tunable sampling protocol interpolating between ITOs trained on off-equilibrium simulations and an equilibrium model by incorporating unbiased correlation functions. Code is available at https://github.com/olsson-group/bopito.
  abstract_embedding: [-0.1337890625, 0.62109375, 0.29296875]... (1536 items)
  authors: ['Juan Viguera Diez', 'Mathias Jacob Schreiner', 'Ola Engkvist']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804858515
  novelty: yes
  reason: Relevance: The paper proposes a novel Boltzmann prior for Implicit Transfer Operator (ITO) learning, which can improve the efficiency and accuracy of molecular dynamics simulations. | Novelty: The Bol...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Boltzmann_priors_for_Implicit_Transfer_Operators.pdf
  sha_abstract: 90396f6e0f64a54399caf017a2ae9275b223e16c1741405a6b430255cad1f04f
  title: Boltzmann priors for Implicit Transfer Operators
  title_normalized: boltzmann_priors_for_implicit_transfer_operators

================================================================================
Document #61 (ID: c48543dca3a2488dd289e085772d32d2232a6c2dde561a503a828f88f89bc73a)
================================================================================
  abstract: Due to the rise in antimicrobial resistance, identifying novel compounds with antibiotic potential is crucial for combatting this global health issue. However, traditional drug development methods are costly and inefficient. Recognizing the pressing need for more effective solutions, researchers have turned to machine learning techniques to streamline the prediction and development of novel antibiotic compounds. While foundation models have shown promise in antibiotic discovery, current mainstream efforts still fall short of fully leveraging the potential of multimodal molecular data. Recent studies suggest that contrastive learning frameworks utilizing multimodal data exhibit excellent performance in representation learning across various domains. Building upon this, we introduce CL-MFAP, an unsupervised contrastive learning (CL)-based multimodal foundation (MF) model specifically tailored for discovering small molecules with potential antibiotic properties (AP) using three types of molecular data. This model employs 1.6 million bioactive molecules with drug-like properties from the ChEMBL dataset to jointly pretrain three encoders: (1) a transformer-based encoder with rotary position embedding for processing SMILES strings; (2) another transformer-based encoder, incorporating a novel bi-level routing attention mechanism to handle molecular graph representations; and (3) a Morgan fingerprint encoder using a multilayer perceptron, to achieve the contrastive learning purpose. The CL-MFAP outperforms baseline models in antibiotic property prediction by effectively utilizing different molecular modalities and demonstrates superior domain-specific performance when fine-tuned for antibiotic-related property prediction tasks.
  abstract_embedding: [0.59375, 0.58984375, -0.0004863739013671875]... (1536 items)
  authors: ['Gen Zhou', 'Sugitha Janarthanan', 'Yutong Lu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805088828
  novelty: yes
  reason: Relevance: The paper proposes a novel multimodal foundation model (CL-MFAP) that leverages contrastive learning to effectively utilize different molecular data modalities for antibiotic property predi...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CL-MFAP__A_Contrastive_Learning-Based_Multimodal_Foundation_Model_for_Molecular_Property_Prediction_and_Antibiotic_Screening.pdf
  sha_abstract: 61b5994c3093a80b6ff72019519dcc394409de14d9eaac3db6e430a076f2d3af
  title: CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening
  title_normalized: clmfap_a_contrastive_learningbased_multimodal_foundation_model_for_molecular_property_prediction_and_antibiotic_screening

================================================================================
Document #62 (ID: 267fbc3ded3096ffcc9d492029a0285e704700649fa9cb73a137df4f60eb46cc)
================================================================================
  abstract: Diffusion-based representation learning has achieved substantial attention due to its promising capabilities in latent representation and sample generation. Recent studies have employed an auxiliary encoder to identify a corresponding representation from data and to adjust the dimensionality of a latent variable $\mathbf{z}$. Meanwhile, this auxiliary structure invokes an *information split problem*; the information of each data instance $\mathbf{x}_0$ is divided into diffusion endpoint $\mathbf{x}_T$ and encoded $\mathbf{z}$ because there exist two inference paths starting from the data. The latent variable modeled by diffusion endpoint $\mathbf{x}_T$ has some disadvantages. The diffusion endpoint $\mathbf{x}_T$ is computationally expensive to obtain and inflexible in dimensionality. To address this problem, we introduce Diffusion Bridge AuteEncoders (DBAE), which enables $\mathbf{z}$-dependent endpoint $\mathbf{x}_T$ inference through a feed-forward architecture. This structure creates an information bottleneck at $\mathbf{z}$, so $\mathbf{x}_T$ becomes dependent on $\mathbf{z}$ in its generation. This results in $\mathbf{z}$ holding the full information of data. We propose an objective function for DBAE to enable both reconstruction and generative modeling, with their theoretical justification. Empirical evidence supports the effectiveness of the intended design in DBAE, which notably enhances downstream inference quality, reconstruction, and disentanglement. Additionally, DBAE generates high-fidelity samples in the unconditional generation. Our code is
available at https://github.com/aailab-kaist/DBAE.
  abstract_embedding: [0.423828125, 0.1923828125, 0.08056640625]... (1536 items)
  authors: ['Yeongmin Kim', 'Kwanghyeon Lee', 'Minsang Park']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805075177
  novelty: yes
  reason: Relevance: The paper proposes a novel diffusion-based autoencoder architecture (DBAE) that aims to address the information split problem in existing diffusion-based representation learning methods. | ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Diffusion_Bridge_AutoEncoders_for_Unsupervised_Representation_Learning.pdf
  sha_abstract: 4fe407b2510583848eaf50dccf7b21a5b908d12cd5bacac066c3f1f05139ba8e
  title: Diffusion Bridge AutoEncoders for Unsupervised Representation Learning
  title_normalized: diffusion_bridge_autoencoders_for_unsupervised_representation_learning

================================================================================
Document #63 (ID: a9f93a87aa5676690b55992649080f63a98eb88f3edd83724318b5faad167a10)
================================================================================
  abstract: As the quality of image generators continues to improve, deepfakes become a topic of considerable societal debate. Image watermarking allows responsible model owners to detect and label their AI-generated content, which can mitigate the harm. Yet, current state-of-the-art methods in image watermarking remain vulnerable to forgery and removal attacks. 
This vulnerability occurs in part because watermarks distort the distribution of generated images, unintentionally revealing information about the watermarking techniques.

In this work, we first demonstrate a distortion-free watermarking method for images, based on a diffusion model's initial noise.
However, detecting the watermark requires comparing the initial noise reconstructed for an image to all previously used initial noises. 
To mitigate these issues, we propose a two-stage watermarking framework for efficient detection. During generation, we augment the initial noise with generated Fourier patterns to embed information about the group of initial noises we used. For detection, we (i) retrieve the relevant group of noises, and (ii) search within the given group for an initial noise that might match our image. This watermarking approach achieves state-of-the-art robustness to forgery and removal against a large battery of attacks. The project code is available at https://github.com/Kasraarabi/Hidden-in-the-Noise.
  abstract_embedding: [-0.004150390625, 0.68359375, 0.2119140625]... (1536 items)
  authors: ['Kasra Arabi', 'Benjamin Feuer', 'R. Teal Witter']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805093277
  novelty: yes
  reason: Relevance: The paper proposes a novel two-stage watermarking framework for efficient detection and robustness against forgery and removal attacks, which is relevant for AI-generated content detection....
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Hidden_in_the_Noise__Two-Stage_Robust_Watermarking_for_Images.pdf
  sha_abstract: 8f2f4f6bf5001523ce13dc15752e3abdf53137a2fcb154dbd4b1011f6d221132
  title: Hidden in the Noise: Two-Stage Robust Watermarking for Images
  title_normalized: hidden_in_the_noise_twostage_robust_watermarking_for_images

================================================================================
Document #64 (ID: 8f5366f225f55df67f05d5c9e70364142b1970065432146795b7e6e1aa840af3)
================================================================================
  abstract: Mutual Information (MI) is a fundamental measure of dependence between random variables, but its practical application is limited because it is difficult to calculate in many circumstances. Variational methods offer one approach by introducing an approximate distribution to create various bounds on MI, which in turn is an easier optimization problem to solve. In practice, the variational distribution chosen is often a Gaussian, which is convenient but lacks flexibility in modeling complicated distributions. In this paper, we introduce new classes of variational estimators based on Normalizing Flows that extend the previous Gaussian-based variational estimators. Our new estimators maintain many of the same theoretical guarantees while simultaneously enhancing the expressivity of the variational distribution. We experimentally verify that our new methods are effective on large MI problems where discriminative-based estimators, such as MINE and InfoNCE, are fundamentally limited. Furthermore, we compare against a diverse set of benchmarking tests to show that the flow-based estimators often perform as well, if not better, than the discriminative-based counterparts. Finally, we demonstrate how these estimators can be effectively utilized in the Bayesian Optimal Experimental Design setting for online sequential decision making.
  abstract_embedding: [0.1728515625, -0.22265625, -0.0615234375]... (1536 items)
  authors: ['Caleb Dahlke', 'Jason Pacheco']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805083815
  novelty: yes
  reason: Relevance: The paper proposes a new class of variational estimators based on normalizing flows, which can improve the expressivity of the variational distribution for mutual information estimation. | ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Flow-based_Variational_Mutual_Information__Fast_and_Flexible_Approximations.pdf
  sha_abstract: 87c5f4c4aebb447db0b4cfe28583276264113d3ad829945a7ecd0485e9e34440
  title: Flow-based Variational Mutual Information: Fast and Flexible Approximations
  title_normalized: flowbased_variational_mutual_information_fast_and_flexible_approximations

================================================================================
Document #65 (ID: b8286da7627f068ef5ba8f04e8e2bf9506b928c684803d64680b1572d0011ec1)
================================================================================
  abstract: Real-world formal theorem proving often depends on a wealth of context, including definitions, lemmas, comments, file structure, and other information. We introduce $\texttt{miniCTX}$, which tests a model's ability to prove formal mathematical theorems that depend on new context that is not seen during training. $\texttt{miniCTX}$ contains theorems sourced from real Lean projects and textbooks, each associated with a context that can span tens of thousands of tokens. Models are tasked with proving a theorem given access to code from the theorem's repository, which contains context that is needed for the proof. As a baseline for $\texttt{miniCTX}$, we tested fine-tuning and prompting methods that condition theorem proving on preceding context. Both approaches substantially outperform traditional methods that rely solely on state information. We found that this ability to use context is not captured by previous benchmarks such as $\texttt{miniF2F}$. Alongside $\texttt{miniCTX}$, we offer $\texttt{ntp-toolkit}$ for automatically extracting and annotating theorem proving data, making it easy to add new projects into $\texttt{miniCTX}$ to ensure that contexts are not seen during training. $\texttt{miniCTX}$ offers a challenging and realistic evaluation of neural theorem provers.
  abstract_embedding: [0.66796875, 0.5625, 0.1298828125]... (1536 items)
  authors: ['Jiewen Hu', 'Thomas Zhu', 'Sean Welleck']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805081295
  novelty: yes
  reason: Relevance: The paper proposes a novel neural theorem prover, miniCTX, that can leverage long-range context information to prove theorems, which is an important advancement in the field of automated th...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: miniCTX__Neural_Theorem_Proving_with__Long-_Contexts.pdf
  sha_abstract: 2ecffffc4e68527d96a2c53287f70d7f192e37ae36cefe300b2529ef89d3f3ca
  title: miniCTX: Neural Theorem Proving with (Long-)Contexts
  title_normalized: minictx_neural_theorem_proving_with_longcontexts

================================================================================
Document #66 (ID: 62b7c89799cac78b31b3008e9e4e2161176a23db8397ea479b56e1d3d3917cfc)
================================================================================
  abstract: Human motion generation is a critical task with a wide spectrum of applications. Achieving high realism in generated motions requires naturalness, smoothness, and plausibility. However, current evaluation metrics often rely on simple heuristics or distribution distances and do not align well with human perceptions. In this work, we propose a data-driven approach to bridge this gap by introducing a large-scale human perceptual evaluation dataset, MotionPercept, and a human motion critic model, MotionCritic, that capture human perceptual preferences. Our critic model offers a more accurate metric for assessing motion quality and could be readily integrated into the motion generation pipeline to enhance generation quality. Extensive experiments demonstrate the effectiveness of our approach in both evaluating and improving the quality of generated human motions by aligning with human perceptions. Code and data are publicly available at https://motioncritic.github.io/.
  abstract_embedding: [0.1591796875, 0.578125, 0.3359375]... (1536 items)
  authors: ['Haoru Wang', 'Wentao Zhu', 'Luyi Miao']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805086281
  novelty: yes
  reason: Relevance: The paper proposes a novel human motion critic model that can be integrated into the motion generation pipeline to enhance the quality of generated motions, which is relevant for AI automat...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Aligning_Human_Motion_Generation_with_Human_Perceptions.pdf
  sha_abstract: 682aa0887a68dc7c941fccc84c79b4eb0d0599655a55f6abb2be18c81f98d151
  title: Aligning Human Motion Generation with Human Perceptions
  title_normalized: aligning_human_motion_generation_with_human_perceptions

================================================================================
Document #67 (ID: 8dd2f4a3a3392f03ff7750f4c59b896539d821b3196537b473fa5268debae650)
================================================================================
  abstract: We study a class of decision-making problems with one-sided feedback, where outcomes are only observable for specific actions. A typical example is bank loans, where the repayment status is known only if a loan is approved and remains undefined if rejected. In such scenarios, conventional approaches to causal decision evaluation and learning from observational data are not directly applicable. In this paper, we introduce a novel value function to evaluate decision rules that addresses the issue of undefined counterfactual outcomes. Without assuming no unmeasured confounders, we establish the identification of the value function using shadow variables. Furthermore, leveraging semiparametric theory, we derive the efficiency bound for the proposed value function and develop efficient methods for decision evaluation and learning. Numerical experiments and a real-world data application demonstrate the empirical performance of our proposed methods.
  abstract_embedding: [0.77734375, 0.2197265625, -0.000621795654296875]... (1536 items)
  authors: ['Jianing Chu', 'Shu Yang', 'Wenbin Lu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805079289
  novelty: yes
  reason: Relevance: The paper proposes a novel value function and efficient methods for decision evaluation and learning in the context of one-sided feedback, which is a relevant problem for many real-world ap...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Efficient_Causal_Decision_Making_with_One-sided_Feedback.pdf
  sha_abstract: 0e405da664001cd9c23883774b629bf8f4cf0e97eb32670c64dd5ecbf465e7dc
  title: Efficient Causal Decision Making with One-sided Feedback
  title_normalized: efficient_causal_decision_making_with_onesided_feedback

================================================================================
Document #68 (ID: 2410dfed83206c439e848b66a396ed66a91532bf4ec74b14649764c7442d5942)
================================================================================
  abstract: The tokenization of audio with neural audio codec models is a vital part of modern AI pipelines for the generation or understanding of speech, alone or in a multimodal context. Traditionally such tokenization models have concentrated on low parameter-count architectures using only components with strong inductive biases. In this work we show that by applying a transformer architecture with large parameter count to this problem, and applying a flexible Finite Scalar Quantization (FSQ) based bottleneck, it is possible to reach state-of-the-art speech quality at extremely low bit-rates of $400$ or $700$ bits-per-second. The trained models strongly out-perform existing baselines in both objective and subjective tests.
  abstract_embedding: [-0.1328125, 0.2001953125, 0.201171875]... (1536 items)
  authors: ['Julian D Parker', 'Anton Smirnov', 'Jordi Pons']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805077542
  novelty: yes
  reason: Relevance: The paper proposes a novel transformer-based architecture for low-bitrate high-quality speech coding, which is an innovative model architecture relevant for AI pipelines. | Novelty: The app...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Scaling_Transformers_for_Low-Bitrate_High-Quality_Speech_Coding.pdf
  sha_abstract: 1dc581d07a9ebada8b6d42cdcb95f959e0576b97eb879fec7b9a900b459faa9d
  title: Scaling Transformers for Low-Bitrate High-Quality Speech Coding
  title_normalized: scaling_transformers_for_lowbitrate_highquality_speech_coding

================================================================================
Document #69 (ID: d39bd0c6f74b5d24d92e3e81f2f5e30c3e780e92dfd86212bf1592ee7f81a994)
================================================================================
  abstract: Non-rigid alignment of point clouds is crucial for scene understanding, reconstruction, and various computer vision and robotics tasks. Recent advancements in implicit deformation networks for non-rigid registration have significantly reduced the reliance on large amounts of annotated training data. However, existing state-of-the-art methods still face challenges in handling occlusion scenarios. To address this issue, this paper introduces an innovative unsupervised method called Occlusion-Aware Registration (OAR) for non-rigidly aligning point clouds. The key innovation of our method lies in the utilization of the adaptive correntropy function as a localized similarity measure, enabling us to treat individual points distinctly. In contrast to previous approaches that solely minimize overall deviations between two shapes, we combine unsupervised implicit neural representations with the maximum correntropy criterion to optimize the deformation of unoccluded regions. This effectively avoids collapsed, tearing, and other physically implausible results. Moreover, we present a theoretical analysis and establish the relationship between the maximum correntropy criterion and the commonly used Chamfer distance, highlighting that the correntropy-induced metric can be served as a more universal measure for point cloud analysis. Additionally, we introduce
locally linear reconstruction to ensure that regions lacking correspondences between shapes still undergo physically natural deformations. Our method achieves superior or competitive performance compared to existing approaches, particularly when dealing with occluded geometries. We also demonstrate the versatility of our method in challenging tasks such as large deformations, shape interpolation, and shape completion under occlusion disturbances.
  abstract_embedding: [-0.416015625, 0.26953125, -0.04052734375]... (1536 items)
  authors: ['Mingyang Zhao', 'Gaofeng Meng', 'Dong-ming Yan']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804876536
  novelty: yes
  reason: Relevance: The paper proposes a novel unsupervised neural deformation method for non-rigid point cloud registration that is robust to occlusion, which is directly relevant to ML model architecture and...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Occlusion-aware_Non-Rigid_Point_Cloud_Registration_via_Unsupervised_Neural_Deformation_Correntropy.pdf
  sha_abstract: 3ae1a6d69b7984c0f9f9c0dcf691ff316c086aa249f8992a356dcd7c41173883
  title: Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised Neural Deformation Correntropy
  title_normalized: occlusionaware_nonrigid_point_cloud_registration_via_unsupervised_neural_deformation_correntropy

================================================================================
Document #70 (ID: 60677f576e22e057a40e7141998399bba81248aa130d8b567d304fe3a4ed32bb)
================================================================================
  abstract: Adversarial training is a widely-applied approach to training deep neural networks to be robust against adversarial perturbation. However, although adversarial training has achieved empirical success in practice, it still remains unclear why adversarial examples exist and how adversarial training methods improve model robustness. In this paper, we provide a theoretical understanding of adversarial examples and adversarial training algorithms from the perspective of feature learning theory. Specifically, we focus on a multiple classification setting, where the structured data can be composed of two types of features: the robust features, which are resistant to perturbation but sparse, and the non-robust features, which are susceptible to perturbation but dense. We train a two-layer smoothed ReLU convolutional neural network to learn our structured data. First, we prove that by using standard training (gradient descent over the empirical risk), the network learner primarily learns the non-robust feature rather than the robust feature, which thereby leads to the adversarial examples that are generated by perturbations aligned with negative non-robust feature directions. Then, we consider the gradient-based adversarial training algorithm, which runs gradient ascent to find adversarial examples and runs gradient descent over the empirical risk at adversarial examples to update models. We show that the adversarial training method can provably strengthen the robust feature learning and suppress the non-robust feature learning to improve the network robustness. Finally, we also empirically validate our theoretical findings with experiments on real-image datasets, including MNIST, CIFAR10 and SVHN.
  abstract_embedding: [0.5234375, 0.310546875, -0.045654296875]... (1536 items)
  authors: ['Binghui Li', 'Yuanzhi Li']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804892748
  novelty: yes
  reason: Relevance: The paper proposes a theoretical understanding of adversarial training and how it can improve model robustness by strengthening the learning of robust features and suppressing non-robust fe...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Adversarial_Training_Can_Provably_Improve_Robustness__Theoretical_Analysis_of_Feature_Learning_Process_Under_Structured_Data.pdf
  sha_abstract: 44e72c15e1c5750dd15ce04f9d106c101295e0ab0590f3da57fe56faf48b6546
  title: Adversarial Training Can Provably Improve Robustness: Theoretical Analysis of Feature Learning Process Under Structured Data
  title_normalized: adversarial_training_can_provably_improve_robustness_theoretical_analysis_of_feature_learning_process_under_structured_data

================================================================================
Document #71 (ID: bf23fe21705e1b214bbab560952efde1e5f68c41c1416bd935157f388c93ef8c)
================================================================================
  abstract: Generative models lack rigorous statistical guarantees with respect to their predictions. In this work, we propose Sequential Conformal Prediction for Generative Models (SCOPE-Gen), a sequential conformal prediction method producing prediction sets that satisfy a rigorous statistical guarantee called conformal admissibility control. This guarantee means that the prediction sets contain at least one admissible (or valid) example, with high probability. To this end, our method first samples an initial set of i.i.d. examples from a black box generative model. Then, this set is iteratively pruned via so-called greedy filters. As a consequence of the iterative generation procedure, admissibility of the final prediction set factorizes as a Markov chain, where each factor can be controlled separately, using conformal prediction. In comparison to prior work, our method demonstrates a large reduction in the number of admissibility evaluations during calibration. This is crucial e.g. in safety-critical applications, where these evaluations must be conducted manually by domain experts and are therefore costly and time consuming. We highlight the advantages of our method in terms of admissibility evaluations and cardinality of the prediction set through experiments in natural language generation and molecular graph extension tasks.
  abstract_embedding: [0.275390625, 0.416015625, 0.031005859375]... (1536 items)
  authors: ['Klaus-Rudolf Kladny', 'Bernhard Schölkopf', 'Michael Muehlebach']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804883099
  novelty: yes
  reason: Relevance: The paper proposes a novel sequential conformal prediction method for generative models, which can improve sample efficiency and provide statistical guarantees on the generated samples. | N...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Conformal_Generative_Modeling_with_Improved_Sample_Efficiency_through_Sequential_Greedy_Filtering.pdf
  sha_abstract: 84f6528c37fb81b3321f92c2bbe029ff9ec1497d1eadd737a7215a5b52b87662
  title: Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering
  title_normalized: conformal_generative_modeling_with_improved_sample_efficiency_through_sequential_greedy_filtering

================================================================================
Document #72 (ID: be41f67eeef149f450f5a43832740c829bec65fad6784c9b8cdd5bc9a8df41d8)
================================================================================
  abstract: Recent advances in Large Language Models (LLMs) have enabled the development of Video-LLMs, advancing multimodal learning by bridging video data with language tasks. However, current video understanding models struggle with processing long video sequences, supporting multi-turn dialogues, and adapting to real-world dynamic scenarios. To address these issues, we propose StreamChat, a training-free framework for streaming video reasoning and conversational interaction. StreamChat leverages a novel hierarchical memory system to efficiently process and compress video features over extended sequences, enabling real-time, multi-turn dialogue. Our framework incorporates a parallel system scheduling strategy that enhances processing speed and reduces latency, ensuring robust performance in real-world applications. Furthermore, we introduce StreamBench, a versatile benchmark that evaluates streaming video understanding across diverse media types and interactive scenarios, including multi-turn interactions and complex reasoning tasks.  Extensive evaluations on StreamBench and other public benchmarks demonstrate that  StreamChat significantly outperforms existing
state-of-the-art models in terms of accuracy and response times, confirming its effectiveness for streaming video understanding. Code is available at StreamChat.
  abstract_embedding: [0.020751953125, -0.1220703125, 0.83984375]... (1536 items)
  authors: ['Haomiao Xiong', 'Zongxin Yang', 'Jiazuo Yu']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804894524
  novelty: yes
  reason: Relevance: The paper proposes a novel framework, StreamChat, for streaming video reasoning and conversational interaction, which includes a hierarchical memory system and a parallel system scheduling ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Streaming_Video_Understanding_and_Multi-round_Interaction_with_Memory-enhanced_Knowledge.pdf
  sha_abstract: a2d0a7b2d4f74ddcc2a445bccf871fe2d9a0b4be306ddb24e733117c3c126143
  title: Streaming Video Understanding and Multi-round Interaction with Memory-enhanced Knowledge
  title_normalized: streaming_video_understanding_and_multiround_interaction_with_memoryenhanced_knowledge

================================================================================
Document #73 (ID: fee1408721f7b8fcf22f4968e99656ef60c712045d5bb6d2a3230cbf3afba968)
================================================================================
  abstract: Large Language Models (LLMs) have shown immense potential in enhancing various aspects of our daily lives, from conversational AI to search and AI assistants. However, their growing capabilities come at the cost of extremely large model sizes, making deployment on edge devices challenging due to memory and computational constraints. This paper introduces a novel approach to LLM weight pruning that directly optimizes for approximating the attention matrix, a core component of transformer architectures. Unlike existing methods that focus on linear approximations, our approach accounts for the non-linear nature of the Softmax attention mechanism. We provide theoretical guarantees for the convergence of our Gradient Descent-based optimization method to a near-optimal pruning mask solution. Our empirical results demonstrate the effectiveness of our non-linear pruning approach in maintaining model performance while significantly reducing computational costs, which is beyond the current state-of-the-art methods, i.e., SparseGPT and Wanda, by a large margin. This work establishes a new theoretical foundation for pruning algorithm design in LLMs, potentially paving the way for more efficient LLM inference on resource-constrained devices.
  abstract_embedding: [0.2431640625, 0.23828125, 0.392578125]... (1536 items)
  authors: ['Yingyu Liang', 'Jiangxuan Long', 'Zhenmei Shi']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804890586
  novelty: yes
  reason: Relevance: The paper proposes a novel pruning approach for attention matrices in LLMs, which is a key component for improving efficiency and deployment on edge devices. | Novelty: The paper introduces...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Beyond_Linear_Approximations__A_Novel_Pruning_Approach_for_Attention_Matrix.pdf
  sha_abstract: 6a9a8ed2e9bfa9e25e246563df607cdf67c0323666f2a7ffb8ff49f6443bd36a
  title: Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix
  title_normalized: beyond_linear_approximations_a_novel_pruning_approach_for_attention_matrix

================================================================================
Document #74 (ID: a565957798a1363ce0ead4487ea8e6f0ecfce3335cc01f35579ebc5932c2d260)
================================================================================
  abstract: Designing a safe policy for uncertain environments is crucial in real-world control systems. However, this challenge remains inadequately addressed within the Markov decision process (MDP) framework. This paper presents the first algorithm guaranteed to identify a near-optimal policy in a robust constrained MDP (RCMDP), where an optimal policy minimizes cumulative cost while satisfying constraints in the worst-case scenario across a set of environments. We first prove that the conventional policy gradient approach to the Lagrangian max-min formulation can become trapped in suboptimal solutions. This occurs when its inner minimization encounters a sum of conflicting gradients from the objective and constraint functions. To address this, we leverage the epigraph form of the RCMDP problem, which resolves the conflict by selecting a single gradient from either the objective or the constraints. Building on the epigraph form, we propose a bisection search algorithm with a policy gradient subroutine and prove that it identifies an $\varepsilon$-optimal policy in an RCMDP with $\widetilde{\mathcal{O}}(\varepsilon^{-4})$ robust policy evaluations.
  abstract_embedding: [0.9765625, 0.51953125, 0.1728515625]... (1536 items)
  authors: ['Toshinori Kitamura', 'Tadashi Kozuno', 'Wataru Kumagai']... (9 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804880835
  novelty: yes
  reason: Relevance: The paper proposes a novel algorithm for identifying near-optimal policies in robust constrained Markov Decision Processes, which is a relevant problem for real-world control systems. | Nov...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Near-Optimal_Policy_Identification_in_Robust_Constrained_Markov_Decision_Processes_via_Epigraph_Form.pdf
  sha_abstract: ab656bc49cbf15df676779a7d6e0fc62a27051b83a0676233c69972e7358057e
  title: Near-Optimal Policy Identification in Robust Constrained Markov Decision Processes via Epigraph Form
  title_normalized: nearoptimal_policy_identification_in_robust_constrained_markov_decision_processes_via_epigraph_form

================================================================================
Document #75 (ID: 13098496faf53d584d6c8e0e2e3e784b364ff21e9463c24c7d66a4f00a17c50d)
================================================================================
  abstract: In reinforcement learning (RL), world models serve as internal simulators, enabling agents to predict environment dynamics and future outcomes in order to make informed decisions. While previous approaches leveraging discrete latent spaces, such as DreamerV3, have demonstrated strong performance in discrete action settings and visual control tasks, their comparative performance in state-based continuous control remains underexplored. In contrast, methods with continuous latent spaces, such as TD-MPC2, have shown notable success in state-based continuous control benchmarks. In this paper, we demonstrate that modeling discrete latent states has benefits over continuous latent states and that discrete codebook encodings are more effective representations for continuous control, compared to alternative encodings, such as one-hot and label-based encodings. Based on these insights, we introduce DCWM: Discrete Codebook World Model, a self-supervised world model with a discrete and stochastic latent space, where latent states are codes from a codebook. We combine DCWM with decision-time planning to get our model-based RL algorithm, named DC-MPC: Discrete Codebook Model Predictive Control, which performs competitively against recent state-of-the-art algorithms, including TD-MPC2 and DreamerV3, on continuous control benchmarks.
  abstract_embedding: [0.63671875, 0.341796875, 0.4453125]... (1536 items)
  authors: ['Aidan Scannell', 'Mohammadreza Nakhaeinezhadfard', 'Kalle Kujanpää']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804884907
  novelty: yes
  reason: Relevance: The paper proposes a novel discrete codebook world model architecture for continuous control, which is relevant for ML research and applications. | Novelty: The discrete codebook approach f...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Discrete_Codebook_World_Models_for_Continuous_Control.pdf
  sha_abstract: 4ecb5992b96ab009e0644e81a836cf294143da8a5d51aac50000e3381dd5587d
  title: Discrete Codebook World Models for Continuous Control
  title_normalized: discrete_codebook_world_models_for_continuous_control

================================================================================
Document #76 (ID: 115f64b8b52fdf2f9a80c19cbfea94393280832fe39c744a216f02b8185e1af6)
================================================================================
  abstract: Weight space learning aims to extract information about a neural network, such as its training dataset or generalization error. Recent approaches learn directly from model weights, but this presents many challenges as weights are high-dimensional and include permutation symmetries between neurons. An alternative approach, Probing, represents a model by passing a set of learned inputs (probes) through the model, and training a predictor on top of the corresponding outputs. Although probing is typically not used as a stand alone approach, our preliminary experiment found that a vanilla probing baseline worked surprisingly well. However, we discover that current probe learning strategies are ineffective. We therefore propose Deep Linear Probe Generators (ProbeGen), a simple and effective modification to probing approaches. ProbeGen adds a shared generator module with a deep linear architecture, providing an inductive bias towards structured probes thus reducing overfitting. While simple, ProbeGen performs significantly better than the state-of-the-art and is very efficient, requiring between 30 to 1000 times fewer FLOPs than other top approaches.
  abstract_embedding: [-0.2373046875, 0.021240234375, 0.1962890625]... (1536 items)
  authors: ['Jonathan Kahana', 'Eliahu Horwitz', 'Imri Shuval']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804878614
  novelty: yes
  reason: Relevance: The paper proposes a novel probe learning strategy, Deep Linear Probe Generators, which is an efficient and effective approach for weight space learning. | Novelty: The proposed Deep Linear...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Deep_Linear_Probe_Generators_for_Weight_Space_Learning.pdf
  sha_abstract: bd02319374fafa9302b10516478a4a477f8b850abc09a201211eb1a1e5dbc1c3
  title: Deep Linear Probe Generators for Weight Space Learning
  title_normalized: deep_linear_probe_generators_for_weight_space_learning

================================================================================
Document #77 (ID: dbcbb605a60b600b91c863f00202c99899620ec2ce78248558fb24192b9e87d7)
================================================================================
  abstract: Diffusion Probabilistic Models (DPMs) have achieved significant success in generative tasks. However, their training and sampling processes suffer from the issue of distribution mismatch. During the denoising process, the input data distributions differ between the training and inference stages, potentially leading to inaccurate data generation. To obviate this, we analyze the training objective of DPMs and theoretically demonstrate that this mismatch can be alleviated through Distributionally Robust Optimization (DRO), which is equivalent to performing robustness-driven Adversarial Training (AT) on DPMs. Furthermore, for the recently proposed Consistency Model (CM), which distills the inference process of the DPM, we prove that its training objective also encounters the mismatch issue. Fortunately, this issue can be mitigated by AT as well. Based on these insights, we propose to conduct efficient AT on both DPM and CM. Finally, extensive empirical studies validate the effectiveness of AT in diffusion-based models. The code is available at https://github.com/kugwzk/AT_Diff.
  abstract_embedding: [0.5390625, 0.51953125, 0.11865234375]... (1536 items)
  authors: ['Zekun Wang', 'Mingyang Yi', 'Shuchen Xue']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804887181
  novelty: yes
  reason: Relevance: The paper proposes a novel adversarial training strategy to improve the robustness of diffusion-based generative models, which is a relevant and important topic for ML research. | Novelty: ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Improved_Diffusion-based_Generative_Model_with_Better_Adversarial_Robustness.pdf
  sha_abstract: ea82003bd7cecc49176a65db9f5b12ca2995cbc9664ce440bf8c5aee0ea62660
  title: Improved Diffusion-based Generative Model with Better Adversarial Robustness
  title_normalized: improved_diffusionbased_generative_model_with_better_adversarial_robustness

================================================================================
Document #78 (ID: 8bfb0b5e4124709691a111154226ee0b34f52643513207daf0507ecc80b4d464)
================================================================================
  abstract: We address the challenge of federated learning on graph-structured data distributed across multiple clients. Specifically, we focus on the prevalent scenario of interconnected subgraphs, where inter-connections between different clients play a critical role. We present a novel framework for this scenario, named FedStruct, that harnesses deep structural dependencies. To uphold privacy, unlike existing methods, FedStruct eliminates the necessity of sharing or generating sensitive node features or embeddings among clients. Instead, it leverages explicit global graph structure information to capture inter-node dependencies. We validate the effectiveness of FedStruct through experimental results conducted on six datasets for semi-supervised node classification, showcasing performance close to the centralized approach across various scenarios, including different data partitioning methods, varying levels of label availability, and number of clients.
  abstract_embedding: [0.0186767578125, 0.5078125, 0.17578125]... (1536 items)
  authors: ['Javad Aliakbari', 'Johan Östman', 'Alexandre Graell i Amat']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804866365
  novelty: yes
  reason: Relevance: The paper proposes a novel federated learning framework, FedStruct, that leverages explicit global graph structure information to capture inter-node dependencies, which is relevant for grap...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Decoupled_Subgraph_Federated_Learning.pdf
  sha_abstract: e0204095f49e5e036d3c2ef9ffc0589a9eb5e57700f223442f462211d7494a0c
  title: Decoupled Subgraph Federated Learning
  title_normalized: decoupled_subgraph_federated_learning

================================================================================
Document #79 (ID: 61563c96f429a3d0c47c154c64ceab8aa64bb0e504311911107fd829d889436f)
================================================================================
  abstract: Spatiotemporal dynamics pervade the natural sciences, from the morphogen dynamics underlying patterning in animal pigmentation to the protein waves controlling cell division. A central challenge lies in understanding how controllable parameters induce qualitative changes in system behavior called bifurcations. This endeavor is particularly difficult in realistic settings where governing partial differential equations (PDEs) are unknown and data is limited and noisy. To address this challenge, we propose TRENDy (Temporal Regression of Effective Nonlinear Dynamics), an equation-free approach to learning low-dimensional, predictive models of spatiotemporal dynamics. TRENDy first maps input data to a low-dimensional space of effective dynamics through a cascade of multiscale filtering operations. Our key insight is the recognition that these effective dynamics can be fit by a neural ordinary differential equation (NODE) having the same parameter space as the input PDE. The preceding filtering operations strongly regularize the phase space of the NODE, making TRENDy significantly more robust to noise compared to existing methods. We train TRENDy to predict the effective dynamics of synthetic and real data representing dynamics from across the physical and life sciences. We then demonstrate how we can automatically locate both Turing and Hopf bifurcations in unseen regions of parameter space. We finally apply our method to the analysis of spatial patterning of the ocellated lizard through development. We found that TRENDy's predicted effective state not only accurately predicts spatial changes over time but also identifies distinct pattern features unique to different anatomical regions, such as the tail, neck, and body--an insight that highlights the potential influence of surface geometry on reaction-diffusion mechanisms and their role in driving spatially varying pattern dynamics.
  abstract_embedding: [0.23828125, 0.4375, 0.0284423828125]... (1536 items)
  authors: ['Matt Ricci', 'Guy Pelc', 'Zoe Piran']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804908542
  novelty: yes
  reason: Relevance: The paper proposes a novel neural ODE-based approach (TRENDy) for learning low-dimensional, predictive models of spatiotemporal dynamics, which is relevant for efficient ML model architectu...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: TRENDy__Temporal_Regression_of_Effective_Nonlinear_Dynamics.pdf
  sha_abstract: b473c4e85b4b4ead90188b00776675dbc233514ea00add44178ca0c84caf812a
  title: TRENDy: Temporal Regression of Effective Nonlinear Dynamics
  title_normalized: trendy_temporal_regression_of_effective_nonlinear_dynamics

================================================================================
Document #80 (ID: 9c64a06e5ba0fd2f3788e64340346ea777702442b75c6ad4b3c6c212e7ccd0f9)
================================================================================
  abstract: We present SNOWS, a one-shot post-training pruning framework aimed at reducing the cost of vision network inference without retraining. Current leading one-shot pruning methods minimize layer-wise least squares reconstruction error which does not take into account deeper network representations. We propose to optimize a more global reconstruction objective. This objective accounts for nonlinear activations deep in the network to obtain a better proxy for the network loss. This nonlinear objective leads to a more challenging optimization problem---we demonstrate it can be solved efficiently using a specialized second-order optimization framework. A key innovation of our framework is the use of Hessian-free optimization to compute exact Newton descent steps without needing to compute or store the full Hessian matrix. A distinct advantage of SNOWS is that it can be readily applied on top of any sparse mask derived from prior methods, readjusting their weights to preserve deep feature representations. SNOWS obtains state-of-the-art results on various one-shot pruning benchmarks including residual networks and Vision Transformers (ViT/B-16 and ViT/L-16, 86m and 304m parameters respectively). Our open-source implementation is available at https://github.com/mazumder-lab/SNOWS.
  abstract_embedding: [0.24609375, 0.1630859375, 0.8828125]... (1536 items)
  authors: ['Ryan Lucas', 'Rahul Mazumder']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804920155
  novelty: yes
  reason: Relevance: The paper proposes a novel one-shot pruning framework that optimizes a global reconstruction objective to preserve deep feature representations, which is relevant for improving the efficien...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Preserving_Deep_Representations_in_One-Shot_Pruning__A_Hessian-Free_Second-Order_Optimization_Framework.pdf
  sha_abstract: bc1a0a1a4c0cc54123c0a39e92efc492f5e2e8578ca7cdbc82128df114c52875
  title: Preserving Deep Representations in One-Shot Pruning: A Hessian-Free Second-Order Optimization Framework
  title_normalized: preserving_deep_representations_in_oneshot_pruning_a_hessianfree_secondorder_optimization_framework

================================================================================
Document #81 (ID: cbdf76257013dd9109e44165c49d228348d987f0aa686db81e03901200fc81d8)
================================================================================
  abstract: Vision-Language adaptation (VL adaptation) transforms Large Language Models (LLMs) into Large Vision-Language Models (LVLMs) for multimodal tasks, but this process often compromises the inherent safety capabilities embedded in the original LLMs. Despite potential harmfulness due to weakened safety measures, in-depth analysis on the effects of VL adaptation on safety remains under-explored. This study examines how VL adaptation influences safety and evaluates the impact of safety fine-tuning methods. Our analysis reveals that safety degradation occurs during VL adaptation, even when the training data is safe. While safety tuning techniques like supervised fine-tuning with safety datasets or reinforcement learning from human feedback mitigate some risks, they still lead to safety degradation and a reduction in helpfulness due to over-rejection issues. Further analysis of internal model weights suggests that VL adaptation may impact certain safety-related layers, potentially lowering overall safety levels. Additionally, our findings demonstrate that the objectives of VL adaptation and safety tuning are divergent, which often results in their simultaneous application being suboptimal. To address this, we suggest the weight merging approach as an optimal solution effectively reducing safety degradation while maintaining helpfulness. These insights help guide the development of more reliable and secure LVLMs for real-world applications.
  abstract_embedding: [0.703125, 0.1611328125, -0.0673828125]... (1536 items)
  authors: ['Seongyun Lee', 'Geewook Kim', 'Jiyeon Kim']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804899613
  novelty: yes
  reason: Relevance: The paper proposes techniques for improving the safety of vision-language models, which is highly relevant for real-world applications. | Novelty: The paper introduces a novel weight mergin...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: How_Does_Vision-Language_Adaptation_Impact_the_Safety_of_Vision_Language_Models_.pdf
  sha_abstract: b38cf3e78d39c9ddbed4a9d7f0b96028f03f425c0cbd46165357b1f203366a9d
  title: How Does Vision-Language Adaptation Impact the Safety of Vision Language Models?
  title_normalized: how_does_visionlanguage_adaptation_impact_the_safety_of_vision_language_models

================================================================================
Document #82 (ID: da33f91cac03fc597320326b57e15d536ea456a83148b33016ae37a577b80615)
================================================================================
  abstract: The increasing demand for controllable outputs in text-to-image generation has spurred advancements in multi-instance generation (MIG), allowing users to define both instance layouts and attributes. However, unlike image-conditional generation methods such as ControlNet, MIG techniques have not been widely adopted in state-of-the-art models like SD2 and SDXL, primarily due to the challenge of building robust renderers that simultaneously handle instance positioning and attribute rendering. In this paper, we introduce Depth-Driven Decoupled Image Synthesis (3DIS), a novel framework that decouples the MIG process into two stages: (i) generating a coarse scene depth map for accurate instance positioning and scene composition, and (ii) rendering fine-grained attributes using pre-trained ControlNet on any foundational model, without additional training. Our 3DIS framework integrates a custom adapter into LDM3D for precise depth-based layouts and employs a finetuning-free method for enhanced instance-level attribute rendering. Extensive experiments on COCO-Position and COCO-MIG benchmarks demonstrate that 3DIS significantly outperforms existing methods in both layout precision and attribute rendering. Notably, 3DIS offers seamless compatibility with diverse foundational models, providing a robust, adaptable solution for advanced multi-instance generation. The code is available at: https://github.com/limuloo/3DIS.
  abstract_embedding: [0.36328125, -0.09130859375, 0.1796875]... (1536 items)
  authors: ['Dewei Zhou', 'Ji Xie', 'Zongxin Yang']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804917956
  novelty: yes
  reason: Relevance: The paper proposes a novel framework, 3DIS, that decouples the multi-instance generation process into depth map generation and attribute rendering, which is an innovative approach to the pr...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: 3DIS__Depth-Driven_Decoupled_Image_Synthesis_for_Universal_Multi-Instance_Generation.pdf
  sha_abstract: 9c490766707f514aae9af8ecf1a1efbe79932b71d733533544f8b681359677f9
  title: 3DIS: Depth-Driven Decoupled Image Synthesis for Universal Multi-Instance Generation
  title_normalized: 3dis_depthdriven_decoupled_image_synthesis_for_universal_multiinstance_generation

================================================================================
Document #83 (ID: 02def91af501b2aa4f6d767d5463f417ed874b9357d1659f37101873e32d02bf)
================================================================================
  abstract: Recently, many self-supervised learning methods for image reconstruction have been proposed that can learn from noisy data alone, bypassing the need for ground-truth references.  Most existing methods cluster around two classes: i) Stein's Unbiased Risk Estimate (SURE) and similar approaches that assume full knowledge of the noise distribution, and ii) Noise2Self and similar cross-validation methods that require very mild knowledge about the noise distribution. The first class of methods tends to be impractical, as the noise level is often unknown in real-world applications, and the second class is often suboptimal compared to supervised learning.
In this paper, we provide a theoretical framework that characterizes this expressivity-robustness trade-off and propose a new approach based on SURE, but unlike the standard SURE, does not require knowledge about the noise level. Throughout a series of experiments, we show that the proposed estimator outperforms other existing self-supervised methods on various imaging inverse problems.
  abstract_embedding: [-0.072265625, 0.158203125, -0.12890625]... (1536 items)
  authors: ['Julián Tachella', 'Mike Davies', 'Laurent Jacques']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804901602
  novelty: yes
  reason: Relevance: The paper proposes a new self-supervised learning method for image reconstruction that does not require knowledge of the noise level, which is an important practical consideration. | Novelt...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: UNSURE__self-supervised_learning_with_Unknown_Noise_level__and_Stein_s_Unbiased_Risk_Estimate.pdf
  sha_abstract: 52681b75046c4b2f5856923756543c84229a74f201a9ab82dc654a3db8904d2a
  title: UNSURE: self-supervised learning with Unknown Noise level  and Stein's Unbiased Risk Estimate
  title_normalized: unsure_selfsupervised_learning_with_unknown_noise_level__and_steins_unbiased_risk_estimate

================================================================================
Document #84 (ID: 711c7d4a763699e995f1b5c6b65f5f958860bbcd2ea634d5454d100d3e4a2fad)
================================================================================
  abstract: We provide a convergence analysis of \emph{deep feature instrumental variable} (DFIV) regression (Xu et al., 2021), a nonparametric approach to IV regression using data-adaptive features learned by deep neural networks in two stages. We prove that the DFIV algorithm achieves the minimax optimal learning rate when the target structural function lies in a Besov space. This is shown under standard nonparametric IV assumptions, and an additional smoothness assumption on the regularity of the conditional distribution of the covariate given the instrument, which controls the difficulty of Stage 1. We further demonstrate that DFIV, as a data-adaptive algorithm, is superior to fixed-feature (kernel or sieve) IV methods in two ways. First, when the target function possesses low spatial homogeneity (i.e., it has both smooth and spiky/discontinuous regions), DFIV still achieves the optimal rate, while fixed-feature methods are shown to be strictly suboptimal. Second, comparing with kernel-based two-stage regression estimators, DFIV is provably more data efficient in the Stage 1 samples.
  abstract_embedding: [0.7109375, 0.267578125, 0.16015625]... (1536 items)
  authors: ['Juno Kim', 'Dimitri Meunier', 'Arthur Gretton']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804915070
  novelty: yes
  reason: Relevance: The paper proposes a novel deep learning-based instrumental variable regression method with theoretical guarantees on its optimality and adaptivity. | Novelty: The proposed DFIV algorithm i...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Optimality_and_Adaptivity_of_Deep_Neural_Features_for_Instrumental_Variable_Regression.pdf
  sha_abstract: 1acb1ec50af45cbaf71b8400d91eea396ea72a87ff43826f87e6a1f7630189a6
  title: Optimality and Adaptivity of Deep Neural Features for Instrumental Variable Regression
  title_normalized: optimality_and_adaptivity_of_deep_neural_features_for_instrumental_variable_regression

================================================================================
Document #85 (ID: fee782e93f149681b36e20cfbf4311045398bcda6ec1b4784635fb81f3edeedb)
================================================================================
  abstract: Procedural materials, represented as functional node graphs, are ubiquitous in computer graphics for photorealistic material appearance design. They allow users to perform intuitive and precise editing to achieve desired visual appearances. However, creating a procedural material given an input image requires professional knowledge and significant effort. In this work, we leverage the ability to convert procedural materials into standard Python programs and fine-tune a large pre-trained vision-language model (VLM) to generate such programs from input images. To enable effective fine-tuning, we also contribute an open-source procedural material dataset and propose to perform program-level augmentation by prompting another pre-trained large language model (LLM). Through extensive evaluation, we show that our method outperforms previous methods on both synthetic and real-world examples.
  abstract_embedding: [0.2373046875, 0.1455078125, -0.1728515625]... (1536 items)
  authors: ['Beichen Li', 'Rundi Wu', 'Armando Solar-Lezama']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804912706
  novelty: yes
  reason: Relevance: The paper proposes a novel method for procedural material generation using large vision-language models, which is relevant for creating photorealistic materials in computer graphics. | Nove...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: VLMaterial__Procedural_Material_Generation_with_Large_Vision-Language_Models.pdf
  sha_abstract: 484d1034786a3e40f8834d6aac1c8cc21c65f7558d82278c78d80192bb78e78a
  title: VLMaterial: Procedural Material Generation with Large Vision-Language Models
  title_normalized: vlmaterial_procedural_material_generation_with_large_visionlanguage_models

================================================================================
Document #86 (ID: ea05a5b1fd226f4220ad015e6be90ab1fc91d7517c5455d018fe0fd3e1459936)
================================================================================
  abstract: Discriminative approaches to classification often learn shortcuts that hold in-distribution but fail even under minor distribution shift. This failure mode stems from an overreliance on features that are spuriously correlated with the label. We show that generative classifiers, which use class-conditional generative models, can avoid this issue by modeling all features, both core and spurious, instead of mainly spurious ones. These generative classifiers are simple to train, avoiding the need for specialized augmentations, strong regularization, extra hyperparameters, or knowledge of the specific spurious correlations to avoid. We find that diffusion-based and autoregressive generative classifiers achieve state-of-the-art performance on five standard image and text distribution shift benchmarks and reduce the impact of spurious correlations in realistic applications, such as medical or satellite datasets. Finally, we carefully analyze a Gaussian toy setting to understand the inductive biases of generative classifiers, as well as the data properties that determine when generative classifiers outperform discriminative ones.
  abstract_embedding: [-0.232421875, 0.578125, 0.1318359375]... (1536 items)
  authors: ['Alexander Cong Li', 'Ananya Kumar', 'Deepak Pathak']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804905786
  novelty: yes
  reason: Relevance: The paper proposes a new generative classifier approach that can avoid shortcut solutions and improve performance on distribution shift benchmarks. | Novelty: The generative classifier appr...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Generative_Classifiers_Avoid_Shortcut_Solutions.pdf
  sha_abstract: 03648b7031675eca7d21544ee7e7ad61790aa0104fc114dda073cb5fb81638ad
  title: Generative Classifiers Avoid Shortcut Solutions
  title_normalized: generative_classifiers_avoid_shortcut_solutions

================================================================================
Document #87 (ID: 9829d0d80fd15045f7c608465a3ce273e051967a975caf590bd9ef51937f2817)
================================================================================
  abstract: Tabular data generation has recently attracted a growing interest due to its different application scenarios. However, 
generating time series of tabular data, where each element of the series depends on the others,
remains a largely unexplored domain. 
This gap is probably due to the difficulty of jointly solving different problems, the main of which are the heterogeneity of tabular data (a problem common to non-time-dependent approaches) and the variable length of a time series.
In this paper, we propose a Diffusion Transformers (DiTs) based approach for tabular data series generation. Inspired by the recent success of DiTs in image and video generation, we extend this framework to deal with heterogeneous data and variable-length sequences. 
Using extensive experiments on six datasets, we show that the proposed approach  outperforms previous work by a large margin.
  abstract_embedding: [0.48046875, -0.037109375, 0.7421875]... (1536 items)
  authors: ['Fabrizio Garuti', 'Enver Sangineto', 'Simone Luetto']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804897911
  novelty: yes
  reason: Relevance: The paper proposes a novel Diffusion Transformer-based approach for generating time series of tabular data, which addresses the challenges of heterogeneity and variable-length sequences. | ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Diffusion_Transformers_for_Tabular_Data_Time_Series_Generation.pdf
  sha_abstract: c31a6a36017ee539d9da44cb5efb4bdad2194eefe1b74aee98440ede84fb62d4
  title: Diffusion Transformers for Tabular Data Time Series Generation
  title_normalized: diffusion_transformers_for_tabular_data_time_series_generation

================================================================================
Document #88 (ID: 6df691222f5a7ec8b9e0d0c1badb903c411ad3de28fc5700636aca45dba5c105)
================================================================================
  abstract: Text-to-video (T2V) models have recently undergone rapid and substantial advancements. Nevertheless, due to limitations in data and computational resources, achieving efficient generation of long videos with rich motion dynamics remains a significant challenge. 
To generate high-quality, dynamic, and temporally consistent long videos, this paper presents ARLON,  a novel framework that boosts diffusion Transformers with autoregressive (\textbf{AR}) models for long (\textbf{LON}) video generation, by integrating the coarse spatial and long-range temporal information provided by the AR model to guide the DiT model effectively.
Specifically, ARLON incorporates several key innovations: 
1) A latent Vector Quantized Variational Autoencoder (VQ-VAE) compresses the input latent space of the DiT model into compact and highly quantized visual tokens, bridging the AR and DiT models and balancing the learning complexity and information density;
2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model, ensuring effective guidance during video generation; 
3) To enhance the tolerance capability of noise introduced from the AR inference, the DiT model is trained with coarser visual latent tokens incorporated with an uncertainty sampling module. 
Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench, with notable improvements in dynamic degree and aesthetic quality, while delivering competitive results on the remaining three and simultaneously accelerating the generation process. In addition, ARLON achieves state-of-the-art performance in long video generation, outperforming other open-source models in this domain. 
Detailed analyses of the improvements in inference efficiency are presented, alongside a practical application that demonstrates the generation of long videos using progressive text prompts. Project page: \url{http://aka.ms/arlon}.
  abstract_embedding: [0.0133056640625, 0.208984375, 0.47265625]... (1536 items)
  authors: ['Zongyi Li', 'Shujie HU', 'Shujie LIU']... (10 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805023664
  novelty: yes
  reason: Relevance: The paper proposes a novel framework, ARLON, that integrates autoregressive models with diffusion transformers to generate high-quality, dynamic, and temporally consistent long videos, whic...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ARLON__Boosting_Diffusion_Transformers_with_Autoregressive_Models_for_Long_Video_Generation.pdf
  sha_abstract: e6260edea24b70ca7a8fbe9f6d6d7d28f775ef9b34e3145b4e035791dfef8397
  title: ARLON: Boosting Diffusion Transformers with Autoregressive Models for Long Video Generation
  title_normalized: arlon_boosting_diffusion_transformers_with_autoregressive_models_for_long_video_generation

================================================================================
Document #89 (ID: 7dfd89459e16e0a296e562f409dd2834ff9a05b4e64213f64b9c61912e6ffdde)
================================================================================
  abstract: Traditional data influence estimation methods, like influence function, assume that learning algorithms are permutation-invariant with respect to training data. However, modern training paradigms—especially for foundation models using stochastic algorithms and non-convergent, multi-stage curricula—are sensitive to data ordering, thus violating this assumption. This mismatch renders influence functions inadequate for answering some critical questions in current machine learning: How can we differentiate the influence of the same data contributing at different stages of training? More generally, how can we capture the dependence of data influence on the optimization trajectory during training? To address this gap, we formalize the concept of \emph{trajectory-specific leave-one-out (LOO) influence}, which quantifies the impact of removing a data point from a specific iteration during training, accounting for the exact sequence of data encountered and the model's optimization trajectory. However, exactly evaluating the trajectory-specific LOO presents a significant computational challenge. To address this, we propose \emph{data value embedding}, a novel technique enabling efficient approximation of trajectory-specific LOO. Specifically, we compute a training data embedding that encapsulates the cumulative interactions between data and the evolving model parameters. The LOO can then be efficiently approximated through a simple dot-product between the data value embedding and the gradient of the given test data. As data value embedding captures training data ordering, it offers valuable insights into model training dynamics. In particular, we uncover distinct phases of data influence, revealing that data points in the early and late stages of training exert a greater impact on the final model. These insights translate into actionable strategies for managing the computational overhead of data selection by strategically timing the selection process, potentially opening new avenues in data curation research.
  abstract_embedding: [0.5390625, 0.0927734375, 0.43359375]... (1536 items)
  authors: ['Jiachen T. Wang', 'Dawn Song', 'James Zou']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804922729
  novelty: yes
  reason: Relevance: The paper proposes a novel technique called 'data value embedding' to efficiently approximate the trajectory-specific leave-one-out (LOO) influence, which captures the temporal dependence o...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Capturing_the_Temporal_Dependence_of_Training_Data_Influence.pdf
  sha_abstract: a97bd3886592075551e69e8a953bac9f31a6b35d19eec5762c0a5d31704149e2
  title: Capturing the Temporal Dependence of Training Data Influence
  title_normalized: capturing_the_temporal_dependence_of_training_data_influence

================================================================================
Document #90 (ID: 9115001dd21579cdd74f01c3a0d6795ba481881b47ccee267a6a11ad79134226)
================================================================================
  abstract: 3D Gaussian Splatting (3DGS) has shown promising results for Novel View Synthesis. However, while it is quite effective when based on high-quality images, its performance declines as image quality degrades, due to lack of resolution, motion blur, noise, compression artifacts, or other factors common in real-world data collection. While some solutions have been proposed for specific types of degradation, general techniques are still missing. To address the problem, we propose a robust HQGS that significantly enhances the 3DGS under various degradation scenarios. We first analyze that 3DGS lacks sufficient attention in some detailed regions in low-quality scenes, leading to the absence of Gaussian primitives in those areas and resulting in loss of detail in the rendered images. To address this issue, we focus on leveraging edge structural information to provide additional guidance for 3DGS, enhancing its robustness. First, we introduce an edge-semantic fusion guidance module that combines rich texture information from high-frequency edge-aware maps with semantic information from images.  The fused features serve as prior guidance to capture detailed distribution across different regions, bringing more attention to areas with detailed edge information and allowing for a higher concentration of Gaussian primitives to be assigned to such areas. Additionally, we present a structural cosine similarity loss to complement pixel-level constraints, further improving the quality of the rendered images. Extensive experiments demonstrate that our method offers better robustness and achieves the best results across various degraded scenes. Source code and trained models are publicly available at: \url{https://github.com/linxin0/HQGS}.
  abstract_embedding: [0.1259765625, -0.0164794921875, 0.05322265625]... (1536 items)
  authors: ['Xin Lin', 'Shi Luo', 'Xiaojun Shan']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805007017
  novelty: yes
  reason: Relevance: The paper proposes a novel method for improving the robustness of 3D Gaussian Splatting for novel view synthesis in degraded scenes, which is relevant for efficient ML models. | Novelty: Th...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: HQGS__High-Quality_Novel_View_Synthesis_with_Gaussian_Splatting_in_Degraded_Scenes.pdf
  sha_abstract: 0b54c2ad734134096cb5c733ef679b0d2c4c11c5d9a7a0c2a4ee718e9db521f3
  title: HQGS: High-Quality Novel View Synthesis with Gaussian Splatting in Degraded Scenes
  title_normalized: hqgs_highquality_novel_view_synthesis_with_gaussian_splatting_in_degraded_scenes

================================================================================
Document #91 (ID: 3c5d52ea6db36d01a59603bbf2b88cb9d1c68b393e0766e3d97b95a3e1d83f64)
================================================================================
  abstract: Deep neural networks are vulnerable to backdoor attacks, a type of adversarial attack that poisons the training data to manipulate the behavior of models trained on such data. 
Clean-label backdoor is a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data.
Early works on clean-label attacks added triggers to a random subset of the training set, ignoring the fact that samples contribute unequally to the attack's success. This results in high poisoning rates and low attack success rates.
To alleviate the problem, several supervised learning-based sample selection strategies have been proposed.
However, these methods assume access to the entire labeled training set and require training, which is expensive and may not always be practical.
This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g., in face recognition systems) and has no knowledge of the victim model or any other classes in the training set.
We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting. 
Our threat model poses a serious threat in training machine learning models with third-party datasets, since the attack can be performed effectively with limited information. Experiments on benchmark datasets illustrate the effectiveness of our strategies in improving clean-label backdoor attacks.
  abstract_embedding: [0.60546875, 0.96484375, 0.26171875]... (1536 items)
  authors: ['Nguyen Hung-Quang', 'Ngoc-Hieu Nguyen', 'The-Anh Ta']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805017647
  novelty: yes
  reason: Relevance: The paper proposes new strategies for selectively poisoning training data to improve the effectiveness of clean-label backdoor attacks, which is a relevant and important problem in ML secur...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Wicked_Oddities__Selectively_Poisoning_for_Effective_Clean-Label_Backdoor_Attacks.pdf
  sha_abstract: fa0368afd2b3e9d8b77423346c6725bc43cad9fba5c21cd39a07bdbec61b10e8
  title: Wicked Oddities: Selectively Poisoning for Effective Clean-Label Backdoor Attacks
  title_normalized: wicked_oddities_selectively_poisoning_for_effective_cleanlabel_backdoor_attacks

================================================================================
Document #92 (ID: d2b59bd020fba96fe84556883192697bc97d6df1a479e04642ab4ddc829e2e4b)
================================================================================
  abstract: Graphical User Interface (GUI) agents hold great potential for automating complex tasks across diverse digital environments, from web applications to desktop software. However, the development of such agents is hindered by the lack of high-quality, multi-step trajectory data required for effective training. Existing approaches rely on expensive and labor-intensive human annotation, making them unsustainable at scale. To address this challenge, we propose AgentTrek, a scalable data synthesis pipeline that generates high-quality web agent trajectories by leveraging web tutorials. Our method automatically gathers tutorial-like texts from the internet, transforms them into task goals with step-by-step instructions, and employs a visual-language model (VLM) agent to simulate their execution in a real digital environment. A VLM-based evaluator ensures the correctness of the generated trajectories. We demonstrate that training GUI agents with these synthesized trajectories significantly improves their grounding and planning performance over the current models. Moreover, our approach is more cost-efficient compared to traditional human annotation methods. This work underscores the potential of guided replay with web tutorials as a viable strategy for large-scale GUI agent training, paving the way for more capable and autonomous digital agents.
  abstract_embedding: [0.69921875, -0.035400390625, 0.337890625]... (1536 items)
  authors: ['Yiheng Xu', 'Dunjie Lu', 'Zhennan Shen']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804924815
  novelty: yes
  reason: Relevance: The paper proposes a novel data synthesis pipeline for generating high-quality web agent trajectories, which is a key challenge for training GUI agents. | Novelty: The approach of leveragin...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: AgentTrek__Agent_Trajectory_Synthesis_via_Guiding_Replay_with_Web_Tutorials.pdf
  sha_abstract: 56be0f23c7ad987c4a2e633f8d54477e9ccb8f319e4c95ddbd6721f34c5ca9f3
  title: AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials
  title_normalized: agenttrek_agent_trajectory_synthesis_via_guiding_replay_with_web_tutorials

================================================================================
Document #93 (ID: 34cd42ff72e358cbf1eaee5505aeb8f70c55a3fa5e2b17040d5331cbbc16fc45)
================================================================================
  abstract: In this work, we focus on Weakly Supervised Spatio-Temporal Video Grounding (WSTVG). It is a multimodal task aimed at localizing specific subjects  spatio-temporally based on textual queries without bounding box supervision. Motivated by recent advancements in multi-modal foundation models for grounding tasks, we first explore the potential of state-of-the-art object detection models for WSTVG. Despite their robust zero-shot capabilities, our adaptation reveals significant limitations, including inconsistent temporal predictions, inadequate understanding of complex queries, and challenges in adapting to difficult scenarios. We propose CoSPaL (Contextual Self-Paced Learning), a novel approach which is designed to overcome these limitations. CoSPaL integrates three core components: (1) Tubelet Phrase Grounding (TPG), which introduces spatio-temporal prediction by linking textual queries to tubelets; (2) Contextual Referral Grounding (CRG), which improves comprehension of complex queries by extracting contextual information to refine object identification over time; and (3) Self-Paced Scene Understanding (SPS), a training paradigm that progressively increases task difficulty, enabling the model to adapt to complex scenarios by transitioning from coarse to fine-grained understanding.
  abstract_embedding: [-0.2080078125, 0.1220703125, 0.515625]... (1536 items)
  authors: ['Akash Kumar', 'Zsolt Kira', 'Yogesh S Rawat']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804993832
  novelty: yes
  reason: Relevance: The paper proposes a novel model architecture (Tubelet Phrase Grounding, Contextual Referral Grounding, Self-Paced Scene Understanding) for weakly supervised spatio-temporal video grounding...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Contextual_Self-paced_Learning_for_Weakly_Supervised_Spatio-Temporal_Video_Grounding.pdf
  sha_abstract: f0ef99df8e38574f2f50aa9ed6a0bb51cef9b41af8cda2245698d6a5d3c13bb8
  title: Contextual Self-paced Learning for Weakly Supervised Spatio-Temporal Video Grounding
  title_normalized: contextual_selfpaced_learning_for_weakly_supervised_spatiotemporal_video_grounding

================================================================================
Document #94 (ID: 5188975fb8f05d03baa9a5a9af1bd2fee9a5958e965943cb78ab97500ec5a847)
================================================================================
  abstract: Reinforcement learning (RL) has increasingly been applied to solve real-world planning problems, with progress in handling large state spaces and time horizons. However, a key bottleneck in many domains is that RL methods cannot accommodate large, combinatorially structured action spaces. In such settings, even representing the set of feasible actions at a single step may require a complex discrete optimization formulation. We leverage recent advances in embedding trained neural networks into optimization problems to propose SEQUOIA, an RL algorithm that directly optimizes for long-term reward over the feasible action space. Our approach embeds a Q-network into a mixed-integer program to select a combinatorial action in each timestep. Here, we focus on planning over restless bandits, a class of planning problems which capture many real-world examples of sequential decision making. We introduce coRMAB, a broader class of restless bandits with combinatorial actions that cannot be decoupled across the arms of the restless bandit, requiring direct solving over the joint, exponentially large action space. We empirically validate SEQUOIA on four novel restless bandit problems with combinatorial constraints: multiple interventions, path constraints, bipartite matching, and capacity constraints. Our approach significantly outperforms existing methods—which cannot address sequential planning and combinatorial selection simultaneously—by an average of 24.8% on these difficult instances.
  abstract_embedding: [0.216796875, 0.298828125, 0.470703125]... (1536 items)
  authors: ['Lily Xu', 'Bryan Wilder', 'Elias Boutros Khalil']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805012927
  novelty: yes
  reason: Relevance: The paper proposes a novel RL algorithm, SEQUOIA, that can handle large, combinatorially structured action spaces by embedding a Q-network into a mixed-integer program. | Novelty: The propo...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Reinforcement_learning_with_combinatorial_actions_for_coupled_restless_bandits.pdf
  sha_abstract: 81c750179b1fbf6318e2fa9498f02a4a26f32947da69aea321a42154728bfdf3
  title: Reinforcement learning with combinatorial actions for coupled restless bandits
  title_normalized: reinforcement_learning_with_combinatorial_actions_for_coupled_restless_bandits

================================================================================
Document #95 (ID: dc250275528283dedd37161a992696f34c62a1ef00607e7c09c09b4280bd942c)
================================================================================
  abstract: Distributionally robust optimization (DRO) is a powerful technique to train robust machine learning models that perform well under distribution shifts. Compared with empirical risk minimization (ERM), DRO optimizes the expected loss under the worst-case distribution in
an uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem, Jin et al. (2021) showed that its dual problem is generalized $(L_0, L_1)$-smooth condition and gradient noise satisfies the affine variance condition, designed an algorithm of mini-batch normalized gradient descent with momentum, and proved its convergence and complexity.   In this paper, we show that the dual problem and the gradient noise satisfy simpler yet more precise partially generalized smoothness condition and partially affine variance condition by studying the optimization variable and dual variable separately, which further yields much simpler algorithm design and convergence analysis. We develop a double stochastic gradient descent with clipping (D-SGD-C) algorithm that converges to an $\epsilon$-stationary point with $\mathcal O(\epsilon^{-4})$ gradient complexity, which matches with results in Jin et al. (2021). Our algorithm does not need to use momentum, and the proof is much simpler, thanks to the more precise characterization of partially generalized smoothness and partially affine variance noise. We further design a variance-reduced method that achieves a lower gradient complexity of $\mathcal O(\epsilon^{-3})$. Our theoretical results and insights are further verified numerically on a number of tasks, and our algorithms outperform the existing DRO method (Jin et al., 2021).
  abstract_embedding: [0.6875, 0.265625, -0.06884765625]... (1536 items)
  authors: ['Qi Zhang', 'Yi Zhou', 'Simon Khan']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804929042
  novelty: yes
  reason: Relevance: The paper proposes a new algorithm (D-SGD-C) and a variance-reduced method for distributionally robust optimization, which are directly implementable ML techniques. | Novelty: The paper pre...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Revisiting_Large-Scale_Non-convex_Distributionally_Robust_Optimization.pdf
  sha_abstract: ac00ec278b8204c377f5fbc94e399e002c0ccf7de73aef0ca04609c4ea99a211
  title: Revisiting Large-Scale Non-convex Distributionally Robust Optimization
  title_normalized: revisiting_largescale_nonconvex_distributionally_robust_optimization

================================================================================
Document #96 (ID: b030201325f186eca119193cd85d9dddf84147503940e9c840f4fb434692a07e)
================================================================================
  abstract: Low-rank adaptation (LoRA) has become a prevalent method for adapting pre-trained large language models to downstream tasks. However, the simple low-rank decomposition form may constrain the optimization flexibility. To address this limitation, we introduce Location-aware Cosine Adaptation (LoCA), a novel frequency-domain parameter-efficient fine-tuning method based on inverse Discrete Cosine Transform (iDCT) with selective locations of learnable components. We begin with a comprehensive theoretical comparison between frequency-domain and low-rank decompositions for fine-tuning pre-trained large models. Our analysis reveals that frequency-domain decomposition with carefully selected frequency components can surpass the expressivity of traditional low-rank-based methods. Furthermore, we demonstrate that iDCT offers a more efficient implementation compared to inverse Discrete Fourier Transform (iDFT), allowing for better selection and tuning of frequency components while maintaining equivalent expressivity to the optimal iDFT-based adaptation. By employing finite-difference approximation to estimate gradients for discrete locations of learnable coefficients on the DCT spectrum, LoCA dynamically selects the most informative frequency components during training. Experiments on diverse language and vision fine-tuning tasks demonstrate that LoCA offers enhanced parameter efficiency while maintains computational feasibility comparable to low-rank-based methods.
  abstract_embedding: [-0.1806640625, 0.06689453125, 0.0693359375]... (1536 items)
  authors: ['Zhekai Du', 'Yinjie Min', 'Jingjing Li']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805019926
  novelty: yes
  reason: Relevance: The paper proposes a novel frequency-domain fine-tuning method (LoCA) that improves upon existing low-rank adaptation techniques, which is relevant for efficient model adaptation. | Novelty...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: LoCA__Location-Aware_Cosine_Adaptation_for_Parameter-Efficient_Fine-Tuning.pdf
  sha_abstract: 7680878b7ce0e6abdbebbbe2b88ed600cfc1b3b6d21868ef52563ee1ea65a5a4
  title: LoCA: Location-Aware Cosine Adaptation for Parameter-Efficient Fine-Tuning
  title_normalized: loca_locationaware_cosine_adaptation_for_parameterefficient_finetuning

================================================================================
Document #97 (ID: 0783c3d189721d8a74801a5887a9b9b9708e7ec5ca55fce3024d7134902fb9d9)
================================================================================
  abstract: The brain's ability to transform sensory inputs into motor functions is central to neuroscience and crucial for the development of embodied intelligence. Sensory-motor integration involves complex neural circuits, diverse neuronal types, and intricate intercellular connections. Bridging the gap between biological realism and behavioral functionality presents a formidable challenge. In this study, we focus on the columnar structure of the superficial layers of mouse barrel cortex as a model system. We constructed a model comprising 4,218 neurons across 13 neuronal subtypes, with neural distribution and connection strengths constrained by anatomical experimental findings. A key innovation of our work is the development of an effective construction and training pipeline tailored for this biologically constrained model. Additionally, we converted an existing simulated whisker sweep dataset into a spiking-based format, enabling our network to be trained and tested on neural signals that more closely mimic those observed in biological systems. The results of object discrimination utilizing whisker signals demonstrate that our barrel cortex model, grounded in biological constraints, achieves a classification accuracy exceeds classical convolutional neural networks (CNNs), recurrent neural networks (RNNs), and long short-term memory networks (LSTMs), by an average of 8.6%, and is on par with recent spiking neural networks (SNNs) in performance. Interestingly, a whisker deprivation experiment, designed in accordance with neuroscience practices, further validates the perceptual capabilities of our model in behavioral tasks.
Critically, it offers significant biological interpretability: post-training analysis reveals that neurons within our model exhibit firing characteristics and distribution patterns similar to those observed in the actual neuronal systems of the barrel cortex. This study advances our understanding of neural processing in the barrel cortex and exemplifies how integrating detailed biological structures into neural network models can enhance both scientific inquiry and artificial intelligence applications. The code is available at https://github.com/fun0515/RSNN_bfd.
  abstract_embedding: [0.12451171875, -0.2001953125, 0.0072021484375]... (1536 items)
  authors: ['Tianfang Zhu', 'Dongli Hu', 'Jiandong Zhou']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805108837
  novelty: yes
  reason: Relevance: The paper proposes a novel biologically constrained neural network model for the barrel cortex that integrates whisker inputs and replicates key brain network dynamics. | Novelty: The paper...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Biologically_Constrained_Barrel_Cortex_Model_Integrates_Whisker_Inputs_and_Replicates_Key_Brain_Network_Dynamics.pdf
  sha_abstract: 72d37a356c45540ca92ea8d2377e8254c3e3b838446700ef8c75471f072b93dd
  title: Biologically Constrained Barrel Cortex Model Integrates Whisker Inputs and Replicates Key Brain Network Dynamics
  title_normalized: biologically_constrained_barrel_cortex_model_integrates_whisker_inputs_and_replicates_key_brain_network_dynamics

================================================================================
Document #98 (ID: aabf5c0a551fa84aaeff6bcbdfcca0af473ec9ccabdb20216e1ff766e8708167)
================================================================================
  abstract: The ability to reconstruct realistic and controllable upper body avatars from casual monocular videos is critical for various applications in communication and entertainment. By equipping the most recent 3D Gaussian Splatting representation with head 3D morphable models (3DMM), existing methods manage to create head avatars with high fidelity. However, most existing methods only reconstruct a head without the body, substantially limiting their application scenarios. We found that naively applying Gaussians to model the clothed chest and shoulders tends to result in blurry reconstruction and noisy floaters under novel poses. This is because of the fundamental limitation of Gaussians and point clouds -- each Gaussian or point can only have a single directional radiance without spatial variance, therefore an unnecessarily large number of them is required to represent complicated spatially varying texture, even for simple geometry. In contrast, we propose to model the body part with a neural texture that consists of coarse and pose-dependent fine colors. To properly render the body texture for each view and pose without accurate geometry nor UV mapping, we optimize another sparse set of Gaussians as anchors that constrain the neural warping field that maps image plane coordinates to the texture space. We demonstrate that Gaussian Head & Shoulders can fit the high-frequency details on the clothed upper body with high fidelity and potentially improve the accuracy and fidelity of the head region. We evaluate our method with casual phone-captured and internet videos and show our method archives superior reconstruction quality and robustness in both self and cross reenactment tasks. To fully utilize the efficient rendering speed of Gaussian splatting, we additionally propose an accelerated inference method of our trained model without Multi-Layer Perceptron (MLP) queries and reach a stable rendering speed of around 130 FPS for any subjects.
  abstract_embedding: [-0.037109375, 0.13671875, 0.298828125]... (1536 items)
  authors: ['Tianhao Walter Wu', 'Jing Yang', 'Zhilin Guo']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805107172
  novelty: yes
  reason: Relevance: The paper proposes a novel neural texture-based approach for high-fidelity reconstruction of upper body avatars from monocular videos, which is relevant for various communication and entert...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Gaussian_Head___Shoulders__High_Fidelity_Neural_Upper_Body_Avatars_with_Anchor_Gaussian_Guided_Texture_Warping.pdf
  sha_abstract: fca6c082b612b2124472f1798c3b22f2c344bc23e578cbc8aa5d69ff60a67aa5
  title: Gaussian Head & Shoulders: High Fidelity Neural Upper Body Avatars with Anchor Gaussian Guided Texture Warping
  title_normalized: gaussian_head__shoulders_high_fidelity_neural_upper_body_avatars_with_anchor_gaussian_guided_texture_warping

================================================================================
Document #99 (ID: 4f5c20474978697ca2c550cc1e80c93b88af213ecbe4f50da5919af88251a37b)
================================================================================
  abstract: Large Language Models (LLMs) such as GPT-4 and Llama3 have significantly impacted various fields by enabling high-quality synthetic data generation and reducing dependence on expensive human-generated datasets. 
Despite this, challenges remain in the areas of generalization, controllability, diversity, and truthfulness within the existing generative frameworks. To address these challenges, this paper presents DataGen, a comprehensive LLM-powered framework designed to produce diverse, accurate, and highly controllable datasets. DataGen is adaptable, supporting all types of text datasets and enhancing the generative process through innovative mechanisms. To augment data diversity, DataGen incorporates an attribute-guided generation module and a group checking feature. For accuracy, it employs a code-based mathematical assessment for label verification alongside a retrieval-augmented generation technique for factual validation. The framework also allows for user-specified constraints, enabling customization of the data generation process to suit particular requirements. Extensive experiments demonstrate the superior quality of data generated by DataGen, and each module within DataGen plays a critical role in this enhancement. Additionally, DataGen is applied in two practical scenarios: benchmarking LLMs and data augmentation. The results indicate that DataGen effectively supports dynamic and evolving benchmarking and that data augmentation improves LLM capabilities in various domains, including agent-oriented abilities and reasoning skills.
  abstract_embedding: [0.2392578125, 0.19921875, 0.044921875]... (1536 items)
  authors: ['Yue Huang', 'Siyuan Wu', 'Chujie Gao']... (11 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805113365
  novelty: yes
  reason: Relevance: The paper proposes a novel LLM-powered framework called DataGen that generates diverse, accurate, and controllable synthetic datasets, which is relevant for improving ML model training and ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: DataGen__Unified_Synthetic_Dataset_Generation_via_Large_Language_Models.pdf
  sha_abstract: addbee4fbff7d109f759d0aac76c57ea27aa15cebc5f4d21a04f4bd9077d8f08
  title: DataGen: Unified Synthetic Dataset Generation via Large Language Models
  title_normalized: datagen_unified_synthetic_dataset_generation_via_large_language_models

================================================================================
Document #100 (ID: 06cebff90144ce736f05bf6d59dbd3e805a71941ac8ae937d5ba076424b4004c)
================================================================================
  abstract: Large Language Models (LLMs) are increasingly being used in workflows involving generating content to be consumed by humans (*e.g.,* marketing) and also in directly interacting with humans (*e.g.,* through chatbots). The development of such systems that are capable of generating verifiably persuasive messages presents both opportunities and challenges for society. On the one hand, such systems could positively impact domains like advertising and social good, such as addressing drug addiction, and on the other, they could be misused for spreading misinformation and shaping political opinions. To channel LLMs' impact on society, we need to develop systems to measure and benchmark their persuasiveness. With this motivation, we introduce **PersuasionBench** and **PersuasionArena**, the first large-scale benchmark and arena containing a battery of tasks to automatically measure the simulative and generative persuasion abilities of large language models. We introduce **transsuasion** (trans = carrying across, suasion = the act of persuading), a novel task of transforming non-persuasive language into persuasive content while preserving other factors determining persuasiveness (sender, receiver, time, and channel). Our findings indicate that the simulative persuasion capabilities of LLMs are barely above random; however, their generative persuasion capabilities are much better. For instance, GPT-4o loses only 36% of the time when playing against the best human persuader. Further, we find that LLMs' persuasiveness correlates positively with model size, but smaller models can also be made to have a higher persuasiveness than much larger models. Notably, targeted training using synthetic and natural datasets significantly enhances smaller models' persuasive capabilities, challenging scale-dependent assumptions. Our findings carry key implications for both model developers and policymakers. For instance, while the EU AI Act and California's SB-1047 aim to regulate AI models based on the number of floating point operations, we demonstrate that simple metrics like this alone fail to capture the full scope of AI's societal impact. We invite the community to explore and contribute to PersuasionArena and PersuasionBench, available at [behavior-in-the-wild.github.io/measure-persuasion](https://behavior-in-the-wild.github.io/measure-persuasion), to advance our understanding of AI-driven persuasion and its societal implications.
  abstract_embedding: [0.80078125, 0.255859375, 0.052490234375]... (1536 items)
  authors: ['Somesh Kumar Singh', 'Yaman Kumar Singla', 'Harini S I']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804672864
  novelty: yes
  reason: Relevance: The paper proposes a novel benchmark and task (transsuasion) for measuring and improving the persuasiveness of large language models, which is directly relevant to ML research and applicati...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Measuring_And_Improving_Persuasiveness_Of_Large_Language_Models.pdf
  sha_abstract: 18fc1889fe853dafa64efb3dbb118cab96b3b3436203e2e7e94b9fb4f2b06782
  title: Measuring And Improving Persuasiveness Of Large Language Models
  title_normalized: measuring_and_improving_persuasiveness_of_large_language_models

================================================================================
Document #101 (ID: 742ed044194bc33f7e945d344f34deced15d4a8442c34cda46a5f0a3e844e00a)
================================================================================
  abstract: Evaluating aligned large language models' (LLMs) ability to recognize and reject unsafe user requests is crucial for safe, policy-compliant deployments. Existing evaluation efforts, however, face three limitations that we address with **SORRY-Bench**, our proposed benchmark. **First**, existing methods often use coarse-grained taxonomies of unsafe topics, and are over-representing some fine-grained topics. For example, among the ten existing datasets that we evaluated, tests for refusals of self-harm instructions are over 3x less represented than tests for fraudulent activities. SORRY-Bench improves on this by using a fine-grained taxonomy of 44 potentially unsafe topics, and 440 class-balanced unsafe instructions, compiled through human-in-the-loop methods. **Second**, evaluations often overlook the linguistic formatting of prompts, like different languages, dialects, and more --- which are only implicitly considered in many evaluations. We supplement SORRY-bench with 20 diverse linguistic augmentations to systematically examine these effects. **Third**, existing evaluations rely on large LLMs (e.g., GPT-4) for evaluation, which can be computationally expensive. We investigate design choices for creating a fast, accurate automated safety evaluator. By collecting 7K+ human annotations and conducting a meta-evaluation of diverse LLM-as-a-judge designs, we show that fine-tuned 7B LLMs can achieve accuracy comparable to GPT-4 scale LLMs, with lower computational cost. Putting these together, we evaluate over 50 proprietary and open-weight LLMs on SORRY-Bench, analyzing their distinctive safety refusal behaviors. We hope our effort provides a building block for systematic evaluations of LLMs' safety refusal capabilities, in a balanced, granular, and efficient manner. Benchmark demo, data, code, and models are available through [https://sorry-bench.github.io](https://sorry-bench.github.io).
  abstract_embedding: [0.6171875, 0.388671875, -0.03564453125]... (1536 items)
  authors: ['Tinghao Xie', 'Xiangyu Qi', 'Yi Zeng']... (16 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804668318
  novelty: yes
  reason: Relevance: The paper proposes a novel benchmark for evaluating the safety refusal capabilities of large language models, which is highly relevant for the deployment of aligned and policy-compliant AI ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SORRY-Bench__Systematically_Evaluating_Large_Language_Model_Safety_Refusal.pdf
  sha_abstract: 1132bdc951c96fa4b830c6af27985f86b76112fa1a30d90fe1911cc4c157e5ad
  title: SORRY-Bench: Systematically Evaluating Large Language Model Safety Refusal
  title_normalized: sorrybench_systematically_evaluating_large_language_model_safety_refusal

================================================================================
Document #102 (ID: 1529614cf443cb5ac04e75e0edd3892e22f6f868261d5c9e4fe27eb89b34fe4d)
================================================================================
  abstract: Spatial intelligence is the ability of a machine to perceive, reason, and act in three dimensions within space and time.
Recent advancements in large-scale auto-regressive models have demonstrated remarkable capabilities across various reasoning tasks. However, these models often struggle with fundamental aspects of spatial reasoning, particularly in answering questions like "Where am I?" and "What will I see?". While some attempts have been done, existing approaches typically treat them as separate tasks, failing to capture their interconnected nature. In this paper, we present **G**enerative **S**patial **T**ransformer (GST), a novel auto-regressive framework that jointly addresses spatial localization and view prediction. Our model simultaneously estimates the camera pose from a single image and predicts the view from a new camera pose, effectively bridging the gap between spatial awareness and visual prediction. The proposed innovative camera tokenization method enables the model to learn the joint distribution of 2D projections and their corresponding spatial perspectives in an auto-regressive manner. This unified training paradigm demonstrates that joint optimization of pose estimation and novel view synthesis leads to improved performance in both tasks, for the first time, highlighting the inherent relationship between spatial awareness and visual prediction.
  abstract_embedding: [0.0830078125, -0.2431640625, 0.326171875]... (1536 items)
  authors: ['Junyi Chen', 'Di Huang', 'Weicai Ye']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804661278
  novelty: yes
  reason: Relevance: The paper proposes a novel auto-regressive model, the Generative Spatial Transformer (GST), that jointly addresses spatial localization and view prediction, which are innovative ML techniqu...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Where_Am_I_and_What_Will_I_See__An_Auto-Regressive_Model_for_Spatial_Localization_and_View_Prediction.pdf
  sha_abstract: 8561e15af7062e74b03c5d28f7c967863a993a8ffc9244c2ac5bf38a306890cf
  title: Where Am I and What Will I See: An Auto-Regressive Model for Spatial Localization and View Prediction
  title_normalized: where_am_i_and_what_will_i_see_an_autoregressive_model_for_spatial_localization_and_view_prediction

================================================================================
Document #103 (ID: af4796a9d4d8262857817dd0267afa0dd59961823f882405fd44f4b19c8730d6)
================================================================================
  abstract: In response to the increasing demand for tackling out-of-domain (OOD) scenarios, test-time adaptation (TTA) has garnered significant research attention in recent years. To adapt a source pre-trained model to target samples without getting access to their labels, existing approaches have typically employed entropy minimization (EM) loss as a primary objective function. In this paper, we propose an adaptive energy alignment (AEA) solution that achieves fast online TTA. We start from the re-interpretation of the EM loss by decomposing it into two energy-based terms with conflicting roles, showing that the EM loss can potentially hinder the assertive model adaptation. Our AEA addresses this challenge by strategically reducing the energy gap between the source and target domains during TTA, aiming to  effectively align the target domain with the source domains and thus to accelerate adaptation. We specifically propose two novel strategies, each contributing a necessary component for TTA: (i) aligning the energy level of each target sample with the energy zone of the source domain that the pre-trained model is already familiar with, and (ii) precisely guiding the direction of the energy alignment by matching the class-wise correlations between the source and target domains. Our approach demonstrates its effectiveness on various domain shift datasets including CIFAR10-C, CIFAR100-C, and TinyImageNet-C.
  abstract_embedding: [0.2333984375, 0.035888671875, 0.1328125]... (1536 items)
  authors: ['Wonjeong Choi', 'Do-Yeon Kim', 'Jungwuk Park']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804675079
  novelty: yes
  reason: Relevance: The paper proposes a novel adaptive energy alignment (AEA) technique for test-time adaptation, which is a relevant technique for improving model performance on out-of-domain data. | Novelty...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Adaptive_Energy_Alignment_for_Accelerating_Test-Time_Adaptation.pdf
  sha_abstract: a60a1c3d3a3eb153c7c9c6ffd13cf8c44ed17abf50ae7e7056f4d8072120ef5d
  title: Adaptive Energy Alignment for Accelerating Test-Time Adaptation
  title_normalized: adaptive_energy_alignment_for_accelerating_testtime_adaptation

================================================================================
Document #104 (ID: 008cfa6328419e617fbfaa3761e3913eabc0283f80211988df2008885a98bd5b)
================================================================================
  abstract: Speculative decoding (SD), where an extra draft model is employed to provide multiple **draft** tokens first and then the original target model verifies these tokens in parallel, has shown great power for LLM inference acceleration.
However, existing SD methods suffer from the mutual waiting problem, i.e., the target model gets stuck when the draft model is *guessing* tokens, and vice versa. This problem is directly incurred by the asynchronous execution of the draft model and the target model, and is exacerbated due to the fixed draft length in speculative decoding.
To address these challenges, we propose a conceptually simple, flexible, and general framework to boost speculative decoding, namely 
**P**arallel sp**E**culative decoding with **A**daptive d**R**aft **L**ength (PEARL). 
Specifically, PEARL proposes *pre-verify* to verify the first draft token in advance during the drafting phase, and *post-verify* to generate more draft tokens during the verification phase.
PEARL parallels the drafting phase and the verification phase via applying the two strategies, and achieves adaptive draft length for different scenarios, which effectively alleviates the mutual waiting problem.
Experiments on various text generation benchmarks demonstrate the effectiveness of our PEARL, leading to a superior speedup performance up to **4.43$\times$** and **1.50$\times$**, compared to auto-regressive decoding and vanilla speculative decoding, respectively.
  abstract_embedding: [0.146484375, 0.2373046875, 0.3828125]... (1536 items)
  authors: ['Tianyu Liu', 'Yun Li', 'Qitan Lv']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804670501
  novelty: yes
  reason: Relevance: The paper proposes a new speculative decoding framework (PEARL) that improves inference efficiency through parallel execution and adaptive draft length. | Novelty: PEARL introduces novel te...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: PEARL__Parallel_Speculative_Decoding_with_Adaptive_Draft_Length.pdf
  sha_abstract: c4ea84ced88430de125af0f2501cec5b3e0a8ff5e44934a312b59cdfe6d97aa4
  title: PEARL: Parallel Speculative Decoding with Adaptive Draft Length
  title_normalized: pearl_parallel_speculative_decoding_with_adaptive_draft_length

================================================================================
Document #105 (ID: 1f763e436aeb5f87954fe69005529f693484e7c364334b46eb89a8c3cfdd7698)
================================================================================
  abstract: The potential of large language models (LLMs) as decision support tools is increasingly being explored in fields such as business, engineering, and medicine, which often face challenging tasks of *decision-making under uncertainty*. In this paper, we show that directly prompting LLMs on these types of decision-making problems can yield poor results, especially as the problem complexity increases. To aid in these tasks, we propose DeLLMa (Decision-making Large Language Model assistant), a framework designed to enhance decision-making accuracy in uncertain environments. DeLLMa involves a multi-step reasoning procedure that integrates recent best practices in scaling *inference-time reasoning*, drawing upon principles from decision theory and utility theory, to provide an accurate and human-auditable decision-making process. We validate our procedure on multiple realistic decision-making environments, demonstrating that DeLLMa can consistently enhance the decision-making performance of leading language models, and achieve up to a 40% increase in accuracy over competing methods. Additionally, we show how performance improves when scaling compute at test time, and carry out human evaluations to benchmark components of DeLLMa.
  abstract_embedding: [0.50390625, 0.0986328125, 0.287109375]... (1536 items)
  authors: ['Ollie Liu', 'Deqing Fu', 'Dani Yogatama']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804677067
  novelty: yes
  reason: Relevance: The paper proposes a novel framework called DeLLMa that enhances decision-making accuracy of large language models in uncertain environments, which is relevant for practical applications. |...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: DeLLMa__Decision_Making_Under_Uncertainty_with_Large_Language_Models.pdf
  sha_abstract: 5f60da8f5660a3f9ca08ee81a0d93c937ab3438df7d1b37302b35f8d5d95b937
  title: DeLLMa: Decision Making Under Uncertainty with Large Language Models
  title_normalized: dellma_decision_making_under_uncertainty_with_large_language_models

================================================================================
Document #106 (ID: edb9a3f5f6638d44937de7b27724e3e651a81a8552e7a8fc856bd159f3cb5378)
================================================================================
  abstract: We present InvMSAFold, an inverse folding method for generating protein sequences optimized for diversity and speed. For a given structure, InvMSAFold generates the parameters of a pairwise probability distribution over the space of sequences, capturing the amino acid covariances observed in Multiple Sequence Alignments (MSA) of homologous proteins. This allows for the efficient generation of highly diverse protein sequences while preserving structural and functional integrity.
We demonstrate that this increased diversity in sampled sequences translates into greater variability in biochemical properties, highlighting the exciting potential of our method for applications such as protein design. The orders of magnitude improvement in sampling speed compared to existing methods unlocks new possibilities for high-throughput in virtual screening.
  abstract_embedding: [0.0771484375, 0.8359375, 0.115234375]... (1536 items)
  authors: ['luca alessandro silva', 'Barthelemy Meynard-Piganeau', 'Carlo Lucibello']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804665930
  novelty: yes
  reason: Relevance: The paper proposes a novel inverse folding method for generating diverse protein sequences while preserving structural and functional integrity, which is relevant for protein design and vir...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Fast_Uncovering_of_Protein_Sequence_Diversity_from_Structure.pdf
  sha_abstract: 8eb22f03bc71b0f57c61fa23d160455d7c6749d88e318cd896a068819c33f4b2
  title: Fast Uncovering of Protein Sequence Diversity from Structure
  title_normalized: fast_uncovering_of_protein_sequence_diversity_from_structure

================================================================================
Document #107 (ID: 624147d6742fb546e283d48bd48df9a579472ec785441ebd5e43d839679e777c)
================================================================================
  abstract: Stochastic Variance Reduced Gradient (SVRG), introduced by Johnson & Zhang (2013), is a theoretically compelling optimization method. However, as Defazio & Bottou (2019) highlight, its effectiveness in deep learning is yet to be proven. In this work, we demonstrate the potential of SVRG in optimizing real-world neural networks. Our empirical analysis finds that, for deeper neural networks, the strength of the variance reduction term in SVRG should be smaller and decrease as training progresses. Inspired by this, we introduce a multiplicative coefficient $\alpha$ to control the strength and adjust it through a linear decay schedule. We name our method $\alpha$-SVRG. Our results show $\alpha$-SVRG better optimizes models, consistently reducing training loss compared to the baseline and standard SVRG across various model architectures and multiple image classification datasets. We hope our findings encourage further exploration into variance reduction techniques in deep learning. Code is available at github.com/davidyyd/alpha-SVRG.
  abstract_embedding: [0.41015625, 0.197265625, -0.11083984375]... (1536 items)
  authors: ['Yida Yin', 'Zhiqiu Xu', 'Zhiyuan Li']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804679117
  novelty: yes
  reason: Relevance: The paper proposes a novel optimization algorithm, alpha-SVRG, which improves upon the standard SVRG method for training deep neural networks. | Novelty: The paper introduces a new multipli...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: A_Coefficient_Makes_SVRG_Effective.pdf
  sha_abstract: 239e70df6a9d37c53d43744e790606c1a9a9cc55401e7c5e7658c9167d3edd5d
  title: A Coefficient Makes SVRG Effective
  title_normalized: a_coefficient_makes_svrg_effective

================================================================================
Document #108 (ID: 14433f61affc7d3a0e2fde7186fe1dd790e0ce8c2a6e5c2bc16a0f6b4def2255)
================================================================================
  abstract: We propose a novel neural network architecture, the normalized Transformer (nGPT) with representation learning on the hypersphere. In nGPT, all vectors forming the embeddings, MLP, attention matrices and hidden states are unit norm normalized. The input stream of tokens travels on the surface of a hypersphere, with each layer contributing a displacement towards the target output predictions. These displacements are defined by the MLP and attention blocks, whose vector components also reside on the same hypersphere. Experiments show that nGPT learns much faster, reducing the number of training steps required to achieve the same accuracy by a factor of 4 to 20, depending on the sequence length.
  abstract_embedding: [0.50390625, 0.016357421875, 0.515625]... (1536 items)
  authors: ['Ilya Loshchilov', 'Cheng-Ping Hsieh', 'Simeng Sun']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804663891
  novelty: yes
  reason: Relevance: The paper proposes a novel Transformer architecture, nGPT, with representation learning on the hypersphere, which could be a valuable technique for efficient training and inference. | Novel...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: nGPT__Normalized_Transformer_with_Representation_Learning_on_the_Hypersphere.pdf
  sha_abstract: 9c456b374f8847aab6ebe1d4ef3e2027b4eee0cdf458dc29c93701a128c4c5d9
  title: nGPT: Normalized Transformer with Representation Learning on the Hypersphere
  title_normalized: ngpt_normalized_transformer_with_representation_learning_on_the_hypersphere

================================================================================
Document #109 (ID: 3fece16679dc53f4a7dbfc0720264764fab5bf97c779bbdfb97e58483184e529)
================================================================================
  abstract: Large language models have shown remarkable reasoning abilities and scaling laws suggest that large parameter count, especially along the depth axis, is the primary driver. In this work, we make a stronger claim --- many reasoning problems require a large depth but not necessarily many parameters. This unlocks a novel application of looped models for reasoning. Firstly, we show that for many synthetic reasoning problems like addition, $p$-hop induction, and math problems, a $k$-layer transformer looped $L$ times nearly matches the performance of a $kL$-layer non-looped model, and is significantly better than a $k$-layer model. This is further corroborated by theoretical results showing that many such reasoning problems can be solved via iterative algorithms, and thus, can be solved effectively using looped models with nearly optimal depth. Perhaps surprisingly, these benefits also translate to practical settings of language modeling --- on many downstream reasoning tasks, a language model with $k$-layers looped $L$ times can be competitive to, if not better than, a $kL$-layer language model. In fact, our empirical analysis reveals an intriguing phenomenon: looped and non-looped models exhibit scaling behavior that depends on their effective depth, akin to the inference-time scaling of chain-of-thought (CoT) reasoning. We further elucidate the connection to CoT reasoning by proving that looped models implicitly generate latent thoughts and can simulate $T$ steps of CoT with $T$ loops. Inspired by these findings, we also present an interesting dichotomy between reasoning and memorization, and design a looping-based regularization that is effective on both fronts.
  abstract_embedding: [0.5546875, -0.09716796875, 0.3203125]... (1536 items)
  authors: ['Nikunj Saunshi', 'Nishanth Dikkala', 'Zhiyuan Li']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804743452
  novelty: yes
  reason: Relevance: The paper proposes a novel looped transformer architecture that can effectively solve various reasoning problems, which is relevant for building efficient and powerful AI models. | Novelty:...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Reasoning_with_Latent_Thoughts__On_the_Power_of_Looped_Transformers.pdf
  sha_abstract: 117b4a8d098d1d18e19701927e217ce52282f3b874faf73c968c79e3a9335147
  title: Reasoning with Latent Thoughts: On the Power of Looped Transformers
  title_normalized: reasoning_with_latent_thoughts_on_the_power_of_looped_transformers

================================================================================
Document #110 (ID: fa5b8a49c29068e607b9b063fc93935b058c23f5cc00da869346efb6c147b093)
================================================================================
  abstract: Kolmogorov-Arnold Networks (KAN) \cite{liu2024kan} were very recently proposed as a potential alternative to the prevalent architectural backbone of many deep learning models, the multi-layer perceptron (MLP). KANs have seen success in various tasks of AI for science, with their empirical efficiency and accuracy demonstrated in function regression, PDE solving, and many more scientific problems.
 
In this article, we revisit the comparison of KANs and MLPs, with emphasis on a theoretical perspective. On the one hand, we compare the representation and approximation capabilities of KANs and MLPs. We establish that MLPs can be represented using KANs of a comparable size. This shows that the approximation and representation capabilities of KANs are at least as good as MLPs. Conversely, we show that KANs can be represented using MLPs, but that in this representation the number of parameters increases by a factor of the KAN grid size. This suggests that KANs with a large grid size may be more efficient than MLPs at approximating certain functions. On the other hand, from the perspective of learning and optimization, we study the spectral bias of KANs compared with MLPs. We demonstrate that KANs are less biased toward low frequencies than MLPs. We highlight that the multi-level learning feature specific to KANs, i.e. grid extension of splines, improves the learning process for high-frequency components.  Detailed comparisons with different choices of depth, width, and grid sizes of KANs are made, shedding some light on how to choose the hyperparameters in practice.
  abstract_embedding: [0.48828125, 0.296875, -0.11962890625]... (1536 items)
  authors: ['Yixuan Wang', 'Jonathan W. Siegel', 'Ziming Liu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804717413
  novelty: yes
  reason: Relevance: The paper proposes a new model architecture (KANs) and analyzes its representation and approximation capabilities compared to MLPs, which is relevant for ML research. | Novelty: The paper p...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: On_the_expressiveness_and_spectral_bias_of_KANs.pdf
  sha_abstract: 1e9d7472d3271a447dbe2f858777cc2584213363686c73b799f4c4ac07ac308f
  title: On the expressiveness and spectral bias of KANs
  title_normalized: on_the_expressiveness_and_spectral_bias_of_kans

================================================================================
Document #111 (ID: 49dd15f8af8a3d18efab5b62b8a9c0081cb1ade341e924ee11903a86dff918ed)
================================================================================
  abstract: In the realm of large-scale language models, a significant challenge arises when extrapolating sequences beyond the maximum allowable length. 
This is because the model's position embedding mechanisms are limited to positions encountered during training, thus preventing effective representation of positions in longer sequences.
We analyzed conventional position encoding methods for long contexts and found the following characteristics.
(1) When the representation dimension is regarded as the time axis, Rotary Position Embedding (RoPE) can be interpreted as a restricted wavelet transform using Haar-like wavelets. 
However, because it uses only a fixed scale parameter, it does not fully exploit the advantages of wavelet transforms, which capture the fine movements of non-stationary signals using multiple scales (window sizes). 
This limitation could explain why RoPE performs poorly in extrapolation.
(2)
Previous research as well as our own analysis indicates that Attention with Linear Biases (ALiBi) functions similarly to windowed attention, using windows of varying sizes.
However, it has limitations in capturing deep dependencies because it restricts the receptive field of the model.
From these insights, we propose a new position representation method that captures multiple scales (i.e., window sizes) by leveraging wavelet transforms without limiting the model's attention field.
Experimental results show that this new method improves the performance of the model in both short and long contexts. 
In particular, our method allows extrapolation of position information without limiting the model's attention field.
  abstract_embedding: [0.25390625, 0.3984375, 0.43359375]... (1536 items)
  authors: ['Yui Oka', 'Taku Hasegawa', 'Kyosuke Nishida']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804714460
  novelty: yes
  reason: Relevance: The paper proposes a new position encoding method based on wavelet transforms, which is a novel model architecture component that could improve performance on long-context tasks. | Novelty:...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Wavelet-based_Positional_Representation_for_Long_Context.pdf
  sha_abstract: b703606e85aa5bdb35db7ac23d9d6b5ee5836e6fd54072b3f5f4f199ddfdca1f
  title: Wavelet-based Positional Representation for Long Context
  title_normalized: waveletbased_positional_representation_for_long_context

================================================================================
Document #112 (ID: 5abd035030841a14bf3c0452534807b0c3d942c9a39d6b14a834765f0f68cc40)
================================================================================
  abstract: The robustness of LLMs to jailbreak attacks, where users design prompts to circumvent safety measures and misuse model capabilities, has been studied primarily for LLMs acting as simple chatbots. Meanwhile, LLM agents---which use external tools and can execute multi-stage tasks---may pose a greater risk if misused, but their robustness remains underexplored. To facilitate research on LLM agent misuse, we propose a new benchmark called AgentHarm. The benchmark includes a diverse set of 110 explicitly malicious agent tasks (440 with augmentations), covering 11 harm categories including fraud, cybercrime, and harassment. In addition to measuring whether models refuse harmful agentic requests, scoring well on AgentHarm requires jailbroken agents to maintain their capabilities following an attack to complete a multi-step task. We evaluate a range of leading LLMs, and find (1) leading LLMs are surprisingly complaint with malicious agent requests without jailbreaking, (2) simple universal jailbreak strings can be adapted to effectively jailbreak agents, and (3) these jailbreaks enable coherent and malicious multi-step agent behavior and retain model capabilities. To enable simple and reliable evaluation of attacks and defenses for LLM-based agents, we publicly release AgentHarm at https://huggingface.co/datasets/ai-safety-institute/AgentHarm.
  abstract_embedding: [1.203125, 0.357421875, 0.02392578125]... (1536 items)
  authors: ['Maksym Andriushchenko', 'Alexandra Souly', 'Mateusz Dziemian']... (12 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804738833
  novelty: yes
  reason: Relevance: The paper proposes a new benchmark, AgentHarm, to measure the robustness of LLM agents against malicious prompts and jailbreak attacks, which is a critical safety concern for real-world dep...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: AgentHarm__A_Benchmark_for_Measuring_Harmfulness_of_LLM_Agents.pdf
  sha_abstract: 112e83a7b152a913153f288f3bee4ae334b3671856467caec6ca6ee3eaa1b397
  title: AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents
  title_normalized: agentharm_a_benchmark_for_measuring_harmfulness_of_llm_agents

================================================================================
Document #113 (ID: 71f56f452c67e1bb5af3d5e0ce7c56be99f45592a415098e9177832984618ace)
================================================================================
  abstract: We propose Step-by-Step Coding (SBSC): a multi-turn math reasoning framework that enables Large Language Models (LLMs) to generate sequence of programs for solving Olympiad level math problems. After each turn/step, by leveraging the code execution outputs and programs of previous steps, the model generates the next sub-task and the corresponding program to complete it. This way, SBSC, sequentially navigates to reach the final answer. SBSC allows more granular, flexible and precise approach to problem-solving compared to existing methods. Extensive experiments highlight the effectiveness of SBSC in tackling competition and Olympiad-level math problems. For Claude-3.5-Sonnet, we observe SBSC (greedy decoding) surpasses existing state-of-the-art (SOTA) program generation based reasoning strategies by absolute 10.7% on AMC12, 8% on AIME and 12.6% on MathOdyssey. Given SBSC is multi-turn in nature, we also benchmark SBSC’s greedy decoding against self- consistency decoding results of existing SOTA math reasoning strategies and observe performance gain by absolute 6.2% on AMC, 6.7% on AIME and 7.4% on MathOdyssey.
  abstract_embedding: [0.1376953125, 0.0201416015625, 0.400390625]... (1536 items)
  authors: ['Kunal Singh', 'Ankan Biswas', 'Sayandeep Bhowmick']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804709231
  novelty: yes
  reason: Relevance: The paper proposes a novel multi-turn math reasoning framework called SBSC that leverages LLMs to generate sequences of programs for solving Olympiad-level math problems. | Novelty: SBSC is...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SBSC__Step-by-Step_Coding_for_Improving_Mathematical_Olympiad_Performance.pdf
  sha_abstract: 998b33220e1b381deabb692ceb7d82425192b1246c910507f29b2b8c25ffa436
  title: SBSC: Step-by-Step Coding for Improving Mathematical Olympiad Performance
  title_normalized: sbsc_stepbystep_coding_for_improving_mathematical_olympiad_performance

================================================================================
Document #114 (ID: 61552bb2cd5d7c1e879a0cf1d4461834daa30b4c506f697f929ddb0bf95d0376)
================================================================================
  abstract: Post-training quantization (PTQ) techniques applied to weights, activations, and the KV cache greatly reduce memory usage, latency, and power consumption of Large Language Models (LLMs), but may lead to large quantization errors when outliers are present. Rotating activation or weight matrices helps remove outliers and benefits quantization. In this work, we identify a collection of applicable rotation parameterizations that lead to identical outputs in full-precision Transformer architectures while enhancing quantization accuracy. In addition, we find that some random rotations lead to much better quantization than others, with an up to 13 points difference in downstream zero-shot reasoning performance. As a result, we propose SpinQuant, a novel approach that incorporates learned rotation matrices for optimal quantized network accuracy. With 4-bit quantization of weight, activation, and KV-cache, SpinQuant narrows the accuracy gap on zero-shot reasoning tasks with full precision to merely 2.9 points on the LLaMA-2 7B model, surpassing LLM-QAT by 19.1 points and SmoothQuant by 25.0 points. Furthermore, SpinQuant also outperforms concurrent work QuaRot, which applies random rotations to remove outliers. In particular, for LLaMA-3 8B models that are hard to quantize, SpinQuant reduces the gap to full precision by up to 45.1% relative to QuaRot. Code is available at https://github.com/facebookresearch/SpinQuant.
  abstract_embedding: [0.05224609375, 0.205078125, 0.39453125]... (1536 items)
  authors: ['Zechun Liu', 'Changsheng Zhao', 'Igor Fedorov']... (9 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804745168
  novelty: yes
  reason: Relevance: The paper proposes a novel quantization technique called SpinQuant that incorporates learned rotation matrices to improve the accuracy of quantized LLMs. | Novelty: SpinQuant is a novel qua...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SpinQuant__LLM_Quantization_with_Learned_Rotations.pdf
  sha_abstract: 19a1e9b0210f36ee3a5ac1980fde673f6d4c0474e3b08532ec06c9cf1447cc1f
  title: SpinQuant: LLM Quantization with Learned Rotations
  title_normalized: spinquant_llm_quantization_with_learned_rotations

================================================================================
Document #115 (ID: 55c049da86efaa64556290e42bcb17774b6102f290e5451fddcd77acd3284e61)
================================================================================
  abstract: Dexterous hands exhibit significant potential for complex real-world grasping tasks. While recent studies have primarily focused on learning policies for specific robotic hands, the development of a universal policy that controls diverse dexterous hands remains largely unexplored.
In this work, we study the learning of cross-embodiment dexterous grasping policies using reinforcement learning (RL). Inspired by the capability of human hands to control various dexterous hands through teleoperation, we propose a universal action space based on the human hand's eigengrasps. The policy outputs eigengrasp actions that are then converted into specific joint actions for each robot hand through a retargeting mapping. We simplify the robot hand's proprioception to include only the positions of fingertips and the palm, offering a unified observation space across different robot hands. Our approach demonstrates an 80\% success rate in grasping objects from the YCB dataset across four distinct embodiments using a single vision-based policy. Additionally, our policy exhibits zero-shot generalization to two previously unseen embodiments and significant improvement in efficient finetuning. For further details and videos, visit our project page (https://sites.google.com/view/crossdex).
  abstract_embedding: [0.8828125, -0.1337890625, 0.115234375]... (1536 items)
  authors: ['Haoqi Yuan', 'Bohan Zhou', 'Yuhui Fu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804712560
  novelty: yes
  reason: Relevance: The paper proposes a novel universal action space and observation space for controlling diverse dexterous robot hands, which is relevant for efficient and scalable robotic grasping. | Novel...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Cross-Embodiment_Dexterous_Grasping_with_Reinforcement_Learning.pdf
  sha_abstract: aeb09c61758897cda7ad1f6d8e56d25507a17eb1c8d04f2a06540dcce03525e7
  title: Cross-Embodiment Dexterous Grasping with Reinforcement Learning
  title_normalized: crossembodiment_dexterous_grasping_with_reinforcement_learning

================================================================================
Document #116 (ID: ef63c41bc33bf930af6cdc5af406bfca5b94c70eca29b11a1e20a2d70c266439)
================================================================================
  abstract: The prohibitive training costs of Large Language Models (LLMs) have emerged as a significant bottleneck in the development of next-generation LLMs. In this paper, we show that it is possible to significantly reduce the training costs of LLMs without sacrificing their performance. Specifically, we introduce patch-level training for LLMs, in which multiple tokens are aggregated into a unit of higher information density, referred to as a `patch', to serve as the fundamental text unit for training LLMs. During patch-level training, we feed the language model shorter sequences of patches and train it to predict the next patch, thereby processing the majority of the training data at a significantly reduced cost. Following this, the model continues token-level training on the remaining training data to align with the inference mode. Experiments on a diverse range of models (370M-2.7B parameters) demonstrate that patch-level training can reduce the overall training costs to 0.5$\times$, without compromising the model performance compared to token-level training. Source code: \url{https://github.com/shaochenze/PatchTrain}.
  abstract_embedding: [0.291015625, 0.1767578125, 0.162109375]... (1536 items)
  authors: ['Chenze Shao', 'Fandong Meng', 'Jie Zhou']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804740424
  novelty: yes
  reason: Relevance: The paper proposes a novel patch-level training approach for large language models, which can significantly reduce training costs without compromising performance. | Novelty: The patch-leve...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Beyond_Next_Token_Prediction__Patch-Level_Training_for_Large_Language_Models.pdf
  sha_abstract: 9708cfcf22e205df0997b86176d4e0ecbd09b2f0c1216a1a4d6e21eb6fdb2ced
  title: Beyond Next Token Prediction: Patch-Level Training for Large Language Models
  title_normalized: beyond_next_token_prediction_patchlevel_training_for_large_language_models

================================================================================
Document #117 (ID: 3aea036afd752025edc99fee8d82e3096127c6f2ca4f14a988705e3bcc4cf82f)
================================================================================
  abstract: Graph Transformers are popular neural networks that extend the well-known Transformer architecture to the graph domain. These architectures operate by applying self-attention on graph nodes and incorporating graph structure through the use of positional encodings (e.g., Laplacian positional encoding) or structural encodings (e.g., random-walk structural encoding). The quality of such encodings is critical, since they provide the necessary \emph{graph inductive biases} to condition the model on graph structure. In this work, we propose \emph{motif structural encoding} (MoSE) as a flexible and powerful structural encoding framework based on counting graph homomorphisms. Theoretically, we compare the expressive power of MoSE to random-walk structural encoding and relate both encodings to the expressive power of standard message passing neural networks. Empirically, we observe that MoSE outperforms other well-known positional and structural encodings across a range of architectures, and it achieves state-of-the-art performance on a widely studied molecular property prediction dataset.
  abstract_embedding: [0.376953125, 0.451171875, 0.30078125]... (1536 items)
  authors: ['Linus Bao', 'Emily Jin', 'Michael M. Bronstein']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804705404
  novelty: yes
  reason: Relevance: The paper proposes a novel structural encoding method (motif structural encoding) for graph transformer models, which is a new model architecture. | Novelty: The proposed motif structural e...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Homomorphism_Counts_as_Structural_Encodings_for_Graph_Learning.pdf
  sha_abstract: aabb8fb183e66f16ec0357e532f2beb59779f15090a469d651cfcfca639d9150
  title: Homomorphism Counts as Structural Encodings for Graph Learning
  title_normalized: homomorphism_counts_as_structural_encodings_for_graph_learning

================================================================================
Document #118 (ID: 90cd116169acb97504d24329d392318a2b9f89b683a8289896e75614c8c17b52)
================================================================================
  abstract: Training language models currently requires pre-determining a fixed compute budget because the typical cosine learning rate schedule depends on the total number of steps. In contrast, the Warmup-Stable-Decay (WSD) schedule uses a constant learning rate to produce a main branch of iterates that can in principle continue indefinitely without a pre-specified compute budget. Then, given any compute budget, one can branch out from the main branch at a proper time with a rapidly decaying learning rate to produce a strong model. Empirically, WSD generates an intriguing, non-traditional loss curve: the loss remains elevated during the stable phase but sharply declines during the decay phase. Towards explaining this phenomenon, we conjecture that pretraining loss exhibits a river valley landscape, which resembles a deep valley with a river at its bottom. Under this assumption, we show that during the stable phase, the iterate undergoes large oscillations due to the high learning rate, yet it progresses swiftly along the river. During the decay phase, the rapidly dropping learning rate minimizes the iterate’s oscillations, moving it closer to the river and revealing true optimization progress. Therefore, the sustained high learning rate phase and fast decaying phase are responsible for progress in the river and the mountain directions, respectively, and are both critical. Our analysis predicts phenomenons consistent with empirical observations and shows that this landscape can naturally emerge from pretraining on a simple bi-gram dataset. Inspired by the theory, we introduce WSD-S, a variant of WSD that reuses previous checkpoints’ decay phases and keeps only one main branch, where we resume from a decayed checkpoint. WSD-S empirically outperforms WSD and Cyclic-Cosine in obtaining multiple pretrained language model checkpoints across various compute budgets in a single run for parameters scaling from 0.1B to 1.2B.
  abstract_embedding: [0.2236328125, 0.337890625, -0.09521484375]... (1536 items)
  authors: ['Kaiyue Wen', 'Zhiyuan Li', 'Jason S. Wang']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804644344
  novelty: yes
  reason: Relevance: The paper proposes a novel learning rate schedule (Warmup-Stable-Decay) and a theoretical explanation for its effectiveness, which could lead to efficiency improvements in training large la...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Understanding_Warmup-Stable-Decay_Learning_Rates__A_River_Valley_Loss_Landscape_View.pdf
  sha_abstract: b2804e5eb0d77fef57d645fb89c3e16a56fa916cc6ca278d712859f3142691b3
  title: Understanding Warmup-Stable-Decay Learning Rates: A River Valley Loss Landscape View
  title_normalized: understanding_warmupstabledecay_learning_rates_a_river_valley_loss_landscape_view

================================================================================
Document #119 (ID: 962f39b7c0430399059063045e9ae2d8ef6d45cf47827e955d213122cc076506)
================================================================================
  abstract: The deployment of Deep Neural Networks (DNNs) in energy-constrained environments, such as Energy Harvesting Wireless Sensor Networks (EH-WSNs), introduces significant challenges due to the intermittent nature of power availability. This study introduces NExUME, a novel training methodology designed specifically for DNNs operating under such constraints. We propose a dynamic adjustment of training parameters—dropout rates and quantization levels—that adapt in real-time to the available energy, which varies in energy harvesting scenarios.

This approach utilizes a model that integrates the characteristics of the network architecture and the specific energy harvesting profile. It dynamically adjusts training strategies, such as the intensity and timing of dropout and quantization, based on predictions of energy availability. This method not only conserves energy but also enhances the network’s adaptability, ensuring robust learning and inference capabilities even under stringent power constraints. Our results show a 6% to 22% improvement in accuracy over current methods, with an increase of less than 5% in computational overhead. This paper details the development of the adaptive training framework, describes the integration of energy profiles with dropout and quantization adjustments, and presents a comprehensive evaluation using real-world data. Additionally, we introduce a novel dataset aimed at furthering the application of energy harvesting in computational settings.
  abstract_embedding: [-0.0289306640625, 0.052490234375, 0.0654296875]... (1536 items)
  authors: ['Cyan Subhra Mishra', 'Deeksha Chaudhary', 'Jack Sampson']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804648791
  novelty: yes
  reason: Relevance: The paper proposes a novel training methodology that dynamically adjusts dropout rates and quantization levels to adapt to intermittent power availability, which is a relevant efficiency im...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: NExUME__Adaptive_Training_and_Inference_for_DNNs_under_Intermittent_Power_Environments.pdf
  sha_abstract: c829ae22f4b4bba4e51d828c65fd0e1aafc4adb571661fd4f7db74a414f69cae
  title: NExUME: Adaptive Training and Inference for DNNs under Intermittent Power Environments
  title_normalized: nexume_adaptive_training_and_inference_for_dnns_under_intermittent_power_environments

================================================================================
Document #120 (ID: ac6873deab65a6e3779ce3d76708bbe90719fb87b5ae82ef158c942764427ccf)
================================================================================
  abstract: Reinforcement learning (RL) has made significant progress in various domains, but scaling it to long-horizon tasks with complex decision-making remains challenging. Skill learning attempts to address this by abstracting actions into higher-level behaviors. However, current approaches often fail to recognize semantically similar behaviors as the same skill and use fixed skill lengths, limiting flexibility and generalization. To address this, we propose Dynamic Contrastive Skill Learning (DCSL), a novel framework that redefines skill representation and learning. DCSL introduces three key ideas: state-transition based skill definition, skill similarity function learning, and dynamic skill length adjustment. By focusing on state transitions and leveraging contrastive learning, DCSL effectively captures the semantic context of behaviors and adapts skill lengths to match the appropriate temporal extent of behaviors. Our approach enables more flexible and adaptive skill extraction, particularly in complex or noisy datasets, and demonstrates competitive performance compared to existing methods in task completion and efficiency.
  abstract_embedding: [0.58984375, 0.236328125, 0.431640625]... (1536 items)
  authors: ['Jinwoo Choi', 'Seung-Woo Seo']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805053449
  novelty: yes
  reason: Relevance: The paper proposes a novel skill learning framework with state-transition based skill definition, skill similarity function learning, and dynamic skill length adjustment, which are relevant...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Dynamic_Contrastive_Skill_Learning_with_State-Transition_Based_Skill_Clustering_and_Dynamic_Length_Adjustment.pdf
  sha_abstract: 95cc22737d21913176b66faee3ed85410b5d1f9c9da0b1f78513b893d2a27871
  title: Dynamic Contrastive Skill Learning with State-Transition Based Skill Clustering and Dynamic Length Adjustment
  title_normalized: dynamic_contrastive_skill_learning_with_statetransition_based_skill_clustering_and_dynamic_length_adjustment

================================================================================
Document #121 (ID: c3dcdd1ab76980fe9275d95c2bde53396b31bf1cee355b2963de5a8f5f61ce91)
================================================================================
  abstract: Image tokenizers are crucial for visual generative models, \eg, diffusion models (DMs) and autoregressive (AR) models, as they construct the latent representation for modeling. Increasing token length is a common approach to improve image reconstruction quality. However, tokenizers with longer token lengths are not guaranteed to achieve better generation quality. There exists a trade-off between reconstruction and generation quality regarding token length. In this paper, we investigate the impact of token length on both image reconstruction and generation and provide a flexible solution to the tradeoff. We propose \textbf{ImageFolder}, a semantic tokenizer that provides spatially aligned image tokens that can be folded during autoregressive modeling to improve both efficiency and quality. To enhance the representative capability without increasing token length, we leverage dual-branch product quantization to capture different contexts of images. Specifically, semantic regularization is introduced in one branch to encourage compacted semantic information while another branch is designed to capture pixel-level details. Extensive experiments demonstrate the superior quality of image generation and shorter token length with ImageFolder tokenizer.
  abstract_embedding: [0.0230712890625, 0.2490234375, 0.20703125]... (1536 items)
  authors: ['Xiang Li', 'Kai Qiu', 'Hao Chen']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805067118
  novelty: yes
  reason: Relevance: The paper proposes a novel image tokenizer, ImageFolder, that improves both image reconstruction and generation quality by leveraging a dual-branch product quantization approach. | Novelty:...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ImageFolder__Autoregressive_Image_Generation_with_Folded_Tokens.pdf
  sha_abstract: 52f7ec61b5d45de995fbd284e4ebb7b828161d5190ed96ac16e5a08760ec133e
  title: ImageFolder: Autoregressive Image Generation with Folded Tokens
  title_normalized: imagefolder_autoregressive_image_generation_with_folded_tokens

================================================================================
Document #122 (ID: ea09c00c40b706be73b46f72a3ca13963fe0b84a50e3fbadc0b7527b3a9a1476)
================================================================================
  abstract: Multilingual large language models (LLMs) are great translators, but this is largely limited to high-resource languages. For many LLMs, translating in and out of low-resource languages remains a challenging task. To maximize data efficiency in this low-resource setting, we introduce Mufu, which includes a selection of automatically generated multilingual candidates and an instruction to correct inaccurate translations in the prompt. Mufu prompts turn a translation task into a postediting one, and seek to harness the LLM’s reasoning capability with auxiliary translation candidates, from which the model is required to assess the input quality, align the semantics cross-lingually, copy from relevant inputs and override instances that are incorrect. Our experiments on En-XX translations over the Flores-200 dataset show LLMs finetuned against Mufu-style prompts are robust to poor quality auxiliary translation candidates, achieving performance superior to NLLB 1.3B distilled model in 64% of low- and very-low-resource language pairs. We then distill these models to reduce inference cost, while maintaining on average 3.1 chrF improvement over finetune-only baseline in low-resource translations.
  abstract_embedding: [0.310546875, 0.419921875, 0.1337890625]... (1536 items)
  authors: ['Zheng Wei Lim', 'Nitish Gupta', 'Honglin Yu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805040570
  novelty: yes
  reason: Relevance: The paper proposes a novel multilingual translation technique called Mufu that leverages large language models and auxiliary translation candidates to improve performance on low-resource la...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Mufu___Multilingual_Fused_Learning_for_Low-Resource_Translation_with_LLM.pdf
  sha_abstract: 9e0306a186210d6b5127370786b642a629bff95a65fc51ae3a93a9bf7a55f249
  title: Mufu:  Multilingual Fused Learning for Low-Resource Translation with LLM
  title_normalized: mufu__multilingual_fused_learning_for_lowresource_translation_with_llm

================================================================================
Document #123 (ID: e9d527f931db86d884b7f1042d5ae9731f81998ddf877d5ad11fc2394712e74b)
================================================================================
  abstract: Cascades and speculative decoding are two common approaches to improving language models' inference efficiency.  Both approaches interleave two models, but via fundamentally distinct mechanisms: deferral rule that invokes the larger model only for “hard” inputs, while  speculative decoding uses speculative execution to primarily invoke the larger model in parallel scoring mode. These mechanisms offer different benefits: empirically, cascades offer compelling cost-quality trade-offs, often even outperforming the large model; speculative cascades offer impressive speed-ups, while guaranteeing quality-neutrality. In this paper, we leverage the best of both these approaches by designing new speculative cascading techniques that implement their deferral rule through speculative execution. We characterize the optimal deferral rule for our speculative cascades, and employ a plug-in approximation to the optimal rule.  Experiments with Gemma and T5 models on a range of language benchmarks show that our approach yields better cost quality trade-offs than cascading and speculative decoding baselines.
  abstract_embedding: [0.259765625, 0.275390625, 0.11962890625]... (1536 items)
  authors: ['Harikrishna Narasimhan', 'Wittawat Jitkrittum', 'Ankit Singh Rawat']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805046697
  novelty: yes
  reason: Relevance: The paper proposes a new speculative cascading technique that combines the benefits of cascading and speculative decoding, which is relevant for improving the efficiency of language models....
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Faster_Cascades_via_Speculative_Decoding.pdf
  sha_abstract: c1740e4314d3ff87a4c6b53014889f0eada36cfb0e6ecf2e8582608fb1d7f6db
  title: Faster Cascades via Speculative Decoding
  title_normalized: faster_cascades_via_speculative_decoding

================================================================================
Document #124 (ID: 05b97cd2b989f0dd8b189a82964f21a857d448852d296dd4d8d05cfa84e6db56)
================================================================================
  abstract: Code has been shown to be effective in enhancing the mathematical reasoning abilities of large language models due to its precision and accuracy. Previous works involving continued mathematical pretraining  often include code that utilizes math-related packages, which are primarily designed for fields such as engineering, machine learning, signal processing, or module testing, rather than being directly focused on mathematical reasoning. In this paper, we introduce a novel method for generating mathematical code accompanied with corresponding reasoning steps for continued pretraining. Our approach begins with the construction of a high-quality mathematical continued pretraining dataset by incorporating math-related web data, code using mathematical packages, math textbooks, and synthetic data. Next, we construct reasoning steps by extracting LaTeX expressions, the conditions needed for the expressions, and the results of the expressions from the previously collected dataset. Based on this extracted information, we generate corresponding code to accurately capture the mathematical reasoning process. Appending the generated code to each reasoning step results in data consisting of paired natural language reasoning steps and their corresponding code. Combining this data with the original dataset results in a 19.2B-token high-performing mathematical pretraining corpus, which we name MathCode-Pile. Training several popular base models with this corpus significantly improves their mathematical abilities, leading to the creation of the MathCoder2 family of models. All of our data processing and training code is open-sourced, ensuring full transparency and easy reproducibility of the entire data collection and training pipeline.
  abstract_embedding: [0.296875, 0.3671875, 0.296875]... (1536 items)
  authors: ['Zimu Lu', 'Aojun Zhou', 'Ke Wang']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804634617
  novelty: yes
  reason: Relevance: The paper proposes a novel method for generating a high-quality mathematical pretraining dataset with corresponding reasoning steps, which can be used to improve the mathematical abilities ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MathCoder2__Better_Math_Reasoning_from_Continued_Pretraining_on_Model-translated_Mathematical_Code.pdf
  sha_abstract: eb66f3255069f9fa1718c1243249ec2d689860b9c41c9b74d04c1684f53b7d3e
  title: MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code
  title_normalized: mathcoder2_better_math_reasoning_from_continued_pretraining_on_modeltranslated_mathematical_code

================================================================================
Document #125 (ID: 127b26d61c6b3b3eb468c4a713ce33d754d93ddc3f3029dd94ccef6378b7a9ea)
================================================================================
  abstract: This paper investigates whether sequence models can learn to perform numerical algorithms, e.g. gradient descent, on the fundamental problem of least squares. Our goal is to inherit two properties of standard algorithms from numerical analysis: (1) machine precision, i.e. we want to obtain solutions that are accurate to near floating point error, and (2) numerical generality, i.e. we want them to apply broadly across problem instances. We find that prior approaches using Transformers fail to meet these criteria, and identify limitations present in existing architectures and training procedures. First, we show that softmax Transformers struggle to perform high-precision multiplications, which prevents them from precisely learning numerical algorithms. Second, we identify an alternate class of architectures, comprised entirely of polynomials, that can efficiently represent high-precision gradient descent iterates. Finally, we investigate precision bottlenecks during training and address them via a high-precision training recipe that reduces stochastic gradient noise. Our recipe enables us to train two polynomial architectures, gated convolutions and linear attention, to perform gradient descent iterates on least squares problems. For the first time, we demonstrate the ability to train to near machine precision. Applied iteratively, our models obtain $100,000\times$ lower MSE than standard Transformers trained end-to-end and they incur a $10,000\times$ smaller generalization gap on out-of-distribution problems. We make progress towards end-to-end learning of numerical algorithms for least squares.
  abstract_embedding: [0.2470703125, 0.1494140625, 0.27734375]... (1536 items)
  authors: ['Jerry Weihong Liu', 'Jessica Grogan', 'Owen M Dugan']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804625272
  novelty: yes
  reason: Relevance: The paper proposes a novel architecture and training procedure for learning high-precision numerical algorithms, specifically for the least squares problem, which is relevant for efficient ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Towards_Learning_High-Precision_Least_Squares_Algorithms_with_Sequence_Models.pdf
  sha_abstract: a0aacaa6150ff4c3864629affca9d59c7d3fcd0f37d4a48bf46efd5ef51d0945
  title: Towards Learning High-Precision Least Squares Algorithms with Sequence Models
  title_normalized: towards_learning_highprecision_least_squares_algorithms_with_sequence_models

================================================================================
Document #126 (ID: faa176f2c09c5d0771f40f5c8802a196b679a05e75c112773dcc6845942252d7)
================================================================================
  abstract: Large Language Models (LLMs) applied to code-related applications have emerged as a prominent field, attracting significant interest from academia and industry. However, as new and improved LLMs are developed, existing evaluation benchmarks (e.g., HumanEvla, MBPP) are no longer sufficient for assessing their capabilities suffering from data contamination, overfitting, saturation, and focus on merely code generation. In this work, we propose LiveCodeBench, a comprehensive and contamination-free evaluation of LLMs for code, which collects new problems over time from contests across three competition platforms, Leetcode, Atcoder, and Codeforces. Notably, our benchmark also focuses on a broader range of code-related capabilities, such as self-repair, code execution, and test output prediction, beyond just code generation. Currently, LiveCodeBench hosts over six hundred coding problems that were published between May 2023 and Aug 2024. We evaluate over 50 LLMs on LiveCodeBench (LCB for brevity) presenting the largest evaluation study of code LLMs on competition problems. Based on the study, we present novel empirical findings on contamination, overfitting, and holistic evaluations. We demonstrate that time-segmented evaluations serve as a robust approach to evade contamination; they are successful at detecting contamination across a wide range of open and closed models including GPT-4O, Claude, Deepseek, and Codestral. Next, we highlight overfitting and saturation of traditional coding benchmarks like HumanEvla and demonstrate LCB allows more reliable evaluations. Finally, our holistic evaluation scenarios allow for measuring the different capabilities of programming agents in isolation.
  abstract_embedding: [0.423828125, 0.20703125, 0.29296875]... (1536 items)
  authors: ['Naman Jain', 'King Han', 'Alex Gu']... (10 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804630250
  novelty: yes
  reason: Relevance: The paper proposes a new comprehensive benchmark for evaluating LLMs on a broad range of code-related capabilities, which is directly relevant for ML research and deployment. | Novelty: The...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: LiveCodeBench__Holistic_and_Contamination_Free_Evaluation_of_Large_Language_Models_for_Code.pdf
  sha_abstract: addae2285a052467c9db4a025661a67521342994cb4d6a4642502e74d7166074
  title: LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code
  title_normalized: livecodebench_holistic_and_contamination_free_evaluation_of_large_language_models_for_code

================================================================================
Document #127 (ID: 9a9b9655a1a8765bd2d52eecc9b4adf3101884737bd274a9897cb2eea3292c56)
================================================================================
  abstract: Building deep reinforcement learning (RL) agents that find a good policy with few samples has proven notoriously challenging. To achieve sample efficiency, recent work has explored updating neural networks with large numbers of gradient steps for every new sample. While such high update-to-data (UTD) ratios have shown strong empirical performance, they also introduce instability to the training process.  Previous approaches need to rely on periodic neural network parameter resets to address this instability, but restarting the training process is infeasible in many real-world applications and requires tuning the resetting interval. In this paper, we focus on one of the core difficulties of stable training with limited samples: the inability of learned value functions to generalize to unobserved on-policy actions. We mitigate this issue directly by augmenting the off-policy RL training process with a small amount of data generated from a learned world model. Our method, Model-Augmented Data for TD Learning (MAD-TD) uses small amounts of generated data to stabilize high UTD training and achieve competitive performance on the most challenging tasks in the DeepMind control suite. Our experiments further highlight the importance of employing a good model to generate data, MAD-TD's ability to combat value overestimation, and its practical stability gains for continued learning.
  abstract_embedding: [0.97265625, 0.146484375, 0.4140625]... (1536 items)
  authors: ['Claas A Voelcker', 'Marcel Hussing', 'Eric Eaton']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804627991
  novelty: yes
  reason: Relevance: The paper proposes a novel training algorithm (MAD-TD) that uses a learned world model to augment the off-policy RL training process, which is an innovative technique to improve sample effi...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MAD-TD__Model-Augmented_Data_stabilizes_High_Update_Ratio_RL.pdf
  sha_abstract: de33890c223c008f9657b46ae8a0f14091ca069c4b024347c2f3b8034ec28770
  title: MAD-TD: Model-Augmented Data stabilizes High Update Ratio RL
  title_normalized: madtd_modelaugmented_data_stabilizes_high_update_ratio_rl

================================================================================
Document #128 (ID: 50c1a594558bb82d81864aa485e5a6bb36b678ef9380f5cbb8c6cedf521f113f)
================================================================================
  abstract: As large language models (LLMs) are rapidly advancing and achieving near-human capabilities on specific tasks, aligning them with human values is becoming more urgent. In scenarios where LLMs outperform humans, we face a weak-to-strong alignment problem where we need to effectively align strong student LLMs through weak supervision generated by weak teachers. Existing alignment methods mainly focus on strong-to-weak alignment and self-alignment settings, and it is impractical to adapt them to the much harder weak-to-strong alignment setting. To fill this gap, we propose a multi-agent contrastive preference optimization (MACPO) framework. MACPO facilitates weak teachers and strong students to learn from each other by iteratively reinforcing unfamiliar positive behaviors while penalizing familiar negative ones. To get this, we devise a mutual positive behavior augmentation strategy to encourage weak teachers and strong students to learn from each other's positive behavior and further provide higher quality positive behavior for the next iteration. Additionally, we propose a hard negative behavior construction strategy to induce weak teachers and strong students to generate familiar negative behavior by fine-tuning on negative behavioral data. Experimental results on the HH-RLHF and PKU-SafeRLHF datasets, evaluated using both automatic metrics and human judgments, demonstrate that MACPO simultaneously improves the alignment performance of strong students and weak teachers. Moreover, as the number of weak teachers increases, MACPO achieves better weak-to-strong alignment performance through more iteration optimization rounds.
  abstract_embedding: [0.546875, 0.60546875, 0.078125]... (1536 items)
  authors: ['Yougang Lyu', 'Lingyong Yan', 'Zihan Wang']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804639388
  novelty: yes
  reason: Relevance: The paper proposes a novel multi-agent contrastive preference optimization (MACPO) framework for aligning strong student LLMs with weak teacher supervision, which is a key challenge in AI a...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MACPO__Weak-to-Strong_Alignment_via_Multi-Agent_Contrastive_Preference_Optimization.pdf
  sha_abstract: 0c932039fcf2bde530985aa566e92b411d4f5499445b7f35310a470443d7860e
  title: MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization
  title_normalized: macpo_weaktostrong_alignment_via_multiagent_contrastive_preference_optimization

================================================================================
Document #129 (ID: 4e7cf710ddcc24cdee5d9fc92bf2c95b75aeb1336878176dd2b9aeca89c734d7)
================================================================================
  abstract: As function approximators, deep neural networks have served as an effective tool to represent various signal types. Recent approaches utilize multi-layer perceptrons (MLPs) to learn a nonlinear mapping from a coordinate to its corresponding signal, facilitating the learning of continuous neural representations from discrete data points. Despite notable successes in learning diverse signal types, coordinate-based MLPs often face issues of overfitting and limited generalizability beyond the training region, resulting in subpar extrapolation performance. This study addresses scenarios where the underlying true signals exhibit periodic properties, either spatially or temporally. We propose a novel network architecture, which extracts periodic patterns from measurements and leverages this information to represent the signal, thereby enhancing generalization and improving extrapolation performance. We demonstrate the efficacy of the proposed method through comprehensive experiments, including the learning of the periodic solutions for differential equations, and time series imputation (interpolation) and forecasting (extrapolation) on real-world datasets.
  abstract_embedding: [0.41796875, 0.470703125, 0.29296875]... (1536 items)
  authors: ['Woojin Cho', 'Minju Jo', 'Kookjin Lee']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804622604
  novelty: yes
  reason: Relevance: The paper proposes a novel neural network architecture for learning periodic signals, which is an innovative model architecture relevant for ML research. | Novelty: The proposed method for ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Neural_Functions_for_Learning_Periodic_Signal.pdf
  sha_abstract: 1ea927545c6ab2b1c639f82a80f82f96eb405b08df2f2ca24e49e93211d762ef
  title: Neural Functions for Learning Periodic Signal
  title_normalized: neural_functions_for_learning_periodic_signal

================================================================================
Document #130 (ID: f137bce46441aabc5906fe50839aca22186b13a3cb4faf340eb124290148895f)
================================================================================
  abstract: Graph Domain Adaptation (GDA) addresses a pressing challenge in cross-network learning, particularly pertinent due to the absence of labeled data in real-world graph datasets. Recent studies attempted to learn domain invariant representations by eliminating structural shifts between graphs. In this work, we show that existing methodologies have overlooked the significance of the graph node attribute, a pivotal factor for graph domain alignment. 
Specifically, we first reveal the impact of node attributes for GDA by theoretically proving that in addition to the graph structural divergence between the domains, the node attribute discrepancy also plays a critical role in GDA. Moreover, we also empirically show that the attribute shift is more substantial than the topology shift, which further underscore the importance of node attribute alignment in GDA. Inspired by this finding, a novel cross-channel module is developed to fuse and align both views between the source and target graphs for GDA. Experimental results on a variety of benchmark verify the effectiveness of our method.
  abstract_embedding: [0.296875, 0.30078125, -0.0693359375]... (1536 items)
  authors: ['Ruiyi Fang', 'Bingheng Li', 'zhao kang']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804632628
  novelty: yes
  reason: Relevance: The paper proposes a novel cross-channel module to align both graph structure and node attributes for graph domain adaptation, which is an important and relevant technique for ML models. | ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: On_the_Benefits_of_Attribute-Driven_Graph_Domain_Adaptation.pdf
  sha_abstract: 32639fb627fececb4968bd2121248d5f9edebfae77eceb9bca62788b1b5a51ef
  title: On the Benefits of Attribute-Driven Graph Domain Adaptation
  title_normalized: on_the_benefits_of_attributedriven_graph_domain_adaptation

================================================================================
Document #131 (ID: 69a516e7592205a1b84fb76980df5b2663e03eb19453fb7ba88980afe6e62f1f)
================================================================================
  abstract: Skill learning from language instructions is a critical challenge in developing intelligent agents that can generalize across diverse tasks and follow complex human instructions. Hierarchical methods address this by decomposing the learning problem into multiple levels, where the high-level and low-level policies are mediated through a latent plan space. Effective modeling and learning of this latent plan space are key to enabling robust and interpretable skill learning. In this paper, we introduce LADS, a hierarchical approach that learns language-conditioned discrete latent plans through semantic skill abstractions. Our method decouples the learning of the latent plan space from the language-conditioned high-level policy to improve training stability. First, we incorporate a trajectory encoder to learn a discrete latent space with the low-level policy, regularized by language instructions. Next, we model the high-level policy as a categorical distribution over these discrete latent plans to capture the multi-modality of the dataset. Through experiments in simulated control environments, we demonstrate that LADS outperforms state-of-the-art methods in both skill learning and compositional generalization.
  abstract_embedding: [0.84375, 0.357421875, 0.41015625]... (1536 items)
  authors: ['Haobin Jiang', 'Jiangxing Wang', 'Zongqing Lu']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804637171
  novelty: yes
  reason: Relevance: The paper proposes a novel hierarchical model architecture with a discrete latent plan space, which is relevant for efficient and interpretable skill learning from language instructions. | ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Discrete_Latent_Plans_via_Semantic_Skill_Abstractions.pdf
  sha_abstract: ba295660ae1e64bf5446e1727b0a9e1629dd6789101f2da29e30ddac5251bef6
  title: Discrete Latent Plans via Semantic Skill Abstractions
  title_normalized: discrete_latent_plans_via_semantic_skill_abstractions

================================================================================
Document #132 (ID: 90170d644c08791de33e2a10eb596ca6da29ff6445eb8585eff65d1256650e78)
================================================================================
  abstract: Large language models (LLMs) have shown remarkable proficiency in generating text, benefiting from extensive training on vast textual corpora. However, LLMs may also acquire unwanted behaviors from the diverse and sensitive nature of their training data, which can include copyrighted and private content. Machine unlearning has been introduced as a viable solution to remove the influence of such problematic content without the need for costly and time-consuming retraining. This process aims to erase specific knowledge from LLMs while preserving as much model utility as possible. Despite the effectiveness of current unlearning methods, little attention has been given to whether existing unlearning methods for LLMs truly achieve forgetting or merely hide the knowledge, which current unlearning benchmarks fail to detect. This paper reveals that applying quantization to models that have undergone unlearning can restore the "forgotten" information. We conduct comprehensive experiments using various quantization techniques across multiple precision levels to thoroughly evaluate this phenomenon. We find that for unlearning methods with utility constraints, the unlearned model retains an average of 21\% of the intended forgotten knowledge in full precision, which significantly increases to 83\% after 4-bit quantization. Based on our empirical findings, we provide a theoretical explanation for the observed phenomenon and propose a quantization-robust unlearning strategy aimed at mitigating this intricate issue. Our results highlight a fundamental tension between preserving the utility of the unlearned model and preventing knowledge recovery through quantization, emphasizing the challenge of balancing these two objectives. Altogether, our study underscores a major failure in existing unlearning methods for LLMs, strongly advocating for more comprehensive and robust strategies to ensure authentic unlearning without compromising model utility. Our code is available at: https://github.com/zzwjames/FailureLLMUnlearning.
  abstract_embedding: [0.002288818359375, 0.384765625, 0.07177734375]... (1536 items)
  authors: ['Zhiwei Zhang', 'Fali Wang', 'Xiaomin Li']... (9 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805058304
  novelty: yes
  reason: Relevance: The paper proposes a novel quantization-based technique to evaluate the effectiveness of machine unlearning methods for large language models, which is directly relevant to improving ML mod...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Catastrophic_Failure_of_LLM_Unlearning_via_Quantization.pdf
  sha_abstract: cef2ec87387938a378ab6f08693d2738d388bd163ee30158da99b2e2e79151b2
  title: Catastrophic Failure of LLM Unlearning via Quantization
  title_normalized: catastrophic_failure_of_llm_unlearning_via_quantization

================================================================================
Document #133 (ID: 3a5a533475b2586109270edffb948bcd09186f4329a1df8372a4035167268efe)
================================================================================
  abstract: Masked diffusion models (MDMs) have emerged as a popular research topic for generative modeling of discrete data, thanks to their superior performance over other discrete diffusion models, and are rivaling the auto-regressive models (ARMs) for language modeling tasks. The recent effort in simplifying the masked diffusion framework further leads to alignment with continuous-space diffusion models and more principled training and sampling recipes. 
In this paper, however, we reveal that both training and sampling of MDMs are theoretically free from the time variable, arguably the key signature of diffusion models, and are instead equivalent to masked models. The connection on the sampling aspect is drawn by our proposed first-hitting sampler (FHS). Specifically, we show that the FHS is theoretically equivalent to MDMs' original generation process while significantly alleviating the time-consuming categorical sampling and achieving a 20$\times$ speedup. In addition, our investigation raises doubts about whether MDMs can truly beat ARMs in text generation. We identify, for the first time, an underlying numerical issue, even with the commonly used 32-bit floating-point precision, which results in inaccurate categorical sampling. 
We show that it lowers the effective temperature both theoretically and empirically, and the resulting decrease in token diversity makes previous evaluations, which assess the generation quality solely through the incomplete generative perplexity metric, somewhat unfair.
  abstract_embedding: [0.154296875, 0.7109375, 0.46875]... (1536 items)
  authors: ['Kaiwen Zheng', 'Yongxin Chen', 'Hanzi Mao']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805073192
  novelty: yes
  reason: Relevance: The paper proposes a new sampling algorithm (first-hitting sampler) and identifies numerical issues in the categorical sampling of masked diffusion models, which are relevant to improving t...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Masked_Diffusion_Models_are_Secretly_Time-Agnostic_Masked_Models_and_Exploit_Inaccurate_Categorical_Sampling.pdf
  sha_abstract: 0c27bc80e84183a0ab222964b4054fbc1ab68222bb7a744b09729da3407a2bc5
  title: Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling
  title_normalized: masked_diffusion_models_are_secretly_timeagnostic_masked_models_and_exploit_inaccurate_categorical_sampling

================================================================================
Document #134 (ID: 6338092b2bfbc8b066ad4bd43cb7e2649ee525d061caaa7856ae923905be7726)
================================================================================
  abstract: In the open world, detecting out-of-distribution (OOD) data, whose labels are disjoint with those of in-distribution (ID) samples, is important for reliable deep neural networks (DNNs). To achieve better detection performance, one type of approach proposes to fine-tune the model with auxiliary OOD datasets to amplify the difference between ID and OOD data through a separation loss defined on model outputs. However, none of these studies consider enlarging the feature disparity, which should be more effective compared to outputs. The main difficulty lies in the diversity of OOD samples, which makes it hard to describe their feature distribution, let alone design losses to separate them from ID features. In this paper, we neatly fence off the problem based on an aggregation property of ID features named Neural Collapse (NC). NC means that the penultimate features of ID samples within a class are nearly identical to the last layer weight of the corresponding class. Based on this property, we propose a simple but effective loss called Separation Loss, which binds the features of OOD data in a subspace orthogonal to the principal subspace of ID features formed by NC. In this way, the features of ID and OOD samples are separated by different dimensions. By optimizing the feature separation loss rather than purely enlarging output differences, our detection achieves SOTA performance on CIFAR10, CIFAR100 and ImageNet benchmarks without any additional data augmentation or sampling, demonstrating the importance of feature separation in OOD detection. Code is available
at https://github.com/Wuyingwen/Pursuing-Feature-Separation-for-OOD-Detection.
  abstract_embedding: [0.046875, 0.384765625, 0.384765625]... (1536 items)
  authors: ['Yingwen Wu', 'Ruiji Yu', 'Xinwen Cheng']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805037102
  novelty: yes
  reason: Relevance: The paper proposes a novel loss function, Separation Loss, to improve out-of-distribution detection by separating the features of in-distribution and out-of-distribution data. | Novelty: Th...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Pursuing_Feature_Separation_based_on_Neural_Collapse_for_Out-of-Distribution_Detection.pdf
  sha_abstract: 9fb664e55c7fa39b06cf4eba29d45fc7617153a60dc06ea803e361e3bafa8856
  title: Pursuing Feature Separation based on Neural Collapse for Out-of-Distribution Detection
  title_normalized: pursuing_feature_separation_based_on_neural_collapse_for_outofdistribution_detection

================================================================================
Document #135 (ID: 70d4297ed9befd928cfe073b4b273f311b71ed65e00980591fc987cbc7dd82ab)
================================================================================
  abstract: Graph Neural Networks (GNNs) have achieved remarkable success in various graph-based learning tasks. While their performance is often attributed to the powerful neighborhood aggregation mechanism, recent studies suggest that other components such as non-linear layers may also significantly affecting how GNNs process the input graph data in the spectral domain. Such evidence challenges the prevalent opinion that neighborhood aggregation mechanisms dominate the behavioral characteristics of GNNs in the spectral domain. To demystify such a conflict, this paper introduces a comprehensive benchmark to measure and evaluate GNNs' capability in capturing and leveraging the information encoded in different frequency components of the input graph data. Specifically, we first conduct an exploratory study demonstrating that GNNs can flexibly yield outputs with diverse frequency components even when certain frequencies are absent or filtered out from the input graph data. We then formulate a novel research problem of measuring and benchmarking the performance of GNNs from a spectral perspective. To take an initial step towards a comprehensive benchmark, we design an evaluation protocol supported by comprehensive theoretical analysis. Finally, we introduce a comprehensive benchmark on real-world datasets, revealing insights that challenge prevalent opinions from a spectral perspective. We believe that our findings will open new avenues for future advancements in this area. Our implementations can be found at: https://github.com/yushundong/Spectral-benchmark.
  abstract_embedding: [0.1875, 0.2275390625, 0.142578125]... (1536 items)
  authors: ['Yushun Dong', 'Patrick Soga', 'Yinhan He']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805049714
  novelty: yes
  reason: Relevance: The paper proposes a novel benchmark to evaluate the spectral properties of graph neural networks, which is a novel and important aspect of GNN architecture and training. | Novelty: The pro...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Graph_Neural_Networks_Are_More_Than_Filters__Revisiting_and_Benchmarking_from_A_Spectral_Perspective.pdf
  sha_abstract: 165d3e13d1668804e8c3e60cd1b9d0d8c7644d68c90541848fcef1dd107d874c
  title: Graph Neural Networks Are More Than Filters: Revisiting and Benchmarking from A Spectral Perspective
  title_normalized: graph_neural_networks_are_more_than_filters_revisiting_and_benchmarking_from_a_spectral_perspective

================================================================================
Document #136 (ID: a1976f6ebff2614a9508ce908f6bed12136a9a659f7839953ffb87bf7904e697)
================================================================================
  abstract: Motion diffusion models and Reinforcement Learning (RL) based control for physics-based simulations have complementary strengths for human motion generation. The former is capable of generating a wide variety of motions, adhering to intuitive control such as text, while the latter offers physically plausible motion and direct interaction with the environment. In this work, we present a method that combines their respective strengths. CLoSD is a text-driven RL physics-based controller, guided by diffusion generation for various tasks. Our key insight is that motion diffusion can serve as an on-the-fly universal planner for a robust RL controller. To this end, CLoSD maintains a closed-loop interaction between two modules — a Diffusion Planner (DiP), and a tracking controller. DiP is a fast-responding autoregressive diffusion model, controlled by textual prompts and target locations, and the controller is a simple and robust motion imitator that continuously receives motion plans from DiP and provides feedback from the environment. CLoSD is capable of seamlessly performing a sequence of different tasks, including navigation to a goal location, striking an object with a hand or foot as specified in a text prompt, sitting down, and getting up.
  abstract_embedding: [0.421875, 0.359375, 0.21875]... (1536 items)
  authors: ['Guy Tevet', 'Sigal Raab', 'Setareh Cohan']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805063027
  novelty: yes
  reason: Relevance: The paper proposes a novel architecture that combines diffusion models and reinforcement learning for multi-task character control, which is relevant for innovative model architectures. | N...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CLoSD__Closing_the_Loop_between_Simulation_and_Diffusion_for_multi-task_character_control.pdf
  sha_abstract: fbab6225bfce7824fa3773240fd9aec3f6e350eee8afdc9471ee89e7d3f204a6
  title: CLoSD: Closing the Loop between Simulation and Diffusion for multi-task character control
  title_normalized: closd_closing_the_loop_between_simulation_and_diffusion_for_multitask_character_control

================================================================================
Document #137 (ID: eb42e23b6d604785b982e1304c2fc0e4bc9c118f7c259868e70954d5e9e752fc)
================================================================================
  abstract: Large language models (LLMs) have brought significant changes to many aspects of our lives.
However, assessing and ensuring their chronological knowledge remains challenging.
Existing approaches fall short in addressing the temporal adaptability of knowledge, often relying on a fixed time-point view. 
To overcome this, we introduce ChroKnowBench, a benchmark dataset designed to evaluate chronologically accumulated knowledge across three key aspects: multiple domains, time dependency, temporal state.
Our benchmark distinguishes between knowledge that evolves (e.g., personal history, scientific discoveries, amended laws) and knowledge that remain constant (e.g., mathematical truths, commonsense facts). 
Building on this benchmark, we present ChroKnowledge (Chronological Categorization of Knowledge), a novel sampling-based framework for evaluating LLMs' non-parametric chronological knowledge.
Our evaluation led to the following observations: 
(1) The ability of eliciting temporal knowledge varies depending on the data format that model was trained on.
(2) LLMs partially recall knowledge or show a cut-off at temporal boundaries rather than recalling all aspects of knowledge correctly.
Thus, we apply our ChroKnowPrompt, an in-depth prompting to elicit chronological knowledge by traversing step-by-step through the surrounding time spans.
We observe that it successfully recalls objects across both open-source and proprietary LLMs, demonstrating versatility, though it faces challenges with dynamic datasets and unstructured formats.
  abstract_embedding: [0.3828125, 0.306640625, 0.23046875]... (1536 items)
  authors: ['Yein Park', 'Chanwoong Yoon', 'Jungwoo Park']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805346031
  novelty: yes
  reason: Relevance: The paper proposes a novel benchmark and framework for evaluating the chronological knowledge of language models, which is an important aspect of model capabilities. | Novelty: The proposed...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ChroKnowledge__Unveiling_Chronological_Knowledge_of_Language_Models_in_Multiple_Domains.pdf
  sha_abstract: b28d1c13bb728f5344d02fbd78418d702bb0304d1b2456b54986cd09d792d4b0
  title: ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains
  title_normalized: chroknowledge_unveiling_chronological_knowledge_of_language_models_in_multiple_domains

================================================================================
Document #138 (ID: 1ad0583ce6efc8e89f2646582bac855010c20dc0b8b75d07a92af5740daded4a)
================================================================================
  abstract: Recent advances in large language and vision-language models have enabled zero-shot inference, allowing models to solve new tasks without task-specific training. Various adaptation techniques such as prompt engineering, In-Context Learning (ICL), and supervised fine-tuning can further enhance the model’s performance on a downstream task, but they require substantial manual effort to construct effective prompts or labeled examples. In this work, we introduce a joint inference framework for fully unsupervised adaptation, eliminating the need for manual prompt engineering and labeled examples. Unlike zero-shot inference, which makes independent predictions, the joint inference makes predictions simultaneously for all inputs in a given task. Since direct joint inference involves computationally expensive optimization, we develop efficient approximation techniques, leading to two unsupervised adaptation methods: unsupervised fine-tuning and unsupervised ICL. We demonstrate the effectiveness of our methods across diverse tasks and models, including language-only Llama-3.1 on natural language processing tasks, reasoning-oriented Qwen2.5-Math on grade school math problems, vision-language OpenFlamingo on vision tasks, and the API-only access GPT-4o model on massive multi-discipline tasks. Our experiments demonstrate substantial improvements over the standard zero-shot approach, including 39% absolute improvement on the challenging GSM8K math reasoning dataset. Remarkably, despite being fully unsupervised, our framework often performs on par with supervised approaches that rely on ground truth labels.
  abstract_embedding: [-0.08935546875, 0.375, 0.197265625]... (1536 items)
  authors: ['Artyom Gadetsky', 'Andrei Atanov', 'Yulun Jiang']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805343833
  novelty: yes
  reason: Relevance: The paper proposes a novel unsupervised adaptation framework that can enhance the performance of large language and vision-language models on downstream tasks without manual prompt engineer...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Large__Vision__Language_Models_are_Unsupervised_In-Context_Learners.pdf
  sha_abstract: 0f73661c7f6c590e011562660724046231dfa94d1e37e37cddc93dacf4b4526f
  title: Large (Vision) Language Models are Unsupervised In-Context Learners
  title_normalized: large_vision_language_models_are_unsupervised_incontext_learners

================================================================================
Document #139 (ID: ffddb7f91e6f138bb60ff05ab03f905181a031912f5a08d3fbb53c1e9be92c78)
================================================================================
  abstract: We empirically investigate the camera bias of person re-identification (ReID) models. Previously, camera-aware methods have been proposed to address this issue, but they are largely confined to training domains of the models. We measure the camera bias of ReID models on unseen domains and reveal that camera bias becomes more pronounced under data distribution shifts. As a debiasing method for unseen domain data, we revisit feature normalization on embedding vectors. While the normalization has been used as a straightforward solution, its underlying causes and broader applicability remain unexplored. We analyze why this simple method is effective at reducing bias and show that it can be applied to detailed bias factors such as low-level image properties and body angle. Furthermore, we validate its generalizability across various models and benchmarks, highlighting its potential as a simple yet effective test-time postprocessing method for ReID. In addition, we explore the inherent risk of camera bias in unsupervised learning of ReID models. The unsupervised models remain highly biased towards camera labels even for seen domain data, indicating substantial room for improvement. Based on observations of the negative impact of camera-biased pseudo labels on training, we suggest simple training strategies to mitigate the bias. By applying these strategies to existing unsupervised learning algorithms, we show that significant performance improvements can be achieved with minor modifications.
  abstract_embedding: [0.07763671875, 0.054931640625, -0.16015625]... (1536 items)
  authors: ['Myungseo Song', 'Jin-Woo Park', 'Jong-Seok Lee']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805334679
  novelty: yes
  reason: Relevance: The paper proposes new techniques for addressing camera bias in person re-identification models, including feature normalization and training strategies to mitigate bias in unsupervised lea...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Exploring_the_Camera_Bias_of_Person_Re-identification.pdf
  sha_abstract: b697890657da353662352bfbb7cef6b40ff2ac49f82b7df250352b60e51b52f4
  title: Exploring the Camera Bias of Person Re-identification
  title_normalized: exploring_the_camera_bias_of_person_reidentification

================================================================================
Document #140 (ID: d95d04d500239bc33c2871200b52282cdc173630d3f17e64a2dc390e8ad691c6)
================================================================================
  abstract: An important paradigm in 3D object detection is the use of multiple modalities to enhance accuracy in both normal and challenging conditions, particularly for long-tail scenarios. To address this, recent studies have explored two directions of adaptive approaches: MoE-based adaptive fusion, which struggles with uncertainties arising from distinct object configurations, and late fusion for output-level adaptive fusion, which relies on separate detection pipelines and limits comprehensive understanding. In this work, we introduce Cocoon, an object- and feature-level uncertainty-aware fusion framework. The key innovation lies in uncertainty quantification for heterogeneous representations, enabling fair comparison across modalities through the introduction of a feature aligner and a learnable surrogate ground truth, termed feature impression. We also define a training objective to ensure that their relationship provides a valid metric for uncertainty quantification. Cocoon consistently outperforms existing static and adaptive methods in both normal and challenging conditions, including those with natural and artificial corruptions. Furthermore, we show the validity and efficacy of our uncertainty metric across diverse datasets.
  abstract_embedding: [0.51171875, -0.2158203125, 0.458984375]... (1536 items)
  authors: ['Minkyoung Cho', 'Yulong Cao', 'Jiachen Sun']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805336825
  novelty: yes
  reason: Relevance: The paper proposes a novel uncertainty-aware sensor fusion framework for 3D object detection, which is relevant for improving the robustness and accuracy of perception systems. | Novelty: T...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Cocoon__Robust_Multi-Modal_Perception_with_Uncertainty-Aware_Sensor_Fusion.pdf
  sha_abstract: 5bb790b29e093c24a962a75eb15c3a36e1a2a3c0d3593cce16d05b758bb07410
  title: Cocoon: Robust Multi-Modal Perception with Uncertainty-Aware Sensor Fusion
  title_normalized: cocoon_robust_multimodal_perception_with_uncertaintyaware_sensor_fusion

================================================================================
Document #141 (ID: 95cc64b26c4d92446e593a7149e5873293d75629e8bb9706f8ba8802c5291b6e)
================================================================================
  abstract: A growing number of machine learning scenarios rely on knowledge distillation where one uses the output of a surrogate model as labels to supervise the training of a target model. In this work, we provide a sharp characterization of this process for ridgeless, high-dimensional regression, under two settings: *(i)* model shift, where the surrogate model is arbitrary, and *(ii)* distribution shift, where the surrogate model is the solution of empirical risk minimization with out-of-distribution data. In both cases, we characterize the precise risk of the target model through non-asymptotic bounds in terms of sample size and data distribution under mild conditions. As a consequence, we identify the form of the optimal surrogate model, which reveals the benefits and limitations of discarding weak features in a data-dependent fashion. In the context of weak-to-strong (W2S) generalization, this has the interpretation that *(i)* W2S training, with the surrogate as the weak model, can provably outperform training with strong labels under the same data budget, but *(ii)* it is unable to improve the data scaling law. We validate our results on numerical experiments both on ridgeless regression and on neural network architectures.
  abstract_embedding: [0.65625, 0.09375, 0.30078125]... (1536 items)
  authors: ['Muhammed Emrullah Ildiz', 'Halil Alperen Gozeten', 'Ege Onur Taga']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805350034
  novelty: yes
  reason: Relevance: The paper proposes a new theoretical framework for understanding knowledge distillation, which is a key technique for efficient model training and deployment. | Novelty: The paper provides ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: High-dimensional_Analysis_of_Knowledge_Distillation__Weak-to-Strong_Generalization_and_Scaling_Laws.pdf
  sha_abstract: 71df15074bd1c7ce8cbfccdd49e57186df466ce2f8b15f5ca87779cde8dc54aa
  title: High-dimensional Analysis of Knowledge Distillation: Weak-to-Strong Generalization and Scaling Laws
  title_normalized: highdimensional_analysis_of_knowledge_distillation_weaktostrong_generalization_and_scaling_laws

================================================================================
Document #142 (ID: f77ae1a0fb0f5f93b0a235d60d58f43622bf3cd98b654a65427d07e8cde3279b)
================================================================================
  abstract: In this paper, we study the problem of video-conditioned policy learning. While previous works mostly focus on learning policies that perform a single skill specified by the given video, we take a step further and aim to learn a policy that can perform multiple skills according to the given video, and generalize to unseen videos by recombining these skills. To solve this problem, we propose our algorithm, Watch-Less-Do-More, an information bottleneck-based imitation learning framework for implicit skill discovery and video-conditioned policy learning. In our method, an information bottleneck objective is employed to control the information contained in the video representation, ensuring that it only encodes information relevant to the current skill (Watch-Less). By discovering potential skills from training videos, the learned policy is able to recombine them and generalize to unseen videos to achieve compositional generalization (Do-More). To evaluate our method, we perform extensive experiments in various environments and show that our algorithm substantially outperforms baselines (up to 2x) in terms of compositional generalization ability.
  abstract_embedding: [0.380859375, 0.279296875, 0.369140625]... (1536 items)
  authors: ['Jiangxing Wang', 'Zongqing Lu']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805341749
  novelty: yes
  reason: Relevance: The paper proposes a novel video-conditioned policy learning algorithm that can discover and recombine multiple skills, which is relevant for building flexible and generalizable AI systems....
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Watch_Less__Do_More__Implicit_Skill_Discovery_for_Video-Conditioned_Policy.pdf
  sha_abstract: 9d57828ca05a647fab5033358fec73f9ea0dec201af2cb4092913494a119690f
  title: Watch Less, Do More: Implicit Skill Discovery for Video-Conditioned Policy
  title_normalized: watch_less_do_more_implicit_skill_discovery_for_videoconditioned_policy

================================================================================
Document #143 (ID: fdd819a57bb6de7b8584eae17b488912a1902623f566946ca31862f81b1679f0)
================================================================================
  abstract: Originally introduced in game theory, Shapley values have emerged as a central tool in explainable machine learning, where they are used to attribute model predictions to specific input features. However, computing Shapley values exactly is expensive: for a model with $n$ features, $O(2^n)$ model evaluations are necessary. To address this issue, approximation algorithms are widely used. One of the most popular is the Kernel SHAP algorithm, which is model agnostic and remarkably effective in practice. However, to the best of our knowledge, Kernel SHAP has no strong non-asymptotic complexity guarantees. We address this issue by introducing *Leverage SHAP*, a light-weight modification of Kernel SHAP that provides provably accurate Shapley value estimates with just $O(n\log n)$ model evaluations. Our approach takes advantage of a connection between Shapley value estimation and agnostic active learning by employing *leverage score sampling*, a powerful regression tool. Beyond theoretical guarantees, we find that Leverage SHAP achieves an approximately 50% reduction in error compared to the highly optimized implementation of Kernel SHAP in the widely used SHAP library [Lundberg & Lee, 2017].
  abstract_embedding: [0.59375, 0.328125, 0.31640625]... (1536 items)
  authors: ['Christopher Musco', 'R. Teal Witter']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805338480
  novelty: yes
  reason: Relevance: The paper proposes a novel algorithm, Leverage SHAP, for efficiently computing Shapley values, which is an important technique for model interpretability and explainability. | Novelty: Leve...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Provably_Accurate_Shapley_Value_Estimation_via_Leverage_Score_Sampling.pdf
  sha_abstract: 9e69e05be24c6d20901f02235207284766d329e802d9836918f501fadd3ebc8a
  title: Provably Accurate Shapley Value Estimation via Leverage Score Sampling
  title_normalized: provably_accurate_shapley_value_estimation_via_leverage_score_sampling

================================================================================
Document #144 (ID: c43f5505350c1f7328b2249b43b5b1f42c3b2050689472bd3690d2aabea61673)
================================================================================
  abstract: Character image animation, which generates high-quality videos from a reference image and target pose sequence, has seen significant progress in recent years. However, most existing methods only apply to human figures, which usually do not generalize well on anthropomorphic characters commonly used in industries like gaming and entertainment. Our in-depth analysis suggests to attribute this limitation to their insufficient modeling of motion, which is unable to comprehend the movement pattern of the driving video, thus imposing a pose sequence rigidly onto the target character. To this end, this paper proposes $\texttt{Animate-X}$, a universal animation framework based on LDM for various character types (collectively named $\texttt{X}$), including anthropomorphic characters. To enhance motion representation, we introduce the Pose Indicator, which captures comprehensive motion pattern from the driving video through both implicit and explicit manner. The former leverages CLIP visual features of a driving video to extract its gist of motion, like the overall movement pattern and temporal relations among motions, while the latter strengthens the generalization of LDM by simulating possible inputs in advance that may arise during inference. Moreover, we introduce a new Animated Anthropomorphic Benchmark ($\texttt{$A^2$Bench}$) to evaluate the performance of $\texttt{Animate-X}$ on universal and widely applicable animation images. Extensive experiments demonstrate the superiority and effectiveness of $\texttt{Animate-X}$ compared to state-of-the-art methods.
  abstract_embedding: [0.5, 0.474609375, 0.3046875]... (1536 items)
  authors: ['Shuai Tan', 'Biao Gong', 'Xiang Wang']... (9 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805352966
  novelty: yes
  reason: Relevance: The paper proposes a novel animation framework, Animate-X, that uses LDM to generate high-quality videos from a reference image and target pose sequence, with a focus on enhancing motion re...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Animate-X__Universal_Character_Image_Animation_with_Enhanced_Motion_Representation.pdf
  sha_abstract: 110617a6f6eb646baeeda2808749d2d509edc167e81306690987cc062caf7921
  title: Animate-X: Universal Character Image Animation with Enhanced Motion Representation
  title_normalized: animatex_universal_character_image_animation_with_enhanced_motion_representation

================================================================================
Document #145 (ID: a06672eeb255675a3a727ea0d4f8cc9afb52c8a5b6a0bbee93d31b2e4aad7dea)
================================================================================
  abstract: Understanding how sensory neurons exhibit selectivity to certain features and invariance to others is central to uncovering the computational principles underlying robustness and generalization in visual perception. Most existing methods for characterizing selectivity and invariance identify single or finite discrete sets of stimuli. Since these are only isolated measurements from an underlying continuous manifold, characterizing invariance properties accurately and comparing them across neurons with varying receptive field size, position, and orientation, becomes challenging. Consequently, a systematic analysis of invariance types at the population level remains under-explored. Building on recent advances in learning continuous invariance manifolds, we introduce a novel method to accurately identify and align invariance manifolds of visual sensory neurons, overcoming these challenges. Our approach first learns the continuous invariance manifold of stimuli that maximally excite a neuron modeled by a response-predicting deep neural network. It then learns an affine transformation on the pixel coordinates such that the same manifold activates another neuron as strongly as possible, effectively aligning their invariance manifolds spatially. This alignment provides a principled way to quantify and compare neuronal invariances irrespective of receptive field differences. Using simulated neurons, we demonstrate that our method accurately learns and aligns known invariance manifolds, robustly identifying functional clusters. When applied to macaque V1 neurons, it reveals functional clusters of neurons, including simple and complex cells. Overall, our method enables systematic, quantitative exploration of the neural invariance landscape, to gain new insights into the functional properties of visual sensory neurons.
  abstract_embedding: [0.1474609375, 0.392578125, 0.1982421875]... (1536 items)
  authors: ['Mohammad Bashiri', 'Luca Baroni', 'Ján Antolík']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805356937
  novelty: yes
  reason: Relevance: The paper proposes a novel method to learn and align continuous invariance manifolds of visual sensory neurons, which is a novel model architecture and training algorithm. | Novelty: The pr...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Learning_and_aligning_single-neuron_invariance_manifolds_in_visual_cortex.pdf
  sha_abstract: 53fb5474a5743108cff31bb646e3fd412f15fc6ca8536aa45c25009d5af0baff
  title: Learning and aligning single-neuron invariance manifolds in visual cortex
  title_normalized: learning_and_aligning_singleneuron_invariance_manifolds_in_visual_cortex

================================================================================
Document #146 (ID: 9aceaef5f036eb4b47152a600b6fc0a3ce905b69f1873a67d95cd88fe7142767)
================================================================================
  abstract: Attention-based transformers have achieved tremendous success across a variety of disciplines including natural languages. To deepen our understanding of their sequential modeling capabilities, there is a growing interest in using Markov input processes to study them. A key finding is that when trained on first-order Markov chains, transformers with two or more layers consistently develop an induction head mechanism to estimate the in-context bigram conditional distribution. In contrast, single-layer transformers, unable to form an induction head, directly learn the Markov kernel but often face a surprising challenge: they become trapped in local minima representing the unigram distribution, whereas deeper models reliably converge to the ground-truth bigram. While single-layer transformers can theoretically model first-order Markov chains, their empirical failure to learn this simple kernel in practice remains a curious phenomenon. To explain this contrasting behavior of single-layer models, in this paper we introduce a new framework for a principled analysis of transformers via Markov chains. Leveraging our framework, we theoretically characterize the loss landscape of single-layer transformers and show the existence of global minima (bigram) and bad local minima (unigram) contingent on data properties and model architecture. We precisely delineate the regimes under which these local optima occur. Backed by experiments, we demonstrate that our theoretical findings are in congruence with the empirical results. Finally, we outline several open problems in this arena.
  abstract_embedding: [0.392578125, 0.32421875, 0.255859375]... (1536 items)
  authors: ['Ashok Vardhan Makkuva', 'Marco Bondaschi', 'Adway Girish']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805373655
  novelty: yes
  reason: Relevance: The paper proposes a new theoretical framework for analyzing the loss landscape of single-layer transformers on Markov chains, which is a novel and relevant contribution. | Novelty: The pap...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Attention_with_Markov__A_Curious_Case_of_Single-layer_Transformers.pdf
  sha_abstract: 2357b4d197c3643af13069e590f421b7f5ad04ba8f25a9154360ae40f7c955b0
  title: Attention with Markov: A Curious Case of Single-layer Transformers
  title_normalized: attention_with_markov_a_curious_case_of_singlelayer_transformers

================================================================================
Document #147 (ID: 09fb17f124eea592390b7bc31145571b155d6f70a72bdba9bed5f43ec30fbea9)
================================================================================
  abstract: Existing preference optimization objectives for language model alignment require additional hyperparameters that must be extensively tuned to achieve optimal performance, increasing both the complexity and time required for fine-tuning large language models. In this paper, we propose a simple yet effective hyperparameter-free preference optimization algorithm for alignment. We observe that promising performance can be achieved simply by optimizing inverse perplexity, which is calculated as the inverse of the exponentiated average log-likelihood of the chosen and rejected responses in the preference dataset. The resulting simple learning objective, SimPER, is easy to implement and eliminates the need for expensive hyperparameter tuning and a reference model, making it both computationally and memory efficient. Extensive experiments on widely used real-world benchmarks, including MT-Bench, AlpacaEval 2, and 10 key benchmarks of the Open LLM Leaderboard with 5 base models, demonstrate that SimPER consistently and significantly outperforms existing approaches—even without any hyperparameters or a reference model. For example, despite its simplicity, SimPER outperforms state-of-the-art methods by up to 5.7 points on AlpacaEval 2 and achieves the highest average ranking across 10 benchmarks on the Open LLM Leaderboard. The source code for SimPER is publicly available at: https://github.com/tengxiao1/SimPER.
  abstract_embedding: [0.1875, 0.58203125, 0.119140625]... (1536 items)
  authors: ['Teng Xiao', 'Yige Yuan', 'Zhengyu Chen']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805371569
  novelty: yes
  reason: Relevance: The paper proposes a novel, hyperparameter-free preference optimization algorithm for language model alignment, which is a valuable technique for improving the performance of large language...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SimPER__A_Minimalist_Approach_to_Preference__Alignment_without_Hyperparameters.pdf
  sha_abstract: 6ce2319d08d4c19ae323033864f3d900b255a480eb80f9aa09c94b90e0157ec8
  title: SimPER: A Minimalist Approach to Preference  Alignment without Hyperparameters
  title_normalized: simper_a_minimalist_approach_to_preference__alignment_without_hyperparameters

================================================================================
Document #148 (ID: 9d0fdcb6c1841b4249a44a1b6ba4a61d58e468db6e31b27654bd7bb6136fafa0)
================================================================================
  abstract: Sparse autoencoders (SAEs) have gained a lot of attention as a promising tool to improve the interpretability of large language models (LLMs) by mapping the complex superposition of *polysemantic* neurons into *monosemantic* features and composing a sparse dictionary of words.

However, traditional performance metrics like Mean Squared Error and $\mathrm{L}_{0}$ sparsity ignore the evaluation of the semantic representational power of SAEs - whether they can acquire interpretable monosemantic features while preserving the semantic relationship of words.For instance, it is not obvious whether a learned sparse feature could distinguish different meanings in one word.

In this paper, we propose a suite of evaluations for SAEs to analyze the quality of monosemantic features by focusing on polysemous words.
Our findings reveal that SAEs developed to improve the MSE-$\mathrm{L}_0$ Pareto frontier may confuse interpretability, which does not necessarily enhance the extraction of monosemantic features.
The analysis of SAEs with polysemous words can also figure out the internal mechanism of LLMs; deeper layers and the Attention module contribute to distinguishing polysemy in a word.

Our semantics-focused evaluation offers new insights into the polysemy and the existing SAE objective and contributes to the development of more practical SAEs.
  abstract_embedding: [-0.02197265625, 0.298828125, 0.322265625]... (1536 items)
  authors: ['Gouki Minegishi', 'Hiroki Furuta', 'Yusuke Iwasawa']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805362022
  novelty: yes
  reason: Relevance: The paper proposes a new evaluation suite to analyze the quality of monosemantic features learned by sparse autoencoders, which is relevant for improving the interpretability of large langu...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Rethinking_Evaluation_of_Sparse_Autoencoders_through_the_Representation_of_Polysemous_Words.pdf
  sha_abstract: 15b0dd0b7f258e1afdcfb1cf5ef765c524f62c84c00e0ddebeca112561c6bd63
  title: Rethinking Evaluation of Sparse Autoencoders through the Representation of Polysemous Words
  title_normalized: rethinking_evaluation_of_sparse_autoencoders_through_the_representation_of_polysemous_words

================================================================================
Document #149 (ID: ba00a8c05384f3a2d7a280813c3e770f84902fc423dc20d05567c7f459e50b6a)
================================================================================
  abstract: Meta-reinforcement learning requires utilizing prior task distribution information obtained during exploration to rapidly adapt to unknown tasks. The efficiency of an agent's exploration hinges on accurately identifying the current task. Recent Bayes-Adaptive Deep RL approaches often rely on reconstructing the environment's reward signal, which is challenging in sparse reward settings, leading to suboptimal exploitation. Inspired by bisimulation metrics, which robustly extracts behavioral similarity in continuous MDPs, we propose SimBelief—a novel meta-RL framework via measuring similarity of task belief in Bayes-Adaptive MDP (BAMDP). SimBelief effectively extracts common features of similar task distributions, enabling efficient task identification and exploration in sparse reward environments. We introduce latent task belief metric to learn the common structure of similar tasks and incorporate it into the real task belief. By learning the latent dynamics across task distributions, we connect shared latent task belief features with specific task features, facilitating rapid task identification and adaptation. Our method outperforms state-of-the-art baselines on sparse reward MuJoCo and panda-gym tasks.
  abstract_embedding: [1.0, 0.142578125, 0.55078125]... (1536 items)
  authors: ['Menglong Zhang', 'Fuyuan Qian', 'Quanying Liu']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805368686
  novelty: yes
  reason: Relevance: The paper proposes a novel meta-reinforcement learning framework that learns task belief similarity and latent dynamics to enable efficient task identification and adaptation in sparse rewa...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Learning_Task_Belief_Similarity_with_Latent_Dynamics_for_Meta-Reinforcement_Learning.pdf
  sha_abstract: 0f8252fc86cd9c84298fe6a11509bb2ba5fb4307c2010571b4dac190ca02de2f
  title: Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning
  title_normalized: learning_task_belief_similarity_with_latent_dynamics_for_metareinforcement_learning

================================================================================
Document #150 (ID: ad9f9027d6e38537b20dfeae24dacc88757661f045a479d732f74215cd22cc09)
================================================================================
  abstract: The probabilistic diffusion model has become highly effective across various domains. Typically, sampling from a diffusion model involves using a denoising distribution characterized by a Gaussian with a learned mean and either fixed or learned covariances. In this paper, we leverage the recently proposed covariance moment matching technique and introduce a novel method for learning the diagonal covariances. Unlike traditional data-driven covariance approximation approaches, our method involves directly regressing the optimal analytic covariance using a new, unbiased objective named Optimal Covariance Matching (OCM). This approach can significantly reduce the approximation error in covariance prediction. We demonstrate how our method can substantially enhance the sampling efficiency, recall rate and likelihood of both diffusion models and latent diffusion models.
  abstract_embedding: [0.0089111328125, 0.478515625, 0.1982421875]... (1536 items)
  authors: ['Zijing Ou', 'Mingtian Zhang', 'Andi Zhang']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805359444
  novelty: yes
  reason: Relevance: The paper proposes a novel method for learning the diagonal covariances in probabilistic diffusion models, which can improve sampling efficiency, recall rate, and likelihood. | Novelty: The...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Improving_Probabilistic_Diffusion_Models_With_Optimal_Diagonal_Covariance_Matching.pdf
  sha_abstract: bda25d72702a1aa0df736a74d8e21a404d2b0e01c9717bfd348bad8673c3b9a2
  title: Improving Probabilistic Diffusion Models With Optimal Diagonal Covariance Matching
  title_normalized: improving_probabilistic_diffusion_models_with_optimal_diagonal_covariance_matching

================================================================================
Document #151 (ID: 38dc46b04fb928ead468eec22fa4b474eb42b71d570c9d7f181774c917775a85)
================================================================================
  abstract: When symmetry is present in the loss function, the model is likely to be trapped in a low-capacity state that is sometimes known as a ``collapse." Being trapped in these low-capacity states can be a major obstacle to training across many scenarios where deep learning technology is applied. We first prove two concrete mechanisms through which symmetries lead to reduced capacities and ignored features during training and inference. We then propose a simple and theoretically justified algorithm, \textit{syre}, to remove almost all symmetry-induced low-capacity states in neural networks. When this type of entrapment is especially a concern, removing symmetries with the proposed method is shown to correlate well with improved optimization or performance. A remarkable merit of the proposed method is that it is model-agnostic and does not require any knowledge of the symmetry.
  abstract_embedding: [0.392578125, 0.408203125, 0.12158203125]... (1536 items)
  authors: ['Liu Ziyin', 'Yizhou Xu', 'Isaac L. Chuang']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805354965
  novelty: yes
  reason: Relevance: The paper proposes a novel algorithm to remove symmetries in neural networks, which can improve optimization and model expressivity. | Novelty: The proposed algorithm to remove symmetries i...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Remove_Symmetries_to_Control_Model_Expressivity_and_Improve_Optimization.pdf
  sha_abstract: e02bb0c60f183294ca6248d9fa69673eebaa4d73f2314c74c829747d4bf9d07c
  title: Remove Symmetries to Control Model Expressivity and Improve Optimization
  title_normalized: remove_symmetries_to_control_model_expressivity_and_improve_optimization

================================================================================
Document #152 (ID: fc5c033cd460b71ff9b4c2f24fdc85b9a2b4574ba0071e10734e6af73ff5055f)
================================================================================
  abstract: Adam is a widely used optimizer in neural network training due to its adaptive learning rate. However, because different data samples influence model updates to varying degrees, treating them equally can lead to inefficient convergence. To address this, a prior work proposed adapting the sampling distribution using a bandit framework to select samples adaptively. While promising, the bandit-based variant of Adam suffers from limited theoretical guarantees.
In this paper, we introduce \textit{Adam with Combinatorial Bandit Sampling} (AdamCB), which integrates combinatorial bandit techniques into Adam to resolve these issues. AdamCB is able to fully utilize feedback from multiple samples at once, enhancing both theoretical guarantees and practical performance. Our regret analysis shows that AdamCB achieves faster convergence than Adam-based methods including the previous bandit-based variant. Numerical experiments demonstrate that AdamCB consistently outperforms existing methods.
  abstract_embedding: [0.6953125, 0.298828125, 0.34375]... (1536 items)
  authors: ['Gyu Yeol Kim', 'Min-hwan Oh']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805363924
  novelty: yes
  reason: Relevance: The paper proposes a novel optimization algorithm, AdamCB, that integrates combinatorial bandit techniques into the Adam optimizer to improve convergence and performance. | Novelty: AdamCB ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: ADAM_Optimization_with_Adaptive_Batch_Selection.pdf
  sha_abstract: 1cdcdc5519c58ef62f40535e95fd7398612870e5b29fef72693fa4abc3eadb34
  title: ADAM Optimization with Adaptive Batch Selection
  title_normalized: adam_optimization_with_adaptive_batch_selection

================================================================================
Document #153 (ID: 339d1111735fba7a8829769d2e79f501249f65434e47dc5c5db85509292a2f1d)
================================================================================
  abstract: The capabilities and limitations of Large Language Models (LLMs) have been sketched out in great detail in recent years, providing an intriguing yet conflicting picture. On the one hand, LLMs demonstrate a general ability to solve problems. On the other hand, they show surprising reasoning gaps when compared to humans, casting doubt on the robustness of their generalisation strategies. The sheer volume of data used in the design of LLMs has precluded us from applying the method traditionally used to measure generalisation: train-test set separation. To overcome this, we study what kind of generalisation strategies LLMs employ when performing reasoning tasks by investigating the pretraining data they rely on. For two models of different sizes (7B and 35B) and 2.5B of their pretraining tokens, we identify what documents influence the model outputs for three simple mathematical reasoning tasks and contrast this to the data that are influential for answering factual questions. We find that, while the models rely on mostly distinct sets of data for each factual question, a document often has a similar influence across different reasoning questions within the same task, indicating the presence of procedural knowledge. We further find that the answers to factual questions often show up in the most influential data. However, for reasoning questions the answers usually do not show up as highly influential, nor do the answers to the intermediate reasoning steps. When we characterise the top ranked documents for the reasoning questions qualitatively, we confirm that the influential documents often contain procedural knowledge, like demonstrating how to obtain a solution using formulae or code. Our findings indicate that the approach to reasoning the models use is unlike retrieval, and more like a generalisable strategy that synthesises procedural knowledge from documents doing a similar form of reasoning.
  abstract_embedding: [0.47265625, -0.0263671875, 0.13671875]... (1536 items)
  authors: ['Laura Ruis', 'Maximilian Mozes', 'Juhan Bae']... (10 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805385929
  novelty: yes
  reason: Relevance: The paper proposes a novel analysis of how large language models leverage procedural knowledge from pretraining data to perform reasoning tasks, which is relevant for improving model archit...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Procedural_Knowledge_in_Pretraining_Drives_Reasoning_in_Large_Language_Models.pdf
  sha_abstract: b812c6041dd782388cad526fe8e20b3e97978275e1806fa75328361d9ded0be5
  title: Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models
  title_normalized: procedural_knowledge_in_pretraining_drives_reasoning_in_large_language_models

================================================================================
Document #154 (ID: 3da020885e3f0882a79a3b2e8bbfe90dd138415bdbe3475d6e8e638d78f1e069)
================================================================================
  abstract: With a growing interest in understanding neural network prediction strategies, Concept Activation Vectors (CAVs) have emerged as a popular tool for modeling human-understandable concepts in the latent space.
Commonly, CAVs are computed by leveraging linear classifiers optimizing the *separability* of latent representations of samples with and without a given concept. However, in this paper we show that such a separability-oriented computation leads to solutions, which may diverge from the actual goal of precisely modeling the concept direction.
This discrepancy can be attributed to the significant influence of distractor directions, i.e., signals unrelated to the concept, which are picked up by filters (i.e., weights) of linear models to optimize class-separability.
To address this, we introduce *pattern-based CAVs*, solely focussing on concept signals, thereby providing more accurate concept directions.
We evaluate various CAV methods in terms of their alignment with the true concept direction and their impact on CAV applications, including concept sensitivity testing and model correction for shortcut behavior caused by data artifacts. 
We demonstrate the benefits of pattern-based CAVs using the Pediatric Bone Age, ISIC2019, and FunnyBirds datasets with VGG, ResNet, ReXNet, EfficientNet, and Vision Transformer as model architectures.
  abstract_embedding: [-0.16796875, 0.5859375, 0.341796875]... (1536 items)
  authors: ['Frederik Pahde', 'Maximilian Dreyer', 'Moritz Weckbecker']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805394767
  novelty: yes
  reason: Relevance: The paper proposes a novel method for computing Concept Activation Vectors (CAVs) that aims to better capture the true concept direction in the latent space, which is relevant for understan...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Navigating_Neural_Space__Revisiting_Concept_Activation_Vectors_to_Overcome_Directional_Divergence.pdf
  sha_abstract: bddda806b752f486e1ecd2aed0b8a09f16b12ed37e9bca91de09b3e19467c202
  title: Navigating Neural Space: Revisiting Concept Activation Vectors to Overcome Directional Divergence
  title_normalized: navigating_neural_space_revisiting_concept_activation_vectors_to_overcome_directional_divergence

================================================================================
Document #155 (ID: 65ca51ac560aedf936f2f4dc8ac929d0d7d444957b923744e06aae35c40cc209)
================================================================================
  abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities through pretraining and alignment. However, superior short-context LLMs may underperform in long-context scenarios due to insufficient long-context alignment. This alignment process remains challenging due to the impracticality of human annotation for extended contexts and the difficulty in balancing short- and long-context performance. To address these challenges, we introduce LongPO, that enables short-context LLMs to self-evolve to excel on long-context tasks by internally transferring short-context capabilities. LongPO harnesses LLMs to learn from self-generated short-to-long preference data, comprising paired responses generated for identical instructions with long-context inputs and their compressed short-context counterparts, respectively. This preference reveals capabilities and potentials of LLMs cultivated during short-context alignment that may be diminished in under-aligned long-context scenarios. Additionally, LongPO incorporates a short-to-long KL constraint to mitigate short-context performance decline during long-context alignment. When applied to Mistral-7B-Instruct-v0.2 from 128K to 512K context lengths, LongPO fully retains short-context performance and largely outperforms naive SFT and DPO in both long- and short-context tasks. Specifically, LongPO-trained models can achieve results on long-context benchmarks comparable to, or even surpassing, those of superior LLMs (e.g., GPT-4-128K) that involve extensive long-context annotation and larger parameter scales. Our code is available at https://github.com/DAMO-NLP-SG/LongPO.
  abstract_embedding: [0.5, 0.326171875, 0.06591796875]... (1536 items)
  authors: ['Guanzheng Chen', 'Xin Li', 'Michael Shieh']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805382560
  novelty: yes
  reason: Relevance: The paper proposes a novel training algorithm (LongPO) that enables large language models to self-evolve and improve their performance on long-context tasks, which is a relevant and importa...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: LongPO__Long_Context_Self-Evolution_of_Large_Language_Models_through_Short-to-Long_Preference_Optimization.pdf
  sha_abstract: b0048d8c1a798023afaf5a824cb80f3222f16cf5fe2101cc4b74a659a4bae9da
  title: LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization
  title_normalized: longpo_long_context_selfevolution_of_large_language_models_through_shorttolong_preference_optimization

================================================================================
Document #156 (ID: 9ef4500a2e7aaa730f24e8ea6046df3a63b7bccb8f82230a92472b760e05b9ce)
================================================================================
  abstract: As large-scale models evolve, language instructions are increasingly utilized in multi-modal tasks. Due to human language habits, these instructions often contain ambiguities in real-world scenarios, necessitating the integration of visual context or common sense for accurate interpretation. However, even highly intelligent large models exhibit observable performance limitations on ambiguous instructions, where weak reasoning abilities of disambiguation can lead to catastrophic errors. To address this issue, this paper proposes Visual-O1, a multi-modal multi-turn chain-of-thought reasoning framework. It simulates human multi-modal multi-turn reasoning, providing instantial experience for highly intelligent models or empirical experience for generally intelligent models to understand ambiguous instructions. Unlike traditional methods that require models to possess high intelligence to understand long texts or perform lengthy complex reasoning, our framework does not notably increase computational overhead and is more general and effective, even for generally intelligent models. Experiments show that our method not only enhances the performance of models of different intelligence levels on ambiguous instructions but also improves their performance on general datasets. Our work highlights the potential of artificial intelligence to work like humans in real-world scenarios with uncertainty and ambiguity. We release our data and code at https://github.com/kodenii/Visual-O1.
  abstract_embedding: [0.380859375, 0.11865234375, 0.57421875]... (1536 items)
  authors: ['Minheng Ni', 'YuTao Fan', 'Lei Zhang']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805380424
  novelty: yes
  reason: Relevance: The paper proposes a novel multi-modal, multi-turn chain-of-thought reasoning framework to address the challenge of understanding ambiguous instructions, which is a relevant problem for lar...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Visual-O1__Understanding_Ambiguous_Instructions_via_Multi-modal_Multi-turn_Chain-of-thoughts_Reasoning.pdf
  sha_abstract: d4816ee0af265f217014590133e2d6b449b02ec29da75a500f89741661a656ad
  title: Visual-O1: Understanding Ambiguous Instructions via Multi-modal Multi-turn Chain-of-thoughts Reasoning
  title_normalized: visualo1_understanding_ambiguous_instructions_via_multimodal_multiturn_chainofthoughts_reasoning

================================================================================
Document #157 (ID: 0221c0efa925615e5585acff41ffef7f61263659de64457d4eaf0719023168d7)
================================================================================
  abstract: Dataset distillation (DD) generates small synthetic datasets that can efficiently train deep networks with a limited amount of memory and compute. Despite the success of DD methods for supervised learning, DD for self-supervised pre-training of deep models has remained unaddressed. Pre-training on unlabeled data is crucial for efficiently generalizing to downstream tasks with limited labeled data. In this work, we propose the first effective DD method for SSL pre-training. First, we show, theoretically and empirically, that naiive application of supervised DD methods to SSL fails, due to the high variance of the SSL gradient. Then, we address this issue by relying on insights from knowledge distillation (KD) literature. Specifically, we train a small student model to match the representations of a larger teacher model trained with SSL. Then, we generate a small synthetic dataset by matching the training trajectories of the student models. As the KD objective has considerably lower variance than SSL, our approach can generate synthetic datasets that can successfully pre-train high-quality encoders. Through extensive experiments, we show that our distilled sets lead to up to 13% higher accuracy than prior work, on a variety of downstream tasks, in the presence of limited labeled data. Code at https://github.com/BigML-CS-UCLA/MKDT.
  abstract_embedding: [0.380859375, 0.341796875, 0.490234375]... (1536 items)
  authors: ['Siddharth Joshi', 'Jiayi Ni', 'Baharan Mirzasoleiman']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805397581
  novelty: yes
  reason: Relevance: The paper proposes a novel dataset distillation method for self-supervised pre-training, which is a relevant and important problem for efficient model training. | Novelty: The proposed meth...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Dataset_Distillation_via_Knowledge_Distillation__Towards_Efficient_Self-Supervised_Pre-training_of_Deep_Networks.pdf
  sha_abstract: 2e4554b8601019440e80a262d8d6c54ecc64958fbcc8588d044ba2f3647b2397
  title: Dataset Distillation via Knowledge Distillation: Towards Efficient Self-Supervised Pre-training of Deep Networks
  title_normalized: dataset_distillation_via_knowledge_distillation_towards_efficient_selfsupervised_pretraining_of_deep_networks

================================================================================
Document #158 (ID: 940a613981a7a8cfdbe948fd386ca3f45268626f54289f5d21a85f75c33197cf)
================================================================================
  abstract: Mixed Integer Linear Programming (MILP) is essential for modeling complex decision-making problems but faces challenges in computational tractability and interpretability. Current deep learning approaches for MILP focus on specific problem classes and do not generalize to unseen classes. To address this shortcoming, we take a foundation model training approach, where we train a single deep learning model on a diverse set of MILP problems to generalize across problem classes. As existing datasets for MILP lack diversity and volume, we introduce MILP-Evolve, a novel LLM-based evolutionary framework that is capable of generating a large set of diverse MILP classes with an unlimited amount of instances. We study our methodology on three key learning tasks that capture diverse aspects of MILP: (1) integrality gap prediction, (2) learning to branch, and (3) a new task of aligning MILP instances with natural language descriptions. Our empirical results show that models trained on the data generated by MILP-Evolve achieve significant improvements on unseen problems, including MIPLIB benchmarks. Our work highlights the potential of moving towards a foundation model approach for MILP that can generalize to a broad range of MILP problem classes. Our code and data are publicly available at https://github.com/microsoft/OptiGuide.
  abstract_embedding: [0.5859375, 0.388671875, 0.09912109375]... (1536 items)
  authors: ['Sirui Li', 'Janardhan Kulkarni', 'Ishai Menache']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805400082
  novelty: yes
  reason: Relevance: The paper proposes a novel foundation model approach for Mixed Integer Linear Programming (MILP) that aims to generalize across diverse problem classes, which is highly relevant for practic...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Towards_Foundation_Models_for_Mixed_Integer_Linear_Programming.pdf
  sha_abstract: 871877e0ae9a455284aff2b17ba7733668cffb97b95f86d9868a68038128242c
  title: Towards Foundation Models for Mixed Integer Linear Programming
  title_normalized: towards_foundation_models_for_mixed_integer_linear_programming

================================================================================
Document #159 (ID: c104b3b61aee48c0ff4bd10d6c78c56df472bd2b92844da40600bb34dd105a9c)
================================================================================
  abstract: While large language models (LLMs) have integrated images, adapting them to graphs remains challenging, limiting their applications in materials and drug design. This difficulty stems from the need for coherent autoregressive generation across texts and graphs. To address this, we introduce Llamole, the first multimodal LLM capable of interleaved text and graph generation, enabling molecular inverse design with retrosynthetic planning. Llamole integrates a base LLM with the Graph Diffusion Transformer and Graph Neural Networks for multi-conditional molecular generation and reaction inference within texts, while the LLM, with enhanced molecular understanding, flexibly controls activation among the different graph modules. Additionally, Llamole integrates A* search with LLM-based cost functions for efficient retrosynthetic planning. We create benchmarking datasets and conduct extensive experiments to evaluate Llamole against in-context learning and supervised fine-tuning. Llamole significantly outperforms 14 adapted LLMs across 12 metrics for controllable molecular design and retrosynthetic planning. Code and model at https://github.com/liugangcode/Llamole.
  abstract_embedding: [0.86328125, 0.2236328125, -0.07080078125]... (1536 items)
  authors: ['Gang Liu', 'Michael Sun', 'Wojciech Matusik']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805376362
  novelty: yes
  reason: Relevance: The paper proposes a novel multimodal LLM architecture, Llamole, that integrates text and graph generation for molecular inverse design and retrosynthetic planning, which are highly relevan...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Multimodal_Large_Language_Models_for_Inverse_Molecular_Design_with_Retrosynthetic_Planning.pdf
  sha_abstract: b6dbdd4431fbfe787f2b3fa6475a1b587e346a514c0be9b4627f8b323561449a
  title: Multimodal Large Language Models for Inverse Molecular Design with Retrosynthetic Planning
  title_normalized: multimodal_large_language_models_for_inverse_molecular_design_with_retrosynthetic_planning

================================================================================
Document #160 (ID: 38f182f99f4ed5eb916043ed0620b2cce2b5ef899b23ae2de5bd678d321e3a75)
================================================================================
  abstract: Cryogenic electron tomography (Cryo-ET) is a powerful technique for visualizing subcellular structures in their native states. Nonetheless, its effectiveness is compromised by anisotropic resolution artifacts caused by the missing-wedge effect. To address this, IsoNet, a deep learning-based method, proposes iteratively reconstructing the missing-wedge information. While successful, IsoNet's dependence on recursive prediction updates often leads to training instability and model divergence. In this study, we introduce CryoGEN—an energy-based probabilistic model that not only mitigates resolution anisotropy but also removes the need for recursive subtomogram averaging, delivering an approximate *10*$\times$ speedup for training. Evaluations across various biological datasets, including immature HIV-1 virions and ribosomes, demonstrate that CryoGEN significantly enhances structural completeness and interpretability of the reconstructed samples.
  abstract_embedding: [-0.1787109375, 0.51953125, -0.1923828125]... (1536 items)
  authors: ['Yunfei Teng', 'Yuxuan Ren', 'Kai Chen']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805403360
  novelty: yes
  reason: Relevance: The paper proposes a new energy-based generative model (CryoGEN) for cryogenic electron tomography reconstruction, which addresses the missing-wedge effect and improves reconstruction speed...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CryoGEN__Generative_Energy-based_Models_for_Cryogenic_Electron_Tomography_Reconstruction.pdf
  sha_abstract: 9d5e6c70280fc2a5ed474c2002e73d46b862ffc9d68051974ffa898660d9d02c
  title: CryoGEN: Generative Energy-based Models for Cryogenic Electron Tomography Reconstruction
  title_normalized: cryogen_generative_energybased_models_for_cryogenic_electron_tomography_reconstruction

================================================================================
Document #161 (ID: 157b1aecec5fc0e63039cbc6ef8d77ddd5a0cb98af690d27cd56893a79fa1d63)
================================================================================
  abstract: Developing agents capable of navigating to a target location based on language instructions and visual information, known as vision-language navigation (VLN), has attracted widespread interest. Most research has focused on ground-based agents, while UAV-based VLN remains relatively underexplored. Recent efforts in UAV vision-language navigation predominantly adopt ground-based VLN settings, relying on predefined discrete action spaces and neglecting the inherent disparities in agent movement dynamics and the complexity of navigation tasks between ground and aerial environments. To address these disparities and challenges, we propose solutions from three perspectives: platform, benchmark, and methodology. To enable realistic UAV trajectory simulation in VLN tasks, we propose the OpenUAV platform,  which features diverse environments, realistic flight control, and extensive algorithmic support. We further construct a target-oriented VLN dataset consisting of approximately 12k trajectories on this platform, serving as the first dataset specifically designed for realistic UAV VLN tasks. To tackle the challenges posed by complex aerial environments, we propose an assistant-guided UAV object search benchmark called UAV-Need-Help, which provides varying levels of guidance information to help UAVs better accomplish realistic VLN tasks. We also propose a UAV navigation LLM that, given multi-view images, task descriptions, and assistant instructions, leverages the multimodal understanding capabilities of the MLLM to jointly process visual and textual information, and performs hierarchical trajectory generation. The evaluation results of our method significantly outperform the baseline models, while there remains a considerable gap between our results and those achieved by human operators, underscoring the challenge presented by the UAV-Need-Help task.
  abstract_embedding: [0.515625, 0.251953125, 0.458984375]... (1536 items)
  authors: ['Xiangyu Wang', 'Donglin Yang', 'Ziqin Wang']... (9 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805427515
  novelty: yes
  reason: Relevance: The paper proposes a new platform, benchmark, and methodology for realistic UAV vision-language navigation, which is an innovative and directly implementable ML technique. | Novelty: The pr...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Towards_Realistic_UAV_Vision-Language_Navigation__Platform__Benchmark__and_Methodology.pdf
  sha_abstract: 4efa15d50c3d317180c7ee351b1a266842f4ea06862da0aea3e505ac12168794
  title: Towards Realistic UAV Vision-Language Navigation: Platform, Benchmark, and Methodology
  title_normalized: towards_realistic_uav_visionlanguage_navigation_platform_benchmark_and_methodology

================================================================================
Document #162 (ID: 2834b3bb6d67e8ae0211d485e033b0c9e3aed70def33a59c01ab64b49e4b1330)
================================================================================
  abstract: Prompt learning has demonstrated promising results in fine-tuning pre-trained multimodal models. However, the performance improvement is limited when applied to more complex and fine-grained tasks. The reason is that most existing methods directly optimize the parameters involved in the prompt generation process through loss backpropagation, which constrains the richness and specificity of the prompt representations. In this paper, we propose Diffusion-Driven Prompt Generator (Diff-Prompt), aiming to use the diffusion model to generate rich and fine-grained prompt information for complex downstream tasks. Specifically, our approach consists of three stages. In the first stage, we train a Mask-VAE to compress the masks into latent space. In the second stage, we leverage an improved Diffusion Transformer (DiT) to train a prompt generator in the latent space, using the masks for supervision. In the third stage, we align the denoising process of the prompt generator with the pre-trained model in the semantic space, and use the generated prompts to fine-tune the model. We conduct experiments on a complex pixel-level downstream task, referring expression comprehension, and compare our method with various parameter-efficient fine-tuning approaches. Diff-Prompt achieves a maximum improvement of 8.87 in R@1 and 14.05 in R@5 compared to the foundation model and also outperforms other state-of-the-art methods across multiple metrics. The experimental results validate the effectiveness of our approach and highlight the potential of using generative models for prompt generation. Code is available at https://github.com/Kelvin-ywc/diff-prompt.
  abstract_embedding: [0.1044921875, 0.55859375, 0.1416015625]... (1536 items)
  authors: ['Weicai Yan', 'Wang Lin', 'Zirun Guo']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805438924
  novelty: yes
  reason: Relevance: The paper proposes a novel diffusion-based prompt generation method that can improve the performance of pre-trained multimodal models on complex downstream tasks. | Novelty: The use of a di...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Diff-Prompt__Diffusion-driven_Prompt_Generator_with_Mask_Supervision.pdf
  sha_abstract: 423cfd7270b26afaa72c85438c671342647d87da7e46c9bf9c8ad15ec55e69c4
  title: Diff-Prompt: Diffusion-driven Prompt Generator with Mask Supervision
  title_normalized: diffprompt_diffusiondriven_prompt_generator_with_mask_supervision

================================================================================
Document #163 (ID: e7341989ab281c32c950175d7f128aa6cd8ac3276ce0dfcfcf242120755b1dc6)
================================================================================
  abstract: Discrete diffusion models with absorbing processes have shown promise in language modeling. The key quantities to be estimated are the ratios between the marginal probabilities of two transitive states at all timesteps, called the concrete score. In this paper, we reveal that the concrete score in absorbing diffusion can be expressed as conditional probabilities of clean data, multiplied by a time-dependent scalar in an analytic form. Motivated by this finding, we propose reparameterized absorbing discrete diffusion (RADD), a dedicated diffusion model without time-condition that characterizes the time-independent conditional probabilities. Besides its simplicity, RADD can reduce the number of function evaluations (NFEs) by caching the output of the time-independent network when the noisy sample remains unchanged in a sampling interval, which enables sampling acceleration. Built upon the new perspective of conditional distributions, we further unify absorbing discrete diffusion and any-order autoregressive models (AO-ARMs), showing that the upper bound on the negative log-likelihood for the diffusion model can be interpreted as an expected negative log-likelihood for AO-ARMs. Further, our RADD models achieve SOTA performance among diffusion models on 5 zero-shot language modeling benchmarks (measured by perplexity) at the GPT-2 scale. Our code is available at  \url{https://github.com/ML-GSAI/RADD}.
  abstract_embedding: [0.46484375, 0.4921875, 0.330078125]... (1536 items)
  authors: ['Jingyang Ou', 'Shen Nie', 'Kaiwen Xue']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805407199
  novelty: yes
  reason: Relevance: The paper proposes a new diffusion model architecture (RADD) with improved efficiency and performance on language modeling tasks. | Novelty: The paper introduces a novel reparameterized abs...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Your_Absorbing_Discrete_Diffusion_Secretly_Models_the_Conditional_Distributions_of_Clean_Data.pdf
  sha_abstract: 736e7a5793b416ef8d5c885aadc5291898f18d96a0dd5329900264752024fff3
  title: Your Absorbing Discrete Diffusion Secretly Models the Conditional Distributions of Clean Data
  title_normalized: your_absorbing_discrete_diffusion_secretly_models_the_conditional_distributions_of_clean_data

================================================================================
Document #164 (ID: d32ca1616efb9566aa7da311b4871949b0dffb6f1c5609071b9f5b83cf37729e)
================================================================================
  abstract: Decision-making is a complex process requiring diverse abilities, making it an excellent framework for evaluating Large Language Models (LLMs). Researchers have examined LLMs' decision-making through the lens of Game Theory. However, existing evaluation mainly focus on two-player scenarios where an LLM competes against another. Additionally, previous benchmarks suffer from test set leakage due to their static design. We introduce GAMA($\gamma$)-Bench, a new framework for evaluating LLMs' Gaming Ability in Multi-Agent environments. It includes eight classical game theory scenarios and a dynamic scoring scheme specially designed to quantitatively assess LLMs' performance. $\gamma$-Bench allows flexible game settings and adapts the scoring system to different game parameters, enabling comprehensive evaluation of robustness, generalizability, and strategies for improvement. Our results indicate that GPT-3.5 demonstrates strong robustness but limited generalizability, which can be enhanced using methods like Chain-of-Thought. We also evaluate 13 LLMs from 6 model families, including GPT-3.5, GPT-4, Gemini, LLaMA-3.1, Mixtral, and Qwen-2. Gemini-1.5-Pro outperforms others, scoring of $69.8$ out of $100$, followed by LLaMA-3.1-70B ($65.9$) and Mixtral-8x22B ($62.4$). Our code and experimental results are publicly available at https://github.com/CUHK-ARISE/GAMABench.
  abstract_embedding: [0.734375, 0.1123046875, -0.034423828125]... (1536 items)
  authors: ['Jen-tse Huang', 'Eric John Li', 'Man Ho LAM']... (10 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805441025
  novelty: yes
  reason: Relevance: The paper proposes a new benchmark framework (GAMA-Bench) for evaluating the decision-making abilities of large language models in multi-agent gaming environments, which is a novel and rele...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Competing_Large_Language_Models_in_Multi-Agent_Gaming_Environments.pdf
  sha_abstract: e2498d3e816d03ad0af889a929b551279d1569c8ac501814fe4ca75937c0e35a
  title: Competing Large Language Models in Multi-Agent Gaming Environments
  title_normalized: competing_large_language_models_in_multiagent_gaming_environments

================================================================================
Document #165 (ID: ea8aa4c2384c8a95636b39d7190aa670d49cc9fb41eda58f022d8569d0944121)
================================================================================
  abstract: The number of models shared online has recently skyrocketed, with over one million public models available on Hugging Face. Sharing models allows other users to build on existing models, using them as initialization for fine-tuning, improving accuracy, and saving compute and energy. However, it also raises important intellectual property issues, as fine-tuning may violate the license terms of the original model or that of its training data. A Model Tree, i.e., a tree data structure rooted at a foundation model and having directed edges between a parent model and other models directly fine-tuned from it (children), would settle such disputes by making the model heritage explicit. Unfortunately, current models are not well documented, with most model metadata (e.g., "model cards") not providing accurate information about heritage. In this paper, we introduce the task of Unsupervised Model Tree Heritage Recovery (Unsupervised MoTHer Recovery) for collections of neural networks. For each pair of models, this task requires: i) determining if they are directly related, and ii) establishing the direction of the relationship. Our hypothesis is that model weights encode this information, the challenge is to decode the underlying tree structure given the weights. We discover several properties of model weights that allow us to perform this task. By using these properties, we formulate the MoTHer Recovery task as finding a directed minimal spanning tree. In extensive experiments we demonstrate that our method successfully reconstructs complex Model Trees.
  abstract_embedding: [0.29296875, 0.48828125, 0.314453125]... (1536 items)
  authors: ['Eliahu Horwitz', 'Asaf Shul', 'Yedid Hoshen']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805431868
  novelty: yes
  reason: Relevance: The paper proposes a novel task of Unsupervised Model Tree Heritage Recovery, which aims to automatically reconstruct the fine-tuning lineage of a collection of neural network models. This ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Unsupervised_Model_Tree_Heritage_Recovery.pdf
  sha_abstract: 363b6cbac981ef97f59ee1926398248d7f0cca3ef70dbf140cff8a31e7b9c32f
  title: Unsupervised Model Tree Heritage Recovery
  title_normalized: unsupervised_model_tree_heritage_recovery

================================================================================
Document #166 (ID: 42219e58e96895e141fd6d09b89f979ee46dc6bbed65fafe4307712bec8842d8)
================================================================================
  abstract: During the inference phase of Large Language Models (LLMs) with long context, a substantial portion of GPU memory is allocated to the KV cache, with memory usage increasing as the sequence length grows. To mitigate the GPU memory footprint associate with KV cache, some previous studies have discarded less important tokens based on the sparsity identified in attention scores in long context scenarios. However, we argue that attention scores cannot indicate the future importance of tokens in subsequent generation iterations, because attention scores are calculated based on current hidden states. Therefore, we propose OmniKV, a token-dropping-free and training-free inference method, which achieves a 1.68x speedup without any loss in performance. It is well-suited for offloading, significantly reducing KV cache memory usage by up to 75% with it. The core innovative insight of OmniKV is: Within a single generation iteration, there is a high degree of similarity in the important tokens identified across consecutive layers. Extensive experiments demonstrate that OmniKV achieves state-of-the-art performance across multiple benchmarks, with particularly advantages in chain-of-thoughts scenarios. OmniKV extends the maximum context length supported by a single A100 for Llama-3-8B from 128K to 450K. Our code is available at https://github.com/antgroup/OmniKV.git.
  abstract_embedding: [0.380859375, 0.1376953125, 0.267578125]... (1536 items)
  authors: ['Jitai Hao', 'Yuke Zhu', 'Tian Wang']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805423543
  novelty: yes
  reason: Relevance: The paper proposes a novel method called OmniKV that improves the efficiency of long-context LLMs by reducing the GPU memory footprint associated with the KV cache, without any loss in perf...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: OmniKV__Dynamic_Context_Selection_for_Efficient_Long-Context_LLMs.pdf
  sha_abstract: ab248f10250076d0218d6ffd4ae0505cc8198ee0289aed5ea2fcc0d3a043e852
  title: OmniKV: Dynamic Context Selection for Efficient Long-Context LLMs
  title_normalized: omnikv_dynamic_context_selection_for_efficient_longcontext_llms

================================================================================
Document #167 (ID: b79c53032a1b45d269437d910fc5af14ecf232cfd6b9146f615d63ff84c03d51)
================================================================================
  abstract: Accurately predicting fluid dynamics and evolution has been a long-standing challenge in physical sciences. Conventional deep learning methods often rely on the nonlinear modeling capabilities of neural networks to establish mappings between past and future states, overlooking the fluid dynamics, or only modeling the velocity field, neglecting the coupling of multiple physical quantities. In this paper, we propose a new physics-informed learning approach that incorporates coupled physical quantities into the prediction process to assist with forecasting. Central to our method lies in the discretization of physical equations, which are directly integrated into the model architecture and loss function. This integration enables the model to provide robust, long-term future predictions. By incorporating physical equations, our model demonstrates temporal extrapolation and spatial generalization capabilities. Experimental results show that our approach achieves the state-of-the-art performance in spatiotemporal prediction across both numerical simulations and real-world extreme-precipitation nowcasting benchmarks.
  abstract_embedding: [0.6640625, -0.087890625, 0.326171875]... (1536 items)
  authors: ['Huaguan Chen', 'Yang Liu', 'Hao Sun']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805435872
  novelty: yes
  reason: Relevance: The paper proposes a new physics-informed neural network architecture for predicting fluid dynamics, which is a novel and relevant model architecture. | Novelty: The proposed physics-inform...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: PINP__Physics-Informed_Neural_Predictor_with_latent_estimation_of_fluid_flows.pdf
  sha_abstract: a9e0afad4c3bdaec886d683e269e85656da565504c019f979c5ed59d2ee6c8ed
  title: PINP: Physics-Informed Neural Predictor with latent estimation of fluid flows
  title_normalized: pinp_physicsinformed_neural_predictor_with_latent_estimation_of_fluid_flows

================================================================================
Document #168 (ID: 025c5e7d9d712b72c9abe6a9a693517427c36fad8f75e9ffa8e7de5d18561987)
================================================================================
  abstract: Zeroth-order optimization (ZO) is a memory-efficient strategy for fine-tuning Large Language Models using only forward passes. However, applying ZO fine-tuning in memory-constrained settings such as mobile phones and laptops remains challenging since these settings often involve weight quantization, while ZO requires full-precision perturbation and update. In this study, we address this limitation by combining static sparse ZO fine-tuning with quantization. Our approach transfers a small, static subset (0.1%) of "sensitive" parameters from pre-training to downstream tasks, focusing fine-tuning on this sparse set of parameters. The remaining untuned parameters are quantized, reducing memory demands. Our proposed workflow enables efficient ZO fine-tuning of an Llama2-7B model on a GPU device with less than 8GB of memory while outperforming full model ZO fine-tuning performance and in-context learning.
  abstract_embedding: [-0.0986328125, 0.455078125, 0.1396484375]... (1536 items)
  authors: ['Wentao Guo', 'Jikai Long', 'Yimeng Zeng']... (12 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805442944
  novelty: yes
  reason: Relevance: The paper proposes a novel method for efficient fine-tuning of LLMs using zeroth-order optimization and static sparsity, which is relevant for improving the efficiency of LLM training and d...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Zeroth-Order_Fine-Tuning_of_LLMs_with_Transferable_Static_Sparsity.pdf
  sha_abstract: a6392519eb03ce215fde58a1551ae2550ea10e787ae6603748e1d5f1485fcf52
  title: Zeroth-Order Fine-Tuning of LLMs with Transferable Static Sparsity
  title_normalized: zerothorder_finetuning_of_llms_with_transferable_static_sparsity

================================================================================
Document #169 (ID: c0483b7c0655cb75b11aef682117ad69c7be2e282531b21bbfa3c7b0c810a7a1)
================================================================================
  abstract: Large language models (LLMs) have demonstrated significant potential in the development of intelligent LLM-based agents. However, when users use these agent applications to perform file operations, their interaction with the file system still remains the traditional paradigm: reliant on manual navigation through precise commands. This paradigm poses a bottleneck to the usability of these systems as users are required to navigate complex folder hierarchies and remember cryptic file names. To address this limitation, we propose an LLM-based Semantic File System (LSFS) for prompt-driven file management in LLM Agent Operating System (AIOS). Unlike conventional approaches, LSFS incorporates LLMs to enable users or agents to interact with files through natural language prompts, facilitating
semantic file management. At the macro-level, we develop a comprehensive API set to achieve semantic file management functionalities, such as semantic file retrieval, file update summarization, and semantic file rollback). At the micro-level, we store files by constructing semantic indexes for them, design and implement syscalls of different semantic operations, e.g., CRUD (create, read, update, delete),
group by, join. Our experiments show that LSFS can achieve at least 15% retrieval accuracy improvement with 2.1× higher retrieval speed in the semantic file retrieval task compared with the traditional file system. In the traditional keyword-based file retrieval task (i.e., retrieving by string-matching), LSFS also performs stably well, i.e., over 89% F1-score with improved usability, especially when the keyword conditions become more complex. Additionally, LSFS supports more advanced file management operations, i.e., semantic file rollback and file sharing and achieves 100% success rates in these tasks, further suggesting the capability of LSFS . The code is available at https://github.com/agiresearch/AIOS-LSFS.
  abstract_embedding: [0.361328125, 0.031982421875, 0.17578125]... (1536 items)
  authors: ['Zeru Shi', 'Kai Mei', 'Mingyu Jin']... (12 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805445144
  novelty: yes
  reason: Relevance: The paper proposes a novel LLM-based Semantic File System (LSFS) that enables prompt-driven file management, which is a significant innovation in file system design. | Novelty: The LSFS app...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: From_Commands_to_Prompts__LLM-based_Semantic_File_System_for_AIOS.pdf
  sha_abstract: 33decfc66b06a1f60bbce9ae35a23360fdfc10f2a8c6aafc10dfc499c13376a7
  title: From Commands to Prompts: LLM-based Semantic File System for AIOS
  title_normalized: from_commands_to_prompts_llmbased_semantic_file_system_for_aios

================================================================================
Document #170 (ID: f6c4bf4da29d115aebb3beda45d3d991f8b36b54893e5af56c62cea66ec9aa92)
================================================================================
  abstract: Understanding transition pathways between two meta-stable states of a molecular system is crucial to advance drug discovery and material design. However, unbiased molecular dynamics (MD) simulations are computationally infeasible because of the high energy barriers that separate these states. Although recent machine learning techniques are proposed to sample rare events, they are often limited to simple systems and rely on collective variables (CVs) derived from costly domain expertise. In this paper, we introduce a novel approach that trains diffusion path samplers (DPS) to address the transition path sampling (TPS) problem without requiring CVs. We reformulate the problem as an amortized sampling from the transition path distribution by minimizing the log-variance divergence between the path distribution induced by DPS and the transition path distribution. Based on the log-variance divergence, we propose learnable control variates to reduce the variance of gradient estimators and the off-policy training objective with replay buffers and simulated annealing techniques to improve sample efficiency and diversity. We also propose a scale-based equivariant parameterization of the bias forces to ensure scalability for large systems. We extensively evaluate our approach, termed TPS-DPS, on a synthetic system, small peptide, and challenging fast-folding proteins, demonstrating that it produces more realistic and diverse transition pathways than existing baselines. We also provide links to [project page](https://kiyoung98.github.io/tps-dps/) and [code](https://github.com/kiyoung98/tps-dps).
  abstract_embedding: [0.671875, 0.458984375, 0.61328125]... (1536 items)
  authors: ['Kiyoung Seong', 'Seonghyun Park', 'Seonghwan Kim']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805463931
  novelty: yes
  reason: Relevance: The paper proposes a novel approach for training diffusion path samplers to address the transition path sampling problem, which is relevant for drug discovery and material design. | Novelty...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Transition_Path_Sampling_with_Improved_Off-Policy_Training_of_Diffusion_Path_Samplers.pdf
  sha_abstract: afd061729f6c176f3f6236c1fb67d2fa366488d62605a67afdbf1886546ff46e
  title: Transition Path Sampling with Improved Off-Policy Training of Diffusion Path Samplers
  title_normalized: transition_path_sampling_with_improved_offpolicy_training_of_diffusion_path_samplers

================================================================================
Document #171 (ID: 00b1f203fe9b5d3277962c204a5db15ed086e3798c949c41b0fb9f87f0b3c7ef)
================================================================================
  abstract: Despite recent progress in Retrieval-Augmented Generation (RAG) achieved by large language models (LLMs), retrievers often recall uncorrelated documents, regarded as "noise" during subsequent text generation. To address this, some methods train LLMs to distinguish between relevant and irrelevant documents using labeled data, enabling them to select the most likely relevant ones as context. However, they remain sensitive to noise, as LLMs can easily make mistakes when the selected document is noisy. Some approaches increase the number of referenced documents and train LLMs to perform stepwise reasoning when presented with multiple documents. Unfortunately, these methods rely on extensive and diverse annotations to ensure generalization, which is both challenging and costly. In this paper, we propose **Backtracking Correction** to address these limitations. Specifically, we reformulate stepwise RAG into a multi-step decision-making process. Starting from the final step, we optimize the model through error sampling and self-correction, and then backtrack to the previous state iteratively. In this way, the model's learning scheme follows an easy-to-hard progression: as the target state moves forward, the context space decreases while the decision space increases. Experimental results demonstrate that **Backtracking Correction** enhances LLMs' ability to make complex multi-step assessments, improving the robustness of RAG in dealing with noisy documents.
  abstract_embedding: [0.3828125, 0.2734375, -0.05517578125]... (1536 items)
  authors: ['Huawen Feng', 'ZekunYao', 'Junhao Zheng']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805455736
  novelty: yes
  reason: Relevance: The paper proposes a novel training algorithm called Backtracking Correction that improves the robustness of Retrieval-Augmented Generation (RAG) models in dealing with noisy documents, whi...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Training_Large_Language_Models_for_Retrieval-Augmented_Question_Answering_through_Backtracking_Correction.pdf
  sha_abstract: 3197838829c0199e7f4d6fe2312946a65d5ba0c5238298089ff69e03ed345633
  title: Training Large Language Models for Retrieval-Augmented Question Answering through Backtracking Correction
  title_normalized: training_large_language_models_for_retrievalaugmented_question_answering_through_backtracking_correction

================================================================================
Document #172 (ID: 8808024cf1e94063bc36b173d5f356863bcc7d5b3df99be4258992fa736fe5ee)
================================================================================
  abstract: Training embodied agents to perform complex robotic tasks presents significant challenges due to the entangled factors of task compositionality, environmental diversity, and dynamic changes. In this work, we introduce a novel imitation learning framework to train closed-loop concept-guided policies that enhance long-horizon task performance by leveraging discovered manipulation concepts. Unlike methods that rely on predefined skills and human-annotated labels, our approach allows agents to autonomously abstract manipulation concepts from their proprioceptive states, thereby alleviating misalignment due to ambiguities in human semantics and environmental complexity. Our framework comprises two primary components: an *Automatic Concept Discovery* module that identifies meaningful and consistent manipulation concepts, and a *Concept-Guided Policy Learning* module that effectively utilizes these manipulation concepts for adaptive task execution, including a *Concept Selection Transformer* for concept-based guidance and a *Concept-Guided Policy* for action prediction with the selected concepts. Experiments demonstrate that our approach significantly outperforms baseline methods across a range of tasks and environments, while showcasing emergent consistency in motion patterns associated with the discovered manipulation concepts. Codes are available at: https://github.com/PeiZhou26/AutoCGP.
  abstract_embedding: [0.4375, 0.376953125, 0.2333984375]... (1536 items)
  authors: ['Pei Zhou', 'Ruizhe Liu', 'Qian Luo']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805446982
  novelty: yes
  reason: Relevance: The paper proposes a novel imitation learning framework that leverages automatically discovered manipulation concepts to train closed-loop concept-guided policies for complex robotic tasks,...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: AutoCGP__Closed-Loop_Concept-Guided_Policies_from_Unlabeled_Demonstrations.pdf
  sha_abstract: 88a818225ea6bda945e161cfb54a707d3c32ec00f13727f7d73891e879df7965
  title: AutoCGP: Closed-Loop Concept-Guided Policies from Unlabeled Demonstrations
  title_normalized: autocgp_closedloop_conceptguided_policies_from_unlabeled_demonstrations

================================================================================
Document #173 (ID: 06b7973a4eed41a512f56918992a798e052248a965ffe690183aa8dc9770ffdb)
================================================================================
  abstract: Diffusion Language Models (DLMs) have emerged as a promising new paradigm for text generative modeling, potentially addressing limitations of autoregressive (AR) models. However, current DLMs have been studied at a smaller scale compared to their AR counterparts and lack fair comparison on language modeling benchmarks. Additionally, training diffusion models from scratch at scale remains challenging. Given the prevalence of open-source AR language models, we propose adapting these models to build text diffusion models. We demonstrate connections between AR and diffusion modeling objectives and introduce a simple continual pre-training approach for training diffusion models. Through systematic evaluation on language modeling, reasoning, and commonsense benchmarks, we show that we can convert AR models ranging from 127M to 7B parameters (GPT2 and LLaMA) into diffusion models DiffuGPT and DiffuLLaMA, using less than 200B tokens for training. Our experimental results reveal that these models outperform earlier DLMs and are competitive with their AR counterparts. We release a suite of DLMs (127M-355M-7B) capable of generating fluent text, performing in-context learning, filling in the middle without prompt re-ordering, and following instructions.
  abstract_embedding: [0.259765625, 0.380859375, 0.294921875]... (1536 items)
  authors: ['Shansan Gong', 'Shivam Agarwal', 'Yizhe Zhang']... (12 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805461267
  novelty: yes
  reason: Relevance: The paper proposes a novel approach to scaling diffusion language models by adapting from autoregressive models, which is directly relevant to innovative model architectures and training te...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Scaling_Diffusion_Language_Models_via_Adaptation_from_Autoregressive_Models.pdf
  sha_abstract: 78f73b00d77f60394656599f83889b95403bbb4502ce0e3651797efb6939554d
  title: Scaling Diffusion Language Models via Adaptation from Autoregressive Models
  title_normalized: scaling_diffusion_language_models_via_adaptation_from_autoregressive_models

================================================================================
Document #174 (ID: e335c1f18aba8b9055b051b0cbc9c33c610944dd28cd2a10fa3f210ea5dc08ba)
================================================================================
  abstract: This paper proposes a new 3D molecule generation framework, called GOAT, for fast and effective 3D molecule generation based on the flow-matching optimal transport objective. Specifically, we formulate a geometric transport formula for measuring the cost of mapping multi-modal features (e.g., continuous atom coordinates and categorical atom types) between a base distribution and a target data distribution. Our formula is solved within a joint, equivariant, and smooth representation space. This is achieved by transforming the multi-modal features into a continuous latent space with equivariant networks. In addition, we find that identifying optimal distributional coupling is necessary for fast and effective transport between any two distributions. We further propose a mechanism for estimating and purifying optimal coupling to train the flow model with optimal transport. By doing so, GOAT can turn arbitrary distribution couplings into new deterministic couplings, leading to an estimated optimal transport plan for fast 3D molecule generation. The purification filters out the subpar molecules to ensure the ultimate generation quality. We theoretically and empirically prove that the proposed optimal coupling estimation and purification yield transport plan with non-increasing cost. Finally, extensive experiments show that GOAT enjoys the efficiency of solving geometric optimal transport, leading to a double speedup compared to the sub-optimal method while achieving the best generation quality regarding validity, uniqueness, and novelty.
  abstract_embedding: [0.390625, 0.1064453125, 0.1103515625]... (1536 items)
  authors: ['Haokai Hong', 'Wanyu Lin', 'KC Tan']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805450895
  novelty: yes
  reason: Relevance: The paper proposes a new 3D molecule generation framework, GOAT, which uses a geometric optimal transport objective and equivariant networks to transform multi-modal features into a continu...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Accelerating_3D_Molecule_Generation_via_Jointly_Geometric_Optimal_Transport.pdf
  sha_abstract: 38b437dcccd7c6564dccae64adb39c5207629bcd96ffc6fa5d426b0fffa03b38
  title: Accelerating 3D Molecule Generation via Jointly Geometric Optimal Transport
  title_normalized: accelerating_3d_molecule_generation_via_jointly_geometric_optimal_transport

================================================================================
Document #175 (ID: 66a38e702aaabf8629a76e34a1a04e1a93d4d7c3bf1021cb241adb220d36be80)
================================================================================
  abstract: A recent line of work in mechanistic interpretability has focused on reverse-engineering the computation performed by neural networks trained on the binary operation of finite groups. We investigate the internals of one-hidden-layer neural networks trained on this task, revealing previously unidentified structure and producing a more complete description of such models in a step towards unifying the explanations of previous works (Chughtai et al., 2023; Stander et al., 2024). Notably, these models approximate equivariance in each input argument. We verify that our explanation applies to a large fraction of networks trained on this task by translating it into a compact proof of model performance, a quantitative evaluation of the extent to which we faithfully and concisely explain model internals. In the main text, we focus on the symmetric group S5. For models trained on this group, our explanation yields a guarantee of model accuracy that runs 3x faster than brute force and gives a >=95% accuracy bound for 45% of the models we trained. We were unable to obtain nontrivial non-vacuous accuracy bounds using only explanations from previous works.
  abstract_embedding: [0.0166015625, 0.392578125, 0.056640625]... (1536 items)
  authors: ['Wilson Wu', 'Louis Jaburi', 'jacob drori']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805457799
  novelty: yes
  reason: Relevance: The paper proposes a novel explanation and verification technique for one-hidden-layer neural networks trained on finite group operations, which can be seen as an innovative training algori...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Towards_a_Unified_and_Verified_Understanding_of_Group-Operation_Networks.pdf
  sha_abstract: d475afb9f3dd8840f600b5793dbe4d0b8a4fcf5d77c57facc38018254f2708d0
  title: Towards a Unified and Verified Understanding of Group-Operation Networks
  title_normalized: towards_a_unified_and_verified_understanding_of_groupoperation_networks

================================================================================
Document #176 (ID: 67d5e41d47ff1eae72323624f1af1618293d4ceef627804428144948be5a57d3)
================================================================================
  abstract: Recent advancements in large language models (LLMs) reveal a perplexing phenomenon in continual learning: despite extensive training, models experience significant performance declines, raising questions about task alignment and underlying knowledge retention. This study first explores the concept of "spurious forgetting", proposing that such performance drops often reflect a decline in task alignment rather than true knowledge loss. Through controlled experiments with a synthesized dataset, we investigate the dynamics of model performance during the initial training phases of new tasks, discovering that early optimization steps can disrupt previously established task alignments. Our theoretical analysis connects these shifts to orthogonal updates in model weights, providing a robust framework for understanding this behavior. Ultimately, we introduce a Freezing strategy that fix the bottom layers of the model, leading to substantial improvements in four continual learning scenarios. Our findings underscore the critical distinction between task alignment and knowledge retention, paving the way for more effective strategies in continual learning.
  abstract_embedding: [0.58984375, -0.003082275390625, -0.04052734375]... (1536 items)
  authors: ['Junhao Zheng', 'Xidi Cai', 'Shengjie Qiu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805453273
  novelty: yes
  reason: Relevance: The paper proposes a novel Freezing strategy to improve task alignment and knowledge retention in continual learning of language models, which is relevant for efficient training and deploym...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Spurious_Forgetting_in_Continual_Learning_of_Language_Models.pdf
  sha_abstract: e92db004b1d3967782a9027fc5c8f5a9f6e1e2f599ac4169bd65b50a39720b20
  title: Spurious Forgetting in Continual Learning of Language Models
  title_normalized: spurious_forgetting_in_continual_learning_of_language_models

================================================================================
Document #177 (ID: 2f3d42b2992cd90974946396d057d006945d7214d7e7de42e769b85480edb215)
================================================================================
  abstract: Kolmogorov–Arnold Network (KAN) is a network structure recently proposed in Liu et al. (2024) that offers improved interpretability and a more parsimonious design in many science-oriented tasks compared to multi-layer perceptrons. This work provides a rigorous theoretical analysis of KAN by establishing generalization bounds for KAN equipped with activation functions that are either represented by linear combinations of basis functions or lying in a low-rank Reproducing Kernel Hilbert Space (RKHS). In the first case, the generalization bound accommodates various choices of basis functions in forming the activation functions in each layer of KAN and is adapted to different operator norms at each layer. For a particular choice of operator norms, the bound scales with the $l_1$ norm of the coefficient matrices and the Lipschitz constants for the activation functions, and it has no dependence on combinatorial parameters (e.g., number of nodes) outside of logarithmic factors. Moreover, our result does not require the boundedness assumption on the loss function and, hence, is applicable to a general class of regression-type loss functions. In the low-rank case, the generalization bound scales polynomially with the underlying ranks as well as the Lipschitz constants of the activation functions in each layer. These bounds are empirically investigated for KANs trained with stochastic gradient descent on simulated and real data sets. The numerical results demonstrate the practical relevance of these bounds.
  abstract_embedding: [0.5234375, 0.388671875, -0.07958984375]... (1536 items)
  authors: ['Xianyang Zhang', 'Huijuan Zhou']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805472041
  novelty: yes
  reason: Relevance: The paper proposes a new network architecture (Kolmogorov-Arnold Network) and provides a theoretical analysis of its generalization properties, which is relevant for improving model efficie...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Generalization_Bounds_and_Model_Complexity_for_Kolmogorov_Arnold_Networks.pdf
  sha_abstract: ddd2193cd2e8c068e81925a495968f2555640ffb45213705617fdd6b46d2397b
  title: Generalization Bounds and Model Complexity for Kolmogorov–Arnold Networks
  title_normalized: generalization_bounds_and_model_complexity_for_kolmogorovarnold_networks

================================================================================
Document #178 (ID: db566ec84d626658d48f744218788742b29b8685968ba05b618455b303867fe1)
================================================================================
  abstract: An important prerequisite for safe control is aligning the policy with the underlying constraints in the environment. In many real-world applications, due to the difficulty of manually specifying these constraints, existing works have proposed recovering constraints from expert demonstrations by solving the Inverse Constraint Learning (ICL) problem. However, ICL is inherently ill-posed, as multiple constraints can equivalently explain the experts' preferences, making the optimal solutions not uniquely identifiable. In this work, instead of focusing solely on a single constraint, we propose the novel approach of Exploratory ICL (ExICL). The goal of ExICL is to recover a diverse set of feasible constraints, thereby providing practitioners the flexibility to select the most appropriate constraint based on the practical needs of deployment. To achieve this goal, we design a generative diffusion verifier that guides the trajectory generation process using the probabilistic representation of an optimal constrained policy. By comparing these decisions with those made by expert agents, we can efficiently verify a candidate constraint. Driven by the verification feedback, ExICL implements an exploratory constraint update mechanism that strategically facilitates diversity within the collection of feasible constraints. Our empirical results demonstrate that ExICL can seamlessly and reliably generalize across different tasks and environments. The code is available at https://github.com/ZhaoRunyi/ExICL.
  abstract_embedding: [0.57421875, 0.73046875, -0.039306640625]... (1536 items)
  authors: ['Runyi Zhao', 'Sheng Xu', 'Bo Yue']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805476860
  novelty: yes
  reason: Relevance: The paper proposes a novel approach called Exploratory Inverse Constraint Learning (ExICL) that aims to recover a diverse set of feasible constraints, which could be valuable for aligning A...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Toward_Exploratory_Inverse_Constraint_Inference_with_Generative_Diffusion_Verifiers.pdf
  sha_abstract: 4d18304d337bc38f84922e8603772c257d14737c3af47ca881dcc542344cdf01
  title: Toward Exploratory Inverse Constraint Inference with Generative Diffusion Verifiers
  title_normalized: toward_exploratory_inverse_constraint_inference_with_generative_diffusion_verifiers

================================================================================
Document #179 (ID: a18c08b5175c040e2b5c8d03b8a80625c5b3c1ad1328fb0db72ec54dc49c39dd)
================================================================================
  abstract: Domain Generalization (DG) aims to learn from multiple known source domains a model that can generalize well to unknown target domains. One of the key approaches in DG is training an encoder which generates domain-invariant representations. However, this approach is not applicable in Federated Domain Generalization (FDG), where data from various domains are distributed across different clients. In this paper, we introduce a novel approach, dubbed Federated Learning via On-server Matching Gradient (FedOMG), which can efficiently leverage domain information from distributed domains. Specifically, we utilize the local gradients as information about the distributed models to find an invariant gradient direction across all domains through gradient inner product maximization. The advantages are two-fold: 1) FedOMG can aggregate the characteristics of distributed models on the centralized server without incurring any additional communication cost, and 2) FedOMG is orthogonal to many existing FL/FDG methods, allowing for additional performance improvements by being seamlessly integrated with them. Extensive experimental evaluations on various settings demonstrate the robustness of FedOMG compared to other FL/FDG baselines. Our method outperforms recent SOTA baselines on four FL benchmark datasets (MNIST, EMNIST, CIFAR-10, and CIFAR-100), and three FDG benchmark datasets (PACS, VLCS, and OfficeHome). The reproducible code is publicly available~\footnote[1]{\url{https://github.com/skydvn/fedomg}}.
  abstract_embedding: [0.625, 0.4609375, -0.13671875]... (1536 items)
  authors: ['Trong Binh Nguyen', 'Duong Minh Nguyen', 'Jinsun Park']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805480694
  novelty: yes
  reason: Relevance: The paper proposes a novel federated learning approach called FedOMG that leverages distributed domain information to learn domain-invariant representations, which is relevant for improving...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Federated_Domain_Generalization_with_Data-free_On-server_Matching_Gradient.pdf
  sha_abstract: e5451dd8105d59d1129baa649e484046b9abe7b66cec7d026cd08ddafc3bf941
  title: Federated Domain Generalization with Data-free On-server Matching Gradient
  title_normalized: federated_domain_generalization_with_datafree_onserver_matching_gradient

================================================================================
Document #180 (ID: 9108bcf67ff6b662a0f7861a8805a320befc7c7e68ed4b36521d045f25b9d00b)
================================================================================
  abstract: Diffusion-based video generation technology has advanced significantly, catalyzing a proliferation of research in human animation. While breakthroughs have been made in driving human animation through various modalities for portraits, most of current solutions for human body animation still focus on video-driven methods, leaving audio-driven taking body generation relatively underexplored. In this paper, we introduce CyberHost, a one-stage audio-driven talking body generation framework that addresses common synthesis degradations in half-body animation, including hand integrity, identity consistency, and natural motion.
CyberHost's key designs are twofold. Firstly, the Region Attention Module (RAM) maintains a set of learnable, implicit, identity-agnostic latent features and combines them with identity-specific local visual features to enhance the synthesis of critical local regions. Secondly, the Human-Prior-Guided Conditions introduce more human structural priors into the model, reducing uncertainty in generated motion patterns and thereby improving the stability of the generated videos.
To our knowledge, CyberHost is the first one-stage audio-driven human diffusion model capable of zero-shot video generation for the human body. Extensive experiments demonstrate that CyberHost surpasses previous works in both quantitative and qualitative aspects. CyberHost can also be extended to video-driven and audio-video hybrid-driven scenarios, achieving similarly satisfactory results.
  abstract_embedding: [0.365234375, 0.3984375, 0.1376953125]... (1536 items)
  authors: ['Gaojie Lin', 'Jianwen Jiang', 'Chao Liang']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805482865
  novelty: yes
  reason: Relevance: The paper proposes a novel one-stage audio-driven diffusion framework for talking body generation, which is an innovative model architecture. | Novelty: The proposed CyberHost framework is ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CyberHost__A_One-stage_Diffusion_Framework_for_Audio-driven_Talking_Body_Generation.pdf
  sha_abstract: 4af083e52131672039a52aebd1b1f2067ba6d068e414cd421968a1cf716c46d1
  title: CyberHost: A One-stage Diffusion Framework for Audio-driven Talking Body Generation
  title_normalized: cyberhost_a_onestage_diffusion_framework_for_audiodriven_talking_body_generation

================================================================================
Document #181 (ID: 4c24b96b596a7c1c7c42a0eb15be35237513cb1fc7cbc80f9875be401fee9709)
================================================================================
  abstract: We explore neuro-symbolic approaches to generalize actionable knowledge, enabling embodied agents to tackle complex tasks more effectively in open-domain environments. A key challenge for embodied agents is the generalization of knowledge across diverse environments and situations, as limited experiences often confine them to their prior knowledge. To address this issue, we introduce a novel framework, NeSyC, a neuro-symbolic continual learner that emulates the hypothetico-deductive model by continually formulating and validating knowledge from limited experiences through the combined use of Large Language Models (LLMs) and symbolic tools. Specifically, we devise a contrastive generality improvement scheme within NeSyC, which iteratively generates hypotheses using LLMs and conducts contrastive validation via symbolic tools. This scheme reinforces the justification for admissible actions while minimizing the inference of inadmissible ones. Additionally, we incorporate a memory-based monitoring scheme that efficiently detects action errors and triggers the knowledge refinement process across domains. Experiments conducted on diverse embodied task benchmarks—including ALFWorld, VirtualHome, Minecraft, RLBench, and a real-world robotic scenario—demonstrate that NeSyC is highly effective in solving complex embodied tasks across a range of open-domain environments.
  abstract_embedding: [0.6640625, 0.267578125, 0.2734375]... (1536 items)
  authors: ['Wonje Choi', 'Jinwoo Park', 'Sanghyun Ahn']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805474577
  novelty: yes
  reason: Relevance: The paper proposes a novel neuro-symbolic continual learning framework (NeSyC) that combines large language models and symbolic tools to enable embodied agents to tackle complex tasks in op...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: NeSyC__A_Neuro-symbolic_Continual_Learner_For_Complex_Embodied_Tasks_in_Open_Domains.pdf
  sha_abstract: 174ab84a6e13c0f94b91c0fc30c0c130aabe6c3bb1898c7e106dddef745edae2
  title: NeSyC: A Neuro-symbolic Continual Learner For Complex Embodied Tasks in Open Domains
  title_normalized: nesyc_a_neurosymbolic_continual_learner_for_complex_embodied_tasks_in_open_domains

================================================================================
Document #182 (ID: 00f0a776c076312de79e5819931d01b45ac9c64799fd394c86c111c4ec7d4d46)
================================================================================
  abstract: Large Language Model's are instruction-finetuned to enhance their ability to follow user instructions and better comprehend input context. Still, they often struggle to follow the input context, especially when it contradicts model's parametric knowledge. This manifests as various failures, such as hallucinations where a model inserts outdated or unwarranted facts into its response. In this work, we observe an intriguing phenomenon: the context reliance of the model decreases as instruction finetuning progresses, $\textit{despite an initial expected increase}$. We call this phenomenon as the $\textbf{context-parametric inversion}$. This is surprising, as one would expect instruction tuning to improve the model's ability to follow input instructions.  We observe this behavior on multiple general purpose instruction tuning datasets such as TULU, Alpaca and Ultrachat, across multiple model families like Llama, Mistral and Pythia.  We perform various controlled studies to eliminate some simple hypothesis for this observed behavior and isolate what datapoints cause this counter-intuitive behavior. We then analyze the phenomenon theoretically, to explain why context reliance varies across the trajectory of finetuning. 
We tie the observed context-parametric inversion to the properties of the finetuning data, which provides us with some potential mitigation strategies that provide limited but insightful gains.
  abstract_embedding: [0.443359375, 0.279296875, -0.041748046875]... (1536 items)
  authors: ['Sachin Goyal', 'Christina Baek', 'J Zico Kolter']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805484701
  novelty: yes
  reason: Relevance: The paper proposes a novel phenomenon called 'context-parametric inversion' related to instruction finetuning of large language models, which could lead to improvements in model alignment a...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Context-Parametric_Inversion__Why_Instruction_Finetuning_May_Not_Actually_Improve_Context_Reliance.pdf
  sha_abstract: ddb23dfb5f724a0aa2c4422256a6951b7cea7096a55b22eda400200b1b3bfe64
  title: Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance
  title_normalized: contextparametric_inversion_why_instruction_finetuning_may_not_actually_improve_context_reliance

================================================================================
Document #183 (ID: c063be34b2d9e37fa52c8798b7f8f8eb87216040085554555244d46ed60c0a31)
================================================================================
  abstract: Transporting between arbitrary distributions is a fundamental goal in generative modeling.
Recently proposed diffusion bridge models provide a potential solution, but they rely on a joint distribution that is difficult to obtain in practice.
Furthermore, formulations based on continuous domains limit their applicability to discrete domains such as graphs.
To overcome these limitations, we propose Discrete Diffusion Schrödinger Bridge Matching (DDSBM), a novel framework that utilizes continuous-time Markov chains to solve the SB problem in a high-dimensional discrete state space.
Our approach extends Iterative Markovian Fitting to discrete domains, and we have proved its convergence to the SB.
Furthermore, we adapt our framework for the graph transformation, and show that our design choice of underlying dynamics characterized by independent modifications of nodes and edges can be interpreted as the entropy-regularized version of optimal transport with a cost function described by the graph edit distance.
To demonstrate the effectiveness of our framework, we have applied DDSBM to molecular optimization in the field of chemistry.
Experimental results demonstrate that DDSBM effectively optimizes molecules' property-of-interest with minimal graph transformation, successfully retaining other features. Source code is available [here](https://github.com/junhkim1226/DDSBM).
  abstract_embedding: [0.54296875, 0.2734375, 0.11279296875]... (1536 items)
  authors: ['Jun Hyeong Kim', 'Seonghwan Kim', 'Seokhyun Moon']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805478524
  novelty: yes
  reason: Relevance: The paper proposes a novel discrete diffusion Schrödinger bridge framework for graph transformation, which is an innovative model architecture and training algorithm. | Novelty: The propose...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Discrete_Diffusion_Schrödinger_Bridge_Matching_for_Graph_Transformation.pdf
  sha_abstract: 513e05c08c214eafb6a0a0b46258abe666723953af01e142fa93850c3a6ecccb
  title: Discrete Diffusion Schrödinger Bridge Matching for Graph Transformation
  title_normalized: discrete_diffusion_schrödinger_bridge_matching_for_graph_transformation

================================================================================
Document #184 (ID: df39a60dccaa7d8dc2307e563dbc3fe36706d878c137a1a15b5cb02ec20c7fcb)
================================================================================
  abstract: Optimization in deep learning remains poorly understood.  A key difficulty is that optimizers exhibit complex oscillatory dynamics, referred to as "edge of stability," which cannot be captured by traditional optimization theory.  In this paper, we show that the path taken by an oscillatory optimizer can often be captured by a  _central flow_: a differential equation which directly models the time-averaged (i.e. smoothed) optimization trajectory. We empirically show that these central flows can predict long-term optimization trajectories for generic neural networks with a high degree of numerical accuracy.  By interpreting these flows, we are able to understand  how gradient descent makes progress even as the loss sometimes goes up; how adaptive optimizers ``adapt'' to the local loss landscape; and how adaptive optimizers implicitly seek out regions of weight space where they can take larger steps.  These insights (and others) are not apparent from the optimizers' update rules, but are revealed by the central flows.  Therefore, we believe that central flows constitute a promising tool for reasoning about optimization in deep learning.
  abstract_embedding: [0.2734375, 0.19921875, -0.01153564453125]... (1536 items)
  authors: ['Jeremy Cohen', 'Alex Damian', 'Ameet Talwalkar']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805488715
  novelty: yes
  reason: Relevance: The paper proposes a novel optimization technique called 'central flows' that can model the complex dynamics of optimizers and provide insights into how they work. | Novelty: The central fl...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Understanding_Optimization_in_Deep_Learning_with_Central_Flows.pdf
  sha_abstract: c5c0a3b3911f0355fdb3889f0811c9f9985f0b99054055705ac877dc709b5494
  title: Understanding Optimization in Deep Learning with Central Flows
  title_normalized: understanding_optimization_in_deep_learning_with_central_flows

================================================================================
Document #185 (ID: 52a26ad097599179f8b3f0e46c637115a8fbb878bebc819d5dff79269bdc30a6)
================================================================================
  abstract: We introduce DrugFlow, a generative model for structure-based drug design that integrates continuous flow matching with discrete Markov bridges, demonstrating state-of-the-art performance in learning chemical, geometric, and physical aspects of three-dimensional protein-ligand data. We endow DrugFlow with an uncertainty estimate that is able to detect out-of-distribution samples. To further enhance the sampling process towards distribution regions with desirable metric values, we propose a joint preference alignment scheme applicable to both flow matching and Markov bridge frameworks. Furthermore, we extend our model to also explore the conformational landscape of the protein by jointly sampling side chain angles and molecules.
  abstract_embedding: [0.3515625, 0.361328125, 0.3046875]... (1536 items)
  authors: ['Arne Schneuing', 'Ilia Igashov', 'Adrian W. Dobbelstein']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805469169
  novelty: yes
  reason: Relevance: The paper proposes a novel generative model for structure-based drug design that integrates continuous flow matching and discrete Markov bridges, which is relevant for innovative model arch...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Multi-domain_Distribution_Learning_for_De_Novo_Drug_Design.pdf
  sha_abstract: 7299172cd01a0123aae5f15f4fa31f56f0fe25422cdc70ad62a6b2f3687da9d2
  title: Multi-domain Distribution Learning for De Novo Drug Design
  title_normalized: multidomain_distribution_learning_for_de_novo_drug_design

================================================================================
Document #186 (ID: 3d149239b7a18c1d841e80386efce8fde731210e7ed330cb55588a4cffbe8398)
================================================================================
  abstract: We consider the problem of learning nonlinear dynamical systems from a single sample trajectory. While the least squares estimate (LSE) is commonly used for this task, it suffers from poor identification errors when the sample size is small or the model fails to capture the system's true dynamics. To overcome these limitations, we propose a robust LSE framework, which incorporates robust optimization techniques, and prove that it is equivalent to regularizing LSE using general Schatten $p$-norms. We provide non-asymptotic performance guarantees for linear systems, achieving an error rate of $\widetilde{\mathcal{O}}(1/\sqrt{T})$, and show that it avoids the curse of dimensionality, unlike state-of-the-art Wasserstein robust optimization models. Empirical results demonstrate substantial improvements in real-world system identification and online control tasks, outperforming existing methods.
  abstract_embedding: [0.248046875, 0.337890625, 0.1298828125]... (1536 items)
  authors: ['Hyuk Park', 'Grani A. Hanasusanto', 'Yingying Li']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805448587
  novelty: yes
  reason: Relevance: The paper proposes a robust least squares estimation framework for learning nonlinear dynamical systems, which is a novel ML technique. | Novelty: The proposed robust optimization approach ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Robust_System_Identification__Finite-sample_Guarantees_and_Connection_to_Regularization.pdf
  sha_abstract: ebedb2e6f85913119937e5fcd8ef0c2e23af81963f7fbae52689f84f5fa82fef
  title: Robust System Identification: Finite-sample Guarantees and Connection to Regularization
  title_normalized: robust_system_identification_finitesample_guarantees_and_connection_to_regularization

================================================================================
Document #187 (ID: d0cd6d39347d5f63b2269288e0e4fa8cf0ad6296b03b4cf264ea988fa19d2e36)
================================================================================
  abstract: Vision Language Models (VLMs) have demonstrated strong capabilities across various visual understanding and reasoning tasks, driven by incorporating image representations into the token inputs of Large Language Models (LLMs). However, their real-world deployment is often constrained by high latency during inference due to the substantial compute required by the LLM to process the large number of input tokens, predominantly arising from the image. To reduce inference costs, one can either downsize the LLM or reduce the number of input tokens needed to represent the image, the latter of which has been the focus of many recent efforts around token compression. However, it is unclear what the optimal trade-off is given a fixed inference budget. 
We first characterize this optimal trade-off between the number of visual tokens and LLM parameters by establishing scaling laws that capture variations in performance with these two factors. Our results reveal a surprising trend: for visual reasoning tasks, the inference-optimal behavior in VLMs is achieved by using the largest LLM that fits within the inference budget while minimizing visual token count - often to a single token. While the token reduction literature has mainly focused on maintaining base model performance by modestly reducing the token count (e.g., $5-10\times$), our results indicate that the compute-optimal inference regime requires operating under even higher token compression ratios. Based on these insights, we take the first steps toward designing token compression algorithms tailored for high-compression settings, utilizing prompt-based compression of tokens. Our work underscores the performance and efficiency benefits of operating in low visual token regimes and the importance of developing tailored token reduction algorithms for such conditions.
  abstract_embedding: [0.061279296875, 0.263671875, 0.51171875]... (1536 items)
  authors: ['Kevin Li', 'Sachin Goyal', 'João D. Semedo']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805494173
  novelty: yes
  reason: Relevance: The paper proposes a novel approach to reducing the number of visual tokens in VLMs, which can lead to significant efficiency improvements during inference. | Novelty: The paper presents a ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Inference_Optimal_VLMs_Need_Fewer_Visual_Tokens_and_More_Parameters.pdf
  sha_abstract: c88738c13ff825d5d3d77962d25af31795562c13e261e7c4c382f4650d5b6780
  title: Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters
  title_normalized: inference_optimal_vlms_need_fewer_visual_tokens_and_more_parameters

================================================================================
Document #188 (ID: f6b1247d80d9998ea8d373e5dba797f5df16d6437bbaa6b151df2f3d4901f418)
================================================================================
  abstract: The quest for robust and generalizable machine learning models has driven recent interest in exploiting symmetries through equivariant neural networks. In the context of PDE solvers, recent works have shown that Lie point symmetries can be a useful inductive bias for Physics-Informed Neural Networks (PINNs) through data and loss augmentation. Despite this, directly enforcing equivariance within the model architecture for these problems remains elusive. This is because many PDEs admit non-compact symmetry groups, oftentimes not studied beyond their infinitesimal generators, making them incompatible with most existing equivariant architectures. In this work, we propose Lie aLgebrA Canonicalization (LieLAC), a novel approach that exploits only the action of infinitesimal generators of the symmetry group, circumventing the need for knowledge of the full group structure. To achieve this, we address existing theoretical issues in the canonicalization literature, establishing connections with frame averaging in the case of continuous non-compact groups. Operating within the framework of canonicalization, LieLAC can easily be integrated with unconstrained pre-trained models, transforming inputs to a canonical form before feeding them into the existing model, effectively aligning the input for model inference according to allowed symmetries. LieLAC utilizes standard Lie group descent schemes, achieving equivariance in pre-trained models. Finally, we showcase LieLAC's efficacy on tasks of invariant image classification and Lie point symmetry equivariant neural PDE solvers using pre-trained models.
  abstract_embedding: [0.031982421875, 0.396484375, 0.0791015625]... (1536 items)
  authors: ['Zakhar Shumaylov', 'Peter Zaika', 'James Rowbottom']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805496194
  novelty: yes
  reason: Relevance: The paper proposes a novel equivariant neural network architecture called LieLAC that can be integrated with pre-trained models to achieve equivariance to Lie group symmetries. | Novelty: L...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Lie_Algebra_Canonicalization__Equivariant_Neural_Operators_under_arbitrary_Lie_Groups.pdf
  sha_abstract: a9e9405feb025a690ea8776bebbcff1112164e4c511982d1307aa1ff852fba10
  title: Lie Algebra Canonicalization: Equivariant Neural Operators under arbitrary Lie Groups
  title_normalized: lie_algebra_canonicalization_equivariant_neural_operators_under_arbitrary_lie_groups

================================================================================
Document #189 (ID: 536e52e2527f7061da1dc2a77f4d8f5d01ff457160f2189e3dba356ca09ffdb1)
================================================================================
  abstract: Federated Learning (FL) offers a promising framework for collaborative and privacy-preserving machine learning across distributed data sources. 
However, the substantial communication costs associated with FL significantly challenge its efficiency. 
Specifically, in each communication round, the communication costs scale linearly with the model's dimension, which presents a formidable obstacle, especially in large model scenarios. 
Despite various communication-efficient strategies, the intrinsic dimension-dependent communication cost remains a major bottleneck for current FL implementations.
This paper proposes a novel dimension-free communication algorithm - DeComFL, which leverages the zeroth-order optimization techniques and reduces the communication cost from $\mathcal{O}(d)$ to $\mathcal{O}(1)$ by transmitting only a constant number of scalar values between clients and the server in each round, regardless of the dimension $d$ of the model parameters.
Theoretically, in non-convex functions, we prove that our algorithm achieves state-of-the-art rates, which show a linear speedup of the number of clients and local steps under standard assumptions. With additional low effective rank assumption, we can further show that the convergence rate is independent of the model dimension $d$ as well.
Empirical evaluations, encompassing both classic deep learning training and large language model fine-tuning, demonstrate significant reductions in communication overhead. 
Notably, DeComFL achieves this by transmitting only around 1MB of data in total between the server and a client to fine-tune a model with billions of parameters. 
The code is available at https://github.com/ZidongLiu/DeComFL.
  abstract_embedding: [0.283203125, 0.43359375, 0.125]... (1536 items)
  authors: ['Zhe Li', 'Bicheng Ying', 'Zidong Liu']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805516246
  novelty: yes
  reason: Relevance: The paper proposes a novel dimension-free communication algorithm for federated learning, which reduces the communication cost from O(d) to O(1) by using zeroth-order optimization technique...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Achieving_Dimension-Free_Communication_in_Federated_Learning_via_Zeroth-Order_Optimization.pdf
  sha_abstract: 5ecd56638a7d57fc993d0d2bce6f664dd7917b67b630c7f120846ae99fcc9cd1
  title: Achieving Dimension-Free Communication in Federated Learning via Zeroth-Order Optimization
  title_normalized: achieving_dimensionfree_communication_in_federated_learning_via_zerothorder_optimization

================================================================================
Document #190 (ID: 0e02685f50d3a966bee5e4cc8dcc40fec9b7ef943eb2fc9a10837d219769253b)
================================================================================
  abstract: Recent work has shown that diffusion models memorize and reproduce training data examples. At the same time, large copyright lawsuits and legislation such as GDPR have highlighted the need for erasing datapoints from diffusion models. However, retraining from scratch is often too expensive. This motivates the setting of data unlearning, i.e., the study of efficient techniques for unlearning specific datapoints from the training set. Existing concept unlearning techniques require an anchor prompt/class/distribution to guide unlearning, which is not available in the data unlearning setting. General-purpose machine unlearning techniques were found to be either unstable or failed to unlearn data. We therefore propose a family of new loss functions called Subtracted Importance Sampled Scores (SISS) that utilize importance sampling and are the first method to unlearn data with theoretical guarantees. SISS is constructed as a weighted combination between simpler objectives that are responsible for preserving model quality and unlearning the targeted datapoints. When evaluated on CelebA-HQ and MNIST, SISS achieved Pareto optimality along the quality and unlearning strength dimensions. On Stable Diffusion, SISS successfully mitigated memorization on nearly 90% of the prompts we tested. We release our code online.
  abstract_embedding: [0.5625, 0.451171875, 0.33984375]... (1536 items)
  authors: ['Silas Alberti', 'Kenan Hasanaliyev', 'Manav Shah']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805508066
  novelty: yes
  reason: Relevance: The paper proposes a new loss function called Subtracted Importance Sampled Scores (SISS) that enables efficient data unlearning in diffusion models, which is a novel and valuable technique...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Data_Unlearning_in_Diffusion_Models.pdf
  sha_abstract: f9809c3aa8412392e95ce3b1d7f9c31a490e00be541cbe489bbfc9e7a0c44abe
  title: Data Unlearning in Diffusion Models
  title_normalized: data_unlearning_in_diffusion_models

================================================================================
Document #191 (ID: e3d23df2190e7a8b5fb4fa84d064eca01355a0a0568d2aea3f680047b07d3afb)
================================================================================
  abstract: We propose a zero-shot method for generating images in arbitrary spaces (e.g., a sphere for 360◦ panoramas and a mesh surface for texture) using a pretrained image diffusion model. The zero-shot generation of various visual content using a pretrained image diffusion model has been explored mainly in two directions. First, Diffusion Synchronization–performing reverse diffusion processes jointly across different projected spaces while synchronizing them in the target space–generates high-quality outputs when enough conditioning is provided, but it struggles in its absence. Second, Score Distillation Sampling–gradually updating the target space data through gradient descent–results in better coherence but often lacks detail. In this paper, we reveal for the first time the interconnection between these two methods while highlighting their differences. To this end, we propose StochSync, a novel approach that combines the strengths of both, enabling effective performance with weak conditioning. Our experiments demonstrate that StochSync provides the best performance in 360◦ panorama generation (where image conditioning is not given), outperforming previous finetuning-based methods, and also delivers comparable results in 3D mesh texturing (where depth conditioning is provided) with previous methods.
  abstract_embedding: [0.1611328125, 0.6171875, 0.33984375]... (1536 items)
  authors: ['Kyeongmin Yeo', 'Jaihoon Kim', 'Minhyuk Sung']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805501239
  novelty: yes
  reason: Relevance: The paper proposes a novel method, StochSync, for generating images in arbitrary spaces using a pretrained diffusion model, which is an innovative approach to image generation. | Novelty: T...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: StochSync__Stochastic_Diffusion_Synchronization_for_Image_Generation_in_Arbitrary_Spaces.pdf
  sha_abstract: f7c538d27a0658b43507adc170d31e1f3acf1466e49103e6c84c570b4b9faf96
  title: StochSync: Stochastic Diffusion Synchronization for Image Generation in Arbitrary Spaces
  title_normalized: stochsync_stochastic_diffusion_synchronization_for_image_generation_in_arbitrary_spaces

================================================================================
Document #192 (ID: 2037b881e02953705b6333b36d3a4ef24003cde1266a9cb76cfa7bdbe27cf35b)
================================================================================
  abstract: Speculative decoding is an  effective method for lossless acceleration of large language models during inference. It uses a fast model to draft a block of tokens which are then verified in parallel by the target model, and provides a guarantee that the output is distributed identically to a sample from the target model. In prior works, draft verification is performed independently token-by-token. Surprisingly, we show that this approach is not optimal. We propose *Block Verification*, a simple draft verification algorithm that verifies the entire block jointly and provides additional wall-clock speedup. We prove that the proposed mechanism is optimal in the expected number of tokens produced each iteration and specifically is never worse than the standard token-level verification.
Empirically, block verification provides modest but consistent wall-clock speedups over the standard token verification algorithm of 5\%-8\% in a range of tasks and datasets.
Given that block verification does not increase code complexity, maintains the strong lossless guarantee of the standard speculative decoding verification algorithm, cannot deteriorate performance, and, in fact, consistently improves it, it can be used as a good default in speculative decoding implementations.
  abstract_embedding: [0.047119140625, 0.1953125, 0.349609375]... (1536 items)
  authors: ['Ziteng Sun', 'Uri Mendlovic', 'Yaniv Leviathan']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805499423
  novelty: yes
  reason: Relevance: The paper proposes a new block-level verification algorithm for speculative decoding, which is an efficient technique for accelerating large language models during inference. | Novelty: The...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Block_Verification_Accelerates_Speculative_Decoding.pdf
  sha_abstract: 91da32b6687ab1b3809bc6ccf7133a40e7f3a84338175e3a36b8afa5e0872f2d
  title: Block Verification Accelerates Speculative Decoding
  title_normalized: block_verification_accelerates_speculative_decoding

================================================================================
Document #193 (ID: 856a97587b3b2036f7c89d303ba4b2964d954317777b53da51d45a03b95802b8)
================================================================================
  abstract: Humans perceive the world through multisensory integration, blending the information of different modalities to adapt their behavior.
Contrastive learning offers an appealing solution for multimodal self-supervised learning. Indeed, by considering each modality as a different view of the same entity, it learns to align features of different modalities in a shared representation space. However, this approach is intrinsically limited as it only learns shared or redundant information between modalities, while multimodal interactions can arise in other ways. In this work, we introduce CoMM, a Contrastive Multimodal learning strategy that enables the communication between modalities in a single multimodal space. Instead of imposing cross- or intra- modality constraints, we propose to align multimodal representations by maximizing the mutual information between augmented versions of these multimodal features. Our theoretical analysis shows that shared, synergistic and unique terms of information naturally emerge from this formulation, allowing us to estimate multimodal interactions beyond redundancy. We test CoMM both in a controlled and in a series of real-world settings: in the former, we demonstrate that CoMM effectively captures redundant, unique and synergistic information between modalities. In the latter, CoMM learns complex multimodal interactions and achieves state-of-the-art results on seven multimodal tasks.
  abstract_embedding: [0.251953125, 0.1337890625, -0.036376953125]... (1536 items)
  authors: ['Benoit Dufumier', 'Javiera Castillo Navarro', 'Devis Tuia']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805512697
  novelty: yes
  reason: Relevance: The paper proposes a novel multimodal contrastive learning strategy (CoMM) that goes beyond learning shared or redundant information between modalities, and instead aims to capture synergis...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: What_to_align_in_multimodal_contrastive_learning_.pdf
  sha_abstract: 9260b21820536539f7c5ade5487265521cc459aa19474a39ab5411fac389203e
  title: What to align in multimodal contrastive learning?
  title_normalized: what_to_align_in_multimodal_contrastive_learning

================================================================================
Document #194 (ID: 3561798277b881f826987695fb9351ff61cabc180a7ba484ffa5c68ed88253aa)
================================================================================
  abstract: The probabilistic forecasting of time series is a well-recognized challenge, particularly in disentangling correlations among interacting time series and addressing the complexities of distribution modeling. By treating time series as temporal dynamics, we introduce **KooNPro**, a novel probabilistic time series forecasting model that combines variance-aware deep **Koo**pman model with **N**eural **Pro**cess. KooNPro introduces a variance-aware continuous spectrum using Gaussian distributions to capture complex temporal dynamics with improved stability. It further integrates the Neural Process to capture fine dynamics, enabling enhanced dynamics capture and prediction. Extensive experiments on nine real-world datasets demonstrate that KooNPro consistently outperforms state-of-the-art baselines. Ablation studies highlight the importance of the Neural Process component and explore the impact of key hyperparameters. Overall, KooNPro presents a promising novel approach for probabilistic time series forecasting.
  abstract_embedding: [0.34375, 0.37890625, 0.47265625]... (1536 items)
  authors: ['Ronghua Zheng', 'Hanru Bai', 'Weiyang Ding']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805491001
  novelty: yes
  reason: Relevance: The paper proposes a novel probabilistic time series forecasting model that combines a variance-aware Koopman model with a Neural Process, which is relevant for innovative model architectur...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: KooNPro__A_Variance-Aware_Koopman_Probabilistic_Model_Enhanced_by_Neural_Process_for_Time_Series_Forecasting.pdf
  sha_abstract: 6e802cc2960fb4d74f3fbe13aa1cebaefab5b705385d4e2fc95233b0c8755f1d
  title: KooNPro: A Variance-Aware Koopman Probabilistic Model Enhanced by Neural Process for Time Series Forecasting
  title_normalized: koonpro_a_varianceaware_koopman_probabilistic_model_enhanced_by_neural_process_for_time_series_forecasting

================================================================================
Document #195 (ID: 8ad96aead9806ae28db8ffba6c6a6159d58da20f1b2fe3e61f5ea05fc5242b0c)
================================================================================
  abstract: Score-based generative models, commonly referred to as diffusion models, have proven to be successful at generating text and image data.
However, their adaptation to mixed-type tabular data remains underexplored. In this work, we propose CDTD, a Continuous Diffusion model for mixed-type Tabular Data. CDTD is based on a novel combination of score matching and score interpolation to enforce a unified continuous noise distribution for both continuous and categorical features. We explicitly acknowledge the necessity of homogenizing distinct data types by relying on model-specific loss calibration and initialization schemes. To further address the high heterogeneity in mixed-type tabular data, we introduce adaptive feature- or type-specific noise schedules. These ensure balanced generative performance across features and optimize the allocation of model capacity across features and diffusion time. Our experimental results show that CDTD consistently outperforms state-of-the-art benchmark models, captures feature correlations exceptionally well, and that heterogeneity in the noise schedule design boosts sample quality. Replication code is available at https://github.com/muellermarkus/cdtd.
  abstract_embedding: [0.6171875, 0.32421875, 0.26953125]... (1536 items)
  authors: ['Markus Mueller', 'Kathrin Gruber', 'Dennis Fok']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805504255
  novelty: yes
  reason: Relevance: The paper proposes a novel continuous diffusion model for mixed-type tabular data, which is an innovative new model architecture. | Novelty: The paper introduces a novel combination of scor...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Continuous_Diffusion_for_Mixed-Type_Tabular_Data.pdf
  sha_abstract: 4db597badf4758697e68063700df241906fa9430ddb187897de58052bb25c906
  title: Continuous Diffusion for Mixed-Type Tabular Data
  title_normalized: continuous_diffusion_for_mixedtype_tabular_data

================================================================================
Document #196 (ID: 72acb4fe6b58bb1328bdb2dc0e937826519d8c8616a97b6a94163537c6cddf0a)
================================================================================
  abstract: We introduce MIM (Masked Image Modeling)-Refiner, a contrastive learning boost for pre-trained MIM models. MIM-Refiner is motivated by the insight that strong representations within MIM models generally reside in intermediate layers. Accordingly, MIM-Refiner leverages multiple instance discrimination (ID) heads that are connected to different intermediate layers. In each head, a nearest neighbor ID objective constructs clusters that capture semantic information which improves performance on downstream tasks, including off-the-shelf and fine-tuning settings.

The refinement process is short and simple -  yet highly effective. Within a few epochs, we refine the features of MIM models from subpar to state-of-the-art, off-the-shelf features. Refining a ViT-H, pre-trained with data2vec 2.0 on ImageNet-1K, sets a new state-of-the-art in linear probing (84.7\%) and low-shot classification among models that are pre-trained on ImageNet-1K. MIM-Refiner efficiently combines the advantages of MIM and ID objectives, enabling scaling ID objectives to billion parameter models using relatively little compute. MIM-Refiner compares favorably against previous state-of-the-art SSL models on various benchmarks such as low-shot classification, long-tailed classification and semantic segmentation.
  abstract_embedding: [0.177734375, 0.220703125, 0.1962890625]... (1536 items)
  authors: ['Benedikt Alkin', 'Lukas Miklautz', 'Sepp Hochreiter']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805518881
  novelty: yes
  reason: Relevance: The paper proposes a novel contrastive learning technique called MIM-Refiner that leverages intermediate representations from pre-trained Masked Image Modeling (MIM) models to improve downs...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MIM-Refiner__A_Contrastive_Learning_Boost_from_Intermediate_Pre-Trained_Masked_Image_Modeling_Representations.pdf
  sha_abstract: 7cffba24cf69355737442a34df58a267d05cbc74450398eef7cef01e3b3ada07
  title: MIM-Refiner: A Contrastive Learning Boost from Intermediate Pre-Trained Masked Image Modeling Representations
  title_normalized: mimrefiner_a_contrastive_learning_boost_from_intermediate_pretrained_masked_image_modeling_representations

================================================================================
Document #197 (ID: 83769b135b9d027eff4bcc24d9fa6a34d34e821b8a4b6525de323eaa54bea5c0)
================================================================================
  abstract: Distance field-based implicit representations like signed/unsigned distance fields have recently gained prominence in geometry modeling and analysis. However, these distance fields are reliant on the closest distance of points to the surface, introducing inaccuracies when interpolating along cube edges during surface extraction. Additionally, their gradients are ill-defined at certain locations, causing distortions in the extracted surfaces. To address this limitation, we propose Shape as Line Segments (SALS), an accurate and efficient implicit geometry representation based on attributed line segments, which can handle arbitrary structures. Unlike previous approaches, SALS leverages a differentiable Line Segment Field to implicitly capture the spatial relationship between line segments and the surface. Each line segment is associated with two key attributes, intersection flag and ratio, from which we propose edge-based dual contouring to extract a surface. We further implement SALS with a neural network, producing a new neural implicit presentation. Additionally, based on SALS, we design a novel learning-based pipeline for reconstructing surfaces from 3D point clouds. We conduct extensive experiments, showcasing the significant advantages of our methods over state-of-the-art methods.
The source code is available at https://github.com/rsy6318/SALS.
  abstract_embedding: [0.4921875, -0.042236328125, 0.10107421875]... (1536 items)
  authors: ['Siyu Ren', 'Junhui Hou']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805520805
  novelty: yes
  reason: Relevance: The paper proposes a novel implicit surface representation based on line segments, which can improve the accuracy and flexibility of surface extraction compared to distance field-based meth...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Shape_as_Line_Segments__Accurate_and_Flexible_Implicit_Surface_Representation.pdf
  sha_abstract: 9a4d25b99793909cbf6da3232d9b90acafb93e18596e93460fc691900fec5150
  title: Shape as Line Segments: Accurate and Flexible Implicit Surface Representation
  title_normalized: shape_as_line_segments_accurate_and_flexible_implicit_surface_representation

================================================================================
Document #198 (ID: 7cfda9a391d386ccc02024ad400d7de320dfa9b4ba9c373f03fa6a6cd4987847)
================================================================================
  abstract: Generative models in drug discovery have recently gained attention as efficient alternatives to brute-force virtual screening. However, most existing models do not account for synthesizability, limiting their practical use in real-world scenarios. In this paper, we propose RxnFlow, which sequentially assembles molecules using predefined molecular building blocks and chemical reaction templates to constrain the synthetic chemical pathway. We then train on this sequential generating process with the objective of generative flow networks (GFlowNets) to generate both highly rewarded and diverse molecules. To mitigate the large action space of synthetic pathways in GFlowNets, we implement a novel action space subsampling method. This enables RxnFlow to learn generative flows over extensive action spaces comprising combinations of 1.2 million building blocks and 71 reaction templates without significant computational overhead. Additionally, RxnFlow can employ modified or expanded action spaces for generation without retraining, allowing for the introduction of additional objectives or the incorporation of newly discovered building blocks. We experimentally demonstrate that RxnFlow outperforms existing reaction-based and fragment-based models in pocket-specific optimization across various target pockets. Furthermore, RxnFlow achieves state-of-the-art performance on CrossDocked2020 for pocket-conditional generation, with an average Vina score of –8.85 kcal/mol and 34.8% synthesizability. Code is available at https://github.com/SeonghwanSeo/RxnFlow.
  abstract_embedding: [0.60546875, 0.12060546875, 0.16015625]... (1536 items)
  authors: ['Seonghwan Seo', 'Minsu Kim', 'Tony Shen']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805524138
  novelty: yes
  reason: Relevance: The paper proposes a novel generative model, RxnFlow, that incorporates chemical reaction templates and building blocks to generate synthesizable drug molecules, which is relevant for drug ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Generative_Flows_on_Synthetic_Pathway_for_Drug_Design.pdf
  sha_abstract: 4d87622f2bfb39e27b3232c1e8f88a21dddcc3d2732d249f44c44f5d955ba90f
  title: Generative Flows on Synthetic Pathway for Drug Design
  title_normalized: generative_flows_on_synthetic_pathway_for_drug_design

================================================================================
Document #199 (ID: caaba49566752a61df60a45aa08436e22606e817d9c98f5fe368890d2e5d1bcf)
================================================================================
  abstract: Text-conditioned human motion generation, which allows for user interaction through natural language, has become increasingly popular. Existing methods typically generate short, isolated motions based on a single input sentence. However, human motions are continuous and can extend over long periods, carrying rich semantics. Creating long, complex motions that precisely respond to streams of text descriptions, particularly in an online and real-time setting, remains a significant challenge. Furthermore, incorporating spatial constraints into text-conditioned motion generation presents additional challenges, as it requires aligning the motion semantics specified by text descriptions with geometric information, such as goal locations and 3D scene geometry. To address these limitations, we propose **DartC**ontrol, in short **DART**, a **D**iffusion-based **A**utoregressive motion primitive model for **R**eal-time **T**ext-driven motion **C**ontrol. Our model, DART, effectively learns a compact motion primitive space jointly conditioned on motion history and text inputs using latent diffusion models. By autoregressively generating motion primitives based on the preceding history and current text input, DART enables real-time, sequential motion generation driven by natural language descriptions. Additionally,  the learned motion primitive space allows for precise spatial motion control, which we formulate either as a latent noise optimization problem or as a Markov decision process addressed through reinforcement learning. We present effective algorithms for both approaches, demonstrating our model’s versatility and superior performance in various motion synthesis tasks. Experiments show our method outperforms existing baselines in motion realism, efficiency, and controllability. Video results and code are available at https://zkf1997.github.io/DART/.
  abstract_embedding: [0.3203125, 0.41015625, 0.279296875]... (1536 items)
  authors: ['Kaifeng Zhao', 'Gen Li', 'Siyu Tang']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804599597
  novelty: yes
  reason: Relevance: The paper proposes a novel diffusion-based autoregressive motion model for real-time text-driven motion control, which is an innovative new model architecture. | Novelty: The proposed DART ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: DartControl__A_Diffusion-Based_Autoregressive_Motion_Model_for_Real-Time_Text-Driven_Motion_Control.pdf
  sha_abstract: c5cff511537f9ff25f26e8617c6df3710ba8fe868246632636d9a345b69d63be
  slack_thread_ts: 1764808437.156999
  title: DartControl: A Diffusion-Based Autoregressive Motion Model for Real-Time Text-Driven Motion Control
  title_normalized: dartcontrol_a_diffusionbased_autoregressive_motion_model_for_realtime_textdriven_motion_control

================================================================================
Document #200 (ID: f94d0e8e9546a1353ebe419f923e877bf8560585ade728fe2fadbfd1e9d9c226)
================================================================================
  abstract: Modern language models have demonstrated remarkable reasoning capabilities by using chain-of-thought (CoT). One hypothesis about the inner workings of CoT is that it breaks down originally complex tasks into smaller subtasks that are more amenable to learning. We formalize this notion by showing possibility and impossibility results of learning from in-context demonstrations with and without CoT. In particular, with CoT, we examine a family of learning algorithms that learn a task step-by-step, capable of composing simpler functions from individual reasoning steps to form an overall complex function. This process reduces the difficulty of learning a task to that of the hardest reasoning step in the chain. Moreover, we prove Transformers can express this algorithm and thus they can efficiently in-context learn arbitrary tasks as long as these tasks can be decomposed into a finite number of subtasks, each of which are efficiently learnable. In contrast, without CoT, we demonstrate that there exist tasks that are inherently unlearnable by the same algorithm. Overall, our results suggest several provably effective ways for decomposing target problems to instantiate CoT. Empirically, we demonstrate our proposed CoT construction significantly enhances the reasoning capabilities of real-world LLMs in solving challenging arithmetic reasoning tasks, including learning polynomials and Boolean formulas.
  abstract_embedding: [0.5703125, -0.150390625, 0.224609375]... (1536 items)
  authors: ['Chenxiao Yang', 'Zhiyuan Li', 'David Wipf']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  execution_completed_at: 2025-12-04T00:40:43.516467
  execution_return_code: 1
  execution_success: False
  execution_time_seconds: 19.03
  ingested_at: 1764804601917
  novelty: yes
  reason: Relevance: The paper proposes a novel chain-of-thought (CoT) training algorithm that can learn complex tasks by decomposing them into simpler subtasks, which is highly relevant for building efficient ...
  relevance: yes
  results_s3_location: s3://trainium-execution-results/results/f94d0e8e9546a1353ebe419f923e877bf8560585ade728fe2fadbfd1e9d9c226/execution_result.json
  s3_bucket: llm-research-papers
  s3_key: Chain-of-Thought_Provably_Enables_Learning_the__Otherwise__Unlearnable.pdf
  sha_abstract: bfd8f4faa8a534eac651d564ba4e8c06e23f674cc628d719487541d41f4e6e89
  slack_thread_ts: 1764808437.159059
  title: Chain-of-Thought Provably Enables Learning the (Otherwise) Unlearnable
  title_normalized: chainofthought_provably_enables_learning_the_otherwise_unlearnable

================================================================================
Document #201 (ID: f20540916c8bf3353e6bc0d5738a21b96f242e27d86281950a6bc00839d1bb0e)
================================================================================
  abstract: SMILES, a crucial textual representation of molecular structures, has garnered significant attention as a foundation for pre-trained language models (LMs). However, most existing pre-trained SMILES LMs focus solely on the single-token level supervision during pre-training, failing to fully leverage the substructural information of molecules. This limitation makes the pre-training task overly simplistic, preventing the models from capturing richer molecular semantic information. Moreover, during pre-training, these SMILES LMs only process corrupted SMILES inputs, never encountering any valid SMILES, which leads to a train-inference mismatch. To address these challenges, we propose SMI-Editor, a novel edit-based pre-trained SMILES LM. SMI-Editor disrupts substructures within a molecule at random and feeds the resulting SMILES back into the model, which then attempts to restore the original SMILES through an editing process. This approach not only introduces fragment-level training signals, but also enables the use of valid SMILES as inputs, allowing the model to learn how to reconstruct complete molecules from these incomplete structures. As a result, the model demonstrates improved scalability and an enhanced ability to capture fragment-level molecular information. Experimental results show that SMI-Editor achieves state-of-the-art performance across multiple downstream molecular tasks, and even outperforming several 3D molecular representation models.
  abstract_embedding: [0.353515625, 0.609375, -0.0059814453125]... (1536 items)
  authors: ['Kangjie Zheng', 'Siyue Liang', 'Junwei Yang']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805102394
  novelty: yes
  reason: Relevance: The paper proposes a novel edit-based pre-training approach for SMILES language models, which introduces fragment-level training signals and enables the use of valid SMILES as inputs, leadi...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SMI-Editor__Edit-based_SMILES_Language_Model_with_Fragment-level_Supervision.pdf
  sha_abstract: ca34e6297c107f89070f58f3b10d197f0c90ab0d5bd33c77e887200ce5418862
  title: SMI-Editor: Edit-based SMILES Language Model with Fragment-level Supervision
  title_normalized: smieditor_editbased_smiles_language_model_with_fragmentlevel_supervision

================================================================================
Document #202 (ID: 5e86322beaf143c96373245385b2c145a1c922e39608d9265e166ad0b55ce196)
================================================================================
  abstract: Building a generalist model for user interface (UI) understanding is challenging due to various foundational issues, such as platform diversity, resolution variation, and data limitation. In this paper, we introduce Ferret-UI 2, a multimodal large language model (MLLM) designed for universal UI understanding across a wide range of platforms, including iPhone, Android, iPad, Webpage, and AppleTV. Building on the foundation of Ferret-UI, Ferret-UI 2 introduces three key innovations: support for multiple platform types, high-resolution perception through adaptive scaling, and advanced task training data generation powered by GPT-4o with set-of-mark visual prompting. These advancements enable Ferret-UI 2 to perform complex, user-centered interactions, making it highly versatile and adaptable for the expanding diversity of platform ecosystems. Extensive empirical experiments on referring, grounding, user-centric advanced tasks (comprising 9 subtasks $\times$ 5 platforms), GUIDE next-action prediction dataset, and GUI-World multi-platform benchmark demonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and also shows strong cross-platform transfer capabilities.
  abstract_embedding: [0.435546875, -0.28125, 0.248046875]... (1536 items)
  authors: ['Zhangheng LI', 'Keen You', 'Haotian Zhang']... (10 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805115967
  novelty: yes
  reason: Relevance: The paper proposes a novel multimodal large language model (MLLM) architecture, Ferret-UI 2, for universal user interface (UI) understanding across multiple platforms, which is highly relev...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Ferret-UI_2__Mastering_Universal_User_Interface_Understanding_Across_Platforms.pdf
  sha_abstract: 299b7c631468e259ac9d25a1c4ebf507be57b7ee478c611d0a2597b588f6c4c8
  title: Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms
  title_normalized: ferretui_2_mastering_universal_user_interface_understanding_across_platforms

================================================================================
Document #203 (ID: 361da2235308c8818fad393b51eee47e7740389a7dbe02515a27fd04a8915f0c)
================================================================================
  abstract: Training Large Language Models (LLMs) presents a significant communication bottleneck, predominantly due to the growing scale of the gradient to communicate across multi-device clusters. However, how to mitigate communication overhead in practice remains a formidable challenge due to the weakness of the methodology of the existing compression methods, especially the neglect of the characteristics of the gradient. In this paper, we consider and demonstrate the low-rank properties of gradient and Hessian observed in LLMs training dynamic, and take advantage of such natural properties to design SEPARATE, a simple low-rank projection for gradient compression in modern large-scale model training processes. SEPARATE realizes dimensional reduction by common random Gaussian variables and an improved moving average error-feedback technique. We theoretically demonstrate that SEPARATE-based optimizers maintain the original convergence rate for SGD and Adam-Type optimizers for general non-convex objectives. Experimental results show that SEPARATE accelerates training speed by up to 2× for GPT-2-Medium pre-training, and improves performance on various benchmarks for LLAMA2-7B fine-tuning.
  abstract_embedding: [0.53515625, -0.021728515625, 0.46875]... (1536 items)
  authors: ['Hanzhen Zhao', 'Xingyu Xie', 'Cong Fang']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805104842
  novelty: yes
  reason: Relevance: The paper proposes a novel gradient compression technique called SEPARATE that leverages the low-rank properties of gradients and Hessians in large language models, which can improve traini...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: SEPARATE__A_Simple_Low-rank_Projection_for_Gradient_Compression_in_Modern_Large-scale_Model_Training_Process.pdf
  sha_abstract: 9c623cc84ba079ff04f49d648e40456fc65b7a9e8672541697d04b921b6fc25e
  title: SEPARATE: A Simple Low-rank Projection for Gradient Compression in Modern Large-scale Model Training Process
  title_normalized: separate_a_simple_lowrank_projection_for_gradient_compression_in_modern_largescale_model_training_process

================================================================================
Document #204 (ID: 1ec7bc725ab9ed71e38dd32d0509a5b8657f18cb6ed619683c939d8906eb31df)
================================================================================
  abstract: Modeling human-like action-to-reaction generation has significant real-world applications, like human-robot interaction and games.
Despite recent advancements in single-person motion generation, it is still challenging to well handle action-to-reaction generation, due to the difficulty of directly predicting reaction from action sequence without prompts, and the absence of a unified representation that effectively encodes multi-person motion.
To address these challenges, we introduce Think-Then-React (TTR), a large language-model-based framework designed to generate human-like reactions.
First, with our fine-grained multimodal training strategy, TTR is capable to unify two processes during inference: a thinking process that explicitly infers action intentions and reasons corresponding reaction description, which serve as semantic prompts, and a reacting process that predicts reactions based on input action and the inferred semantic prompts.
Second, to effectively represent multi-person motion in language models, we propose a unified motion tokenizer by decoupling egocentric pose and absolute space features, which effectively represents action and reaction motion with same encoding.
Extensive experiments demonstrate that TTR outperforms existing baselines, achieving significant improvements in evaluation metrics, such as reducing FID from 3.988 to 1.942.
  abstract_embedding: [0.373046875, 0.41796875, 0.51171875]... (1536 items)
  authors: ['Wenhui Tan', 'Boyuan Li', 'Chuhao Jin']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805095194
  novelty: yes
  reason: Relevance: The paper proposes a novel language-model-based framework for generating human-like reactions from action sequences, which is a relevant and innovative approach to motion generation. | Nove...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Think_Then_React__Towards_Unconstrained_Action-to-Reaction_Motion_Generation.pdf
  sha_abstract: 7577f40e4d5f3806a6a4ff20610283795fd76729ff41f27cd6cc460191bf054d
  title: Think Then React: Towards Unconstrained Action-to-Reaction Motion Generation
  title_normalized: think_then_react_towards_unconstrained_actiontoreaction_motion_generation

================================================================================
Document #205 (ID: 9ad32df4723703816a30c7c6995b646ed4779f0bbad499182e94a56758637d7d)
================================================================================
  abstract: Denoising diffusion bridge models (DDBMs) are a powerful variant of diffusion models for interpolating between two arbitrary paired distributions given as endpoints. Despite their promising performance in tasks like image translation, DDBMs require a computationally intensive sampling process that involves the simulation of a (stochastic) differential equation through hundreds of network evaluations. In this work, we take the first step in fast sampling of DDBMs without extra training, motivated by the well-established recipes in diffusion models. We generalize DDBMs via a class of non-Markovian diffusion bridges defined on the discretized timesteps concerning sampling, which share the same marginal distributions and training objectives, give rise to generative processes ranging from stochastic to deterministic, and result in diffusion bridge implicit models (DBIMs). DBIMs are not only up to 25$\times$ faster than the vanilla sampler of DDBMs but also induce a novel, simple, and insightful form of ordinary differential equation (ODE) which inspires high-order numerical solvers. Moreover, DBIMs maintain the generation diversity in a distinguished way, by using a booting noise in the initial sampling step, which enables faithful encoding, reconstruction, and semantic interpolation in image translation tasks. Code is available at \url{https://github.com/thu-ml/DiffusionBridge}.
  abstract_embedding: [0.1435546875, 0.6328125, 0.38671875]... (1536 items)
  authors: ['Kaiwen Zheng', 'Guande He', 'Jianfei Chen']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805098368
  novelty: yes
  reason: Relevance: The paper proposes a new diffusion bridge implicit model (DBIM) architecture and training algorithm that improves the efficiency of denoising diffusion bridge models (DDBMs) for image trans...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Diffusion_Bridge_Implicit_Models.pdf
  sha_abstract: 02ebb6c664597ebfb273f873b506b1c97b12ea6ef9940f138a945d4be57ee4ae
  title: Diffusion Bridge Implicit Models
  title_normalized: diffusion_bridge_implicit_models

================================================================================
Document #206 (ID: 1fd3618e3f671faba42501f795683f6529218e367d7d866199216fb307e81848)
================================================================================
  abstract: We tackle the problem of parameter-efficient fine-tuning (PEFT) of a pre-trained large deep model on many different but related tasks. Instead of the simple but strong baseline strategy of task-wise independent fine-tuning, we aim to meta-learn the core shared information that can be used for unseen test tasks to improve the prediction performance further. That is, we propose a method for {\em learning-to-fine-tune} (LiFT). LiFT introduces a novel hierarchical Bayesian model that can be superior to both existing general meta learning algorithms like MAML and recent LoRA zoo mixing approaches such as LoRA-Retriever and model-based clustering. In our Bayesian model, the parameters of the task-specific LoRA modules are regarded as random variables where these task-wise LoRA modules are governed/regularized by higher-level latent random variables, which represents the prior of the LoRA modules that capture the shared information across all training tasks. To make the posterior inference feasible, we propose a novel SGLD-Gibbs sampling algorithm that is computationally efficient. To represent the posterior samples from the SGLD-Gibbs, we propose an online EM algorithm that maintains a Gaussian mixture representation for the posterior in an online manner in the course of iterative posterior sampling. We demonstrate the effectiveness of LiFT on NLP and vision multi-task meta learning benchmarks.
  abstract_embedding: [0.02734375, 0.349609375, 0.3828125]... (1536 items)
  authors: ['Minyoung Kim', 'Timothy Hospedales']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805110995
  novelty: yes
  reason: Relevance: The paper proposes a novel hierarchical Bayesian model for parameter-efficient fine-tuning (PEFT) of pre-trained large models, which is relevant for improving efficiency and performance. | ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: LiFT__Learning_to_Fine-Tune_via_Bayesian_Parameter_Efficient_Meta_Fine-Tuning.pdf
  sha_abstract: acb24036a419b330039e747be336d223aa500add9cd4638723a38c45b0f9229a
  title: LiFT: Learning to Fine-Tune via Bayesian Parameter Efficient Meta Fine-Tuning
  title_normalized: lift_learning_to_finetune_via_bayesian_parameter_efficient_meta_finetuning

================================================================================
Document #207 (ID: 0bc54d1b71c3f848335c5daa772ad110149aa4239b0f4eb0c678e36ab46f0115)
================================================================================
  abstract: We study beyond worst-case dimensionality reduction for $s$-sparse vectors (vectors with at most $s$ non-zero coordinates). Our work is divided into two parts, each focusing on a different facet of beyond worst-case analysis:

\noindent (a)  We first consider average-case guarantees for embedding $s$-sparse vectors. Here, a well-known folklore upper bound based on the birthday-paradox states: For any collection $X$ of $s$-sparse vectors in $\mathbb{R}^d$, there exists a linear map $A: \mathbb{R}^d \rightarrow \mathbb{R}^{O(s^2)}$ which \emph{exactly} preserves the norm of $99\%$ of the vectors in $X$ in any $\ell_p$ norm (as opposed to the usual setting where guarantees hold for all vectors). We provide novel lower bounds showing that this is indeed optimal in many settings. Specifically, any oblivious linear map satisfying similar average-case guarantees must map to $\Omega(s^2)$ dimensions. The same lower bound also holds for a wider class of sufficiently smooth maps, including `encoder-decoder schemes', where we compare the norm of the original vector to that of a smooth function of the embedding. These lower bounds reveal a surprising separation result for smooth embeddings of sparse vectors, as an upper bound of $O(s \log(d))$ is possible if we instead use arbitrary functions, e.g., via compressed sensing algorithms.


 (b) Given these lower bounds, we specialize to sparse \emph{non-negative} vectors to hopes of improved upper bounds. For a dataset $X$ of non-negative $s$-sparse vectors and any $p \ge 1$, we can non-linearly embed $X$ to $O(s\log(|X|s)/\varepsilon^2)$ dimensions while preserving all pairwise distances in $\ell_p$ norm up to $1\pm \varepsilon$, with no dependence on $p$. Surprisingly, the non-negativity assumption enables much smaller embeddings than arbitrary sparse vectors, where the best known bound suffers an exponential $(\log |X|)^{O(p)}$ dependence. Our map also guarantees \emph{exact} dimensionality reduction for the $\ell_{\infty}$ norm by embedding $X$ into $O(s\log |X|)$ dimensions, which is tight. We further give separation results showing that both the non-linearity of $f$ and the non-negativity of $X$ are necessary, and provide downstream algorithmic improvements using our embedding.
  abstract_embedding: [0.17369219660758972, 0.17889337241649628, 0.41720280051231384]... (1536 items)
  authors: ['Sandeep Silwal', 'David Woodruff', 'Qiuyi Zhang']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805129085
  novelty: yes
  reason: Relevance: The paper proposes novel dimensionality reduction techniques for sparse vectors, including average-case guarantees and non-linear embeddings for non-negative sparse vectors, which could be ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Beyond_Worst-Case_Dimensionality_Reduction_for_Sparse_Vectors.pdf
  sha_abstract: c617cdcdeff48204b886058fea7e8094a035f52e752bf42f1afbd9d0096f2cba
  title: Beyond Worst-Case Dimensionality Reduction for Sparse Vectors
  title_normalized: beyond_worstcase_dimensionality_reduction_for_sparse_vectors

================================================================================
Document #208 (ID: 128122deb3728ec24511d52b14f74812e744a3820d3646e1de2b1ffd049d8300)
================================================================================
  abstract: Recently, Multimodal Large Language Models (MLLMs) have been used as agents to control keyboard and mouse inputs by directly perceiving the Graphical User Interface (GUI) and generating corresponding commands.
However, current agents primarily demonstrate strong understanding capabilities in static environments and are mainly applied to relatively simple domains, such as Web or mobile interfaces.
We argue that a robust GUI agent should be capable of perceiving temporal information on the GUI, including dynamic Web content and multi-step tasks.
Additionally, it should possess a comprehensive understanding of various GUI scenarios, including desktop software and multi-window interactions.
To this end, this paper introduces a new dataset, termed GUI-World, which features meticulously crafted Human-MLLM annotations, extensively covering six GUI scenarios and eight types of GUI-oriented questions in three formats.
We evaluate the capabilities of current state-of-the-art MLLMs, including Image LLMs and Video LLMs, in understanding various types of GUI content, especially dynamic and sequential content. Our findings reveal that current models struggle with dynamic GUI content without manually annotated keyframes or operation history. On the other hand, Video LLMs fall short in all GUI-oriented tasks given the sparse GUI video dataset. Therefore, we take the initial step of leveraging a fine-tuned Video LLM, GUI-Vid, as a GUI-oriented assistant, demonstrating an improved understanding of various GUI tasks. However, due to the limitations in the performance of base LLMs, we conclude that using video LLMs as GUI agents remains a significant challenge. We believe our work provides valuable insights for future research in dynamic GUI content understanding. All the dataset and code are publicly available at: https://gui-world.github.io.
  abstract_embedding: [0.251953125, -0.1640625, 0.322265625]... (1536 items)
  authors: ['Dongping Chen', 'Yue Huang', 'Siyuan Wu']... (20 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805131852
  novelty: yes
  reason: Relevance: The paper proposes a new benchmark dataset and evaluation of multimodal large language models for understanding dynamic graphical user interfaces, which is a relevant and important task for...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: GUI-World__A_Video_Benchmark_and_Dataset_for_Multimodal_GUI-oriented_Understanding.pdf
  sha_abstract: 4953ea8f30417e55cd0167435f84da452b1dd385042dba0ee5808eefe7abcd00
  title: GUI-World: A Video Benchmark and Dataset for Multimodal GUI-oriented Understanding
  title_normalized: guiworld_a_video_benchmark_and_dataset_for_multimodal_guioriented_understanding

================================================================================
Document #209 (ID: 29512d27286c3c169d967cf6ef57850f436fc9ef1fb763431e7c779703dcab9e)
================================================================================
  abstract: Model extraction aims to acquire a pre-trained black-box model concealed behind a black-box API. 
Existing defense strategies against model extraction primarily concentrate on preventing the unauthorized extraction of API functionality. However, two significant challenges still need to be solved: (i) Neural network architecture of the API constitutes a form of intellectual property that also requires protection; (ii) The current practice of allocating the same network architecture to both attack and benign queries results in substantial resource wastage. To address these challenges, we propose a novel \textit{Dynamic Neural Fortresses} (DNF) defense method, employing a dynamic Early-Exit neural network, deviating from the conventional fixed architecture. Firstly, we facilitate the random exit of attack queries from the network at earlier layers. This strategic exit point selection significantly reduces the computational cost for attack queries. Furthermore, the random exit of attack queries from earlier layers introduces increased uncertainty for attackers attempting to discern the exact architecture, thereby enhancing architectural protection. On the contrary, we aim to facilitate benign queries to exit at later layers, preserving model utility, as these layers typically yield meaningful information. 
Extensive experiments on defending against various model extraction scenarios and datasets demonstrate the effectiveness of DNF, achieving a notable 2$\times$ improvement in efficiency and an impressive reduction of up to 12\% in clone model accuracy compared to SOTA defense methods. Additionally, DNF provides strong protection against neural architecture theft, effectively safeguarding network architecture from being stolen.
  abstract_embedding: [0.47265625, 0.5859375, 0.75390625]... (1536 items)
  authors: ['Siyu Luan', 'Zhenyi Wang', 'Li Shen']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805133869
  novelty: yes
  reason: Relevance: The paper proposes a novel dynamic neural network architecture, called Dynamic Neural Fortresses (DNF), to defend against model extraction attacks by strategically controlling the exit poin...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Dynamic_Neural_Fortresses__An_Adaptive_Shield_for_Model_Extraction_Defense.pdf
  sha_abstract: 416ecf6c671a790ff7c092459402c3c4e821c7fefed3c6ee4f7bfaddea6227b2
  title: Dynamic Neural Fortresses: An Adaptive Shield for Model Extraction Defense
  title_normalized: dynamic_neural_fortresses_an_adaptive_shield_for_model_extraction_defense

================================================================================
Document #210 (ID: f344d8422a7eb5537007422cbeed6264a565f8feac9b6d01225bba59a57ea51a)
================================================================================
  abstract: Synthetic tabular data generation has traditionally been a challenging problem due to the high complexity of the underlying distributions that characterise this type of data. Despite recent advances in deep generative models (DGMs), existing methods often fail to produce realistic datapoints that are well-aligned with available background knowledge.
In this paper, we address this limitation by introducing Disjunctive Refinement Layer (DRL), a novel layer designed
to enforce the alignment of generated data with the background knowledge specified in user-defined constraints.
DRL is the first method able to automatically make deep learning models inherently compliant with constraints as expressive as quantifier-free linear formulas, which can define non-convex and even disconnected spaces. 
Our experimental analysis shows that DRL not only guarantees constraint satisfaction but also improves efficacy in downstream tasks. Notably, when applied to DGMs that frequently violate constraints, DRL eliminates violations entirely. Further, it improves performance metrics by up to 21.4\% in F1-score and 20.9\% in Area Under the ROC Curve, thus demonstrating its practical impact on data generation.
  abstract_embedding: [0.482421875, 0.357421875, 0.43359375]... (1536 items)
  authors: ['Mihaela C. Stoian', 'Eleonora Giunchiglia']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805120520
  novelty: yes
  reason: Relevance: The paper proposes a novel layer (DRL) that can enforce linear constraints on deep generative models, which is a relevant technique for improving the realism and usefulness of synthetic tab...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Beyond_the_convexity_assumption__Realistic_tabular_data_generation_under_quantifier-free_real_linear_constraints.pdf
  sha_abstract: 64eb50c4397f2cfe23988f6391cf3e3f402480a39d0cd71ee985df2c6787ff58
  title: Beyond the convexity assumption: Realistic tabular data generation under quantifier-free real linear constraints
  title_normalized: beyond_the_convexity_assumption_realistic_tabular_data_generation_under_quantifierfree_real_linear_constraints

================================================================================
Document #211 (ID: 758b009c654906702a21a84f572880bbd69bd62a61ba7f6dc08ca9f59ae396e3)
================================================================================
  abstract: We present Perm, a learned parametric representation of human 3D hair designed to facilitate various hair-related applications. Unlike previous work that jointly models the global hair structure and local curl patterns, we propose to disentangle them using a PCA-based strand representation in the frequency domain, thereby allowing more precise editing and output control. Specifically, we leverage our strand representation to fit and decompose hair geometry textures into low- to high-frequency hair structures, termed guide textures and residual textures, respectively. These decomposed textures are later parameterized with different generative models, emulating common stages in the hair grooming process. We conduct extensive experiments to validate the architecture design of Perm, and finally deploy the trained model as a generic prior to solve task-agnostic problems, further showcasing its flexibility and superiority in tasks such as single-view hair reconstruction, hairstyle editing, and hair-conditioned image generation. More details can be found on our project page: https://cs.yale.edu/homes/che/projects/perm/.
  abstract_embedding: [-0.2216796875, 0.396484375, -0.11962890625]... (1536 items)
  authors: ['Chengan He', 'Xin Sun', 'Zhixin Shu']... (11 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805126643
  novelty: yes
  reason: Relevance: The paper proposes a novel parametric representation for 3D hair modeling, which can enable innovative applications like hair reconstruction, editing, and generation. | Novelty: The propose...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Perm__A_Parametric_Representation_for_Multi-Style_3D_Hair_Modeling.pdf
  sha_abstract: 0cdc1ebf940c6aaad554454dd8e3a9d2d1d50dfa31410b3d3fad4abb2de5bfce
  title: Perm: A Parametric Representation for Multi-Style 3D Hair Modeling
  title_normalized: perm_a_parametric_representation_for_multistyle_3d_hair_modeling

================================================================================
Document #212 (ID: 8db72f47096b5d294fb92935366d0d18649047a6c7dd391b6763f9d404bff4f7)
================================================================================
  abstract: Low-rank adaptation, also known as LoRA, has emerged as a prominent method for parameter-efficient fine-tuning of foundation models.
Despite its computational efficiency, LoRA still yields inferior performance compared to full fine-tuning.
In this paper, we first uncover a fundamental connection between the optimization processes of LoRA and full fine-tuning: using LoRA for optimization is mathematically equivalent to full fine-tuning using a low-rank gradient for parameter updates.
And this low-rank gradient can be expressed in terms of the gradients of the two low-rank matrices in LoRA.
Leveraging this insight, we introduce LoRA-Pro, a method that enhances LoRA's performance by strategically adjusting the gradients of these low-rank matrices.
This adjustment allows the low-rank gradient to more accurately approximate the full fine-tuning gradient, thereby narrowing the performance gap between LoRA and full fine-tuning.
Furthermore, we theoretically derive the optimal solutions for adjusting the gradients of the low-rank matrices, applying them during fine-tuning in LoRA-Pro.
We conduct extensive experiments across natural language understanding, dialogue generation, mathematical reasoning, code generation, and image classification tasks, demonstrating that LoRA-Pro substantially improves LoRA's performance, effectively narrowing the gap with full fine-tuning.
Our code is publicly available at https://github.com/mrflogs/LoRA-Pro.
  abstract_embedding: [0.4609375, 0.10205078125, 0.21875]... (1536 items)
  authors: ['Zhengbo Wang', 'Jian Liang', 'Ran He']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805122568
  novelty: yes
  reason: Relevance: The paper proposes a new optimization strategy for low-rank adapters (LoRA), which is a parameter-efficient fine-tuning technique for foundation models. | Novelty: The paper introduces a no...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: LoRA-Pro__Are_Low-Rank_Adapters_Properly_Optimized_.pdf
  sha_abstract: d35e853e4eca260ec3d226c2515e488b8b62ab16a1ca826057dbfef31e2ae8e7
  title: LoRA-Pro: Are Low-Rank Adapters Properly Optimized?
  title_normalized: lorapro_are_lowrank_adapters_properly_optimized

================================================================================
Document #213 (ID: 7196e409834ec9f6ff24196a4d7aa244eebfb00b6962ef3336f5aa1459c0e39c)
================================================================================
  abstract: Graph Neural Networks (GNNs) have achieved promising results in tasks such as node classification and graph classification. However, recent studies reveal that GNNs are vulnerable to backdoor attacks, posing a significant threat to their real-world adoption. Despite initial efforts to defend against specific graph backdoor attacks, there is no work on defending against various types of backdoor attacks where generated triggers have different properties. Hence, we first empirically verify that prediction variance under edge dropping is a crucial indicator for identifying poisoned nodes. With this observation, we propose using random edge dropping to detect backdoors and theoretically show that it can efficiently distinguish poisoned nodes from clean ones. Furthermore, we introduce a novel robust training strategy to efficiently counteract the impact of the triggers. Extensive experiments on real-world datasets show that our framework can effectively identify poisoned nodes, significantly degrade the attack success rate, and maintain clean accuracy when defending against various types of graph backdoor attacks with different properties. Our code is available at: https://github.com/zzwjames/RIGBD.
  abstract_embedding: [0.4609375, 1.0078125, 0.0235595703125]... (1536 items)
  authors: ['Zhiwei Zhang', 'Minhua Lin', 'Junjie Xu']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805118300
  novelty: yes
  reason: Relevance: The paper proposes a novel defense mechanism against graph backdoor attacks, which is an important problem for the real-world deployment of GNNs. | Novelty: The proposed method of using ran...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Robustness_Inspired_Graph_Backdoor_Defense.pdf
  sha_abstract: 8d57e1290400b8ea90bce616de65071c6423a0bdb8fc0e6ec2c6df76c136d38c
  title: Robustness Inspired Graph Backdoor Defense
  title_normalized: robustness_inspired_graph_backdoor_defense

================================================================================
Document #214 (ID: dc33ac05d1de6b56102d99f341f56495f8ad948ae70411ca081560d221666157)
================================================================================
  abstract: Learned image compression (LIC) has demonstrated superior rate-distortion (R-D) performance compared to traditional codecs, but is challenged by training inefficiency that could incur more than two weeks to train a state-of-the-art model from scratch. Existing LIC methods overlook the slow convergence caused by compacting energy in learning nonlinear transforms. In this paper, we first reveal that such energy compaction consists of two components, \emph{i.e.}, feature decorrelation and uneven energy modulation. On such basis, we propose a linear auxiliary transform (AuxT) to disentangle energy compaction in training nonlinear transforms. The proposed AuxT obtains coarse approximation to achieve efficient energy compaction such that distribution fitting with the nonlinear transforms can be simplified to fine details. We then develop wavelet-based linear shortcuts (WLSs) for AuxT that leverages wavelet-based downsampling and orthogonal linear projection for feature decorrelation and subband-aware scaling for uneven energy modulation. AuxT is lightweight and plug-and-play to be integrated into diverse LIC models to address the slow convergence issue. Experimental results demonstrate that the proposed approach can accelerate training of LIC models by 2  times and simultaneously achieves an average 1\% BD-rate reduction. To our best knowledge, this is one of the first successful attempt that can significantly improve the convergence of LIC with comparable or superior rate-distortion performance.
  abstract_embedding: [-0.146484375, -0.220703125, 0.24609375]... (1536 items)
  authors: ['Han Li', 'Shaohui Li', 'Wenrui Dai']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805279551
  novelty: yes
  reason: Relevance: The paper proposes a novel linear auxiliary transform to improve the training efficiency of learned image compression models, which is directly relevant to ML model architecture and trainin...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: On_Disentangled_Training_for_Nonlinear_Transform_in_Learned_Image_Compression.pdf
  sha_abstract: 5f109f0302211769b18e450131ddf2b4debfff928a2f5b66785025bb1a3cc20c
  title: On Disentangled Training for Nonlinear Transform in Learned Image Compression
  title_normalized: on_disentangled_training_for_nonlinear_transform_in_learned_image_compression

================================================================================
Document #215 (ID: 952b81e5651fb161d87e333f79c116d6229668b91cc77dae7cd54ea9e1b4aa50)
================================================================================
  abstract: Large language models (LLMs) often produce errors, including factual inaccuracies, biases, and reasoning failures, collectively referred to as "hallucinations". Recent studies have demonstrated that LLMs' internal states encode information regarding the truthfulness of their outputs, and that this information can be utilized to detect errors. In this work, we show that the internal representations of LLMs encode much more information about truthfulness than previously recognized. We first discover that the truthfulness information is concentrated in specific tokens, and leveraging this property significantly enhances error detection performance. Yet, we show that such error detectors fail to generalize across datasets, implying that---contrary to prior claims---truthfulness encoding is not universal but rather multifaceted. Next, we show that internal representations can also be used for predicting the types of errors the model is likely to make, facilitating the development of tailored mitigation strategies. Lastly, we reveal a discrepancy between LLMs' internal encoding and external behavior: they may encode the correct answer, yet consistently generate an incorrect one. Taken together, these insights deepen our understanding of LLM errors from the model's internal perspective, which can guide future research on enhancing error analysis and mitigation.
  abstract_embedding: [0.384765625, 0.35546875, 0.052734375]... (1536 items)
  authors: ['Hadas Orgad', 'Michael Toker', 'Zorik Gekhman']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805189714
  novelty: yes
  reason: Relevance: The paper proposes novel techniques for analyzing and mitigating errors in large language models, which is highly relevant for improving the reliability and safety of these models. | Novelt...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: LLMs_Know_More_Than_They_Show__On_the_Intrinsic_Representation_of_LLM_Hallucinations.pdf
  sha_abstract: 8e6b314ee1be595d58d9ed42481465d03ed3dfce8f34fcc168c682dfa92203d3
  title: LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations
  title_normalized: llms_know_more_than_they_show_on_the_intrinsic_representation_of_llm_hallucinations

================================================================================
Document #216 (ID: d42873b5f219f28d67d4b265799186ebe2354f13a68123e384e311cd5a1329e3)
================================================================================
  abstract: The outstanding capability of diffusion models in generating high-quality images poses significant threats when misused by adversaries. In particular, we assume malicious adversaries exploiting diffusion models for inpainting tasks, such as replacing a specific region with a celebrity. While existing methods for protecting images from manipulation in diffusion-based generative models have primarily focused on image-to-image and text-to-image tasks, the challenge of preventing unauthorized inpainting has been rarely addressed, often resulting in suboptimal protection performance. To mitigate inpainting abuses, we propose ADVPAINT, a novel defensive framework that generates adversarial perturbations that effectively disrupt the adversary’s inpainting tasks. ADVPAINT targets the self- and cross-attention blocks in a target diffusion inpainting model to distract semantic understanding and prompt interactions during image generation. ADVPAINT also employs a two-stage perturbation strategy, dividing the perturbation region based on an enlarged bounding box around the object, enhancing robustness across diverse masks of varying shapes and sizes. Our experimental results demonstrate that ADVPAINT’s perturbations are highly effective in disrupting the adversary’s inpainting tasks, outperforming existing methods; ADVPAINT attains over a 100-point increase in FID and substantial decreases in precision.
  abstract_embedding: [0.177734375, 0.68359375, -0.039794921875]... (1536 items)
  authors: ['Joonsung Jeon', 'Woo Jae Kim', 'Suhyeon Ha']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805272093
  novelty: yes
  reason: Relevance: The paper proposes a novel defensive framework, AdvPaint, that generates adversarial perturbations to disrupt inpainting tasks in diffusion-based generative models, which is a relevant and ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: AdvPaint__Protecting_Images_from_Inpainting_Manipulation_via_Adversarial_Attention_Disruption.pdf
  sha_abstract: 980f0e381e76e840e008ea29183824ab7ecd4b87db372cedc107502ce0c7d56f
  title: AdvPaint: Protecting Images from Inpainting Manipulation via Adversarial Attention Disruption
  title_normalized: advpaint_protecting_images_from_inpainting_manipulation_via_adversarial_attention_disruption

================================================================================
Document #217 (ID: 7521988db362e7791b2cf000e784876f7a4c8690f1bcaad532ce74a98cfe2359)
================================================================================
  abstract: Instruction tuning is critical for adapting large language models (LLMs) to downstream tasks, and recent studies have demonstrated that small amounts of human-curated data can outperform larger datasets, challenging traditional data scaling laws. While LLM-based data quality rating systems offer a cost-effective alternative to human annotation, they often suffer from inaccuracies and biases, even in powerful models like GPT-4. In this work, we introduce $DS^2$, a **D**iversity-aware **S**core curation method for **D**ata **S**election. By systematically modeling error patterns through a score transition matrix, $DS^2$ corrects LLM-based scores and promotes diversity in the selected data samples. Our approach shows that a curated subset (just 3.3\% of the original dataset) outperforms full-scale datasets (300k samples) across various machine-alignment benchmarks, and matches or surpasses human-aligned datasets such as LIMA with the same sample size (1k samples). These findings challenge conventional data scaling assumptions, highlighting that redundant, low-quality samples can degrade performance and reaffirming that ``more can be less''.
  abstract_embedding: [0.388671875, 0.2041015625, 0.244140625]... (1536 items)
  authors: ['Jinlong Pang', 'Jiaheng Wei', 'Ankit Shah']... (9 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805192510
  novelty: yes
  reason: Relevance: The paper proposes a novel data curation method, DS2, that improves the efficiency of LLM-driven data rating systems, which is directly relevant to improving ML model training and performan...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Improving_Data_Efficiency_via_Curating_LLM-Driven_Rating_Systems.pdf
  sha_abstract: 3c5115fbf29eb8d1030f0c8b99d76fd2e7c686dced2331392748dac665fed628
  title: Improving Data Efficiency via Curating LLM-Driven Rating Systems
  title_normalized: improving_data_efficiency_via_curating_llmdriven_rating_systems

================================================================================
Document #218 (ID: 215c640777a892a3cb28f5344b1388d6faa0decf95cd38b2c3c16a515f3a592f)
================================================================================
  abstract: Diffusion probabilistic models have achieved remarkable success in generative tasks across diverse data types. While recent studies have explored alternative degradation processes beyond Gaussian noise, this paper bridges two key diffusion paradigms: hot diffusion, which relies entirely on noise, and cold diffusion, which uses only blurring without noise. We argue that hot diffusion fails to exploit the strong correlation between high-frequency image detail and low-frequency structures, leading to random behaviors in the early steps of generation. Conversely, while cold diffusion leverages image correlations for prediction, it neglects the role of noise (randomness) in shaping the data manifold, resulting in out-of-manifold issues and partially explaining its performance drop. To integrate both strengths, we propose Warm Diffusion, a unified Blur-Noise Mixture Diffusion Model (BNMD), to control blurring and noise jointly. Our divide-and-conquer strategy exploits the spectral dependency in images, simplifying score model estimation by disentangling the denoising and deblurring processes. We further analyze the Blur-to-Noise Ratio (BNR) using spectral analysis to investigate the trade-off between model learning dynamics and changes in the data manifold. Extensive experiments across benchmarks validate the effectiveness of our approach for image generation.
  abstract_embedding: [-0.07958984375, 0.484375, 0.07763671875]... (1536 items)
  authors: ['Hao-Chien Hsueh', 'Wen-Hsiao Peng', 'Ching-Chun Huang']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805285933
  novelty: yes
  reason: Relevance: The paper proposes a new diffusion model architecture, the Blur-Noise Mixture Diffusion Model (BNMD), which integrates both blurring and noise for improved image generation performance. | N...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Warm_Diffusion__Recipe_for_Blur-Noise_Mixture_Diffusion_Models.pdf
  sha_abstract: d8a966485ca60086a96e0b535c104e5b024bb671b30e6dd89aa850646e09a406
  title: Warm Diffusion: Recipe for Blur-Noise Mixture Diffusion Models
  title_normalized: warm_diffusion_recipe_for_blurnoise_mixture_diffusion_models

================================================================================
Document #219 (ID: 60e2fef95ba5b54f06487cc2a5a766161213205272aff8b220adffdbb537cb16)
================================================================================
  abstract: Given the limitations of backpropagation, perturbation-based gradient computation methods have recently gained focus for learning with only forward passes, also referred to as queries. Conventional forward learning consumes enormous queries on each data point for accurate gradient estimation through Monte Carlo sampling, which hinders the scalability of those algorithms. However, not all data points deserve equal queries for gradient estimation. In this paper, we study the problem of improving the forward learning efficiency from a novel perspective: how to reduce the gradient estimation variance with minimum cost? For this, we allocate the optimal number of queries within a set budget during training to balance estimation accuracy and computational efficiency. Specifically, with a simplified proxy objective and a reparameterization technique, we derive a novel plug-and-play query allocator with minimal parameters. Theoretical results are carried out to verify its optimality. We conduct extensive experiments for fine-tuning Vision Transformers on various datasets and further deploy the allocator to two black-box applications: prompt tuning and multimodal alignment for foundation models. All findings demonstrate that our proposed allocator significantly enhances the scalability of forward-learning algorithms, paving the way for real-world applications. The implementation is available at https://github.com/RTkenny/FLOPS-Forward-Learning-with-OPtimal-Sampling.
  abstract_embedding: [-0.1552734375, 0.234375, 0.201171875]... (1536 items)
  authors: ['Tao Ren', 'Zishi Zhang', 'Jinyang Jiang']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805184027
  novelty: yes
  reason: Relevance: The paper proposes a novel query allocation strategy to improve the efficiency of forward learning algorithms, which is relevant for training ML models on AWS Trainium. | Novelty: The propo...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: FLOPS__Forward_Learning_with_OPtimal_Sampling.pdf
  sha_abstract: ca5b40ef9754d7fdcb2cd8fc10822215c8b9624d118855cf2a1221a49d8802e0
  title: FLOPS: Forward Learning with OPtimal Sampling
  title_normalized: flops_forward_learning_with_optimal_sampling

================================================================================
Document #220 (ID: 8363e86d91659739d7cbb426139bb2835765131eaae268074d242b5b62ec1594)
================================================================================
  abstract: In scenarios where language models must incorporate new information efficiently without extensive retraining, traditional fine-tuning methods are prone to overfitting, degraded generalization, and unnatural language generation. To address these limitations, we introduce Consistent In-Context Editing (ICE), a novel approach leveraging the model's in-context learning capability to optimize towards a contextual distribution rather than a one-hot target. ICE introduces a simple yet effective optimization framework for the model to internalize new knowledge by aligning its output distributions with and without additional context. This method enhances the robustness and effectiveness of gradient-based tuning methods, preventing overfitting and preserving the model's integrity. We analyze ICE across four critical aspects of knowledge editing: accuracy, locality, generalization, and linguistic quality, demonstrating its advantages. Experimental results confirm the effectiveness of ICE and demonstrate its potential for continual editing, ensuring that the integrity of the model is preserved while updating information.
  abstract_embedding: [0.060546875, 0.515625, -0.31640625]... (1536 items)
  authors: ['Siyuan Qi', 'Bangcheng Yang', 'Kailin Jiang']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805194836
  novelty: yes
  reason: Relevance: The paper proposes a novel in-context learning technique called Consistent In-Context Editing (ICE) that can efficiently incorporate new information into language models without extensive r...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: In-Context_Editing__Learning_Knowledge_from_Self-Induced_Distributions.pdf
  sha_abstract: 0c8abfd2edb4b415ba53ef5d2a8b3110448aa2aca21cb7ce33068324d57ae05f
  title: In-Context Editing: Learning Knowledge from Self-Induced Distributions
  title_normalized: incontext_editing_learning_knowledge_from_selfinduced_distributions

================================================================================
Document #221 (ID: e3dcdcaa2824ee836274d6aa6369a1d5ec98f5cd45a77a8d1e99ff311587ed1d)
================================================================================
  abstract: Generative models can now produce photorealistic synthetic data which is virtually indistinguishable from the real data used to train it. This is a significant evolution over previous models which could produce reasonable facsimiles of the training data, but ones which could be visually distinguished from the training data by human evaluation. Recent work on OOD detection has raised doubts that generative model likelihoods are optimal OOD detectors due to issues involving likelihood misestimation, entropy in the generative process, and typicality. We speculate that generative OOD detectors also failed because their models focused on the pixels rather than the semantic content of the data, leading to failures in near-OOD cases where the pixels may be similar but the information content is significantly different. We hypothesize that estimating typical sets using self-supervised learners leads to better OOD detectors. We introduce a novel approach that leverages representation learning, and informative summary statistics based on manifold estimation, to address all of the aforementioned issues. Our method outperforms other unsupervised approaches and achieves state-of-the art performance on well-established challenging benchmarks, and new synthetic data detection tasks.
  abstract_embedding: [0.115234375, 0.212890625, 0.25]... (1536 items)
  authors: ['Debargha Ganguly', 'Warren Richard Morningstar', 'Andrew Seohwan Yu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805196631
  novelty: yes
  reason: Relevance: The paper proposes a novel approach for out-of-distribution (OOD) detection that leverages representation learning and manifold estimation, which could be valuable for AWS Trainium. | Novel...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Forte___Finding_Outliers_with_Representation_Typicality_Estimation.pdf
  sha_abstract: c46833e4f8558e6baf29d04427cf582c64dff9816ee3bbdf3dfdb16b95b1ea4b
  title: Forte : Finding Outliers with Representation Typicality Estimation
  title_normalized: forte__finding_outliers_with_representation_typicality_estimation

================================================================================
Document #222 (ID: cd720e0d1c50cb0f33914f91d25c79c05095c94d2682dc19b43ca06783f05113)
================================================================================
  abstract: Computationally intensive decoding procedures---including search, reranking, and self-critique---can improve the quality of language model (LM) outputs in problems spanning code generation, numerical reasoning, and dialog.
Existing work typically applies the same decoding procedure for every input to an LM. But not all inputs require the same amount of computation to process. Can we allocate decoding computation adaptively, using more resources to answer questions whose answers will be harder to compute? We present an approach that predicts the distribution of rewards given an input and computation budget, then allocates additional computation to inputs for which it is predicted to be most useful. We apply this approach in two decoding procedures: first, an adaptive best-of-$k$ procedure that dynamically selects the number of samples to generate as input to a reranker; second, a routing procedure that dynamically responds to a query using a decoding procedure that is expensive but accurate, or one that is cheaper but less capable. Across a suite of programming, mathematics, and dialog tasks, we show that accurate computation-allocation procedures can be learned, and reduce computation by up to 50% at no cost to quality.
  abstract_embedding: [0.0810546875, 0.2734375, 0.224609375]... (1536 items)
  authors: ['Mehul Damani', 'Idan Shenfeld', 'Andi Peng']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805185966
  novelty: yes
  reason: Relevance: The paper proposes an innovative input-adaptive allocation of language model computation, which can improve the efficiency of decoding procedures like search, reranking, and self-critique. ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Learning_How_Hard_to_Think__Input-Adaptive_Allocation_of_LM_Computation.pdf
  sha_abstract: ffdd9d00c028857ff1fbf8b999816800c84bfa3efd783d3bbe37b4760d8d104b
  title: Learning How Hard to Think: Input-Adaptive Allocation of LM Computation
  title_normalized: learning_how_hard_to_think_inputadaptive_allocation_of_lm_computation

================================================================================
Document #223 (ID: 75698d2819a086b3ec4d19d1caecaf35320e6dbee405bfe7701449531bcbae1a)
================================================================================
  abstract: Multi-modal Large Language Models (MLLMs) have recently showcased superior proficiency in general visual scenarios. However, we identify their mathematical capabilities remain under-explored with three areas to be improved: visual encoding of math diagrams, diagram-language alignment, and chain-of-thought (CoT) reasoning. This draws forth an urgent demand for an effective training paradigm and a large-scale, comprehensive dataset with detailed CoT rationales, which is challenging to collect and costly to annotate manually. To tackle this issue, we propose MAVIS, a MAthematical VISual instruction tuning pipeline for MLLMs, featuring an automatic data engine to efficiently create mathematical visual datasets.
We design the data generation process to be entirely independent of human intervention or GPT API usage, while ensuring the diagram-caption correspondence, question-answer correctness, and CoT reasoning quality. With this approach, we curate two datasets, MAVIS-Caption (558K diagram-caption pairs) and MAVIS-Instruct (834K visual math problems with CoT rationales), and propose four progressive stages for training MLLMs from scratch.
First, we utilize MAVIS-Caption to fine-tune a math-specific vision encoder (CLIP-Math) through contrastive learning, tailored for improved diagram visual encoding. Second, we also leverage MAVIS-Caption to align the CLIP-Math with a large language model (LLM) by a projection layer, enhancing vision-language alignment in mathematical domains. Third, we adopt MAVIS-Instruct to perform the instruction tuning for robust problem-solving skills, and term the resulting model as MAVIS-7B. Fourth, we apply Direct Preference Optimization (DPO) to enhance the CoT capabilities of our model, further refining its step-wise reasoning performance.
On various mathematical benchmarks, our MAVIS-7B achieves leading results among open-source MLLMs, e.g., surpassing other 7B models by +9.3% and the second-best LLaVA-NeXT (110B) by +6.9%, demonstrating the effectiveness of our method.
  abstract_embedding: [0.3203125, 0.17578125, -0.034423828125]... (1536 items)
  authors: ['Renrui Zhang', 'Xinyu Wei', 'Dongzhi Jiang']... (11 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805303714
  novelty: yes
  reason: Relevance: The paper proposes a novel training pipeline (MAVIS) that includes a custom vision encoder (CLIP-Math), vision-language alignment, and instruction tuning to improve the mathematical capabil...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MAVIS__Mathematical_Visual_Instruction_Tuning_with_an_Automatic_Data_Engine.pdf
  sha_abstract: 99aa00182297997a995df4d07a06b462ca20e0eb0d5ec13d53bd965d1dfdb059
  title: MAVIS: Mathematical Visual Instruction Tuning with an Automatic Data Engine
  title_normalized: mavis_mathematical_visual_instruction_tuning_with_an_automatic_data_engine

================================================================================
Document #224 (ID: a59b4dc93390f045e5f582e0257c635d7d47c5c7b37fe24ba9b2b37b6f55eb31)
================================================================================
  abstract: Go-Explore is a powerful family of algorithms designed to solve hard-exploration problems built on the principle of archiving discovered states, and iteratively returning to and exploring from the most promising states. This approach has led to superhuman performance across a wide variety of challenging problems including Atari games and robotic control, but requires manually designing heuristics to guide exploration (i.e., determine which states to save and explore from, and what actions to consider next), which is time-consuming and infeasible in general. To resolve this, we propose Intelligent Go-Explore (IGE) which greatly extends the scope of the original Go-Explore by replacing these handcrafted heuristics with the intelligence and internalized human notions of interestingness captured by giant pretrained foundation models (FMs). This provides IGE with a human-like ability to instinctively identify how interesting or promising any new state is (e.g., discovering new objects, locations, or behaviors), even in complex environments where heuristics are hard to define. Moreover, IGE offers the exciting opportunity to recognize and capitalize on serendipitous discoveries---states encountered during exploration that are valuable in terms of exploration, yet where what makes them interesting was not anticipated by the human user. We evaluate our algorithm on a diverse range of language and vision-based tasks that require search and exploration. Across these tasks, IGE strongly exceeds classic reinforcement learning and graph search baselines, and also succeeds where prior state-of-the-art FM agents like Reflexion completely fail. Overall, Intelligent Go-Explore combines the tremendous strengths of FMs and the powerful Go-Explore algorithm, opening up a new frontier of research into creating more generally capable agents with impressive exploration capabilities. All our code is open-sourced at: https://github.com/conglu1997/intelligent-go-explore.
  abstract_embedding: [0.271484375, 0.255859375, 0.0947265625]... (1536 items)
  authors: ['Cong Lu', 'Shengran Hu', 'Jeff Clune']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805294096
  novelty: yes
  reason: Relevance: The paper proposes a novel algorithm, Intelligent Go-Explore, that combines the strengths of foundation models and the Go-Explore exploration algorithm, which could be valuable for training...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Intelligent_Go-Explore__Standing_on_the_Shoulders_of_Giant_Foundation_Models.pdf
  sha_abstract: c994159eba7cb6c078620fda9b282c94b85dca48642bc60bb8e78d22c44c4d44
  title: Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation Models
  title_normalized: intelligent_goexplore_standing_on_the_shoulders_of_giant_foundation_models

================================================================================
Document #225 (ID: 78695c4de48d35193092052deb7fc2bcac25a085e6fcf82d022dca7588638bcf)
================================================================================
  abstract: Despite the recent progress in long-context language models, it remains elusive how transformer-based models exhibit the capability to retrieve relevant information from arbitrary locations within the long context. This paper aims to address this question. Our systematic investigation across a wide spectrum of models reveals that a special type of attention heads are largely responsible for retrieving information, which we dub retrieval heads. We identify intriguing properties of retrieval heads:(1) universal: all the explored models with long-context capability have a set of retrieval heads; (2) sparse: only a small portion (less than 5\%) of the attention heads are retrieval. (3) intrinsic: retrieval heads already exist in models pretrained with short context. When extending the context length by continual pretraining, it is still the same set of heads that perform information retrieval. (4) dynamically activated: take Llama-2 7B for example, 12 retrieval heads always attend to the required information no matter how the context is changed. The rest of the retrieval heads are activated in different contexts. (5) causal: completely pruning retrieval heads leads to failure in retrieving relevant information and results in hallucination, while pruning random non-retrieval heads does not affect the model's retrieval ability. We further show that retrieval heads strongly influence chain-of-thought (CoT) reasoning, where the model needs to frequently refer back the question and previously-generated context. Conversely, tasks where the model directly generates the answer using its intrinsic knowledge are less impacted by masking out retrieval heads. These observations collectively explain which internal part of the model seeks information from the input tokens. We believe our insights will foster future research on reducing hallucination, improving reasoning, and compressing the KV cache.
  abstract_embedding: [0.2578125, -0.006805419921875, 0.322265625]... (1536 items)
  authors: ['Wenhao Wu', 'Yizhong Wang', 'Guangxuan Xiao']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805300086
  novelty: yes
  reason: Relevance: The paper proposes a novel mechanism, retrieval heads, that explains how transformer-based models can retrieve relevant information from long contexts, which is an important capability for ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Retrieval_Head_Mechanistically_Explains_Long-Context_Factuality.pdf
  sha_abstract: af70edec3b9426604b3c88ea7e943b7dc09f6c671ab0afd87f478a767fc26e26
  title: Retrieval Head Mechanistically Explains Long-Context Factuality
  title_normalized: retrieval_head_mechanistically_explains_longcontext_factuality

================================================================================
Document #226 (ID: 6bf428ebdee70c673dc17e1f51002edb2327582f07e5a721b320ef465c0a26eb)
================================================================================
  abstract: Existing retrieval benchmarks primarily consist of information-seeking queries (e.g., aggregated questions from search engines) where keyword or semantic-based retrieval is usually sufficient. However, many complex real-world queries require in-depth reasoning to identify relevant documents that go beyond surface form matching. For example, finding documentation for a coding question requires understanding the logic and syntax of the functions involved. To better benchmark retrieval on such challenging queries, we introduce BRIGHT, the first text retrieval benchmark that requires intensive reasoning to retrieve relevant documents. Our dataset consists of 1,398 real-world queries spanning diverse domains such as economics, psychology, mathematics, coding, and more. These queries are drawn from naturally occurring or carefully curated human data. Extensive evaluation reveals that even state-of-the-art retrieval models perform poorly on BRIGHT. The leading model on the MTEB leaderboard (Muennighoff et al., 2023), which achieves a score of 59.0 nDCG@10,1 produces a score of nDCG@10 of 18.0 on BRIGHT. We show that incorporating explicit reasoning about the query improves retrieval performance by up to 12.2 points. Moreover, incorporating retrieved documents from the top-performing retriever boosts question answering performance by over 6.6 points. We believe that BRIGHT paves the way for future research on retrieval systems in more realistic and challenging settings.
  abstract_embedding: [0.330078125, 0.50390625, 0.2734375]... (1536 items)
  authors: ['Hongjin SU', 'Howard Yen', 'Mengzhou Xia']... (15 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805296765
  novelty: yes
  reason: Relevance: The paper proposes a new benchmark dataset (BRIGHT) that requires intensive reasoning for text retrieval, which is a novel and relevant challenge for ML models. | Novelty: The BRIGHT benchm...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: BRIGHT__A_Realistic_and_Challenging_Benchmark_for_Reasoning-Intensive_Retrieval.pdf
  sha_abstract: 483dd0b4a675df6b284d7d9f6a1dab983b3ef0db0448eb89b84c457b9dc55501
  title: BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval
  title_normalized: bright_a_realistic_and_challenging_benchmark_for_reasoningintensive_retrieval

================================================================================
Document #227 (ID: cc5f142b21e4bca419121714a2fb3e19758f54fd2c91bd82756b1b7cae2d9cb0)
================================================================================
  abstract: Scientific discovery contributes largely to the prosperity of human society, and recent progress shows that LLMs could potentially catalyst the process. However, it is still unclear whether LLMs can discover novel and valid hypotheses in chemistry. In this work, we investigate this main research question: whether LLMs can automatically discover novel and valid chemistry research hypotheses, given only a research question? With extensive discussions with chemistry experts, we adopt the assumption that a majority of chemistry hypotheses can be resulted from a research background question and several inspirations. With this key insight, we break the main question into three smaller fundamental questions. In brief, they are: (1) given a background question, whether LLMs can retrieve good inspirations; (2) with background and inspirations, whether LLMs can lead to hypothesis; and (3) whether LLMs can identify good hypotheses to rank them higher. To investigate these questions, we construct a benchmark consisting of 51 chemistry papers published in Nature or a similar level in 2024 (all papers are only available online since 2024). Every paper is divided by chemistry PhD students into three components: background, inspirations, and hypothesis. The goal is to rediscover the hypothesis given only the background and a large chemistry literature corpus consisting the ground truth inspiration papers, with LLMs trained with data up to 2023. We also develop an LLM-based multi-agent framework that leverages the assumption, consisting of three stages reflecting the more smaller questions. The proposed method can rediscover many hypotheses with very high similarity with the ground truth ones, covering the main innovations.
  abstract_embedding: [0.80859375, 0.404296875, 0.1845703125]... (1536 items)
  authors: ['Zonglin Yang', 'Wanhao Liu', 'Ben Gao']... (9 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805310260
  novelty: yes
  reason: Relevance: The paper proposes a novel LLM-based multi-agent framework for automatically discovering novel chemistry research hypotheses, which is directly relevant to ML research and applications. | N...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MOOSE-Chem__Large_Language_Models_for_Rediscovering_Unseen_Chemistry_Scientific_Hypotheses.pdf
  sha_abstract: a571ccd6e38cad846225c7445da21d99e73af5db50a72f2c7aac661fedf88d6c
  title: MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses
  title_normalized: moosechem_large_language_models_for_rediscovering_unseen_chemistry_scientific_hypotheses

================================================================================
Document #228 (ID: 9bf818e170ba517686853206e3cff57be8aa3bb68232cd95833fa445ba6d2edb)
================================================================================
  abstract: We propose a novel approach for 3D mesh reconstruction from multi-view images. We improve upon the large reconstruction model LRM that use a transformer-based triplane generator and a Neural Radiance Field (NeRF) model trained on multi-view images. We introduce three key components to significantly enhance the 3D reconstruction quality. First of all, we examine the original LRM architecture and find several shortcomings. Subsequently, we introduce respective modifications to the LRM architecture, which lead to improved multi-view image representation and more computationally efficient training. Second, in order to improve geometry reconstruction and enable supervision at full image resolution, we extract meshes from the NeRF in a differentiable manner and fine-tune the NeRF model through mesh rendering. These modifications allow us to achieve state-of-the-art performance on both 2D and 3D evaluation metrics on Google Scanned Objects (GSO) dataset and OmniObject3D dataset. Finally, we introduce a lightweight per-instance texture refinement procedure to better reconstruct complex textures, such as text and portraits on assets. To address this, we introduce a lightweight per-instance texture refinement procedure. This procedure fine-tunes the triplane representation and the NeRF's color estimation model on the mesh surface using the input multi-view images in just 4 seconds. This refinement achieves faithful reconstruction of complex textures. Additionally, our approach enables various downstream applications, including text/image-to-3D generation.
  abstract_embedding: [0.287109375, 0.046875, -0.002655029296875]... (1536 items)
  authors: ['Peiye Zhuang', 'Songfang Han', 'Chaoyang Wang']... (10 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805305931
  novelty: yes
  reason: Relevance: The paper proposes a novel approach for 3D mesh reconstruction that introduces several key architectural modifications and refinement techniques to improve the quality of the reconstruction...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: GTR__Improving_Large_3D_Reconstruction_Models_through_Geometry_and_Texture_Refinement.pdf
  sha_abstract: 18765e171d12fc494cfd7226b22db293971c46829230dcdf1a4f48a39a642cf8
  title: GTR: Improving Large 3D Reconstruction Models through Geometry and Texture Refinement
  title_normalized: gtr_improving_large_3d_reconstruction_models_through_geometry_and_texture_refinement

================================================================================
Document #229 (ID: a1a727a93fda146e773f15386f9ecf746c222ac2ca9f03a470943f052f6ab087)
================================================================================
  abstract: Will a Visual Language Model (VLM)-based bot warn us about slipping if it detects a wet floor? Recent VLMs have demonstrated impressive capabilities, yet their ability to infer outcomes and causes remains underexplored. To address this, we introduce NL-Eye, a benchmark designed to assess VLMs' visual abductive reasoning skills. NL-Eye adapts the abductive Natural Language Inference (NLI) task to the visual domain, requiring models to evaluate the plausibility of hypothesis images based on a premise image and explain their decisions. NL-Eye consists of 350 carefully curated triplet examples (1,050 images) spanning diverse reasoning categories: physical, functional, logical, emotional, cultural, and social. The data curation process involved two steps—writing textual descriptions and generating images using text-to-image models, both requiring substantial human involvement to ensure high-quality and challenging scenes. Our experiments show that VLMs struggle significantly on NL-Eye, often performing at random baseline levels, while humans excel in both plausibility prediction and explanation quality. This demonstrates a deficiency in the abductive reasoning capabilities of modern VLMs. NL-Eye represents a crucial step toward developing VLMs capable of robust multimodal reasoning for real-world applications, including accident-prevention bots and generated video verification.
  abstract_embedding: [0.41015625, 0.265625, 0.40234375]... (1536 items)
  authors: ['Mor Ventura', 'Michael Toker', 'Nitay Calderon']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805308352
  novelty: yes
  reason: Relevance: The paper proposes a new benchmark (NL-Eye) to assess the abductive reasoning capabilities of visual language models, which is a novel and important task for real-world applications. | Nove...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: NL-Eye__Abductive_NLI_For_Images.pdf
  sha_abstract: 7b0370e26bb3593ecc9d32c71ba5a33ab12ab00d83e5ab64ddd91d6889d4e052
  title: NL-Eye: Abductive NLI For Images
  title_normalized: nleye_abductive_nli_for_images

================================================================================
Document #230 (ID: 9d05c9b13b2d769fd509fb23506cc085bd54a20d521870dd2a4cd064a828794f)
================================================================================
  abstract: Event-guided imaging has received significant attention due to its potential to revolutionize instant imaging systems. However, the prior methods primarily focus on enhancing RGB images in a post-processing manner, neglecting the challenges of image signal processor (ISP) dealing with event sensor and the benefits events provide for reforming the ISP process. To achieve this, we conduct the first research on event-guided ISP. First, we present a new event-RAW paired dataset, collected with a novel but still confidential sensor that records pixel-level aligned events and RAW images. This dataset includes 3373 RAW images with $2248\times 3264$ resolution and their corresponding events, spanning 24 scenes with 3 exposure modes and 3 lenses. Second, we propose a convential ISP pipeline to generate good RGB frames as reference. This convential ISP pipleline performs basic ISP operations, e.g., demosaicing, white balancing, denoising and color space transforming, with a ColorChecker as reference. Third, we classify the existing learnable ISP methods into 3 classes, and select multiple methods to train and evaluate on our new dataset. Lastly, since there is no prior work for reference, we propose a simple event-guided ISP method and test it on our dataset. We further put forward key technical challenges and future directions in RGB-Event ISP. In summary, to the best of our knowledge, this is the very first research focusing on event-guided ISP, and we hope it will inspire the community.
  abstract_embedding: [-0.126953125, 0.06494140625, 0.27734375]... (1536 items)
  authors: ['Yunfan LU', 'Yanlin Qian', 'Ziyang Rao']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805316611
  novelty: yes
  reason: Relevance: The paper proposes a new dataset and benchmark for event-guided image signal processing, which is a novel application of event-based sensors. | Novelty: The paper introduces the first resea...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: RGB-Event_ISP__The_Dataset_and_Benchmark.pdf
  sha_abstract: 7677ae398e79cfd4a0c8eee45394f148636530cdde40ad92c126afe8b5b832b3
  title: RGB-Event ISP: The Dataset and Benchmark
  title_normalized: rgbevent_isp_the_dataset_and_benchmark

================================================================================
Document #231 (ID: db54f043abf73b69acb0154facf870067e0396fffb67e60204132d4d8c852ef6)
================================================================================
  abstract: Large language models (LLMs) could be valuable personal AI agents across various domains, provided they can precisely follow user instructions. However, recent studies have shown significant limitations in LLMs' instruction-following capabilities, raising concerns about their reliability in high-stakes applications. 
Accurately estimating LLMs' uncertainty in adhering to instructions is critical to mitigating deployment risks. We present, to our knowledge, the first systematic evaluation of the uncertainty estimation abilities of LLMs in the context of instruction-following. 
Our study identifies key challenges with existing instruction-following benchmarks, where multiple factors are entangled with uncertainty stems from instruction-following, complicating the isolation and comparison across methods and models.
To address these issues, we introduce a controlled evaluation setup with two benchmark versions of data, enabling a comprehensive comparison of uncertainty estimation methods under various conditions.
Our findings show that existing uncertainty methods struggle, particularly when models make subtle errors in instruction following. While internal model states provide some improvement, they remain inadequate in more complex scenarios. 
The insights from our controlled evaluation setups provide a crucial understanding of LLMs' limitations and potential for uncertainty estimation in instruction-following tasks, paving the way for more trustworthy AI agents.
  abstract_embedding: [0.28125, 0.05712890625, 0.1884765625]... (1536 items)
  authors: ['Juyeon Heo', 'Miao Xiong', 'Christina Heinze-Deml']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805314749
  novelty: yes
  reason: Relevance: The paper proposes a novel evaluation setup to assess the uncertainty estimation capabilities of LLMs in instruction-following tasks, which is relevant for developing more trustworthy AI ag...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Do_LLMs_estimate_uncertainty_well_in_instruction-following_.pdf
  sha_abstract: b76bd4af926c2820594d770badbcca82d202a958509c80a74e267c99e086fe7c
  title: Do LLMs estimate uncertainty well in instruction-following?
  title_normalized: do_llms_estimate_uncertainty_well_in_instructionfollowing

================================================================================
Document #232 (ID: 00e25bd390d1300ea13f30df1a752b26e246949560e153e195028a755dabb7b0)
================================================================================
  abstract: Modern text-to-video synthesis models demonstrate coherent, photorealistic generation of complex videos from a text description. However, most existing models lack fine-grained control over camera movement, which is critical for downstream applications related to content creation, visual effects, and 3D vision. Recently, new methods demonstrate the ability to generate videos with controllable camera poses---these techniques leverage pre-trained U-Net-based diffusion models that explicitly disentangle spatial and temporal generation. Still, no existing approach enables camera control for new, transformer-based video diffusion models that process spatial and temporal information jointly. Here, we propose to tame video transformers for 3D camera control using a ControlNet-like conditioning mechanism that incorporates spatiotemporal camera embeddings based on Plucker coordinates. The approach demonstrates state-of-the-art performance for controllable video generation after fine-tuning on the RealEstate10K dataset. To the best of our knowledge, our work is the first to enable camera control for transformer-based video diffusion models.
  abstract_embedding: [0.1494140625, -0.07666015625, 0.39453125]... (1536 items)
  authors: ['Sherwin Bahmani', 'Ivan Skorokhodov', 'Aliaksandr Siarohin']... (12 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805323225
  novelty: yes
  reason: Relevance: The paper proposes a novel ControlNet-like conditioning mechanism to enable camera control for transformer-based video diffusion models, which is an innovative approach to improving the cap...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: VD3D__Taming_Large_Video_Diffusion_Transformers_for_3D_Camera_Control.pdf
  sha_abstract: 8a3a9ef7434a85c94b35aa0471bbe73bb3cac8dfc19e016c537a564f3c9a6b13
  title: VD3D: Taming Large Video Diffusion Transformers for 3D Camera Control
  title_normalized: vd3d_taming_large_video_diffusion_transformers_for_3d_camera_control

================================================================================
Document #233 (ID: 437de0588521a062496bf46c5996f6485824e7b64d18c28d9b0d8550afa738b5)
================================================================================
  abstract: Causal Transformers are trained to predict the next token for a given context. While it is widely accepted that self-attention is crucial for encoding the causal structure of sequences, the precise underlying mechanism behind this in-context autoregressive learning ability remains unclear. In this paper, we take a step towards understanding this phenomenon by studying the approximation ability of Transformers for next-token prediction. Specifically, we explore the capacity of causal Transformers to predict the next token $x_{t+1}$ given an autoregressive sequence $(x_1, \dots, x_t)$ as a prompt, where $ x_{t+1} = f(x_t) $, and $ f $ is a context-dependent function that varies with each sequence.
On the theoretical side, we focus on specific instances, namely when $ f $ is linear or when $ (x_t)$ is periodic. We explicitly construct a Transformer (with linear, exponential, or softmax attention) that learns the mapping $f$ in-context through a causal kernel descent method. The causal kernel descent method we propose provably estimates $x_{t+1} $ based solely on past and current observations $ (x_1, \dots, x_t) $, with connections to the Kaczmarz algorithm in Hilbert spaces. We present experimental results that validate our theoretical findings and suggest their applicability to more general mappings $f$.
  abstract_embedding: [0.322265625, 0.10009765625, 0.033935546875]... (1536 items)
  authors: ['Michael Eli Sander', 'Gabriel Peyré']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805318405
  novelty: yes
  reason: Relevance: The paper proposes a novel causal kernel descent method for Transformers to learn context-dependent next-token prediction functions, which is relevant for improving the autoregressive capab...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Towards_Understanding_the_Universality_of_Transformers_for_Next-Token_Prediction.pdf
  sha_abstract: 2f3f58542fbac2363191c2440073fbfd5d559dbf3f599b40bdc294a91fc97b7d
  title: Towards Understanding the Universality of Transformers for Next-Token Prediction
  title_normalized: towards_understanding_the_universality_of_transformers_for_nexttoken_prediction

================================================================================
Document #234 (ID: 9d3bd766039f2ee064d006c1ef9c0eb7424546632992b35dc9d371c6ced500e5)
================================================================================
  abstract: Machine unlearning is a promising approach to mitigate undesirable memorization of training data in ML models. However, in this work we show that existing approaches for unlearning in LLMs are surprisingly susceptible to a simple set of benign relearning attacks. With access to only a small and potentially loosely related set of data, we find that we can “jog” the memory of unlearned models to reverse the effects of unlearning. For example, we show that relearning on public medical articles can lead an unlearned LLM to output harmful knowledge about bioweapons, and relearning general wiki information about the book series Harry Potter can force the model to output verbatim memorized text. We formalize this unlearning-relearning pipeline, explore the attack across three popular unlearning benchmarks, and discuss future directions and guidelines that result from our study. Our work indicates that current approximate unlearning methods simply suppress the model outputs and fail to robustly forget target knowledge in the LLMs.
  abstract_embedding: [0.60546875, 0.53125, 0.00537109375]... (1536 items)
  authors: ['Shengyuan Hu', 'Yiwei Fu', 'Steven Wu']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805330437
  novelty: yes
  reason: Relevance: The paper proposes a novel attack on existing machine unlearning techniques, which is a critical issue for deploying LLMs safely. | Novelty: The paper introduces a new unlearning-relearning...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Unlearning_or_Obfuscating__Jogging_the_Memory_of_Unlearned_LLMs_via_Benign_Relearning.pdf
  sha_abstract: 45a931da7b061f992864d584407138a718a84876e26144ac0729f1d4d46ae370
  title: Unlearning or Obfuscating? Jogging the Memory of Unlearned LLMs via Benign Relearning
  title_normalized: unlearning_or_obfuscating_jogging_the_memory_of_unlearned_llms_via_benign_relearning

================================================================================
Document #235 (ID: a48946b7e180a349bb004360b0cb5fd4b34dc0934dd75debf72ba16cdb09bb5f)
================================================================================
  abstract: In-Context Learning (ICL) has significantly expanded the general-purpose nature of large language models, allowing them to adapt to novel tasks using merely the inputted context. This has motivated a series of papers that analyze tractable synthetic domains and postulate precise mechanisms that may underlie ICL. However, the use of relatively distinct setups that often lack a sequence modeling nature to them makes it unclear how general the reported insights from such studies are. Motivated by this, we propose a synthetic sequence modeling task that involves learning to simulate a finite mixture of Markov chains. As we show, models trained on this task reproduce most well-known results on ICL, hence offering a unified setting for studying the concept. Building on this setup, we demonstrate we can explain a model’s behavior by decomposing it into four broad algorithms that combine a fuzzy retrieval vs. inference approach with either unigram or bigram statistics of the context. These algorithms engage in a competitive dynamics to dominate model behavior, with the precise experimental conditions dictating which algorithm ends up superseding others: e.g., we find merely varying context size or amount of training yields (at times sharp) transitions between which algorithm dictates the model behavior, revealing a mechanism that explains the transient nature of ICL. In this sense, we argue ICL is best thought of as a mixture of different algorithms, each with its own peculiarities, instead of a monolithic capability. This also implies that making general claims about ICL that hold universally across all settings may be infeasible.
  abstract_embedding: [0.0306396484375, 0.498046875, 0.00074005126953125]... (1536 items)
  authors: ['Core Francisco Park', 'Ekdeep Singh Lubana', 'Hidenori Tanaka']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805348221
  novelty: yes
  reason: Relevance: The paper proposes a novel synthetic task and algorithms for in-context learning, which is a key capability for large language models. | Novelty: The paper presents a new perspective on in-...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Competition_Dynamics_Shape_Algorithmic_Phases_of_In-Context_Learning.pdf
  sha_abstract: c9e362d080bbb9bdb7699e4ef4d8b3ba68414800f4ac965f4809f087213cfada
  title: Competition Dynamics Shape Algorithmic Phases of In-Context Learning
  title_normalized: competition_dynamics_shape_algorithmic_phases_of_incontext_learning

================================================================================
Document #236 (ID: 70215d957a3dfe0084d06a17f29ad50685e634ba7a78a3e3f6b490d369512594)
================================================================================
  abstract: Jailbreak attacks serve as essential red-teaming tools, proactively assessing whether LLMs can behave responsibly and safely in adversarial environments. Despite diverse strategies (e.g., cipher, low-resource language, persuasions, and so on) that have been proposed and shown success, these strategies are still manually designed, limiting their scope and effectiveness as a red-teaming tool. In this paper, we propose AutoDAN-Turbo, a black-box jailbreak method that can automatically discover as many jailbreak strategies as possible from scratch, without any human intervention or predefined scopes (e.g., specified candidate strategies), and use them for red-teaming. As a result, AutoDAN-Turbo can significantly outperform baseline methods, achieving a 74.3% higher average attack success rate on public benchmarks. Notably, AutoDAN-Turbo achieves an 88.5 attack success rate on GPT-4-1106-turbo. In addition, AutoDAN-Turbo is a unified framework that can incorporate existing human-designed jailbreak strategies in a plug-and-play manner. By integrating human-designed strategies, AutoDAN-Turbo can even achieve a higher attack success rate of 93.4 on GPT-4-1106-turbo.
  abstract_embedding: [0.28125, 0.23046875, 0.326171875]... (1536 items)
  authors: ['Xiaogeng Liu', 'Peiran Li', 'G. Edward Suh']... (10 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805301872
  novelty: yes
  reason: Relevance: The paper proposes a novel method, AutoDAN-Turbo, for automatically discovering jailbreak strategies to assess the safety and robustness of large language models. | Novelty: The paper intro...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: AutoDAN-Turbo__A_Lifelong_Agent_for_Strategy_Self-Exploration_to_Jailbreak_LLMs.pdf
  sha_abstract: 7ab7f3089e22ebce08192483df2f958a8130d6d08fefb3dedd914c385b1bac3f
  title: AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs
  title_normalized: autodanturbo_a_lifelong_agent_for_strategy_selfexploration_to_jailbreak_llms

================================================================================
Document #237 (ID: 9fb5bcb7f6e697f675425e5c3bbdcd17955a8be4bc42b84a6811d9659160c188)
================================================================================
  abstract: Diffusion models have achieved great success in generating high-dimensional samples across various applications. While the theoretical guarantees for continuous-state diffusion models have been extensively studied, the convergence analysis of the discrete-state counterparts remains under-explored. In this paper, we study the theoretical aspects of score-based discrete diffusion models under the Continuous Time Markov Chain (CTMC) framework. We introduce a discrete-time sampling algorithm in the general state space $[S]^d$ that utilizes score estimators at predefined time points. We derive convergence bounds for the Kullback-Leibler (KL) divergence and total variation (TV) distance between the generated sample distribution and the data distribution, considering both scenarios with and without early stopping under reasonable assumptions. Notably, our KL divergence bounds are nearly linear in the dimension $d$, aligning with state-of-the-art results for diffusion models. Our convergence analysis employs a Girsanov-based method and establishes key properties of the discrete score function, which are essential for characterizing the discrete-time sampling process.
  abstract_embedding: [0.5, 0.53515625, 0.25390625]... (1536 items)
  authors: ['Zikun Zhang', 'Zixiang Chen', 'Quanquan Gu']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805290810
  novelty: yes
  reason: Relevance: The paper proposes a new discrete-time sampling algorithm for score-based diffusion models, which is a novel model architecture with potential efficiency improvements. | Novelty: The paper ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Convergence_of_Score-Based_Discrete_Diffusion_Models__A_Discrete-Time_Analysis.pdf
  sha_abstract: f70ec12c35a76a20f14fc445be1ff5527602e424c01ef1a7db22730b99960cbe
  title: Convergence of Score-Based Discrete Diffusion Models: A Discrete-Time Analysis
  title_normalized: convergence_of_scorebased_discrete_diffusion_models_a_discretetime_analysis

================================================================================
Document #238 (ID: 33a068eeef54d3ece7dd0024d6a5bb960c2454def5279a1057db90b16fe3774d)
================================================================================
  abstract: Researchers are investing substantial effort in developing powerful general-purpose agents, wherein Foundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection, Toolformer). However, the history of machine learning teaches us that hand-designed solutions are eventually replaced by learned solutions. We describe a newly forming research area, Automated Design of Agentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including inventing novel building blocks and/or combining them in new ways. We further demonstrate that there is an unexplored yet promising approach within ADAS where agents can be defined in code and new agents can be automatically discovered by a meta agent programming ever better ones in code. Given that programming languages are Turing Complete, this approach theoretically enables the learning of any possible agentic system: including novel prompts, tool use, workflows, and combinations thereof. We present a simple yet effective algorithm named Meta Agent Search to demonstrate this idea, where a meta agent iteratively programs interesting new agents based on an ever-growing archive of previous discoveries. Through extensive experiments across multiple domains including coding, science, and math, we show that our algorithm can progressively invent agents with novel designs that greatly outperform state-of-the-art hand-designed agents. Importantly, we consistently observe the surprising result that agents invented by Meta Agent Search maintain superior performance even when transferred across domains and models, demonstrating their robustness and generality. Provided we develop it safely, our work illustrates the potential of an exciting new research direction toward automatically designing ever-more powerful agentic systems to benefit humanity.
  abstract_embedding: [0.703125, 0.294921875, 0.1923828125]... (1536 items)
  authors: ['Shengran Hu', 'Cong Lu', 'Jeff Clune']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805325776
  novelty: yes
  reason: Relevance: The paper proposes a novel approach to automatically designing agentic systems, which involves a meta agent programming new agents in code. This is an innovative model architecture and trai...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Automated_Design_of_Agentic_Systems.pdf
  sha_abstract: 1e46b598b32f30a1269372110dfd4223befcd2ec55e690b12c2173ebed731504
  title: Automated Design of Agentic Systems
  title_normalized: automated_design_of_agentic_systems

================================================================================
Document #239 (ID: 849cfe1358d8f74caeaa7965fc20bab03a9e91df61514e925e7a4c702e180cec)
================================================================================
  abstract: Recently, the study of heavy-tailed noises in first-order nonconvex stochastic optimization has gotten a lot of attention since it was recognized as a more realistic condition as suggested by many empirical observations. Specifically, the stochastic noise (the difference between the stochastic and true gradient) is considered to have only a finite $\mathfrak{p}$-th moment where $\mathfrak{p}\in\left(1,2\right]$ instead of assuming it always satisfies the classical finite variance assumption. To deal with this more challenging setting, people have proposed different algorithms and proved them to converge at an optimal $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{3\mathfrak{p}-2}})$ rate for smooth objectives after $T$ iterations. Notably, all these new-designed algorithms are based on the same technique – gradient clipping. Naturally, one may want to know whether the clipping method is a necessary ingredient and the only way to guarantee convergence under heavy-tailed noises. In this work, by revisiting the existing Batched Normalized Stochastic Gradient Descent with Momentum (Batched NSGDM) algorithm, we provide the first convergence result under heavy-tailed noises but without gradient clipping. Concretely, we prove that Batched NSGDM can achieve the optimal $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{3\mathfrak{p}-2}})$ rate even under the relaxed smooth condition. More interestingly, we also establish the first $\mathcal{O}(T^{\frac{1-\mathfrak{p}}{2\mathfrak{p}}})$ convergence rate in the case where the tail index $\mathfrak{p}$ is unknown in advance, which is arguably the common scenario in practice.
  abstract_embedding: [0.302734375, 0.26171875, 0.203125]... (1536 items)
  authors: ['Zijian Liu', 'Zhengyuan Zhou']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805332700
  novelty: yes
  reason: Relevance: The paper proposes a new optimization algorithm, Batched NSGDM, that achieves optimal convergence rates under heavy-tailed noise without gradient clipping, which is a novel technique. | Nov...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Nonconvex_Stochastic_Optimization_under_Heavy-Tailed_Noises__Optimal_Convergence_without_Gradient_Clipping.pdf
  sha_abstract: ef8781698909539c5f457d98666ea16eaffd8d7ba8f0993016ee1423589ace66
  title: Nonconvex Stochastic Optimization under Heavy-Tailed Noises: Optimal Convergence without Gradient Clipping
  title_normalized: nonconvex_stochastic_optimization_under_heavytailed_noises_optimal_convergence_without_gradient_clipping

================================================================================
Document #240 (ID: 08879129b11496ae1aa5cd3ead1bdb3aa4d8b2063f249be4c39dc3452d3fa5ac)
================================================================================
  abstract: The Mixture of Experts (MoE) architecture has emerged as a promising solution to reduce computational overhead by selectively activating subsets of model parameters.
The effectiveness of MoE models depends primarily on their routing mechanisms, with the widely adopted Top-K routing scheme used for activating experts.
However, the Top-K scheme has notable limitations,
including unnecessary activations and underutilization of experts.
In this work, 
rather than modifying the routing mechanism as done in previous studies,
we propose the Ternary Choice MoE (TC-MoE),
a novel approach that expands the expert space by applying the ternary set {-1, 0, 1} to each expert.
This expansion allows more efficient and effective expert activations without incurring significant computational costs.
Additionally, 
given the unique characteristics of the expanded expert space,
we introduce a new load balance loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency.
Extensive experiments demonstrate that TC-MoE achieves an average improvement of over 1.1% compared with traditional approaches,
while reducing the average number of activated experts by up to 9%.
These results confirm that TC-MoE effectively addresses the inefficiencies of conventional routing schemes,
offering a more efficient and scalable solution for MoE-based large language models.
Code and models are available at https://github.com/stiger1000/TC-MoE.
  abstract_embedding: [0.1748046875, 0.279296875, 0.296875]... (1536 items)
  authors: ['Shen Yan', 'Xingyan Bin', 'Sijun Zhang']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805320862
  novelty: yes
  reason: Relevance: The paper proposes a novel Mixture of Experts (MoE) architecture called TC-MoE that expands the expert space and introduces new loss functions to improve efficiency and effectiveness. | Nov...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: TC-MoE__Augmenting_Mixture_of_Experts_with_Ternary_Expert_Choice.pdf
  sha_abstract: d32dbbcc50ddf04339c857e4e8da7fd11a98f664f1005d0ccf3cc26e450e25bf
  title: TC-MoE: Augmenting Mixture of Experts with Ternary Expert Choice
  title_normalized: tcmoe_augmenting_mixture_of_experts_with_ternary_expert_choice

================================================================================
Document #241 (ID: 5d9dc8e050a6d9a0fb4028f0b5702e7862ccbcbf7c8d8beda0da40736966c199)
================================================================================
  abstract: We consider the problem of model multiplicity in downstream decision-making, a setting where two predictive models of equivalent accuracy cannot agree on what action to take for a downstream decision-making problem. Prior work attempts to address model multiplicity by resolving prediction disagreement between models. However, we show that even when the two predictive models approximately agree on their individual predictions almost everywhere, these models can lead the downstream decision-maker to take actions with substantially higher losses. We address this issue by proposing a framework that calibrates the predictive models with respect to both a finite set of downstream decision-making problems and the individual probability prediction. Specifically, leveraging tools from multi-calibration, we provide an algorithm that, at each time-step, first reconciles the differences in individual probability prediction, then calibrates the updated models such that they are indistinguishable from the true probability distribution to the decision-makers. We extend our results to the setting where one does not have direct access to the true probability distribution and instead relies on a set of i.i.d data to be the empirical distribution. Furthermore, we generalize our results to the settings where one has more than two predictive models and an infinitely large downstream action set. Finally, we provide a set of experiments to evaluate our methods empirically. Compared to existing work, our proposed algorithm creates a pair of predictive models with improved downstream decision-making losses and agrees on their best-response actions almost everywhere.
  abstract_embedding: [0.6171875, -0.01055908203125, 0.345703125]... (1536 items)
  authors: ['Ally Yalei Du', 'Dung Daniel Ngo', 'Steven Wu']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805312273
  novelty: yes
  reason: Relevance: The paper proposes a novel framework for reconciling model multiplicity in downstream decision-making, which is a relevant problem for ML applications. | Novelty: The proposed framework for...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Reconciling_Model_Multiplicity_for_Downstream_Decision_Making.pdf
  sha_abstract: f70b39a57ef8b790340754ffd4b6ef30b42a110e88ee111475283d58b0467653
  title: Reconciling Model Multiplicity for Downstream Decision Making
  title_normalized: reconciling_model_multiplicity_for_downstream_decision_making

================================================================================
Document #242 (ID: faba204626cab2cabc2b7d8d4cd40335cd90a57ab47ca4bb0f8e3a54973bd800)
================================================================================
  abstract: Connectionist Temporal Classification (CTC) is a widely used method for automatic speech recognition (ASR), renowned for its simplicity and computational efficiency. However, it often falls short in recognition performance.  In this work, we propose the Consistency-Regularized CTC (CR-CTC), which enforces consistency between two CTC distributions obtained from different augmented views of the input speech mel-spectrogram. We provide in-depth insights into its essential behaviors from three perspectives: 1) it conducts self-distillation between random pairs of sub-models that process different augmented views; 2) it learns contextual representation through masked prediction for positions within time-masked regions, especially when we increase the amount of time masking; 3) it suppresses the extremely peaky CTC distributions, thereby reducing overfitting and improving the generalization ability. Extensive experiments on LibriSpeech, Aishell-1, and GigaSpeech datasets demonstrate the effectiveness of our CR-CTC. It significantly improves the CTC performance, achieving state-of-the-art results comparable to those attained by transducer or systems combining CTC and attention-based encoder-decoder (CTC/AED). We release our code at \url{https://github.com/k2-fsa/icefall}.
  abstract_embedding: [0.263671875, 0.423828125, 0.57421875]... (1536 items)
  authors: ['Zengwei Yao', 'Wei Kang', 'Xiaoyu Yang']... (10 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805141482
  novelty: yes
  reason: Relevance: The paper proposes a novel consistency regularization technique for CTC-based speech recognition, which improves the model's performance and generalization. | Novelty: The consistency regul...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CR-CTC__Consistency_regularization_on_CTC_for_improved_speech_recognition.pdf
  sha_abstract: 3ee7e607019fa5a6ebde8adfb64c2ccbbb01554d8482f6eda77f55a20f97a9c5
  title: CR-CTC: Consistency regularization on CTC for improved speech recognition
  title_normalized: crctc_consistency_regularization_on_ctc_for_improved_speech_recognition

================================================================================
Document #243 (ID: d0cdcac281c874ff746b53d21961326c0d8d756f8ef457f1741fc7481002712f)
================================================================================
  abstract: Crowd counting and localization involve extracting the number and distribution of crowds from images or videos using computer vision techniques. Most counting methods are based on density regression and are based on an ``intersection'' hypothesis, *i.e.*, one pixel is influenced by multiple points in the ground truth, which is inconsistent with reality since one pixel would not contain two objects. This paper proposes Proximal Mapping Loss (PML), a density regression method that eliminates this hypothesis. {PML} divides the predicted density map into multiple point-neighbor cases through the nearest neighbor, and then dynamically constructs a learning target for each sub-case via proximal mapping, leading to more robust and accurate training. {Furthermore}, PML is theoretically linked to various existing loss functions, such as Gaussian-blurred L2 loss, Bayesian loss, and the training schemes in P2PNet and DMC, demonstrating its versatility and adaptability. Experimentally, PML significantly improves the performance of crowd counting and localization, and illustrates the robustness against annotation noise. The code is available at [https://github.com/Elin24/pml](https://github.com/Elin24/pml).
  abstract_embedding: [-0.326171875, 0.2578125, 0.35546875]... (1536 items)
  authors: ['Wei Lin', 'Jia Wan', 'Antoni B. Chan']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805143881
  novelty: yes
  reason: Relevance: The paper proposes a novel loss function, Proximal Mapping Loss, for crowd counting and localization, which addresses the inconsistency in the 'intersection' hypothesis of existing density ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Proximal_Mapping_Loss__Understanding_Loss_Functions_in_Crowd_Counting___Localization.pdf
  sha_abstract: 0864c730631025a088c232150950a6c1170cb7fc76fcb4d37ee8de69a7349cb9
  title: Proximal Mapping Loss: Understanding Loss Functions in Crowd Counting & Localization
  title_normalized: proximal_mapping_loss_understanding_loss_functions_in_crowd_counting__localization

================================================================================
Document #244 (ID: 9056dd11cc645883aec30a0aff23089e65128ceef0ee7e444428b0382c0dd27b)
================================================================================
  abstract: Scene image editing is crucial for entertainment, photography, and advertising design. Existing methods solely focus on either 2D individual object or 3D global scene editing. This results in a lack of a unified approach to effectively control and manipulate scenes at the 3D level with different levels of granularity. In this work, we propose 3DitScene, a novel and unified scene editing framework leveraging language-guided disentangled Gaussian Splatting that enables seamless editing from 2D to 3D, allowing precise control over scene composition and individual objects. We first incorporate 3D Gaussians that are refined through generative priors and optimization techniques. Language features from CLIP then introduce semantics into 3D geometry for object disentanglement. With the disentangled Gaussians, 3DitScene allows for manipulation at both the global and individual levels, revolutionizing creative expression and empowering control over scenes and objects. Experimental results demonstrate the effectiveness and versatility of 3DitScene in scene image editing.
  abstract_embedding: [0.431640625, 0.1396484375, -0.138671875]... (1536 items)
  authors: ['Qihang Zhang', 'Yinghao Xu', 'Chaoyang Wang']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805139445
  novelty: yes
  reason: Relevance: The paper proposes a novel scene editing framework that leverages language-guided disentangled Gaussian Splatting, enabling seamless editing from 2D to 3D with precise control over scene co...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: 3DitScene__Editing_Any_Scene_via_Language-guided_Disentangled_Gaussian_Splatting.pdf
  sha_abstract: 134685b4b3e7dbda50fd264b128d48d3868a6b45a8334f056f968a1a32d1ad2b
  title: 3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting
  title_normalized: 3ditscene_editing_any_scene_via_languageguided_disentangled_gaussian_splatting

================================================================================
Document #245 (ID: 04c31696fbe23627d0b4c5974167123ddbfba639e31ade31db0f558a3ed1a660)
================================================================================
  abstract: Risk-sensitive reinforcement learning (RL) with an entropic risk measure typically requires knowledge of the transition kernel or performs unstable updates w.r.t. exponential Bellman equations. As a consequence, algorithms that optimize this objective have been restricted to tabular or low-dimensional continuous environments. In this work we leverage the connection between the entropic risk measure and the RL-as-inference framework to develop a risk-sensitive variational actor-critic algorithm (rsVAC). Our work extends the variational framework to incorporate stochastic rewards and proposes a variational model-based actor-critic approach that modulates policy risk via a risk parameter.  We consider, both, the risk-seeking and risk-averse regimes and present rsVAC learning variants for each setting.  Our experiments demonstrate that this approach produces risk-sensitive policies and yields improvements in both tabular and risk-aware variants of complex continuous control tasks in MuJoCo.
  abstract_embedding: [0.6875, 0.10595703125, 0.0216064453125]... (1536 items)
  authors: ['Alonso Granados', 'Reza Ebrahimi', 'Jason Pacheco']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805154728
  novelty: yes
  reason: Relevance: The paper proposes a novel risk-sensitive variational actor-critic algorithm that can optimize for both risk-seeking and risk-averse policies, which is relevant for practical applications. ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Risk-Sensitive_Variational_Actor-Critic__A_Model-Based_Approach.pdf
  sha_abstract: 32d217e2b5dfa544021888351a3808f56b8bcce646100cc102d1c0b224ea335f
  title: Risk-Sensitive Variational Actor-Critic: A Model-Based Approach
  title_normalized: risksensitive_variational_actorcritic_a_modelbased_approach

================================================================================
Document #246 (ID: eb0ac11e6eef3a31bb88de72c72d2c7ae65088005415fc1021be5054514f7978)
================================================================================
  abstract: We present Agent S, an open agentic framework that enables autonomous interaction with computers through Graphical User Interface (GUI), aimed at transforming human-computer interaction by automating complex, multi-step tasks. Agent S addresses three key challenges in automating computer tasks: acquiring domain-specific knowledge, planning over long task horizons, and handling dynamic, non-uniform interfaces. To this end, Agent S introduces experience-augmented hierarchical planning, which learns from external knowledge search and internal experience retrieval at multiple levels, facilitating efficient task planning and subtask execution. 
In addition, it employs an Agent-Computer Interface (ACI) to better elicit the reasoning and control capabilities of GUI agents based on Multimodal Large Language Models (MLLMs). Evaluation on the OSWorld benchmark shows that Agent S outperforms the baseline by 9.37\% on success rate (an 83.6\% relative improvement) and achieves a new state-of-the-art. Comprehensive analysis highlights the effectiveness of individual components and provides insights for future improvements. Furthermore, Agent S demonstrates broad generalizability to different operating systems on a newly-released WindowsAgentArena benchmark. Code available at https://github.com/simular-ai/Agent-S.
  abstract_embedding: [1.046875, -0.0038299560546875, 0.36328125]... (1536 items)
  authors: ['Saaket Agashe', 'Jiuzhou Han', 'Shuyu Gan']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805160216
  novelty: yes
  reason: Relevance: The paper proposes a novel agentic framework, Agent S, that uses hierarchical planning and multimodal language models to automate complex, multi-step tasks on graphical user interfaces. | N...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Agent_S__An_Open_Agentic_Framework_that_Uses_Computers_Like_a_Human.pdf
  sha_abstract: 6bf7781bd80f2614345b8d796b28f95860da905174d9d41ab3975ff390b8194a
  title: Agent S: An Open Agentic Framework that Uses Computers Like a Human
  title_normalized: agent_s_an_open_agentic_framework_that_uses_computers_like_a_human

================================================================================
Document #247 (ID: 3a97bce64f18d626377c08bd36cc5e562b8b182b16550455703fe0828ccd11d5)
================================================================================
  abstract: Large language models (LLMs) can solve an increasing number of complex reasoning tasks while making surprising mistakes in basic numerical understanding and processing (such as $9.11 > 9.9$). The latter ability is essential for tackling complex arithmetic and mathematical problems and serves as a foundation for most reasoning tasks, but previous work paid little attention to it or only discussed several restricted tasks (like integer addition). In this paper, we comprehensively investigate the numerical understanding and processing ability (NUPA) of LLMs. Firstly, we introduce a benchmark covering four common numerical representations and 17 distinct numerical tasks in four major categories, resulting in 41 meaningful combinations in total. These tasks are derived from primary and secondary education curricula, encompassing nearly all everyday numerical understanding and processing scenarios, and the rules of these tasks are very simple and clear.
Through the benchmark, we find that current LLMs fail frequently in many of the tasks. To study the problem, we train small models with existing and potential techniques for enhancing NUPA (such as tokenizers, PEs, and number formats), comprehensively evaluating their effectiveness using our testbed. We also finetune practical-scale LLMs on our proposed NUPA tasks and find that 1) naive finetuning can improve NUPA a lot on many but not all tasks, and 2) surprisingly, techniques designed to enhance NUPA prove ineffective for finetuning pretrained models. We further explore the impact of chain-of-thought techniques on NUPA. Our work provides a more detailed and comprehensive understanding of NUPA in LLMs.
  abstract_embedding: [0.20703125, 0.062255859375, 0.212890625]... (1536 items)
  authors: ['Haotong Yang', 'Yi Hu', 'Shijia Kang']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805164493
  novelty: yes
  reason: Relevance: The paper proposes a comprehensive benchmark for evaluating the numerical understanding and processing ability (NUPA) of large language models, and explores techniques to enhance NUPA, whic...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Number_Cookbook__Number_Understanding_of_Language_Models_and_How_to_Improve_It.pdf
  sha_abstract: b9e4ca76fd7602c48b4e36f277cc0d07c939879f4fa018983059cad21dd4f05d
  title: Number Cookbook: Number Understanding of Language Models and How to Improve It
  title_normalized: number_cookbook_number_understanding_of_language_models_and_how_to_improve_it

================================================================================
Document #248 (ID: 6e1a346b65ab8cb0a3d4ec3f365b68fc65e10eba7f5973422b5bd18afa24dc3c)
================================================================================
  abstract: Self-supervised learning has the potential of lifting several of the key challenges in reinforcement learning today, such as exploration, representation learning, and reward design. Recent work (METRA) has effectively argued that moving away from mutual information and instead optimizing a certain Wasserstein distance is important for good performance. In this paper, we argue that the benefits seen in that paper can largely be explained within the existing framework of mutual information skill learning (MISL).
Our analysis suggests a new MISL method (contrastive successor features) that retains the excellent performance of METRA with fewer moving parts, and highlights connections between skill learning, contrastive representation learning, and successor features. Finally, through careful ablation studies, we provide further insight into some of the key ingredients for both our method and METRA.
  abstract_embedding: [0.291015625, -0.11669921875, -0.055419921875]... (1536 items)
  authors: ['Chongyi Zheng', 'Jens Tuyls', 'Joanne Peng']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805124742
  novelty: yes
  reason: Relevance: The paper proposes a new mutual information skill learning (MISL) method called contrastive successor features, which is an innovative training algorithm for reinforcement learning. | Novel...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Can_a_MISL_Fly__Analysis_and_Ingredients_for_Mutual_Information_Skill_Learning.pdf
  sha_abstract: b2a861b1f2ced633a2e227ab80d96df133177dc809f8b88ee69729fdc2d8e2cb
  title: Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning
  title_normalized: can_a_misl_fly_analysis_and_ingredients_for_mutual_information_skill_learning

================================================================================
Document #249 (ID: 20926a9034bf267aa8d8b22c23136c60872cb01ab741642fdb08a4d59eabb8e4)
================================================================================
  abstract: The development of large language models (LLMs) has significantly advanced the emergence of large multimodal models (LMMs). While LMMs have achieved tremendous success by promoting the synergy between multimodal comprehension and creation, they often face challenges when confronted with out-of-distribution data, such as which can hardly distinguish orientation, quantity, color, structure, etc. This is primarily due to their reliance on image encoders trained to encode images into task-relevant features, which may lead them to disregard irrelevant details. Delving into the modeling capabilities of diffusion models for images naturally prompts the question: Can diffusion models serve as the eyes of large language models for image perception? In this paper, we propose DEEM, a simple but effective approach that utilizes the generative feedback of diffusion models to align the semantic distributions of the image encoder. This addresses the drawbacks of previous methods that solely relied on image encoders like CLIP-ViT, thereby enhancing the model's resilience against out-of-distribution samples and reducing visual hallucinations. Importantly, this is achieved without requiring additional training modules and with fewer training parameters. We extensively evaluated DEEM on both our newly constructed RobustVQA benchmark and other well-known benchmarks, POPE and MMVP, for visual hallucination and perception. In particular, DEEM improves LMM's  visual perception performance to a large extent (e.g., 4\% ↑ on RobustVQA, 6.5\% ↑ on MMVP and 12.8 \% ↑ on POPE ). Compared to the state-of-the-art interleaved content generation models, DEEM  exhibits enhanced robustness and a superior capacity to alleviate model hallucinations while utilizing fewer trainable parameters, less pre-training data (10\%), and a smaller base model size. Extensive experiments demonstrate that DEEM enhances the performance of LMMs on various downstream tasks without inferior performance in the long term, including visual question answering, image captioning, and text-conditioned image synthesis.
  abstract_embedding: [0.177734375, 0.34765625, 0.224609375]... (1536 items)
  authors: ['Run Luo', 'Yunshui Li', 'Longze Chen']... (13 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805156925
  novelty: yes
  reason: Relevance: The paper proposes a novel approach (DEEM) that utilizes diffusion models to enhance the image perception capabilities of large language models, which is directly relevant to innovative mod...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: DEEM__Diffusion_models_serve_as_the_eyes_of_large_language_models_for_image_perception.pdf
  sha_abstract: e6545ed08a6d68c7948838535077df1bc046ed90ce9c75652645f7e982a1abbe
  title: DEEM: Diffusion models serve as the eyes of large language models for image perception
  title_normalized: deem_diffusion_models_serve_as_the_eyes_of_large_language_models_for_image_perception

================================================================================
Document #250 (ID: d239472f0f285517cbd032a1993a6aa9190ee13d1c3a204ab75ff104926970b8)
================================================================================
  abstract: Self-supervision has the potential to transform reinforcement learning (RL), paralleling the breakthroughs it has enabled in other areas of machine learning. While self-supervised learning in other domains aims to find patterns in a fixed dataset, self-supervised goal-conditioned reinforcement learning (GCRL) agents discover *new* behaviors by learning from the goals achieved during unstructured interaction with the environment. However, these methods have failed to see similar success, both due to a lack of data from slow environment simulations as well as a lack of stable algorithms. We take a step toward addressing both of these issues by releasing a high-performance codebase and benchmark (`JaxGCRL`) for self-supervised GCRL, enabling researchers to train agents for millions of environment steps in minutes on a single GPU. By utilizing GPU-accelerated replay buffers, environments, and a stable contrastive RL algorithm, we reduce training time by up to $22\times$. Additionally, we assess key design choices in contrastive RL, identifying those that most effectively stabilize and enhance training performance. With this approach, we provide a foundation for future research in self-supervised GCRL, enabling researchers to quickly iterate on new ideas and evaluate them in diverse and challenging environments. Code: [https://anonymous.4open.science/r/JaxGCRL-2316/README.md](https://anonymous.4open.science/r/JaxGCRL-2316/README.md)
  abstract_embedding: [0.67578125, 0.32421875, 0.033203125]... (1536 items)
  authors: ['Michał Bortkiewicz', 'Władysław Pałucki', 'Vivek Myers']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805152316
  novelty: yes
  reason: Relevance: The paper proposes a new codebase and benchmark for self-supervised goal-conditioned reinforcement learning, which is an innovative approach to improving the efficiency and stability of RL ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Accelerating_Goal-Conditioned_Reinforcement_Learning_Algorithms_and_Research.pdf
  sha_abstract: 66c57f2f9b4dcd87217625cf8a924b87b9a23c2a74a334d4f701f085b431c22b
  title: Accelerating Goal-Conditioned Reinforcement Learning Algorithms and Research
  title_normalized: accelerating_goalconditioned_reinforcement_learning_algorithms_and_research

================================================================================
Document #251 (ID: c9b7ebf4475e926cdc717bd909962817f56a40af1b79f51d9d578d0030a2ab74)
================================================================================
  abstract: Electrocardiogram (ECG) is essential for the clinical diagnosis of arrhythmias and other heart diseases, but deep learning methods based on ECG often face limitations due to the need for high-quality annotations. Although previous ECG self-supervised learning (eSSL) methods have made significant progress in representation learning from unannotated ECG data, they typically treat ECG signals as ordinary time-series data, segmenting the signals using fixed-size and fixed-step time windows, which often ignore the form and rhythm characteristics and latent semantic relationships in ECG signals. In this work, we introduce a novel perspective on ECG signals, treating heartbeats as words and rhythms as sentences. Based on this perspective, we first designed the QRS-Tokenizer, which generates semantically meaningful ECG sentences from the raw ECG signals. Building on these, we then propose HeartLang, a novel self-supervised learning framework for ECG language processing, learning general representations at form and rhythm levels. Additionally, we construct the largest heartbeat-based ECG vocabulary to date, which will further advance the development of ECG language processing. We evaluated HeartLang across six public ECG datasets, where it demonstrated robust competitiveness against other eSSL methods. Our data and code are publicly available at https://github.com/PKUDigitalHealth/HeartLang.
  abstract_embedding: [-0.058349609375, 0.455078125, 0.380859375]... (1536 items)
  authors: ['Jiarui Jin', 'Haoyu Wang', 'Hongyan Li']... (6 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805146091
  novelty: yes
  reason: Relevance: The paper proposes a novel ECG language model that treats heartbeats as words and rhythms as sentences, which is an innovative approach to ECG representation learning. | Novelty: The propos...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Reading_Your_Heart__Learning_ECG_Words_and_Sentences_via_Pre-training_ECG_Language_Model.pdf
  sha_abstract: f528ca055a2db662893826494627b8054b7d8bab3086ddcf4d2f1ea5f51ad7b2
  title: Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG Language Model
  title_normalized: reading_your_heart_learning_ecg_words_and_sentences_via_pretraining_ecg_language_model

================================================================================
Document #252 (ID: e16ed180dcd0abc3b05ffe6a85f2bf8446f73baa071fa0074f4763ee57e2b8b4)
================================================================================
  abstract: Group Equivariant Convolution (GConv) empowers models to explore underlying symmetry in data, improving performance. However, real-world scenarios often deviate from ideal symmetric systems caused by physical permutation, characterized by non-trivial actions of a symmetry group, resulting in asymmetries that affect the outputs, a phenomenon known as Symmetry Breaking. Traditional GConv-based methods are constrained by rigid operational rules within group space, assuming data remains strictly symmetry after limited group transformations. This limitation makes it difficult to adapt to Symmetry-Breaking and non-rigid transformations. Motivated by this, we mainly focus on a common scenario: Rotational Symmetry-Breaking. By relaxing strict group transformations within Strict Rotation-Equivariant group $\mathbf{C}_n$, we redefine a Relaxed Rotation-Equivariant group $\mathbf{R}_n$ and introduce a novel Relaxed Rotation-Equivariant GConv (R2GConv) with only a minimal increase of $4n$ parameters compared to GConv. Based on R2GConv, we propose a Relaxed Rotation-Equivariant Network (R2Net) as the backbone and develop a Relaxed Rotation-Equivariant Object Detector (R2Det) for 2D object detection. Experimental results demonstrate the effectiveness of the proposed R2GConv in natural image classification, and R2Det achieves excellent performance in 2D object detection with improved generalization capabilities and robustness. The code is available in \texttt{https://github.com/wuer5/r2det}.
  abstract_embedding: [0.1103515625, 0.259765625, 0.59375]... (1536 items)
  authors: ['Zhiqiang Wu', 'Yingjie Liu', 'Hanlin Dong']... (8 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805149891
  novelty: yes
  reason: Relevance: The paper proposes a novel Relaxed Rotation-Equivariant GConv (R2GConv) and a Relaxed Rotation-Equivariant Network (R2Net) for 2D object detection, which are directly implementable ML techn...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: R2Det__Exploring_Relaxed_Rotation_Equivariance_in_2D_Object_Detection.pdf
  sha_abstract: e95063e02ae0f857caa299399762579fe93e232560a4c31830106ded18ca5467
  title: R2Det: Exploring Relaxed Rotation Equivariance in 2D Object Detection
  title_normalized: r2det_exploring_relaxed_rotation_equivariance_in_2d_object_detection

================================================================================
Document #253 (ID: fe90438ae33f85896b470fe53d724023fcb80be8204913d891f333023dd57a75)
================================================================================
  abstract: Knowledge editing techniques have emerged as essential tools for updating the factual knowledge of large language models (LLMs) and multimodal models (LMMs), allowing them to correct outdated or inaccurate information without retraining from scratch. However, existing benchmarks for multimodal knowledge editing primarily focus on entity-level knowledge represented as simple triplets, which fail to capture the complexity of real-world multimodal information. To address this issue, we introduce MMKE-Bench, a comprehensive **M**ulti**M**odal **K**nowledge **E**diting Benchmark, designed to evaluate the ability of LMMs to edit diverse visual knowledge in real-world scenarios. MMKE-Bench addresses these limitations by incorporating three types of editing tasks: visual entity editing, visual semantic editing, and user-specific editing.  Besides, MMKE-Bench uses free-form natural language to represent and edit knowledge, offering a more flexible and effective format. The benchmark consists of 2,940 pieces of knowledge and 8,363 images across 33 broad categories, with evaluation questions automatically generated and human-verified. We assess five state-of-the-art knowledge editing methods on three prominent LMMs, revealing that no method excels across all criteria, and that visual and user-specific edits are particularly challenging. MMKE-Bench sets a new standard for evaluating the robustness of multimodal knowledge editing techniques, driving progress in this rapidly evolving field.
  abstract_embedding: [0.294921875, 0.423828125, -0.115234375]... (1536 items)
  authors: ['Yuntao Du.', 'Kailin Jiang', 'Zhi Gao']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805179932
  novelty: yes
  reason: Relevance: The paper proposes a new benchmark for evaluating multimodal knowledge editing techniques, which is relevant for improving the robustness and capabilities of large language models and multi...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: MMKE-Bench__A_Multimodal_Editing_Benchmark_for_Diverse_Visual_Knowledge.pdf
  sha_abstract: 864098e6a70909d4e0da98c3fd65ca128b13f45dc9361db82dfdd322a6d68338
  title: MMKE-Bench: A Multimodal Editing Benchmark for Diverse Visual Knowledge
  title_normalized: mmkebench_a_multimodal_editing_benchmark_for_diverse_visual_knowledge

================================================================================
Document #254 (ID: b98fc11ed8848de435f1f30de5682849404eb9d7f1d6c2ae27d44a2ca1c6cd3e)
================================================================================
  abstract: Spiking Neural Networks (SNNs) offer a promising, biologically inspired approach for processing spatiotemporal data, particularly for time series forecasting.
However, conventional neuron models like the Leaky Integrate-and-Fire (LIF) struggle to capture long-term dependencies and effectively process multi-scale temporal dynamics.
To overcome these limitations, we introduce the Temporal Segment Leaky Integrate-and-Fire (TS-LIF) model, featuring a novel dual-compartment architecture.
The dendritic and somatic compartments specialize in capturing distinct frequency components, providing functional heterogeneity that enhances the neuron's ability to process both low- and high-frequency information.
Furthermore, the newly introduced direct somatic current injection reduces information loss during intra-neuronal transmission, while dendritic spike generation improves multi-scale information extraction.
We provide a theoretical stability analysis of the TS-LIF model and explain how each compartment contributes to distinct frequency response characteristics.
Experimental results show that TS-LIF outperforms traditional SNNs in time series forecasting, demonstrating better accuracy and robustness, even with missing data.
TS-LIF advances the application of SNNs in time-series forecasting, providing a biologically inspired approach that captures complex temporal dynamics and offers potential for practical implementation in diverse forecasting scenarios.
  abstract_embedding: [0.296875, 0.32421875, 0.080078125]... (1536 items)
  authors: ['FENG SHIBO', 'Wanjin Feng', 'Xingyu Gao']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805173105
  novelty: yes
  reason: Relevance: The paper proposes a novel spiking neuron model (TS-LIF) with a dual-compartment architecture to better capture long-term dependencies and multi-scale temporal dynamics in time series forec...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: TS-LIF__A_Temporal_Segment_Spiking_Neuron_Network_for_Time_Series_Forecasting.pdf
  sha_abstract: bc96303b6d09ac93c34aa11777f19beeb4aa96142d3fbb41501311650381f439
  title: TS-LIF: A Temporal Segment Spiking Neuron Network for Time Series Forecasting
  title_normalized: tslif_a_temporal_segment_spiking_neuron_network_for_time_series_forecasting

================================================================================
Document #255 (ID: c7342e1645ea92604c07a1ddcae59ae46eb24f0d410e55bef01a13c45f008a8f)
================================================================================
  abstract: Consistency distillation is a prevalent way for accelerating diffusion models adopted in consistency (trajectory) models, in which a student model is trained to traverse backward on the probability flow (PF) ordinary differential equation (ODE) trajectory determined by the teacher model. Preconditioning is a vital technique for stabilizing consistency distillation, by linear combining the input data and the network output with pre-defined coefficients as the consistency function. It imposes the boundary condition of consistency functions without restricting the form and expressiveness of the neural network. However, previous preconditionings are hand-crafted and may be suboptimal choices. In this work, we offer the first theoretical insights into the preconditioning in consistency distillation, by elucidating its design criteria and the connection to the teacher ODE trajectory. Based on these analyses, we further propose a principled way dubbed \textit{Analytic-Precond} to analytically optimize the preconditioning according to the consistency gap (defined as the gap between the teacher denoiser and the optimal student denoiser) on a generalized teacher ODE. We demonstrate that Analytic-Precond can facilitate the learning of trajectory jumpers, enhance the alignment of the student trajectory with the teacher's, and achieve $2\times$ to $3\times$ training acceleration of consistency trajectory models in multi-step generation across various datasets.
  abstract_embedding: [0.48828125, 0.40234375, 0.271484375]... (1536 items)
  authors: ['Kaiwen Zheng', 'Guande He', 'Jianfei Chen']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805178136
  novelty: yes
  reason: Relevance: The paper proposes a novel preconditioning technique for consistency distillation, which is a key technique for accelerating diffusion models. | Novelty: The paper presents a principled, an...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Elucidating_the_Preconditioning_in_Consistency_Distillation.pdf
  sha_abstract: 92ac9a9c96c0178e57c8869d44e27ffa094e424fa40fffc5b6a8a5555482ea3c
  title: Elucidating the Preconditioning in Consistency Distillation
  title_normalized: elucidating_the_preconditioning_in_consistency_distillation

================================================================================
Document #256 (ID: a35bfec65838ae3743adafe322e412cf2a4924c4607335d5f366b17cd0fc0474)
================================================================================
  abstract: Recent advancements in Large Vision-Language Models (LVLMs) have significantly expanded their utility in tasks like image captioning and visual question answering. However, they still struggle with object hallucination, where models generate descriptions that inaccurately reflect the visual content by including nonexistent objects or misrepresenting existing ones. While previous methods, such as data augmentation and training-free approaches, strive to tackle this issue, they still encounter scalability challenges and often depend on additional external modules. In this work, we propose Ensemble Decoding (ED), a novel strategy that splits the input image into sub-images and combines logit distributions by assigning weights through the attention map. Furthermore, we introduce ED adaptive plausibility constraint to calibrate logit distribution and FastED, a variant designed for speed-critical applications. Extensive experiments across hallucination benchmarks demonstrate that our proposed method achieves state-of-the-art performance, validating the effectiveness of our approach.
  abstract_embedding: [0.212890625, 0.08935546875, 0.390625]... (1536 items)
  authors: ['Yeongjae Cho', 'Keonwoo Kim', 'Taebaek Hwang']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805166240
  novelty: yes
  reason: Relevance: The paper proposes a novel ensemble decoding strategy and attention-guided techniques to mitigate multimodal hallucination, which is a relevant problem for large vision-language models. | N...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Do_You_Keep_an_Eye_on_What_I_Ask__Mitigating_Multimodal_Hallucination_via_Attention-Guided_Ensemble_Decoding.pdf
  sha_abstract: 15f4130bbf6f2a3c46850a23ebfe4a2b6e38315a7a54c662f0cb44518bae6fde
  title: Do You Keep an Eye on What I Ask? Mitigating Multimodal Hallucination via Attention-Guided Ensemble Decoding
  title_normalized: do_you_keep_an_eye_on_what_i_ask_mitigating_multimodal_hallucination_via_attentionguided_ensemble_decoding

================================================================================
Document #257 (ID: dba8b0cd6a14472da629f0baf38ee01ba799396d3de5e2f1e21c73598ff0a812)
================================================================================
  abstract: Leveraging billions of years of evolution, scientists have trained protein language models (pLMs) to understand the sequence and structure space of proteins aiding in the design of more functional proteins. Although they have shown ability to improve efficiency in engineering, it remains unclear under what conditions they will succeed or fail. We aim to predict the circumstances in which pLMs can successfully perform zero-shot fitness estimation. Our work demonstrates the trends observed over hundreds of deep mutational scans across multiple different fitness objectives. We find that the likelihood, or abstractly, implicit preference of a certain protein sequence imbued during pretraining is predictive fitness prediction capabilities. Both over-preferred and under-preferred wild type sequences harm performance. Generating a causal link between training data and likelihood, we show a power law tail over what data increases protein likelihood which is tied to training sequence homology. Lastly, proteins of low likelihood can be remedied by unsupervised finetuning. In sum, the zero-shot fitness estimation abilities of pLMs can be predicted by the likelihood of the engineered sequence, thus suggesting when pLMs should be deployed in protein maturation campaigns and a way to improve their performance under circumstances of low likelihood.
  abstract_embedding: [0.012939453125, 0.66796875, 0.007293701171875]... (1536 items)
  authors: ['Cade W Gordon', 'Amy X. Lu', 'Pieter Abbeel']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805182165
  novelty: yes
  reason: Relevance: The paper proposes a novel method for predicting the fitness of protein language models, which is relevant for improving the efficiency of protein engineering. | Novelty: The paper presents...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Protein_Language_Model_Fitness_is_a_Matter_of_Preference.pdf
  sha_abstract: fc4c5178a3c07c20d156b8697c1683d2f8601a671024ef16007c983f87af8773
  title: Protein Language Model Fitness is a Matter of Preference
  title_normalized: protein_language_model_fitness_is_a_matter_of_preference

================================================================================
Document #258 (ID: 194862b5d3ee40be75c75f1b40c6ae3e3cb8cdcc506ed47b992cf5d1a3eafc10)
================================================================================
  abstract: Sampling algorithms play an important role in controlling the quality and runtime of diffusion model inference. In recent years, a number of works (Chen et al., 2023c;b; Benton et al., 2023; Lee et al., 2022) have analyzed algorithms for diffusion sampling with provable guarantees; these works show that for essentially any data distribution, one can approximately sample in polynomial time given a sufficiently accurate estimate of its score functions at different noise levels. 

In this work, we propose a new scheme inspired by Shen and Lee's randomized midpoint method for log-concave sampling  (Shen & Lee, 2019). We prove that this approach achieves the best known dimension dependence for sampling from arbitrary smooth distributions in total variation distance ($\widetilde O(d^{5/12})$ compared to $\widetilde O(\sqrt{d})$ from prior work). We also show that our algorithm can be parallelized to run in only $\widetilde O(\log^2 d)$ parallel rounds, constituting the first provable guarantees for parallel sampling with diffusion models.
    
As a byproduct of our methods, for the well-studied problem of log-concave sampling in total variation distance, we give an algorithm and simple analysis achieving dimension dependence $\widetilde O(d^{5/12})$ compared to $\widetilde O(\sqrt{d})$ from prior work.
  abstract_embedding: [0.10546875, 0.51171875, 0.38671875]... (1536 items)
  authors: ['Shivam Gupta', 'Linda Cai', 'Sitan Chen']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805167785
  novelty: yes
  reason: Relevance: The paper proposes a new sampling algorithm for diffusion models, which is a key component of efficient diffusion model inference. | Novelty: The proposed algorithm achieves better dimensio...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Faster_Diffusion_Sampling_with_Randomized_Midpoints__Sequential_and_Parallel.pdf
  sha_abstract: 9b122cd657c9e89e19f50bef09c59f5b62735e5f59d424e18b17dabb8d577f1e
  title: Faster Diffusion Sampling with Randomized Midpoints: Sequential and Parallel
  title_normalized: faster_diffusion_sampling_with_randomized_midpoints_sequential_and_parallel

================================================================================
Document #259 (ID: 0467e96b12355cb2e37583a2cc44fad2675e0a24fa70561bf5d9a57bb80bd823)
================================================================================
  abstract: Diffusion and flow-matching models achieve remarkable generative performance but at the cost of many neural function evaluations (NFE), which slows inference and limits applicability to time-critical tasks. The ReFlow procedure can accelerate sampling by straightening generation trajectories. But it is an iterative procedure, typically requiring training on simulated data, and results in reduced sample quality. To mitigate sample deterioration, we examine the design space of ReFlow and highlight potential pitfalls in prior heuristic practices. We then propose seven improvements for training dynamics, learning and inference, which are verified with thorough ablation studies on CIFAR10 $32 \times 32$, AFHQv2 $64 \times 64$, and FFHQ $64 \times 64$. Combining all our techniques, we achieve state-of-the-art FID scores (without / with guidance, resp.) for fast generation via neural ODEs: $2.23$ / $1.98$ on CIFAR10, $2.30$ / $1.91$ on AFHQv2, $2.84$ / $2.67$ on FFHQ, and $3.49$ / $1.74$ on ImageNet-64, all with merely $9$ NFEs.
  abstract_embedding: [0.45703125, 0.1337890625, 0.2431640625]... (1536 items)
  authors: ['Beomsu Kim', 'Yu-Guan Hsieh', 'Michal Klein']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805169735
  novelty: yes
  reason: Relevance: The paper proposes several improvements to the ReFlow procedure, which is a technique for accelerating sampling in diffusion and flow-matching models, a key area of ML research. | Novelty: ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Simple_ReFlow__Improved_Techniques_for_Fast_Flow_Models.pdf
  sha_abstract: 6762a0c1dbd783e2fc3b3de46b9ce622daa4d5c635d4a0db8a5f04c6da7d608e
  title: Simple ReFlow: Improved Techniques for Fast Flow Models
  title_normalized: simple_reflow_improved_techniques_for_fast_flow_models

================================================================================
Document #260 (ID: 386384e642b8f1b88cda829e53ae148804a9436663998729c84bb53106e1091e)
================================================================================
  abstract: In the field of equivariant networks, achieving affine equivariance, particularly for general group representations, has long been a challenge.
In this paper, we propose the steerable EquivarLayer, a generalization of InvarLayer (Li et al., 2024), by building on the concept of equivariants beyond invariants.
The steerable EquivarLayer supports affine equivariance with arbitrary input and output representations, marking the first model to incorporate steerability into networks for the affine group.
To integrate it with canonicalization, a promising approach for making pre-trained models equivariant, we introduce a novel Det-Pooling module, expanding the applicability of EquivarLayer and the range of groups suitable for canonicalization.
We conduct experiments on image classification tasks involving group transformations to validate the steerable EquivarLayer in the role of a canonicalization function, demonstrating its effectiveness over data augmentation.
  abstract_embedding: [0.162109375, 0.169921875, 0.365234375]... (1536 items)
  authors: ['Yikang Li', 'Yeqing Qiu', 'Yuxuan Chen']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764805135708
  novelty: yes
  reason: Relevance: The paper proposes a novel steerable equivariant layer that supports affine equivariance, which is a significant advancement in the field of equivariant networks. | Novelty: The proposed st...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Affine_Steerable_Equivariant_Layer_for_Canonicalization_of_Neural_Networks.pdf
  sha_abstract: 15d91b02b33bcd5c155838d6780930a3599d966f38a973ea5011e4d83997f6bf
  title: Affine Steerable Equivariant Layer for Canonicalization of Neural Networks
  title_normalized: affine_steerable_equivariant_layer_for_canonicalization_of_neural_networks

================================================================================
Document #261 (ID: b5d31df8cb3e2fb4cfebf2ff70ee2f15df924e7371db8e7a81002fa0e9214ca8)
================================================================================
  abstract: Feedback data is widely used for fine-tuning and evaluating state-of-the-art AI models. Pairwise text preferences, where human or AI annotators select the “better” of two options, are particularly common. Such preferences are used to train (reward) models or to rank models with aggregate statistics. For many applications it is desirable to understand annotator preferences in addition to modelling them  – not least because extensive prior work has shown various unintended biases in preference datasets. Yet, preference datasets remain challenging to interpret. Neither black-box reward models nor statistics can answer why one text is preferred over another. Manual interpretation of the numerous (long) response pairs is usually equally infeasible. In this paper, we introduce the Inverse Constitutional AI (ICAI) problem, formulating the interpretation of pairwise text preference data as a compression task. In constitutional AI, a set of principles (a constitution) is used to provide feedback and fine-tune AI models. ICAI inverts this process: given a feedback dataset, we aim to extract a constitution that best enables a large language model (LLM) to reconstruct the original annotations. We propose a corresponding ICAI algorithm and validate its generated constitutions quantitatively based on annotation reconstruction accuracy on several datasets: (a) synthetic feedback data with known principles; (b) AlpacaEval cross-annotated human feedback data; (c) crowdsourced Chatbot Arena data; and (d) PRISM data from diverse demographic groups. As an example application, we further demonstrate the detection of biases in human feedback data. As a short and interpretable representation of the original dataset, generated constitutions have many potential use cases: they may help identify undesirable annotator biases, better understand model performance, scale feedback to unseen data, or assist with adapting AI models to individual user or group preferences. We release the source code for our algorithm and experiments at https://github.com/rdnfn/icai.
  abstract_embedding: [-0.01092529296875, 0.330078125, -0.11669921875]... (1536 items)
  authors: ['Arduin Findeis', 'Timo Kaufmann', 'Eyke Hüllermeier']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  executed_on_trn_updated_at: 2025-12-04T00:41:43.703870
  ingested_at: 1764804597481
  novelty: yes
  reason: Relevance: The paper proposes a novel method called Inverse Constitutional AI (ICAI) that aims to extract a set of principles (a constitution) from pairwise text preference data, which can be used to ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Inverse_Constitutional_AI__Compressing_Preferences_into_Principles.pdf
  sha_abstract: 25a816fd95f6c5a39f7fabdbec1f2aa6234d2f164a4bb794c354c6baf254d857
  slack_thread_ts: 1764808437.158339
  title: Inverse Constitutional AI: Compressing Preferences into Principles
  title_normalized: inverse_constitutional_ai_compressing_preferences_into_principles

================================================================================
Document #262 (ID: 4778d0ada460a0d8b43c999e139be079a99a1839e6d241f645dd4680c1b95294)
================================================================================
  abstract: This paper proposes the Degradation Classification Pre-Training (DCPT), which enables models to learn how to classify the degradation type of input images for universal image restoration pre-training. Unlike the existing self-supervised pre-training methods, DCPT utilizes the degradation type of the input image as an extremely weak supervision, which can be effortlessly obtained, even intrinsic in all image restoration datasets. DCPT comprises two primary stages. Initially, image features are extracted from the encoder. Subsequently, a lightweight decoder, such as ResNet18, is leveraged to classify the degradation type of the input image solely based on the features extracted in the first stage, without utilizing the input image. The encoder is pre-trained with a straightforward yet potent DCPT, which is used to address universal image restoration and achieve outstanding performance. Following DCPT, both convolutional neural networks (CNNs) and transformers demonstrate performance improvements, with gains of up to 2.55 dB in the 10D all-in-one restoration task and 6.53 dB in the mixed degradation scenarios. Moreover, previous self-supervised pretraining methods, such as masked image modeling, discard the decoder after pre-training, while our DCPT utilizes the pre-trained parameters more effectively. This superiority arises from the degradation classifier acquired during DCPT, which facilitates transfer learning between models of identical architecture trained on diverse degradation types. Source code and models are available at \url{https://github.com/MILab-PKU/dcpt}.
  abstract_embedding: [-0.07373046875, 0.0306396484375, -0.08349609375]... (1536 items)
  authors: ['JiaKui Hu', 'Lujia Jin', 'Zhengjian Yao']... (4 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804612877
  novelty: yes
  reason: Relevance: The paper proposes a novel pre-training method called Degradation Classification Pre-Training (DCPT) that can improve the performance of both CNN and transformer-based image restoration mod...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Universal_Image_Restoration_Pre-training_via_Degradation_Classification.pdf
  sha_abstract: 0ffa4f4e1c77c9dfa3cd11b517bf448061d610b00c411635b5103a0d6b234c86
  slack_thread_ts: 1764808991.755929
  title: Universal Image Restoration Pre-training via Degradation Classification
  title_normalized: universal_image_restoration_pretraining_via_degradation_classification

================================================================================
Document #263 (ID: 399c1dd966a90db61f03df2ed685707c89bbbb8d820e1b36535b80fcec9c00d0)
================================================================================
  abstract: Measuring biodiversity is crucial for understanding ecosystem health. While prior works have developed machine learning models for taxonomic classification of photographic images and DNA separately, in this work, we introduce a multi-modal approach combining both, using CLIP-style contrastive learning to align images, barcode DNA, and text-based representations of taxonomic labels in a unified embedding space. This allows for accurate classification of both known and unknown insect species without task-specific fine-tuning, leveraging contrastive learning for the first time to fuse DNA and image data. Our method surpasses previous single-modality approaches in accuracy by over 8% on zero-shot learning tasks, showcasing its effectiveness in biodiversity studies.
  abstract_embedding: [0.34765625, 0.546875, 0.01068115234375]... (1536 items)
  authors: ['ZeMing Gong', 'Austin Wang', 'Xiaoliang Huo']... (7 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804619871
  novelty: yes
  reason: Relevance: The paper proposes a novel multi-modal approach that combines image and DNA data for accurate biodiversity classification, which is relevant for AWS Trainium in 2025. | Novelty: The paper i...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: CLIBD__Bridging_Vision_and_Genomics_for_Biodiversity_Monitoring_at_Scale.pdf
  sha_abstract: 827b9146e8be83e507ae171c4cd2e2da35db0e9c5385cb44164356e60965ea52
  slack_thread_ts: 1764809023.734919
  title: CLIBD: Bridging Vision and Genomics for Biodiversity Monitoring at Scale
  title_normalized: clibd_bridging_vision_and_genomics_for_biodiversity_monitoring_at_scale

================================================================================
Document #264 (ID: 0b496f4b0c8e8524c53a8b41d77d26550b019d5be9dc1f3adee4621c6816afd5)
================================================================================
  abstract: The video-conditioned policy takes prompt videos of the desired tasks as a condition and is regarded for its prospective generalizability. Despite its promise, training a video-conditioned policy is non-trivial due to the need for abundant demonstrations. In some tasks, the expert rollouts are merely available as videos, and costly and time-consuming efforts are required to annotate action labels. To address this, we explore training video-conditioned policy on a mixture of demonstrations and unlabeled expert videos to reduce reliance on extensive manual annotation. We introduce the Joint Embedding Predictive Transformer (JEPT) to learn a video-conditioned policy through sequence modeling. JEPT is designed to jointly learn visual transition prediction and inverse dynamics. The visual transition is captured from both demonstrations and expert videos, on the basis of which the inverse dynamics learned from demonstrations is generalizable to the tasks without action labels. Experiments on a series of simulated visual control tasks evaluate that JEPT can effectively leverage the mixture dataset to learn a generalizable policy. JEPT outperforms baselines in the tasks without action-labeled data and unseen tasks. We also experimentally reveal the potential of JEPT as a simple visual priors injection approach to enhance the video-conditioned policy.
  abstract_embedding: [0.2392578125, 0.3515625, 0.4609375]... (1536 items)
  authors: ['Hao Luo', 'Zongqing Lu']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804615443
  novelty: yes
  reason: Relevance: The paper proposes a novel Joint Embedding Predictive Transformer (JEPT) model that can learn a video-conditioned policy from a mixture of demonstrations and unlabeled expert videos, which ...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Learning_Video-Conditioned_Policy_on_Unlabelled_Data_with_Joint_Embedding_Predictive_Transformer.pdf
  sha_abstract: f1b0ca9e6d8f866b78a820e5cc52d865bbd83b95adbb7e31604e28eed89ac8a3
  slack_thread_ts: 1764809058.783759
  title: Learning Video-Conditioned Policy on Unlabelled Data with Joint Embedding Predictive Transformer
  title_normalized: learning_videoconditioned_policy_on_unlabelled_data_with_joint_embedding_predictive_transformer

================================================================================
Document #265 (ID: 5c4065371aa218edd77b5ec7f5379f447c916e5e11ba09d1c49e5fb86a53d968)
================================================================================
  abstract: Many works have developed no-regret algorithms for contextual bandits with function approximation, where the mean rewards over context-action pairs belong to a function class $\mathcal{F}$. Although there are many approaches to this problem, algorithms based on the principle of optimism, such as optimistic least squares have gained in importance. It can be shown the regret of this algorithm scales as $\widetilde{\mathcal{O}}\left(\sqrt{d_{\mathrm{eluder}}(\mathcal{F}) \log(\mathcal{F}) T }\right)$ where $d_{\mathrm{eluder}}(\mathcal{F})$ is a statistical measure of the complexity of the function class $\mathcal{F}$ known as eluder dimension.  Unfortunately, even if the variance of the measurement noise of the rewards at time $t$ equals $\sigma_t^2$ and these are close to zero, the optimistic least squares algorithm’s regret scales with $\sqrt{T}$. In this work we are the first to develop algorithms that satisfy regret bounds for contextual bandits with function approximation of the form $\widetilde{\mathcal{O}}\left( \sigma \sqrt{\log(\mathcal{F})d_{\mathrm{eluder}}(\mathcal{F}) T } + d_{\mathrm{eluder}}(\mathcal{F}) \cdot \log(|\mathcal{F}|)\right) $ when the variances are unknown and satisfy $\sigma_t^2 = \sigma$ for all $t$ and $\widetilde{\mathcal{O}}\left( d_{\mathrm{eluder}}(\mathcal{F})\sqrt{\log(\mathcal{F})\sum_{t=1}^T \sigma_t^2  } + d_{\mathrm{eluder}}(\mathcal{F}) \cdot \log(|\mathcal{F}|)\right) $  when the variances change every time-step. These bounds generalize existing techniques for deriving second order bounds in contextual linear problems.
  abstract_embedding: [0.06689453125, 0.33203125, 0.349609375]... (1536 items)
  authors: ['Aldo Pacchiano']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  ingested_at: 1764804610485
  novelty: yes
  reason: Relevance: The paper proposes new algorithms and regret bounds for contextual bandits with function approximation, which is a relevant problem for ML research and applications. | Novelty: The paper pr...
  relevance: yes
  s3_bucket: llm-research-papers
  s3_key: Second_Order_Bounds_for_Contextual_Bandits_with_Function_Approximation.pdf
  sha_abstract: c7c09ffa87238bf57b8f9d3eeb7283b305dcb7ea8abcf4172f93baf48ba83c41
  slack_thread_ts: 1764809131.308209
  title: Second Order Bounds for Contextual Bandits with Function Approximation
  title_normalized: second_order_bounds_for_contextual_bandits_with_function_approximation

================================================================================
Document #266 (ID: af6f244a9c6b4f35fe3e93966051c07639ff37bbb9222231dc0170a9fc93e1d7)
================================================================================
  abstract: Momentum based optimizers are central to a wide range of machine learning applications. These typically rely on an Exponential Moving Average (EMA) of gradients, which decays exponentially the present contribution of older gradients. This accounts for gradients being local linear approximations which lose their relevance as the iterate moves along the loss landscape. This work questions the use of a single EMA to accumulate past gradients and empirically demonstrates how this choice can be sub-optimal: a single EMA cannot simultaneously give a high weight to the immediate past, and a non-negligible weight to older gradients. Building on this observation, we propose AdEMAMix, a simple modification of the Adam optimizer with a mixture of two EMAs to better take advantage of past gradients. Our experiments on language modeling and image classification show---quite surprisingly---that gradients can stay relevant for tens of thousands of steps. They help to converge faster, and often to lower minima: e.g., a $1.3$B parameter AdEMAMix LLM trained on $101$B tokens performs comparably to an AdamW model trained on $197$B tokens ($+95\%$). Moreover, our method significantly slows-down model forgetting during training. Our work motivates further exploration of different types of functions to leverage past gradients, beyond EMAs.
  abstract_embedding: [1.1015625, 0.16796875, 0.134765625]... (1536 items)
  authors: ['Matteo Pagliardini', 'Pierre Ablin', 'David Grangier']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  execution_completed_at: 2025-12-04T00:46:31.366693
  execution_return_code: 1
  execution_success: False
  execution_time_seconds: 280.44
  ingested_at: 1764804605225
  novelty: yes
  reason: Relevance: The paper proposes a novel optimizer, AdEMAMix, which uses a mixture of two exponential moving averages to better leverage past gradients, leading to faster convergence and better performan...
  relevance: yes
  results_s3_location: s3://trainium-execution-results/results/af6f244a9c6b4f35fe3e93966051c07639ff37bbb9222231dc0170a9fc93e1d7/execution_result.json
  s3_bucket: llm-research-papers
  s3_key: The_AdEMAMix_Optimizer__Better__Faster__Older.pdf
  sha_abstract: 721eabf7ce68db7817d060b77be44e0509751c9f60cee971170ebcba5bcda532
  slack_thread_ts: 1764808437.266569
  title: The AdEMAMix Optimizer: Better, Faster, Older
  title_normalized: the_ademamix_optimizer_better_faster_older

================================================================================
Document #267 (ID: ba215ce230aa4c3f527a3fe70050ef4267c4beb5a26fd3236e320144e5271a13)
================================================================================
  abstract: Consistency models (CMs) offer faster sampling than traditional diffusion models, but their training is resource-intensive. For example, as of 2024, training a state-of-the-art CM on CIFAR-10 takes one week on 8 GPUs. In this work, we propose an effective scheme for training CMs that largely improves the efficiency of building such models. Specifically, by expressing CM trajectories via a particular differential equation, we argue that diffusion models can be viewed as a special case of CMs. We can thus fine-tune a consistency model starting from a pretrained diffusion model and progressively approximate the full consistency condition to stronger degrees over the training process. Our resulting method, which we term Easy Consistency Tuning (ECT), achieves vastly reduced training times while improving upon the quality of previous methods: for example, ECT achieves a 2-step FID of 2.73 on CIFAR10 within 1 hour on a single A100 GPU, matching Consistency Distillation trained for hundreds of GPU hours. Owing to this computational efficiency, we investigate the scaling laws of CMs under ECT, showing that they obey the classic power law scaling, hinting at their ability to improve efficiency and performance at larger scales. Our [code](https://github.com/locuslab/ect) is available.
  abstract_embedding: [0.466796875, 0.484375, 0.51171875]... (1536 items)
  authors: ['Zhengyang Geng', 'Ashwini Pokle', 'Weijian Luo']... (5 items)
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  execution_completed_at: 2025-12-04T00:46:31.431285
  execution_return_code: 1
  execution_success: False
  execution_time_seconds: 293.75
  ingested_at: 1764804607566
  novelty: yes
  reason: Relevance: The paper proposes a new training algorithm for consistency models, which are a type of innovative diffusion model architecture. The method aims to improve the efficiency of training these ...
  relevance: yes
  results_s3_location: s3://trainium-execution-results/results/ba215ce230aa4c3f527a3fe70050ef4267c4beb5a26fd3236e320144e5271a13/execution_result.json
  s3_bucket: llm-research-papers
  s3_key: Consistency_Models_Made_Easy.pdf
  sha_abstract: b978c9f23f73106902eda090ff5d0c4fcbb5debeed4bbbaee7fb1f176ae5fdef
  slack_thread_ts: 1764808437.419329
  title: Consistency Models Made Easy
  title_normalized: consistency_models_made_easy

================================================================================
Document #268 (ID: a9695efa2156e730300d18a2cd4e51d4e30fd37c565c8a62a3c7353c00d6dd2a)
================================================================================
  abstract: Machine unlearning is a critical area of research aimed at safeguarding data privacy by enabling the removal of sensitive information from machine learning models. One unique challenge in this field is catastrophic unlearning, where erasing specific data from a well-trained model unintentionally removes essential knowledge, causing the model to deviate significantly from a retrained one. To address this, we introduce a novel approach that regularizes the unlearning process by utilizing synthesized mixup samples, which simulate the data susceptible to catastrophic effects. At the core of our approach is a generator-unlearner framework, MixUnlearn, where a generator adversarially produces challenging mixup examples, and the unlearner effectively forgets target information based on these synthesized data. Specifically, we first introduce a novel contrastive objective to train the generator in an adversarial direction: generating examples that prompt the unlearner to reveal information that should be forgotten, while losing essential knowledge. Then the unlearner, guided by two other contrastive loss terms, processes the synthesized and real data jointly to ensure accurate unlearning without losing critical knowledge, overcoming catastrophic effects. Extensive evaluations across benchmark datasets demonstrate that our method significantly outperforms state-of-the-art approaches, offering a robust solution to machine unlearning. This work not only deepens understanding of unlearning mechanisms but also lays the foundation for effective machine unlearning with mixup augmentation.
  abstract_embedding: [0.59375, 0.435546875, -0.00180816650390625]... (1536 items)
  authors: ['Zhuoyi PENG', 'Yixuan Tang', 'Yi Yang']
  date: 2024-10-04
  decision: accept
  executed_on_trn: False
  execution_completed_at: 2025-12-04T00:46:46.317782
  execution_return_code: 1
  execution_success: False
  execution_time_seconds: 14.64
  ingested_at: 1764804617456
  novelty: yes
  reason: Relevance: The paper proposes a novel adversarial mixup unlearning framework that aims to address the challenge of catastrophic unlearning in machine learning models. | Novelty: The proposed MixUnlear...
  relevance: yes
  results_s3_location: s3://trainium-execution-results/results/a9695efa2156e730300d18a2cd4e51d4e30fd37c565c8a62a3c7353c00d6dd2a/execution_result.json
  s3_bucket: llm-research-papers
  s3_key: Adversarial_Mixup_Unlearning.pdf
  sha_abstract: 1b3a949996b7e8156fd9fa98bf390418e538058900fa63c891cfafd66ce49ab7
  slack_thread_ts: 1764808990.197139
  title: Adversarial Mixup Unlearning
  title_normalized: adversarial_mixup_unlearning
