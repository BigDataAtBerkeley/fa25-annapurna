"""
Efficient On-Device Machine Learning with a Biologically-Plausible Forward-Only Algorithm

Generated by AWS Bedrock Claude
Paper ID: 7uj63JkBP8oloYi_-CJp
Authors: Baichuan Huang, Amir Aminifar
Generated at: 2025-10-19T17:32:39.746524
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from typing import Tuple, Callable, List

class BioFOLayer(nn.Module):
    """
    Implementation of the Biologically-plausible Forward-Only (Bio-FO) layer.
    """
    def __init__(self, in_features: int, out_features: int):
        super().__init__()
        self.weight = nn.Parameter(torch.randn(out_features, in_features))
        self.bias = nn.Parameter(torch.randn(out_features))
        self.activation = nn.ReLU()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        out = torch.matmul(x, self.weight.T) + self.bias
        return self.activation(out)

class BioFOModel(nn.Module):
    """
    Implementation of the Biologically-plausible Forward-Only (Bio-FO) model.
    """
    def __init__(self, input_size: int, hidden_sizes: List[int], output_size: int):
        super().__init__()
        self.layers = nn.ModuleList([])
        layer_sizes = [input_size] + hidden_sizes + [output_size]
        for i in range(len(layer_sizes) - 1):
            self.layers.append(BioFOLayer(layer_sizes[i], layer_sizes[i+1]))

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        for layer in self.layers:
            x = layer(x)
        return x

def load_data(data_dir: str, batch_size: int) -> Tuple[DataLoader, DataLoader]:
    """
    Load and preprocess the data.
    """
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    train_data = datasets.ImageFolder(f"{data_dir}/train", transform=transform)
    test_data = datasets.ImageFolder(f"{data_dir}/test", transform=transform)

    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)

    return train_loader, test_loader

def train_model(model: nn.Module, train_loader: DataLoader, test_loader: DataLoader,
                num_epochs: int, learning_rate: float, device: str) -> Tuple[List[float], List[float]]:
    """
    Train the Bio-FO model and track training and test accuracy.
    """
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    model = model.to(device)

    train_acc_history = []
    test_acc_history = []

    for epoch in range(num_epochs):
        train_correct = 0
        train_total = 0
        for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}", leave=False):
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            _, predicted = torch.max(outputs.data, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()

        train_acc = train_correct / train_total
        train_acc_history.append(train_acc)

        test_correct = 0
        test_total = 0
        with torch.no_grad():
            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                test_total += labels.size(0)
                test_correct += (predicted == labels).sum().item()

        test_acc = test_correct / test_total
        test_acc_history.append(test_acc)

        print(f"Epoch {epoch+1}/{num_epochs}, Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}")

    return train_acc_history, test_acc_history

def visualize_results(train_acc_history: List[float], test_acc_history: List[float], num_epochs: int):
    """
    Visualize the training and test accuracy over epochs.
    """
    plt.figure(figsize=(10, 6))
    plt.plot(range(1, num_epochs+1), train_acc_history, label="Train Accuracy")
    plt.plot(range(1, num_epochs+1), test_acc_history, label="Test Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.title("Training and Test Accuracy")
    plt.legend()
    plt.show()

def main():
    # Config
    data_dir = "path/to/data"
    batch_size = 64
    num_epochs = 50
    learning_rate = 0.001
    input_size = 784  # For MNIST dataset
    hidden_sizes = [256, 128]
    output_size = 10  # For MNIST dataset
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # Load data
    train_loader, test_loader = load_data(data_dir, batch_size)

    # Create model
    model = BioFOModel(input_size, hidden_sizes, output_size)

    # Train model
    train_acc_history, test_acc_history = train_model(
        model, train_loader, test_loader, num_epochs, learning_rate, device
    )

    # Visualize results
    visualize_results(train_acc_history, test_acc_history, num_epochs)

if __name__ == "__main__":
    main()