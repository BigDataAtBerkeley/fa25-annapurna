"""
Scaling Deep Learning Training with MPMD Pipeline Parallelism

Generated by AWS Bedrock Claude
Paper ID: 6Oj63JkBP8oloYi_7CKj
Authors: Anxhelo Xhebraj, Sean Lee, Hanfeng Chen, Vinod Grover
Generated at: 2025-10-19T17:32:17.033995
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from typing import Tuple, Callable

# Data Loading and Preprocessing
def load_data(data_path: str, batch_size: int) -> Tuple[DataLoader, DataLoader]:
    """
    Load and preprocess the data for training and testing.

    Args:
        data_path (str): Path to the data directory.
        batch_size (int): Batch size for training and testing.

    Returns:
        Tuple[DataLoader, DataLoader]: Training and testing data loaders.
    """
    # Define transformations
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])

    # Load datasets
    train_dataset = datasets.MNIST(data_path, train=True, download=True, transform=transform)
    test_dataset = datasets.MNIST(data_path, train=False, download=True, transform=transform)

    # Create data loaders
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, test_loader

# Model Architecture
class PipelinedModel(nn.Module):
    """
    Pipelined deep learning model for MNIST classification.
    """
    def __init__(self, input_size: int, hidden_size: int, num_classes: int, num_stages: int):
        super(PipelinedModel, self).__init__()
        self.num_stages = num_stages
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.num_classes = num_classes

        # Define model stages
        self.stages = nn.ModuleList([
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, num_classes)
        ])

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pass of the pipelined model.

        Args:
            x (torch.Tensor): Input tensor.

        Returns:
            torch.Tensor: Output tensor.
        """
        for stage in self.stages:
            x = stage(x)
        return x

# Training Loop
def train(model: nn.Module,
          train_loader: DataLoader,
          test_loader: DataLoader,
          epochs: int,
          lr: float,
          device: torch.device) -> Tuple[list, list]:
    """
    Train the pipelined model and evaluate its performance.

    Args:
        model (nn.Module): PyTorch model to train.
        train_loader (DataLoader): Training data loader.
        test_loader (DataLoader): Testing data loader.
        epochs (int): Number of training epochs.
        lr (float): Learning rate for the optimizer.
        device (torch.device): Device to use for training (CPU or GPU).

    Returns:
        Tuple[list, list]: Lists of training and testing accuracies.
    """
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=lr)

    train_accs = []
    test_accs = []

    model.to(device)

    for epoch in range(epochs):
        train_loss = 0.0
        train_correct = 0
        test_correct = 0

        # Training loop
        model.train()
        for data, target in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}"):
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * data.size(0)
            train_correct += (output.max(1)[1] == target).sum().item()

        # Evaluation loop
        model.eval()
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)
                output = model(data)
                test_correct += (output.max(1)[1] == target).sum().item()

        train_acc = train_correct / len(train_loader.dataset)
        test_acc = test_correct / len(test_loader.dataset)
        train_accs.append(train_acc)
        test_accs.append(test_acc)

        print(f"Epoch {epoch+1}/{epochs}, Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}")

    return train_accs, test_accs

# Visualization
def plot_accuracies(train_accs: list, test_accs: list, epochs: int) -> None:
    """
    Plot the training and testing accuracies over epochs.

    Args:
        train_accs (list): List of training accuracies.
        test_accs (list): List of testing accuracies.
        epochs (int): Number of training epochs.
    """
    plt.figure(figsize=(8, 6))
    plt.plot(range(1, epochs+1), train_accs, label='Training Accuracy')
    plt.plot(range(1, epochs+1), test_accs, label='Testing Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Training and Testing Accuracies')
    plt.legend()
    plt.show()

# Example Usage
if __name__ == "__main__":
    # Load data
    data_path = "path/to/data"
    batch_size = 64
    train_loader, test_loader = load_data(data_path, batch_size)

    # Define model parameters
    input_size = 28 * 28
    hidden_size = 128
    num_classes = 10
    num_stages = 5

    # Initialize model
    model = PipelinedModel(input_size, hidden_size, num_classes, num_stages)

    # Train and evaluate the model
    epochs = 10
    lr = 0.01
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    train_accs, test_accs = train(model, train_loader, test_loader, epochs, lr, device)

    # Plot accuracies
    plot_accuracies(train_accs, test_accs, epochs)

# Load data
data_path = "path/to/data"
batch_size = 64
train_loader, test_loader = load_data(data_path, batch_size)

# Define model parameters
input_size = 28 * 28
hidden_size = 128
num_classes = 10
num_stages = 5

# Initialize model
model = PipelinedModel(input_size, hidden_size, num_classes, num_stages)

# Train and evaluate the model
epochs = 10
lr = 0.01
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
train_accs, test_accs = train(model, train_loader, test_loader, epochs, lr, device)

# Plot accuracies
plot_accuracies(train_accs, test_accs, epochs)